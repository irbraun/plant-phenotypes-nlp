{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notebook for how approaches to generating word embeddings and sentence embeddings with BERT pretrained models.\n",
    "# Token embeddings with BERT are generated based on context, so the embeddings are unique to the sentence in which\n",
    "# the word is occuring. These models should also be fine-tuned on domain sentences if possible in order to more \n",
    "# accurately model words that weren't frequent in the general corpus. Code for the first section is from:\n",
    "# mccormickml.com/2019/05/14/BERT-word-embeddings-tutorial/#33-creating-word-and-sentence-vectors-from-hidden-states\n",
    "\n",
    "import torch\n",
    "from pytorch_pretrained_bert import BertTokenizer, BertModel, BertForMaskedLM\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "text1 = \"white embryo and seedling (albino), lethal hypocotyl\"\n",
    "text2 = \"Increased abundance of miRNA precursors.\"\n",
    "text3 = \"incomplete penetrance; increased aluminum resistance; accumulates lower levels of Al in the root tips.\"\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "marked_text = \"{} {} {}\".format(\"[CLS]\",text1,\"[SEP]\")\n",
    "tokenized_text = tokenizer.tokenize(marked_text)\n",
    "indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "# All 1's if just one sentence, otherwise 0's then 1's to indicate the two sentences.\n",
    "segments_ids = [1] * len(tokenized_text) \n",
    "\n",
    "print(tokenized_text)\n",
    "print(indexed_tokens) \n",
    "print(segments_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the token and segment lists into tensors.\n",
    "tokens_tensor = torch.tensor([indexed_tokens])\n",
    "segments_tensor = torch.tensor([segments_ids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and describe the pretained BERT model.\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do a forward pass (don't need gradients or backpropagation) for the tokens in this sentence.\n",
    "with torch.no_grad():\n",
    "    encoded_layers,_ = model(tokens_tensor,segments_tensor)\n",
    "\n",
    "# The dimensions of the encoded layers are [Layer, Batch, Token, Hidden Unit].\n",
    "print (\"Number of layers:\", len(encoded_layers))\n",
    "print (\"Number of batches:\", len(encoded_layers[0]))\n",
    "print (\"Number of tokens:\", len(encoded_layers[0][0]))\n",
    "print (\"Number of hidden units:\", len(encoded_layers[0][0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want to rearrange the encoded layers nested list so that the dimensions are [Batch, Token, Layer, Hidden Unit].\n",
    "token_embeddings = torch.stack(encoded_layers, dim=0)\n",
    "print(token_embeddings.size())\n",
    "token_embeddings = token_embeddings.permute(1,2,0,3)\n",
    "print(token_embeddings.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which layers to use as embeddings is a modeling choice that is context dependent, this uses the last four, either\n",
    "# concatenating all the layers together or summing them.\n",
    "token_vecs_cat = []\n",
    "token_vecs_sum = []\n",
    "batch = 0\n",
    "for token in token_embeddings[batch]:\n",
    "    concatenated_layer_vectors = torch.cat((token[-1], token[-2], token[-3], token[-4]), dim=0)\n",
    "    token_vecs_cat.append(concatenated_layer_vectors)\n",
    "    sum_vec = torch.sum(token[-4:], dim=0)\n",
    "    token_vecs_sum.append(sum_vec)\n",
    "    \n",
    "# The token_vecs_cat list now has dimensions [Tokens, Length of 4 Layers] for this one input sentence. \n",
    "# The token_vecs_sum list now has dimensions [Tokens, Length of 1 Layer] for this one input sentence.\n",
    "print ('Shape is: %d x %d' % (len(token_vecs_cat), len(token_vecs_cat[0])))\n",
    "print ('Shape is: %d x %d' % (len(token_vecs_sum), len(token_vecs_sum[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a vector to represent the entire sentence.\n",
    "layer_to_use = 10\n",
    "batch = 0\n",
    "token_vectors = encoded_layers[layer_to_use][batch]\n",
    "sentence_embedding = torch.mean(token_vectors,dim=0)\n",
    "print(sentence_embedding.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining some of the previous steps into a single function for generating sentence embeddings.\n",
    "def embed(text, model):\n",
    "    marked_text = \"{} {} {}\".format(\"[CLS]\",text,\"[SEP]\")\n",
    "    tokenized_text = tokenizer.tokenize(marked_text)\n",
    "    indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "    segments_ids = [1] * len(tokenized_text)\n",
    "    tokens_tensor = torch.tensor([indexed_tokens])\n",
    "    segments_tensor = torch.tensor([segments_ids])\n",
    "    token_embeddings = torch.stack(encoded_layers, dim=0)\n",
    "    token_embeddings = token_embeddings.permute(1,2,0,3)\n",
    "    token_vecs_cat = []\n",
    "    token_vecs_sum = []\n",
    "    batch = 0\n",
    "    for token in token_embeddings[batch]:\n",
    "        concatenated_layer_vectors = torch.cat((token[-1], token[-2], token[-3], token[-4]), dim=0)\n",
    "        token_vecs_cat.append(np.array(concatenated_layer_vectors))\n",
    "        sum_vec = torch.sum(token[-4:], dim=0)\n",
    "        token_vecs_sum.append(np.array(sum_vec))\n",
    " \n",
    "    a = np.array(token_vecs_sum)\n",
    "    return(np.mean(a,axis=0))\n",
    "        \n",
    "# Running the function on 1000 sentences to check the runtime.\n",
    "texts = [text1]*1000      \n",
    "vectors = [embed(text, model) for text in texts]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
