{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertModel, BertForMaskedLM, BertConfig\n",
    "\n",
    "\n",
    "small_bert_configuration = BertConfig(\n",
    "    vocab_size=100, \n",
    "    hidden_size=50, \n",
    "    num_hidden_layers=2, \n",
    "    num_attention_heads=2,\n",
    "    intermediate_size=200,\n",
    "    max_position_embeddings=200,\n",
    "    return_dict=True,\n",
    "    \n",
    ")\n",
    "\n",
    "model = BertModel(small_bert_configuration)\n",
    "\n",
    "\n",
    "model = BertForMaskedLM(small_bert_configuration)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "putting in training mode\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "print(\"putting in training mode\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AdamW\n",
    "optimizer = AdamW(model.parameters(), lr=1e-5)\n",
    "no_decay = ['bias', 'LayerNorm.weight']\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
    "    {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "]\n",
    "optimizer = AdamW(optimizer_grouped_parameters, lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PreTrainedTokenizer(name_or_path='', vocab_size=16, model_max_len=1000000000000000019884624838656, is_fast=False, padding_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'})\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "from ipywidgets import IntProgress\n",
    "from transformers import BertTokenizer\n",
    "#tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "\n",
    "tokenizer = BertTokenizer(vocab_file=\"/Users/irbraun/Desktop/v.txt\", pad_token=\"[PAD]\")\n",
    "\n",
    "\n",
    "\n",
    "print(tokenizer)\n",
    "print(tokenizer.pad_token_id)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "text_batch = [\n",
    "    \"stop this madness\", \n",
    "    \"you do not care\",\n",
    "    \"something about this is not right at all\",\n",
    "    \"something is not right about this\"\n",
    "]\n",
    "encoding = tokenizer(text_batch, return_tensors='pt', padding=True, truncation=True)\n",
    "input_ids = encoding['input_ids']\n",
    "attention_mask = encoding['attention_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2,  4,  5,  6,  1,  0,  0,  0,  0,  0],\n",
       "        [ 2,  7,  8,  9, 10,  1,  0,  0,  0,  0],\n",
       "        [ 2, 11, 12,  5, 13,  9, 14,  2, 15,  1],\n",
       "        [ 2, 11, 13,  9, 14, 12,  5,  1,  0,  0]])"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding.input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding.token_type_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 0, 0]])"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding.attention_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataset.TensorDataset at 0x122fee668>"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "dataset = TensorDataset(encoding.input_ids, encoding.attention_mask)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, RandomSampler\n",
    "batch_size = 4\n",
    "train_dataloader = DataLoader(dataset, sampler=RandomSampler(dataset), batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79250"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.num_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The BERT model has 42 different named parameters.\n",
      "\n",
      "==== Embedding Layer ====\n",
      "\n",
      "bert.embeddings.word_embeddings.weight                     (100, 50)\n",
      "bert.embeddings.position_embeddings.weight                 (200, 50)\n",
      "bert.embeddings.token_type_embeddings.weight                 (2, 50)\n",
      "bert.embeddings.LayerNorm.weight                               (50,)\n",
      "bert.embeddings.LayerNorm.bias                                 (50,)\n",
      "\n",
      "==== First Transformer ====\n",
      "\n",
      "bert.encoder.layer.0.attention.self.query.weight            (50, 50)\n",
      "bert.encoder.layer.0.attention.self.query.bias                 (50,)\n",
      "bert.encoder.layer.0.attention.self.key.weight              (50, 50)\n",
      "bert.encoder.layer.0.attention.self.key.bias                   (50,)\n",
      "bert.encoder.layer.0.attention.self.value.weight            (50, 50)\n",
      "bert.encoder.layer.0.attention.self.value.bias                 (50,)\n",
      "bert.encoder.layer.0.attention.output.dense.weight          (50, 50)\n",
      "bert.encoder.layer.0.attention.output.dense.bias               (50,)\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.weight         (50,)\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.bias           (50,)\n",
      "bert.encoder.layer.0.intermediate.dense.weight             (200, 50)\n",
      "bert.encoder.layer.0.intermediate.dense.bias                  (200,)\n",
      "bert.encoder.layer.0.output.dense.weight                   (50, 200)\n",
      "bert.encoder.layer.0.output.dense.bias                         (50,)\n",
      "bert.encoder.layer.0.output.LayerNorm.weight                   (50,)\n",
      "bert.encoder.layer.0.output.LayerNorm.bias                     (50,)\n",
      "\n",
      "==== Output Layer ====\n",
      "\n",
      "cls.predictions.transform.dense.weight                      (50, 50)\n",
      "cls.predictions.transform.dense.bias                           (50,)\n",
      "cls.predictions.transform.LayerNorm.weight                     (50,)\n",
      "cls.predictions.transform.LayerNorm.bias                       (50,)\n"
     ]
    }
   ],
   "source": [
    "params = list(model.named_parameters())\n",
    "print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n",
    "\n",
    "print('==== Embedding Layer ====\\n')\n",
    "\n",
    "for p in params[0:5]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
    "\n",
    "print('\\n==== First Transformer ====\\n')\n",
    "\n",
    "for p in params[5:21]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
    "\n",
    "print('\\n==== Output Layer ====\\n')\n",
    "\n",
    "for p in params[-4:]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = \n",
    "\n",
    "\n",
    "\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "# The DataLoader needs to know our batch size for training, so we specify it \n",
    "# here. For fine-tuning BERT on a specific task, the authors recommend a batch \n",
    "# size of 16 or 32.\n",
    "batch_size = 32\n",
    "\n",
    "# Create the DataLoaders for our training and validation sets.\n",
    "# We'll take training samples in random order. \n",
    "train_dataloader = DataLoader(\n",
    "            train_dataset,  # The training samples.\n",
    "            sampler = RandomSampler(train_dataset), # Select batches randomly\n",
    "            batch_size = batch_size # Trains with this batch size.\n",
    "        )\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n",
    "# I believe the 'W' stands for 'Weight Decay fix\"\n",
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
    "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "# Number of training epochs. The BERT authors recommend between 2 and 4. \n",
    "# We chose to run for 4, but we'll see later that this may be over-fitting the\n",
    "# training data.\n",
    "epochs = 3\n",
    "\n",
    "# Total number of training steps is [number of batches] x [number of epochs]. \n",
    "# (Note that this is not the same as the number of training samples).\n",
    "\n",
    "#total_steps = len(train_dataloader) * epochs\n",
    "total_steps = 1*epochs\n",
    "\n",
    "# Create the learning rate scheduler.\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
    "                                            num_training_steps = total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using deprecated `--per_gpu_train_batch_size` argument which will be removed in a future version. Using `--per_device_train_batch_size` is preferred.\n",
      "Using deprecated `--per_gpu_train_batch_size` argument which will be removed in a future version. Using `--per_device_train_batch_size` is preferred.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "only one element tensors can be converted to Python scalars",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-143-99c13e101375>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m )\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/envs/py3/lib/python3.6/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, model_path, trial)\u001b[0m\n\u001b[1;32m    755\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 757\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_iterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    758\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    759\u001b[0m                 \u001b[0;31m# Skip past any already trained steps if resuming training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/envs/py3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/envs/py3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    473\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/envs/py3/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda2/envs/py3/lib/python3.6/site-packages/transformers/data/data_collator.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, examples)\u001b[0m\n\u001b[1;32m    253\u001b[0m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"input_ids\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_collate_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m         \u001b[0;31m# If special token mask has been preprocessed, pop it from the dict.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/envs/py3/lib/python3.6/site-packages/transformers/data/data_collator.py\u001b[0m in \u001b[0;36m_collate_batch\u001b[0;34m(examples, tokenizer)\u001b[0m\n\u001b[1;32m    181\u001b[0m     \u001b[0;31m# Tensorize if necessary.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexamples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m         \u001b[0mexamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mexamples\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;31m# Check if padding is necessary.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/envs/py3/lib/python3.6/site-packages/transformers/data/data_collator.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    181\u001b[0m     \u001b[0;31m# Tensorize if necessary.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexamples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m         \u001b[0mexamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mexamples\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;31m# Check if padding is necessary.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: only one element tensors can be converted to Python scalars"
     ]
    }
   ],
   "source": [
    "from transformers import DataCollatorForLanguageModeling\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer, mlm=True, mlm_probability=0.15\n",
    ")\n",
    "\n",
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./EsperBERTo\",\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=1,\n",
    "    per_gpu_train_batch_size=64,\n",
    "    save_steps=10_000,\n",
    "    save_total_limit=2,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=dataset,\n",
    "    prediction_loss_only=True,\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 10])\n",
      "tensor([[ 2, 11, 12,  5, 13,  9, 14,  2, 15,  1]])\n",
      "torch.Size([1, 10])\n",
      "tensor([[ 2, 11, 12,  5, 13,  9, 14,  2,  3,  1]])\n",
      "tensor(4.6353, grad_fn=<NllLossBackward>)\n",
      "tensor([[[ 1.7337e-01,  5.6298e-02, -1.2305e-02, -1.5025e-02,  1.6851e-01,\n",
      "          -7.2564e-02,  3.3484e-01, -2.1791e-01,  8.8291e-02, -1.0965e-01,\n",
      "           4.6384e-02,  3.9461e-02,  9.9061e-03, -4.3853e-02, -2.2948e-01,\n",
      "          -3.4744e-01, -2.7318e-01, -2.3657e-02,  4.2941e-01, -3.2415e-02,\n",
      "          -1.4915e-02, -2.1313e-02, -2.4112e-02,  1.7946e-01, -4.2223e-02,\n",
      "          -3.2972e-02,  3.0619e-02, -2.4226e-01, -1.8104e-01, -2.4036e-02,\n",
      "           2.0741e-01,  9.9586e-02, -1.7982e-01,  6.9737e-03, -1.4867e-01,\n",
      "          -1.2062e-01, -1.5489e-01, -2.4821e-03,  3.4308e-02, -1.7115e-01,\n",
      "          -1.2163e-01, -9.3340e-02, -7.3554e-03,  2.0202e-01,  1.5587e-01,\n",
      "           9.4902e-02,  7.0439e-02,  1.1978e-02,  1.2689e-01, -3.6209e-02,\n",
      "          -3.0630e-01,  1.3450e-01,  1.1919e-01, -2.4746e-01,  1.4959e-01,\n",
      "           8.2590e-02,  1.6779e-01, -1.6626e-01,  2.4735e-01,  7.5149e-02,\n",
      "           7.1664e-02, -1.4261e-01,  9.4383e-02, -9.6019e-03, -1.7095e-01,\n",
      "          -1.8956e-01, -7.6704e-02,  9.8712e-02,  2.4580e-02,  1.2230e-01,\n",
      "           2.1885e-01,  1.1096e-01,  6.1893e-02, -3.4662e-01, -4.7044e-02,\n",
      "           1.5613e-01, -1.3452e-01, -5.5390e-02,  9.0261e-02, -1.0077e-01,\n",
      "           2.3879e-01,  1.3059e-01, -6.4289e-02,  6.9789e-02,  2.1999e-01,\n",
      "           1.0119e-01, -6.0093e-02, -1.0887e-01,  1.0857e-01,  1.2349e-01,\n",
      "           9.0708e-02, -1.4795e-01,  4.9718e-02, -1.3466e-01, -3.5783e-02,\n",
      "           3.6241e-02,  3.8915e-02,  3.8279e-02,  2.8752e-02, -8.2695e-02],\n",
      "         [-7.3139e-03,  7.0169e-02,  2.2493e-02,  8.8489e-02, -1.3443e-02,\n",
      "          -1.8099e-02,  2.0421e-02, -1.9559e-01,  6.4611e-02, -8.1239e-02,\n",
      "           1.4397e-01, -4.8508e-02, -4.0645e-02,  5.2059e-02, -5.4780e-02,\n",
      "          -1.9217e-01, -3.1139e-01, -1.2405e-01,  1.1518e-01, -1.0220e-01,\n",
      "           2.1188e-01,  7.7246e-02,  8.8408e-02,  8.5949e-02,  6.2072e-02,\n",
      "           1.6443e-03,  1.4308e-01, -1.9083e-01, -5.9916e-02,  2.5662e-01,\n",
      "           2.5262e-01,  3.6355e-02, -1.7016e-01, -1.0647e-01, -8.9859e-02,\n",
      "          -5.5908e-02, -1.1289e-01,  1.7526e-01, -1.6887e-02, -9.5172e-02,\n",
      "          -1.2470e-01, -6.7322e-03,  2.5411e-03,  2.3035e-01, -2.6453e-02,\n",
      "           1.1291e-02,  1.5827e-01, -1.2200e-03,  1.6351e-01, -5.9314e-03,\n",
      "          -2.0914e-01,  1.1486e-01,  1.3118e-01, -6.6427e-02,  5.8907e-02,\n",
      "           1.3011e-01, -2.4940e-02, -1.3793e-01,  2.0412e-01, -3.1543e-02,\n",
      "           1.7723e-01, -1.9073e-01,  1.7333e-01, -9.5106e-02, -1.2507e-02,\n",
      "          -2.3437e-01, -1.5440e-01,  1.2579e-01,  6.2398e-02,  5.2710e-02,\n",
      "          -9.4534e-03, -1.2361e-02, -1.3282e-01, -2.0377e-01, -1.3969e-01,\n",
      "           2.8135e-01, -8.7512e-02, -1.4374e-01,  9.0962e-02, -9.4403e-02,\n",
      "          -4.0963e-02,  8.1396e-03,  3.6973e-02, -7.1330e-02,  1.8388e-02,\n",
      "           2.2979e-01,  3.4433e-02,  4.0373e-03,  2.0583e-02,  1.4250e-01,\n",
      "           2.2504e-01, -2.5255e-01,  8.4361e-02, -1.0858e-02,  2.0222e-01,\n",
      "          -1.1594e-01, -8.5685e-02, -9.0109e-02, -2.0420e-02, -2.1237e-02],\n",
      "         [-1.3453e-01,  1.0738e-01, -9.2125e-02, -4.4639e-02,  7.8193e-02,\n",
      "           1.4561e-01,  1.8137e-01, -3.4771e-01,  2.9710e-01,  2.0236e-02,\n",
      "          -4.2244e-02, -1.5036e-01,  1.2384e-01, -1.4581e-02, -8.1339e-02,\n",
      "          -7.2399e-02,  5.6899e-03, -1.7099e-01,  2.5498e-01,  1.0348e-01,\n",
      "           2.1147e-01, -7.4082e-02,  4.1597e-03, -2.0476e-02,  5.8618e-02,\n",
      "          -1.9960e-01, -7.5520e-03,  9.0192e-02,  1.8466e-02,  1.5593e-01,\n",
      "           2.3414e-02, -9.0351e-02, -5.6787e-02, -7.3996e-02, -8.2823e-02,\n",
      "           1.6011e-01, -1.8340e-01,  2.8037e-01,  6.5390e-02, -1.3497e-01,\n",
      "          -2.2132e-01, -1.7104e-01,  4.5520e-02,  9.5696e-02,  1.8119e-01,\n",
      "           6.7805e-02,  1.6760e-01, -2.1561e-02,  2.5014e-01,  1.7928e-02,\n",
      "          -1.2479e-01,  3.9010e-02,  1.0546e-01, -6.0693e-02,  6.9333e-02,\n",
      "           4.1880e-02, -1.1707e-01, -1.1025e-01,  9.9187e-03, -6.0732e-02,\n",
      "           3.1662e-02, -1.4810e-01,  1.5442e-01, -3.6080e-01, -8.7757e-02,\n",
      "          -1.1130e-01, -1.9623e-01,  5.0809e-02,  1.1480e-01,  1.8276e-01,\n",
      "           4.6218e-03, -2.1877e-01,  1.1964e-03, -7.4968e-02, -7.1728e-02,\n",
      "           1.0033e-01, -2.5956e-02,  1.1294e-02,  1.7096e-01, -2.0085e-02,\n",
      "          -4.4264e-02, -8.9776e-02, -1.6857e-02, -5.3657e-02, -7.7633e-02,\n",
      "           1.6895e-01, -5.3855e-02,  4.7933e-02, -1.0426e-01,  2.3915e-01,\n",
      "           2.7804e-01,  5.8630e-02,  7.2482e-02, -3.9644e-02, -1.9943e-02,\n",
      "           1.3989e-01, -1.8258e-01, -2.2455e-01, -1.1525e-01, -8.9350e-02],\n",
      "         [ 1.6163e-01, -1.2996e-01, -2.4442e-01,  1.8387e-02,  1.1487e-02,\n",
      "          -6.4637e-02,  5.8998e-02, -3.0003e-01, -2.3129e-02, -2.3400e-01,\n",
      "           3.7066e-02, -4.8858e-02, -1.6352e-01, -2.4394e-02, -9.1669e-02,\n",
      "          -2.5408e-01, -8.2338e-02, -1.7397e-01,  3.7481e-02, -1.5766e-01,\n",
      "           6.4379e-02,  5.9122e-02,  1.6150e-01,  1.2945e-01,  3.5131e-01,\n",
      "          -5.9805e-02,  2.6749e-02, -3.2119e-01,  6.2278e-02, -4.5214e-03,\n",
      "           9.0500e-02,  3.9775e-01,  5.1546e-02,  2.0502e-01,  9.5960e-02,\n",
      "           7.6028e-02, -9.0432e-02,  3.2962e-01,  2.5721e-02, -9.9384e-02,\n",
      "          -1.6630e-01,  2.6740e-02,  1.9665e-02, -8.2837e-02,  1.3963e-01,\n",
      "           3.7947e-02,  1.2698e-01, -3.3982e-02,  1.7131e-01,  6.7491e-02,\n",
      "          -1.6649e-01, -1.7635e-01,  1.2092e-01, -1.7572e-01,  5.8923e-03,\n",
      "          -8.4304e-02,  2.1146e-01, -1.3641e-01,  4.2369e-02, -9.2205e-02,\n",
      "          -5.7494e-02, -1.4633e-01, -2.0231e-02, -5.7737e-02, -6.7677e-02,\n",
      "          -2.4362e-01, -1.9990e-01,  2.0703e-01,  1.9789e-02,  1.7824e-01,\n",
      "          -1.3362e-01, -2.0969e-01, -2.6907e-01, -1.6689e-01, -1.3259e-01,\n",
      "           9.0079e-02, -1.3751e-01, -8.5009e-02,  4.7150e-02, -1.8323e-01,\n",
      "           2.1815e-01, -4.0977e-02,  2.0538e-02,  1.1930e-01,  3.7165e-02,\n",
      "           2.7818e-01, -9.2830e-02,  1.6627e-02,  6.4768e-02,  2.0135e-01,\n",
      "           1.7326e-01, -3.1871e-01,  1.5407e-01, -8.6889e-03, -2.8958e-02,\n",
      "           1.3806e-01,  3.3045e-02,  1.1402e-01, -1.9758e-02, -2.4105e-02],\n",
      "         [-6.5969e-02,  2.4785e-01,  5.1366e-02,  8.8246e-02,  1.4984e-01,\n",
      "          -1.5205e-01,  2.3474e-01,  1.0035e-01, -6.0021e-02, -9.7402e-02,\n",
      "          -6.3353e-03, -1.2322e-01,  1.5119e-02, -1.1575e-01, -9.7986e-02,\n",
      "          -2.6800e-01, -1.7805e-01,  3.8270e-02,  2.2540e-01,  7.8193e-03,\n",
      "           3.3560e-02, -4.3242e-02,  5.9858e-02,  5.3807e-02,  4.7456e-03,\n",
      "           7.0118e-03, -1.1656e-01,  3.7525e-03, -2.7325e-01,  1.1691e-01,\n",
      "           2.1223e-01, -4.8897e-03, -1.7286e-01, -1.1959e-01, -8.1980e-02,\n",
      "          -1.6575e-01, -2.9707e-02,  2.9564e-02, -8.7066e-02, -1.7807e-01,\n",
      "           7.7058e-02, -8.5168e-02,  3.8197e-02,  8.6479e-02,  6.3885e-03,\n",
      "           8.6752e-02,  2.2534e-02, -5.1761e-02,  1.6910e-01, -5.6483e-02,\n",
      "          -2.9539e-01,  1.8003e-01,  1.6134e-01, -1.7117e-01,  1.8340e-01,\n",
      "           3.8907e-02,  2.0284e-01, -6.8391e-02,  3.0094e-01, -1.2437e-02,\n",
      "          -6.1491e-02, -2.2013e-02,  2.1268e-01,  4.7079e-02, -1.2331e-01,\n",
      "          -1.8206e-01, -1.3442e-01,  1.2494e-01, -1.9341e-01,  1.1456e-01,\n",
      "           1.5181e-01,  1.8318e-01,  5.6059e-02, -2.3487e-01, -1.1564e-01,\n",
      "           5.6686e-02, -4.7506e-02, -1.6196e-01,  8.4910e-02, -1.2073e-01,\n",
      "           7.6237e-02,  3.3172e-02, -7.8964e-02, -1.8475e-02,  1.6244e-01,\n",
      "           8.6258e-02,  4.9831e-02, -1.1282e-01,  5.8473e-02,  1.6091e-01,\n",
      "           1.2376e-01, -8.4202e-02,  1.8922e-01,  3.6556e-02, -7.7650e-02,\n",
      "           1.1439e-01,  7.5593e-02,  3.5521e-03,  1.5066e-01, -1.7242e-02],\n",
      "         [-2.2530e-02, -1.0632e-01, -3.8657e-03, -2.0843e-02,  1.6608e-01,\n",
      "          -5.9948e-02,  1.8130e-01, -1.6843e-01,  7.7360e-02, -4.4910e-02,\n",
      "          -1.9914e-02, -1.7380e-01,  1.7923e-01, -5.5991e-02, -1.3843e-01,\n",
      "          -2.3776e-01, -2.6886e-01, -4.2249e-02,  1.6686e-01, -1.5205e-01,\n",
      "           3.9769e-02, -1.1621e-01,  1.3362e-01, -1.1152e-02,  9.7285e-02,\n",
      "           9.1360e-02,  1.8130e-01, -9.2199e-02, -1.1228e-01, -1.4952e-02,\n",
      "           2.2566e-01,  9.5751e-02, -1.4108e-01,  1.9411e-01, -1.2662e-01,\n",
      "          -7.1146e-02, -1.6682e-01,  1.5604e-01,  9.0218e-02, -2.0142e-02,\n",
      "          -1.9198e-01,  2.1583e-02,  9.3936e-02,  1.6127e-01, -6.2506e-02,\n",
      "          -2.7379e-02,  4.5459e-03, -9.7381e-02,  2.8930e-01,  6.7410e-02,\n",
      "          -2.0502e-01,  2.5044e-02,  3.1581e-01, -2.2874e-01,  1.1526e-01,\n",
      "           1.8091e-01, -1.0573e-02, -3.0297e-01,  2.5688e-02, -1.3979e-01,\n",
      "           1.0588e-01, -2.1945e-01,  1.0935e-01, -8.1077e-02,  2.2564e-01,\n",
      "          -3.8047e-01,  1.2898e-02, -4.8697e-02, -4.9163e-02,  2.0008e-01,\n",
      "           1.1035e-02,  1.6735e-01, -1.5763e-02, -4.0811e-01, -2.1773e-01,\n",
      "           1.0794e-01, -2.2459e-01, -6.2399e-02,  6.2511e-03, -7.8669e-02,\n",
      "           1.7223e-01,  7.2743e-02, -1.4462e-01,  3.1339e-02,  7.2267e-02,\n",
      "          -2.8182e-02, -6.1599e-02,  1.7500e-01, -2.0221e-01,  1.1691e-01,\n",
      "           2.4744e-01, -1.0743e-01,  1.4200e-01,  9.9088e-02, -1.6891e-02,\n",
      "          -1.4148e-02, -1.8900e-01, -6.3940e-03, -1.3651e-01, -1.0181e-01],\n",
      "         [-1.3467e-01,  2.3267e-01, -3.7820e-02,  5.4260e-02, -1.3670e-01,\n",
      "           6.3640e-02,  9.9312e-02, -9.1182e-02,  1.1493e-01, -9.9363e-02,\n",
      "           8.6345e-02, -5.6576e-02, -1.5316e-01, -1.7672e-02, -1.5263e-01,\n",
      "          -3.8665e-01, -2.3423e-01, -6.5623e-03,  2.2144e-01,  1.2178e-01,\n",
      "           4.9568e-03,  2.8410e-02, -1.1936e-02,  5.1958e-02,  6.2630e-03,\n",
      "           9.3342e-02,  1.1949e-02, -2.2539e-01, -4.4976e-02,  5.5937e-02,\n",
      "           2.9117e-01,  9.0268e-02, -1.2465e-01, -1.1864e-01, -9.9591e-02,\n",
      "           9.4509e-02, -1.1164e-01,  2.1624e-01, -1.3461e-01, -2.2820e-01,\n",
      "          -3.9429e-02,  2.8961e-02,  9.6050e-02,  1.4844e-01,  1.4893e-01,\n",
      "           5.8528e-02,  7.7516e-02,  1.1728e-02,  8.0055e-02, -3.0393e-02,\n",
      "          -7.4892e-02,  1.0019e-01,  1.9091e-01, -8.8532e-02,  8.1268e-02,\n",
      "           9.3365e-02,  1.4925e-01, -1.9232e-02,  2.4698e-01, -7.3170e-02,\n",
      "           3.4720e-03,  2.6052e-02,  2.2069e-01,  3.1168e-02, -6.2730e-02,\n",
      "          -1.9412e-01, -1.5544e-01,  8.6096e-02, -8.7025e-02,  9.5660e-02,\n",
      "           1.8685e-02, -4.7033e-02,  1.4070e-02, -2.8734e-01, -1.4499e-02,\n",
      "           1.6127e-01, -7.3118e-02, -1.9453e-01,  6.8287e-02, -3.0481e-02,\n",
      "          -4.4403e-02, -8.1696e-03, -9.6184e-02,  2.2049e-01,  7.4307e-02,\n",
      "           3.2708e-01, -4.6995e-02, -5.0163e-02,  5.2020e-02,  2.3694e-01,\n",
      "           2.3919e-01, -1.3759e-01,  1.5175e-01,  7.9322e-02,  3.4824e-02,\n",
      "           1.4499e-01,  1.1980e-01, -6.9873e-02, -2.0602e-02,  3.4870e-02],\n",
      "         [ 2.5928e-01,  2.6415e-01, -5.8843e-02,  1.6658e-01,  1.3500e-01,\n",
      "          -1.6171e-01,  2.6124e-01,  1.8873e-01, -3.6615e-02, -1.5160e-01,\n",
      "           2.6332e-02,  9.0941e-02,  1.3327e-01, -2.2764e-01, -1.1881e-02,\n",
      "          -9.1029e-02, -5.6705e-02, -4.3164e-02,  2.0667e-01,  7.3225e-02,\n",
      "          -1.0529e-01, -2.0320e-01, -5.4339e-02, -2.0301e-02,  2.3343e-01,\n",
      "           1.5609e-01,  1.4761e-01, -1.8843e-01, -3.2584e-02,  2.4327e-01,\n",
      "           1.5086e-01,  1.0759e-01,  1.4405e-01, -2.5686e-02, -9.4733e-02,\n",
      "          -1.2565e-01,  9.7883e-02,  8.3299e-02,  4.9773e-03, -9.1133e-02,\n",
      "           1.4782e-01, -7.9631e-02, -1.3852e-01,  3.7929e-02,  2.7270e-01,\n",
      "           3.9514e-02,  6.1935e-02,  4.9518e-03, -2.1305e-02, -3.6945e-02,\n",
      "          -1.0933e-01,  2.0539e-01,  1.4040e-01, -9.5536e-02,  1.9348e-01,\n",
      "           1.4200e-01,  2.8652e-02, -7.9249e-02,  3.0240e-01,  2.1922e-01,\n",
      "          -6.6264e-02, -5.5045e-02,  1.0574e-01,  1.0281e-01, -1.6935e-01,\n",
      "          -1.0227e-01,  5.1846e-02,  9.7659e-02, -1.6173e-01, -4.6444e-02,\n",
      "          -1.1313e-01, -1.0734e-01,  1.1370e-01, -7.9320e-02, -6.4027e-02,\n",
      "           4.5705e-02, -5.5382e-02, -9.8980e-02,  8.1903e-02,  4.7091e-03,\n",
      "           2.3461e-01,  2.4716e-02, -1.9670e-01, -4.3727e-02,  1.0474e-01,\n",
      "           1.0520e-01,  3.2148e-02, -5.8762e-02,  1.7135e-01,  1.4222e-01,\n",
      "           3.8374e-02, -2.1984e-01, -1.2496e-01, -9.8212e-02, -9.1776e-02,\n",
      "           1.7083e-01,  9.9519e-02,  1.5475e-01,  4.3041e-01, -1.4155e-01],\n",
      "         [ 8.2855e-02,  1.5695e-01, -4.8719e-02,  2.3181e-02,  8.4812e-02,\n",
      "          -6.5291e-02,  3.8131e-01, -3.9756e-02,  7.7591e-02, -3.1445e-02,\n",
      "           2.5204e-02,  4.2378e-02, -1.5287e-02,  3.6497e-03, -2.3631e-01,\n",
      "          -1.7062e-01, -2.1322e-01, -9.5057e-02,  2.5238e-01,  1.1210e-01,\n",
      "          -2.2601e-02, -2.6631e-02,  7.2900e-02,  7.6790e-03, -6.0612e-02,\n",
      "          -2.2537e-03, -1.4500e-02, -6.6447e-02,  1.5836e-02,  1.2555e-01,\n",
      "           1.9304e-01, -1.5712e-01, -2.4613e-01, -1.3503e-01, -1.0838e-01,\n",
      "          -4.1430e-02, -1.5313e-01, -2.6376e-02, -7.6718e-02, -8.1404e-02,\n",
      "          -6.3996e-02, -2.1093e-01, -1.2792e-02,  6.6389e-02,  1.9708e-01,\n",
      "           1.5693e-01, -7.8733e-02, -3.2315e-02,  7.6026e-02,  2.6080e-02,\n",
      "          -1.8710e-01,  8.9061e-02, -5.6851e-02, -1.6935e-01, -2.5259e-02,\n",
      "           4.4622e-03,  1.7380e-01,  5.7184e-02,  1.4317e-01,  2.5356e-02,\n",
      "          -3.0541e-02,  4.4257e-02, -3.4593e-02, -7.2008e-02, -9.1777e-02,\n",
      "          -1.8956e-02, -7.9353e-02,  1.8162e-01,  2.2100e-02,  7.1286e-02,\n",
      "           1.3387e-01,  1.4827e-01, -5.7196e-03, -2.2796e-01,  4.8865e-02,\n",
      "           3.4839e-01,  3.8480e-02, -1.8571e-01,  8.9073e-02, -2.5745e-02,\n",
      "           1.4224e-01, -4.7241e-03, -2.7685e-04, -8.2812e-03,  1.8589e-01,\n",
      "           2.7999e-01, -6.8085e-02, -9.4011e-02, -7.0620e-02,  1.9001e-01,\n",
      "           2.9583e-01, -1.3330e-01, -1.5248e-02,  6.5801e-02, -3.1571e-02,\n",
      "           1.0507e-01,  8.6840e-02, -1.0592e-01,  7.9998e-02, -1.3764e-01],\n",
      "         [ 5.7488e-02,  2.0374e-01, -1.2600e-01, -1.0262e-01,  1.8589e-01,\n",
      "           2.5265e-02,  1.3968e-01,  6.9125e-02, -7.5967e-03,  1.5433e-01,\n",
      "           1.3471e-01,  4.1836e-02,  1.6806e-01, -1.5882e-01, -4.9357e-02,\n",
      "          -2.9526e-01, -4.3713e-01,  8.6824e-02,  2.6603e-01, -2.4816e-01,\n",
      "          -1.0354e-01, -1.1214e-03, -7.3174e-03,  3.2500e-02, -7.5352e-02,\n",
      "           4.2722e-02, -2.1140e-02, -8.4130e-02, -5.2036e-02,  8.9461e-02,\n",
      "           2.6205e-01,  7.4492e-02, -1.1688e-01, -2.9720e-02, -9.5734e-02,\n",
      "           5.6923e-02, -1.2697e-01,  1.7861e-01,  2.7654e-02, -5.4752e-02,\n",
      "          -1.0897e-01,  8.0749e-02, -4.3080e-02,  1.7568e-01,  8.1978e-02,\n",
      "          -4.5855e-02,  4.5555e-02, -1.2760e-01,  1.5636e-01,  5.4461e-02,\n",
      "          -1.8659e-01,  1.7084e-01,  1.8686e-01, -1.5406e-01,  2.4425e-01,\n",
      "           3.0289e-01,  3.2435e-02, -4.8282e-02,  1.8868e-01,  6.9751e-02,\n",
      "           2.7492e-01, -3.0998e-01,  1.1539e-01, -1.2011e-01,  1.5150e-02,\n",
      "          -1.4740e-01, -8.8950e-02,  5.3891e-02, -1.1237e-01,  1.2204e-01,\n",
      "           1.5350e-01,  1.8759e-01,  6.9574e-02, -1.2229e-01, -6.9534e-02,\n",
      "           1.6156e-01, -2.0221e-01, -4.2686e-02,  4.9839e-02, -7.5641e-02,\n",
      "           1.2887e-01,  2.8904e-01, -2.3125e-01, -1.2436e-01,  8.1635e-02,\n",
      "           1.3207e-02,  1.3322e-01, -3.1665e-02, -3.8534e-02,  1.5064e-01,\n",
      "           3.8208e-02, -6.4946e-02,  9.9987e-02,  8.6318e-02,  1.6421e-01,\n",
      "           1.4699e-01,  4.7159e-02,  2.2392e-02, -2.8702e-02,  1.4053e-02]]],\n",
      "       grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer(\"something about this is not right at [MASK].\", return_tensors=\"pt\", padding=True, truncation=True)\n",
    "labels = tokenizer(\"something about this is not right at all\", return_tensors=\"pt\", padding=True, truncation=True)[\"input_ids\"]\n",
    "\n",
    "\n",
    "\n",
    "encoding = tokenizer(text_batch, return_tensors='pt', padding=True, truncation=True)\n",
    "input_ids = encoding['input_ids']\n",
    "attention_mask = encoding['attention_mask']\n",
    "\n",
    "\n",
    "text_batch = [\n",
    "    \"stop this madness\", \n",
    "    \"you do not care\",\n",
    "    \"something about this is not right at all\",\n",
    "    \"something about this is not right at [MASK]\",\n",
    "    \"something is not right about this\"]\n",
    "\n",
    "\n",
    "inputs = tokenizer(text_batch[2], return_tensors=\"pt\")\n",
    "print(inputs[\"input_ids\"].shape)\n",
    "print(inputs[\"input_ids\"])\n",
    "\n",
    "labels = tokenizer(text_batch[3], return_tensors=\"pt\")\n",
    "print(labels[\"input_ids\"].shape)\n",
    "print(labels[\"input_ids\"])\n",
    "labels = labels[\"input_ids\"]\n",
    "\n",
    "model.train()\n",
    "outputs = model(**inputs, labels=labels)\n",
    "loss = outputs.loss\n",
    "logits = outputs.logits\n",
    "print(loss)\n",
    "print(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[ 2,  4,  5,  3,  1,  0,  0,  0,  0,  0],\n",
      "        [ 2,  7,  8,  9,  3,  1,  0,  0,  0,  0],\n",
      "        [ 2, 11, 12,  5, 13,  9, 14,  2,  3,  1],\n",
      "        [ 2, 11, 13,  9, 14, 12,  3,  1,  0,  0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 0, 0]])}\n",
      "torch.Size([4, 10])\n",
      "torch.Size([4, 10])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import TensorDataset, random_split\n",
    "\n",
    "\n",
    "text_batch = [\n",
    "    \"stop this madness\", \n",
    "    \"you do not care\",\n",
    "    \"something about this is not right at all\",\n",
    "    \"something is not right about this\"]\n",
    "\n",
    "text_batch_masked = [\n",
    "    \"stop this [MASK]\", \n",
    "    \"you do not [MASK]\",\n",
    "    \"something about this is not right at [MASK]\",\n",
    "    \"something is not right about [MASK]\"]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#inputs = tokenizer(text_batch, return_tensors=\"pt\")\n",
    "labels_dict = tokenizer(text_batch, return_tensors='pt', padding=True, truncation=True)\n",
    "inputs_dict = tokenizer(text_batch_masked, return_tensors='pt', padding=True, truncation=True)\n",
    "\n",
    "print(inputs_dict)\n",
    "\n",
    "print(inputs_dict[\"input_ids\"].shape)\n",
    "print(labels_dict[\"input_ids\"].shape)\n",
    "\n",
    "# Combine the training inputs into a TensorDataset.\n",
    "dataset = TensorDataset(inputs_dict[\"input_ids\"], inputs_dict[\"attention_mask\"], labels_dict[\"input_ids\"])\n",
    "\n",
    "\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "batch_size = 32\n",
    "train_dataloader = DataLoader(\n",
    "    dataset,  # The training samples.\n",
    "    sampler = RandomSampler(dataset), # Select batches randomly\n",
    "    batch_size = batch_size # Trains with this batch size.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.6035, grad_fn=<NllLossBackward>)\n",
      "4.603512763977051\n",
      "tensor(4.5893, grad_fn=<NllLossBackward>)\n",
      "4.589305400848389\n",
      "tensor(4.5936, grad_fn=<NllLossBackward>)\n",
      "4.593636512756348\n",
      "tensor(4.6005, grad_fn=<NllLossBackward>)\n",
      "4.600455284118652\n",
      "tensor(4.5967, grad_fn=<NllLossBackward>)\n",
      "4.596670150756836\n",
      "tensor(4.6087, grad_fn=<NllLossBackward>)\n",
      "4.608651161193848\n",
      "tensor(4.5965, grad_fn=<NllLossBackward>)\n",
      "4.596545219421387\n",
      "tensor(4.5860, grad_fn=<NllLossBackward>)\n",
      "4.5860395431518555\n",
      "tensor(4.5896, grad_fn=<NllLossBackward>)\n",
      "4.589615345001221\n",
      "tensor(4.5974, grad_fn=<NllLossBackward>)\n",
      "4.597408294677734\n",
      "tensor(4.5844, grad_fn=<NllLossBackward>)\n",
      "4.584423065185547\n",
      "tensor(4.6066, grad_fn=<NllLossBackward>)\n",
      "4.606635093688965\n",
      "tensor(4.5944, grad_fn=<NllLossBackward>)\n",
      "4.594357967376709\n",
      "tensor(4.6038, grad_fn=<NllLossBackward>)\n",
      "4.603768348693848\n",
      "tensor(4.5964, grad_fn=<NllLossBackward>)\n",
      "4.596415996551514\n",
      "tensor(4.5886, grad_fn=<NllLossBackward>)\n",
      "4.588630676269531\n",
      "tensor(4.5823, grad_fn=<NllLossBackward>)\n",
      "4.582271575927734\n",
      "tensor(4.5978, grad_fn=<NllLossBackward>)\n",
      "4.597832679748535\n",
      "tensor(4.5908, grad_fn=<NllLossBackward>)\n",
      "4.590806484222412\n",
      "tensor(4.5906, grad_fn=<NllLossBackward>)\n",
      "4.590603351593018\n"
     ]
    }
   ],
   "source": [
    "# The training loop that uses the data loader constructed above.\n",
    "epochs = 20\n",
    "for epoch_i in range(0, epochs):\n",
    "    model.train()\n",
    "    total_train_loss =0 \n",
    "    for step,batch in enumerate(train_dataloader):\n",
    "        \n",
    "\n",
    "        model.zero_grad()\n",
    "        outputs = model(input_ids=batch[0], attention_mask=batch[1], labels=batch[2])\n",
    "        loss = outputs.loss\n",
    "        logits = outputs.logits\n",
    "        #print(loss)\n",
    "        #print(logits)\n",
    "        \n",
    "        \n",
    "        print(loss)\n",
    "        \n",
    "        total_train_loss += loss.item()\n",
    "\n",
    "        # Perform a backward pass to calculate the gradients.\n",
    "        loss.backward()\n",
    "        \n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        \n",
    "        scheduler.step()\n",
    "        optimizer.step()\n",
    "        \n",
    "    avg_train_loss = total_train_loss / len(train_dataloader) \n",
    "    print(avg_train_loss)\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# This training code is based on the `run_glue.py` script here:\n",
    "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
    "\n",
    "# Set the seed value all over the place to make this reproducible.\n",
    "seed_val = 42\n",
    "\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "# We'll store a number of quantities such as training and validation loss, \n",
    "# validation accuracy, and timings.\n",
    "training_stats = []\n",
    "\n",
    "# Measure the total training time for the whole run.\n",
    "total_t0 = time.time()\n",
    "\n",
    "# For each epoch...\n",
    "for epoch_i in range(0, epochs):\n",
    "    \n",
    "    # ========================================\n",
    "    #               Training\n",
    "    # ========================================\n",
    "    \n",
    "    # Perform one full pass over the training set.\n",
    "\n",
    "    print(\"\")\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "    print('Training...')\n",
    "\n",
    "    # Measure how long the training epoch takes.\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Reset the total loss for this epoch.\n",
    "    total_train_loss = 0\n",
    "\n",
    "    # Put the model into training mode. Don't be mislead--the call to \n",
    "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
    "    # `dropout` and `batchnorm` layers behave differently during training\n",
    "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
    "    model.train()\n",
    "\n",
    "    # For each batch of training data...\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "\n",
    "        # Progress update every 40 batches.\n",
    "        if step % 40 == 0 and not step == 0:\n",
    "            # Calculate elapsed time in minutes.\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "            \n",
    "            # Report progress.\n",
    "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
    "\n",
    "        # Unpack this training batch from our dataloader. \n",
    "        #\n",
    "        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
    "        # `to` method.\n",
    "        #\n",
    "        # `batch` contains three pytorch tensors:\n",
    "        #   [0]: input ids \n",
    "        #   [1]: attention masks\n",
    "        #   [2]: labels \n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "\n",
    "        # Always clear any previously calculated gradients before performing a\n",
    "        # backward pass. PyTorch doesn't do this automatically because \n",
    "        # accumulating the gradients is \"convenient while training RNNs\". \n",
    "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
    "        model.zero_grad()        \n",
    "\n",
    "        # Perform a forward pass (evaluate the model on this training batch).\n",
    "        # The documentation for this `model` function is here: \n",
    "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
    "        # It returns different numbers of parameters depending on what arguments\n",
    "        # arge given and what flags are set. For our useage here, it returns\n",
    "        # the loss (because we provided labels) and the \"logits\"--the model\n",
    "        # outputs prior to activation.\n",
    "        loss, logits = model(b_input_ids, \n",
    "                             token_type_ids=None, \n",
    "                             attention_mask=b_input_mask, \n",
    "                             labels=b_labels)\n",
    "\n",
    "        # Accumulate the training loss over all of the batches so that we can\n",
    "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
    "        # single value; the `.item()` function just returns the Python value \n",
    "        # from the tensor.\n",
    "        total_train_loss += loss.item()\n",
    "\n",
    "        # Perform a backward pass to calculate the gradients.\n",
    "        loss.backward()\n",
    "\n",
    "        # Clip the norm of the gradients to 1.0.\n",
    "        # This is to help prevent the \"exploding gradients\" problem.\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        # Update parameters and take a step using the computed gradient.\n",
    "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
    "        # modified based on their gradients, the learning rate, etc.\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update the learning rate.\n",
    "        scheduler.step()\n",
    "\n",
    "    # Calculate the average loss over all of the batches.\n",
    "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
    "    \n",
    "    # Measure how long this epoch took.\n",
    "    training_time = format_time(time.time() - t0)\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
    "        \n",
    "    # ========================================\n",
    "    #               Validation\n",
    "    # ========================================\n",
    "    # After the completion of each training epoch, measure our performance on\n",
    "    # our validation set.\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"Running Validation...\")\n",
    "\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Put the model in evaluation mode--the dropout layers behave differently\n",
    "    # during evaluation.\n",
    "    model.eval()\n",
    "\n",
    "    # Tracking variables \n",
    "    total_eval_accuracy = 0\n",
    "    total_eval_loss = 0\n",
    "    nb_eval_steps = 0\n",
    "\n",
    "    # Evaluate data for one epoch\n",
    "    for batch in validation_dataloader:\n",
    "        \n",
    "        # Unpack this training batch from our dataloader. \n",
    "        #\n",
    "        # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
    "        # the `to` method.\n",
    "        #\n",
    "        # `batch` contains three pytorch tensors:\n",
    "        #   [0]: input ids \n",
    "        #   [1]: attention masks\n",
    "        #   [2]: labels \n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "        \n",
    "        # Tell pytorch not to bother with constructing the compute graph during\n",
    "        # the forward pass, since this is only needed for backprop (training).\n",
    "        with torch.no_grad():        \n",
    "\n",
    "            # Forward pass, calculate logit predictions.\n",
    "            # token_type_ids is the same as the \"segment ids\", which \n",
    "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
    "            # The documentation for this `model` function is here: \n",
    "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
    "            # Get the \"logits\" output by the model. The \"logits\" are the output\n",
    "            # values prior to applying an activation function like the softmax.\n",
    "            (loss, logits) = model(b_input_ids, \n",
    "                                   token_type_ids=None, \n",
    "                                   attention_mask=b_input_mask,\n",
    "                                   labels=b_labels)\n",
    "            \n",
    "        # Accumulate the validation loss.\n",
    "        total_eval_loss += loss.item()\n",
    "\n",
    "        # Move logits and labels to CPU\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "        # Calculate the accuracy for this batch of test sentences, and\n",
    "        # accumulate it over all batches.\n",
    "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
    "        \n",
    "\n",
    "    # Report the final accuracy for this validation run.\n",
    "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
    "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
    "\n",
    "    # Calculate the average loss over all of the batches.\n",
    "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
    "    \n",
    "    # Measure how long the validation run took.\n",
    "    validation_time = format_time(time.time() - t0)\n",
    "    \n",
    "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
    "    print(\"  Validation took: {:}\".format(validation_time))\n",
    "\n",
    "    # Record all statistics from this epoch.\n",
    "    training_stats.append(\n",
    "        {\n",
    "            'epoch': epoch_i + 1,\n",
    "            'Training Loss': avg_train_loss,\n",
    "            'Valid. Loss': avg_val_loss,\n",
    "            'Valid. Accur.': avg_val_accuracy,\n",
    "            'Training Time': training_time,\n",
    "            'Validation Time': validation_time\n",
    "        }\n",
    "    )\n",
    "\n",
    "print(\"\")\n",
    "print(\"Training complete!\")\n",
    "\n",
    "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import LineByLineTextDataset\n",
    "\n",
    "dataset = LineByLineTextDataset(\n",
    "    tokenizer=tokenizer,\n",
    "    file_path=\"/Users/irbraun/Desktop/s.txt\",\n",
    "    block_size=128,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataCollatorForLanguageModeling(tokenizer=PreTrainedTokenizer(name_or_path='', vocab_size=17, model_max_len=1000000000000000019884624838656, is_fast=False, padding_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}), mlm=True, mlm_probability=0.15)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import DataCollatorForLanguageModeling\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer, mlm=True, mlm_probability=0.15\n",
    ")\n",
    "\n",
    "data_collator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./EsperBERTo\",\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=1,\n",
    "    per_gpu_train_batch_size=64,\n",
    "    save_steps=10_000,\n",
    "    save_total_limit=2,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=dataset,\n",
    "    prediction_loss_only=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using deprecated `--per_gpu_train_batch_size` argument which will be removed in a future version. Using `--per_device_train_batch_size` is preferred.\n",
      "Using deprecated `--per_gpu_train_batch_size` argument which will be removed in a future version. Using `--per_device_train_batch_size` is preferred.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "forward() got an unexpected keyword argument 'labels'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-107-3435b262f1ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda2/envs/py3/lib/python3.6/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, model_path, trial)\u001b[0m\n\u001b[1;32m    773\u001b[0m                         \u001b[0mtr_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    774\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 775\u001b[0;31m                     \u001b[0mtr_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    776\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_total_flos\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloating_point_ops\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/envs/py3/lib/python3.6/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   1110\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1111\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1112\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1114\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_gpu\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/envs/py3/lib/python3.6/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mcompute_loss\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   1134\u001b[0m         \u001b[0mSubclass\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0moverride\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcustom\u001b[0m \u001b[0mbehavior\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1135\u001b[0m         \"\"\"\n\u001b[0;32m-> 1136\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1137\u001b[0m         \u001b[0;31m# Save past state if it exists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1138\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpast_index\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/envs/py3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: forward() got an unexpected keyword argument 'labels'"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "forward() got an unexpected keyword argument 'labels'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-edda4dbd5f79>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/envs/py3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: forward() got an unexpected keyword argument 'labels'"
     ]
    }
   ],
   "source": [
    "labels = torch.tensor([1,0]).unsqueeze(0)\n",
    "outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "loss = outputs.loss\n",
    "loss.backward()\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import get_linear_schedule_with_warmup\n",
    "num_warmup_steps = 5\n",
    "num_train_steps = 10\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps, num_train_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'loss' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-a254559c8319>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'loss' is not defined"
     ]
    }
   ],
   "source": [
    "loss.backward()\n",
    "optimizer.step()\n",
    "scheduler.step()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
