{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import math\n",
    "import sys\n",
    "import gensim\n",
    "import os\n",
    "import warnings\n",
    "import torch\n",
    "import itertools\n",
    "import multiprocessing as mp\n",
    "from collections import Counter, defaultdict\n",
    "from inspect import signature\n",
    "from scipy.stats import ks_2samp\n",
    "from sklearn.metrics import precision_recall_curve, f1_score, auc\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from scipy import spatial, stats\n",
    "from nltk.corpus import brown\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from pytorch_pretrained_bert import BertTokenizer, BertModel, BertForMaskedLM\n",
    "from gensim.parsing.preprocessing import strip_non_alphanum, stem_text, preprocess_string, remove_stopwords\n",
    "from gensim.utils import simple_preprocess\n",
    "\n",
    "sys.path.append(\"../../oats\")\n",
    "from oats.utils.utils import save_to_pickle, load_from_pickle, merge_list_dicts, flatten, to_hms\n",
    "from oats.datasets.dataset import Dataset\n",
    "from oats.datasets.groupings import Groupings\n",
    "from oats.annotation.ontology import Ontology\n",
    "from oats.datasets.string import String\n",
    "from oats.datasets.edges import Edges\n",
    "from oats.annotation.annotation import annotate_using_noble_coder\n",
    "from oats.graphs import pairwise as pw\n",
    "from oats.graphs.indexed import IndexedGraph\n",
    "from oats.graphs.models import train_logistic_regression_model, apply_logistic_regression_model\n",
    "from oats.graphs.models import train_random_forest_model, apply_random_forest_model\n",
    "from oats.nlp.vocabulary import get_overrepresented_tokens, build_vocabulary_from_tokens\n",
    "from oats.utils.utils import function_wrapper_with_duration\n",
    "from oats.nlp.preprocess import concatenate_with_bar_delim\n",
    "\n",
    "mpl.rcParams[\"figure.dpi\"] = 400\n",
    "warnings.simplefilter('ignore')\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('brown', quiet=True)\n",
    "nltk.download('averaged_perceptron_tagger', quiet=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_filename = \"../data/pickles/text_plus_annotations_dataset.pickle\"        # The full dataset pickle.\n",
    "groupings_filename = \"../data/pickles/lloyd_subsets.pickle\"                      # The groupings pickle.\n",
    "background_corpus_filename = \"../data/corpus_related_files/untagged_text_corpora/background.txt\"       # Text file with background content.\n",
    "phenotypes_corpus_filename = \"../data/corpus_related_files/untagged_text_corpora/phenotypes_small.txt\" # Text file with specific content.\n",
    "doc2vec_pubmed_filename = \"../gensim/pubmed_dbow/doc2vec_2.bin\"                  # File holding saved Doc2Vec model.\n",
    "doc2vec_wikipedia_filename = \"../gensim/enwiki_dbow/doc2vec.bin\"                 # File holding saved Doc2Vec model.\n",
    "word2vec_model_filename = \"../gensim/wiki_sg/word2vec.bin\"                       # File holding saved Word2Vec model.\n",
    "ontology_filename = \"../ontologies/mo.obo\"                                       # Ontology file in OBO format.\n",
    "noblecoder_jarfile_path = \"../lib/NobleCoder-1.0.jar\"                            # Jar for NOBLE Coder tool.\n",
    "biobert_pmc_path = \"../gensim/biobert_v1.0_pmc/pytorch_model\"                    # Path for PyTorch BioBERT model.\n",
    "biobert_pubmed_path = \"../gensim/biobert_v1.0_pubmed/pytorch_model\"              # Path for PyTorch BioBERT model.\n",
    "biobert_pubmed_pmc_path = \"../gensim/biobert_v1.0_pubmed_pmc/pytorch_model\"      # Path for PyTorch BioBERT model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in the dataframe: 30169\n",
      "Number of unique IDs:            30169\n",
      "Number of unique descriptions:   4566\n",
      "Number of unique gene name sets: 30169\n",
      "Number of species represented:   6\n",
      "Number of rows in the dataframe: 6030\n",
      "Number of unique IDs:            6030\n",
      "Number of unique descriptions:   3611\n",
      "Number of unique gene name sets: 6030\n",
      "Number of species represented:   1\n"
     ]
    }
   ],
   "source": [
    "dataset = load_from_pickle(dataset_filename)\n",
    "dataset.describe()\n",
    "dataset.filter_by_species(\"ath\")\n",
    "dataset.filter_has_description()\n",
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Files and models related to the machine learning text embedding methods.\n",
    "doc2vec_wiki_model = gensim.models.Doc2Vec.load(doc2vec_wikipedia_filename)\n",
    "doc2vec_pubmed_model = gensim.models.Doc2Vec.load(doc2vec_pubmed_filename)\n",
    "word2vec_model = gensim.models.Word2Vec.load(word2vec_model_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain a mapping between IDs and the raw text descriptions associated with that ID from the dataset.\n",
    "descriptions = dataset.get_description_dictionary()\n",
    "\n",
    "# Preprocessing of the text descriptions. Different methods are necessary for different approaches.\n",
    "descriptions_full_preprocessing = {i:\" \".join(preprocess_string(d)) for i,d in descriptions.items()}\n",
    "descriptions_simple_preprocessing = {i:\" \".join(simple_preprocess(d)) for i,d in descriptions.items()}\n",
    "descriptions_no_stopwords = {i:remove_stopwords(d) for i,d in descriptions.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_pos_tokens = lambda text,pos: \" \".join([t[0] for t in nltk.pos_tag(word_tokenize(text)) if t[1].lower()==pos.lower()])\n",
    "descriptions_noun_only =  {i:get_pos_tokens(d,\"NN\") for i,d in descriptions.items()}\n",
    "descriptions_noun_only_full_preprocessing = {i:\" \".join(preprocess_string(d)) for i,d in descriptions_noun_only.items()}\n",
    "descriptions_noun_only_simple_preprocessing = {i:\" \".join(simple_preprocess(d)) for i,d in descriptions_noun_only.items()}\n",
    "descriptions_adj_only =  {i:get_pos_tokens(d,\"JJ\") for i,d in descriptions.items()}\n",
    "descriptions_adj_only_full_preprocessing = {i:\" \".join(preprocess_string(d)) for i,d in descriptions_adj_only.items()}\n",
    "descriptions_adj_only_simple_preprocessing = {i:\" \".join(simple_preprocess(d)) for i,d in descriptions_adj_only.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the ontology term annotators over either raw or preprocessed text descriptions.\n",
    "annotations_noblecoder_precise = annotate_using_noble_coder(descriptions, noblecoder_jarfile_path, \"mo\", precise=1)\n",
    "annotations_noblecoder_partial = annotate_using_noble_coder(descriptions, noblecoder_jarfile_path, \"mo\", precise=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ontology = Ontology(ontology_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same preprocessing steps but on the query string.\n",
    "query = open(\"/Users/irbraun/Desktop/autophagy.txt\",\"r\").read()\n",
    "query = {0:query}\n",
    "query_full_preprocessing = {i:\" \".join(preprocess_string(d)) for i,d in query.items()}\n",
    "query_simple_preprocessing = {i:\" \".join(simple_preprocess(d)) for i,d in query.items()}\n",
    "query_no_stopwords = {i:remove_stopwords(d) for i,d in query.items()}\n",
    "get_pos_tokens = lambda text,pos: \" \".join([t[0] for t in nltk.pos_tag(word_tokenize(text)) if t[1].lower()==pos.lower()])\n",
    "query_noun_only =  {i:get_pos_tokens(d,\"NN\") for i,d in query.items()}\n",
    "query_noun_only_full_preprocessing = {i:\" \".join(preprocess_string(d)) for i,d in query_noun_only.items()}\n",
    "query_noun_only_simple_preprocessing = {i:\" \".join(simple_preprocess(d)) for i,d in query_noun_only.items()}\n",
    "query_adj_only =  {i:get_pos_tokens(d,\"JJ\") for i,d in query.items()}\n",
    "query_adj_only_full_preprocessing = {i:\" \".join(preprocess_string(d)) for i,d in query_adj_only.items()}\n",
    "query_adj_only_simple_preprocessing = {i:\" \".join(simple_preprocess(d)) for i,d in query_adj_only.items()}\n",
    "query_annotations_noblecoder_precise = annotate_using_noble_coder(query, noblecoder_jarfile_path, \"mo\", precise=1)\n",
    "query_annotations_noblecoder_partial = annotate_using_noble_coder(query, noblecoder_jarfile_path, \"mo\", precise=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a list of tuples, each tuple will be used to build to find a matrix of pairwise distances.\n",
    "# The naming scheme for methods should include both a name substring and then a hyperparameter substring\n",
    "# separated by a colon. Anything after the colon will be removed from the name and put in a separate \n",
    "# column in the output table. This is so that the name column can be directly used for making figures, so\n",
    "# if two hyperparameter choices are both going to be used in a figure, keep them in the name substring not\n",
    "# the hyperparameter section. The required items in each tuple are:\n",
    "# Index 0: name of the method\n",
    "# Index 1: function to call for running this method\n",
    "# Index 2: arguments to pass to that function as dictionary of keyword args\n",
    "# Index 3: distance metric to apply to vectors generated with that method\n",
    "\n",
    "\n",
    "name_function_args_tuples = [\n",
    "    \n",
    "    # Methods that use neural networks to generate embeddings.\n",
    "    (\"Doc2Vec Wikipedia:Size=300\", pw.pairwise_doc2vec_twogroup, {\"model\":doc2vec_wiki_model, \"object_dict_1\":query, \"object_dict_2\":descriptions, \"metric\":\"cosine\"}, spatial.distance.cosine),\n",
    "    (\"Doc2Vec PubMed:Size=100\", pw.pairwise_doc2vec_twogroup, {\"model\":doc2vec_pubmed_model, \"object_dict_1\":query, \"object_dict_2\":descriptions, \"metric\":\"cosine\"}, spatial.distance.cosine),\n",
    "\n",
    "    #(\"BERT Base:Layers=2,Concatenated\", pw.pairwise_bert_onegroup, {\"model\":bert_model_base, \"tokenizer\":bert_tokenizer_base, \"object_dict\":descriptions, \"metric\":\"cosine\", \"method\":\"concat\", \"layers\":2}, spatial.distance.cosine),\n",
    "    #(\"BERT Base:Layers=3,Concatenated\", pw.pairwise_bert_onegroup, {\"model\":bert_model_base, \"tokenizer\":bert_tokenizer_base, \"object_dict\":descriptions, \"metric\":\"cosine\", \"method\":\"concat\", \"layers\":3}, spatial.distance.cosine),\n",
    "    #(\"BERT Base:Layers=4,Concatenated\", pw.pairwise_bert_onegroup, {\"model\":bert_model_base, \"tokenizer\":bert_tokenizer_base, \"object_dict\":descriptions, \"metric\":\"cosine\", \"method\":\"concat\", \"layers\":4}, spatial.distance.cosine),\n",
    "    #(\"BERT Base:Layers=2,Summed\", pw.pairwise_bert_onegroup, {\"model\":bert_model_base, \"tokenizer\":bert_tokenizer_base, \"object_dict\":descriptions, \"metric\":\"cosine\", \"method\":\"sum\", \"layers\":2}, spatial.distance.cosine),\n",
    "    #(\"BERT Base:Layers=3,Summed\", pw.pairwise_bert_onegroup, {\"model\":bert_model_base, \"tokenizer\":bert_tokenizer_base, \"object_dict\":descriptions, \"metric\":\"cosine\", \"method\":\"sum\", \"layers\":3}, spatial.distance.cosine),\n",
    "    #(\"BERT Base:Layers=4,Summed\", pw.pairwise_bert_onegroup, {\"model\":bert_model_base, \"tokenizer\":bert_tokenizer_base, \"object_dict\":descriptions, \"metric\":\"cosine\", \"method\":\"sum\", \"layers\":4}, spatial.distance.cosine),\n",
    "    #(\"BioBERT:PMC,Layers=2,Concatenated\", pw.pairwise_bert_onegroup, {\"model\":bert_model_pmc, \"tokenizer\":bert_tokenizer_pmc, \"object_dict\":descriptions, \"metric\":\"cosine\", \"method\":\"concat\", \"layers\":2}, spatial.distance.cosine),\n",
    "    #(\"BioBERT:PMC,Layers=3,Concatenated\", pw.pairwise_bert_onegroup, {\"model\":bert_model_pmc, \"tokenizer\":bert_tokenizer_pmc, \"object_dict\":descriptions, \"metric\":\"cosine\", \"method\":\"concat\", \"layers\":3}, spatial.distance.cosine),\n",
    "    #(\"BioBERT:PMC,Layers=4,Concatenated\", pw.pairwise_bert_onegroup, {\"model\":bert_model_pmc, \"tokenizer\":bert_tokenizer_pmc, \"object_dict\":descriptions, \"metric\":\"cosine\", \"method\":\"concat\", \"layers\":4}, spatial.distance.cosine),\n",
    "    #(\"BioBERT:PubMed,Layers=4,Concatenated\", pw.pairwise_bert_onegroup, {\"model\":bert_model_pubmed, \"tokenizer\":bert_tokenizer_pubmed, \"object_dict\":descriptions, \"metric\":\"cosine\", \"method\":\"concat\", \"layers\":4}, spatial.distance.cosine),\n",
    "    #(\"BioBERT:PubMed,PMC,Layers=4,Concatenated\", pw.pairwise_bert_onegroup, {\"model\":bert_model_pubmed_pmc, \"tokenizer\":bert_tokenizer_pubmed_pmc, \"object_dict\":descriptions, \"metric\":\"cosine\", \"method\":\"concat\", \"layers\":4}, spatial.distance.cosine),\n",
    "        \n",
    "    # Methods that use variations on the n-grams approach with full preprocessing (includes stemming).\n",
    "    (\"N-Grams:Full,Words,1-grams,2-grams\", pw.pairwise_ngrams_twogroup, {\"object_dict_1\":query_full_preprocessing, \"object_dict_2\":descriptions_full_preprocessing, \"metric\":\"cosine\", \"binary\":False, \"analyzer\":\"word\", \"ngram_range\":(1,2),\"max_features\":10000, \"tfidf\":False}, spatial.distance.cosine),\n",
    "    (\"N-Grams:Full,Words,1-grams,2-grams,Binary\", pw.pairwise_ngrams_twogroup, {\"object_dict_1\":query_full_preprocessing, \"object_dict_2\":descriptions_full_preprocessing, \"metric\":\"jaccard\", \"binary\":True, \"analyzer\":\"word\", \"ngram_range\":(1,2), \"max_features\":10000, \"tfidf\":False}, spatial.distance.jaccard),\n",
    "    (\"N-Grams:Full,Words,1-grams\", pw.pairwise_ngrams_twogroup, {\"object_dict_1\":query_full_preprocessing, \"object_dict_2\":descriptions_full_preprocessing, \"metric\":\"cosine\", \"binary\":False, \"analyzer\":\"word\", \"ngram_range\":(1,1), \"max_features\":10000, \"tfidf\":False}, spatial.distance.cosine),\n",
    "    (\"N-Grams:Full,Words,1-grams,Binary\", pw.pairwise_ngrams_twogroup, {\"object_dict_1\":query_full_preprocessing, \"object_dict_2\":descriptions_full_preprocessing, \"metric\":\"jaccard\", \"binary\":True, \"analyzer\":\"word\", \"ngram_range\":(1,1), \"max_features\":10000, \"tfidf\":False}, spatial.distance.jaccard),\n",
    "    (\"N-Grams:Full,Words,1-grams,2-grams,TFIDF\", pw.pairwise_ngrams_twogroup, {\"object_dict_1\":query_full_preprocessing, \"object_dict_2\":descriptions_full_preprocessing, \"metric\":\"cosine\", \"binary\":False, \"analyzer\":\"word\", \"ngram_range\":(1,2),\"max_features\":10000, \"tfidf\":True}, spatial.distance.cosine),\n",
    "    (\"N-Grams:Full,Words,1-grams,2-grams,Binary,TFIDF\", pw.pairwise_ngrams_twogroup, {\"object_dict_1\":query_full_preprocessing, \"object_dict_2\":descriptions_full_preprocessing, \"metric\":\"cosine\", \"binary\":True, \"analyzer\":\"word\", \"ngram_range\":(1,2), \"max_features\":10000, \"tfidf\":True}, spatial.distance.cosine),\n",
    "    (\"N-Grams:Full,Words,1-grams,TFIDF\", pw.pairwise_ngrams_twogroup, {\"object_dict_1\":query_full_preprocessing, \"object_dict_2\":descriptions_full_preprocessing, \"metric\":\"cosine\", \"binary\":False, \"analyzer\":\"word\", \"ngram_range\":(1,1), \"max_features\":10000, \"tfidf\":True}, spatial.distance.cosine),\n",
    "    (\"N-Grams:Full,Words,1-grams,Binary,TFIDF\", pw.pairwise_ngrams_twogroup, {\"object_dict_1\":query_full_preprocessing, \"object_dict_2\":descriptions_full_preprocessing, \"metric\":\"cosine\", \"binary\":True, \"analyzer\":\"word\", \"ngram_range\":(1,1), \"max_features\":10000, \"tfidf\":True}, spatial.distance.cosine),\n",
    "    \n",
    "    # Methods that use variations on the n-grams approach with simple preprocessing (no stemming).\n",
    "    (\"N-Grams:simple,Words,1-grams,2-grams\", pw.pairwise_ngrams_twogroup, {\"object_dict_1\":query_simple_preprocessing, \"object_dict_2\":descriptions_simple_preprocessing, \"metric\":\"cosine\", \"binary\":False, \"analyzer\":\"word\", \"ngram_range\":(1,2),\"max_features\":10000, \"tfidf\":False}, spatial.distance.cosine),\n",
    "    (\"N-Grams:simple,Words,1-grams,2-grams,Binary\", pw.pairwise_ngrams_twogroup, {\"object_dict_1\":query_simple_preprocessing, \"object_dict_2\":descriptions_simple_preprocessing, \"metric\":\"jaccard\", \"binary\":True, \"analyzer\":\"word\", \"ngram_range\":(1,2), \"max_features\":10000, \"tfidf\":False}, spatial.distance.jaccard),\n",
    "    (\"N-Grams:simple,Words,1-grams\", pw.pairwise_ngrams_twogroup, {\"object_dict_1\":query_simple_preprocessing, \"object_dict_2\":descriptions_simple_preprocessing, \"metric\":\"cosine\", \"binary\":False, \"analyzer\":\"word\", \"ngram_range\":(1,1), \"max_features\":10000, \"tfidf\":False}, spatial.distance.cosine),\n",
    "    (\"N-Grams:simple,Words,1-grams,Binary\", pw.pairwise_ngrams_twogroup, {\"object_dict_1\":query_simple_preprocessing, \"object_dict_2\":descriptions_simple_preprocessing, \"metric\":\"jaccard\", \"binary\":True, \"analyzer\":\"word\", \"ngram_range\":(1,1), \"max_features\":10000, \"tfidf\":False}, spatial.distance.jaccard),\n",
    "    (\"N-Grams:simple,Words,1-grams,2-grams,TFIDF\", pw.pairwise_ngrams_twogroup, {\"object_dict_1\":query_simple_preprocessing, \"object_dict_2\":descriptions_simple_preprocessing, \"metric\":\"cosine\", \"binary\":False, \"analyzer\":\"word\", \"ngram_range\":(1,2),\"max_features\":10000, \"tfidf\":True}, spatial.distance.cosine),\n",
    "    (\"N-Grams:simple,Words,1-grams,2-grams,Binary,TFIDF\", pw.pairwise_ngrams_twogroup, {\"object_dict_1\":query_simple_preprocessing, \"object_dict_2\":descriptions_simple_preprocessing, \"metric\":\"cosine\", \"binary\":True, \"analyzer\":\"word\", \"ngram_range\":(1,2), \"max_features\":10000, \"tfidf\":True}, spatial.distance.cosine),\n",
    "    (\"N-Grams:simple,Words,1-grams,TFIDF\", pw.pairwise_ngrams_twogroup, {\"object_dict_1\":query_simple_preprocessing, \"object_dict_2\":descriptions_simple_preprocessing, \"metric\":\"cosine\", \"binary\":False, \"analyzer\":\"word\", \"ngram_range\":(1,1), \"max_features\":10000, \"tfidf\":True}, spatial.distance.cosine),\n",
    "    (\"N-Grams:simple,Words,1-grams,Binary,TFIDF\", pw.pairwise_ngrams_twogroup, {\"object_dict_1\":query_simple_preprocessing, \"object_dict_2\":descriptions_simple_preprocessing, \"metric\":\"cosine\", \"binary\":True, \"analyzer\":\"word\", \"ngram_range\":(1,1), \"max_features\":10000, \"tfidf\":True}, spatial.distance.cosine),\n",
    "    \n",
    "    # Methods that use variations on the n-grams approach selecting for specific parts-of-speech.\n",
    "    (\"N-Grams:Full,Nouns,1-grams\", pw.pairwise_ngrams_twogroup, {\"object_dict_1\":query_noun_only_full_preprocessing,\"object_dict_2\":descriptions_noun_only_full_preprocessing, \"metric\":\"cosine\", \"binary\":False, \"analyzer\":\"word\", \"ngram_range\":(1,1), \"max_features\":10000, \"tfidf\":False}, spatial.distance.cosine),\n",
    "    (\"N-Grams:Full,Nouns,1-grams,Binary\", pw.pairwise_ngrams_twogroup, {\"object_dict_1\":query_noun_only_full_preprocessing,\"object_dict_2\":descriptions_noun_only_full_preprocessing, \"metric\":\"jaccard\", \"binary\":True, \"analyzer\":\"word\", \"ngram_range\":(1,1), \"max_features\":10000, \"tfidf\":False}, spatial.distance.jaccard),\n",
    "    (\"N-Grams:Full,Nouns,1-grams,TFIDF\", pw.pairwise_ngrams_twogroup, {\"object_dict_1\":query_noun_only_full_preprocessing,\"object_dict_2\":descriptions_noun_only_full_preprocessing, \"metric\":\"cosine\", \"binary\":False, \"analyzer\":\"word\", \"ngram_range\":(1,1), \"max_features\":10000, \"tfidf\":True}, spatial.distance.cosine),\n",
    "    (\"N-Grams:Full,Nouns,1-grams,Binary,TFIDF\", pw.pairwise_ngrams_twogroup, {\"object_dict_1\":query_noun_only_full_preprocessing,\"object_dict_2\":descriptions_noun_only_full_preprocessing, \"metric\":\"cosine\", \"binary\":True, \"analyzer\":\"word\", \"ngram_range\":(1,1), \"max_features\":10000, \"tfidf\":True}, spatial.distance.cosine),\n",
    "    (\"N-Grams:Full,Adjectives,1-grams\", pw.pairwise_ngrams_twogroup, {\"object_dict_1\":query_adj_only_full_preprocessing,\"object_dict_2\":descriptions_adj_only_full_preprocessing, \"metric\":\"cosine\", \"binary\":False, \"analyzer\":\"word\", \"ngram_range\":(1,1), \"max_features\":10000, \"tfidf\":False}, spatial.distance.cosine),\n",
    "    (\"N-Grams:Full,Adjectives,1-grams,Binary\", pw.pairwise_ngrams_twogroup, {\"object_dict_1\":query_adj_only_full_preprocessing,\"object_dict_2\":descriptions_adj_only_full_preprocessing, \"metric\":\"jaccard\", \"binary\":True, \"analyzer\":\"word\", \"ngram_range\":(1,1), \"max_features\":10000, \"tfidf\":False}, spatial.distance.jaccard),\n",
    "    (\"N-Grams:Full,Adjectives,1-grams,TFIDF\", pw.pairwise_ngrams_twogroup, {\"object_dict_1\":query_adj_only_full_preprocessing,\"object_dict_2\":descriptions_adj_only_full_preprocessing, \"metric\":\"cosine\", \"binary\":False, \"analyzer\":\"word\", \"ngram_range\":(1,1), \"max_features\":10000, \"tfidf\":True}, spatial.distance.cosine),\n",
    "    (\"N-Grams:Full,Adjectives,1-grams,Binary,TFIDF\", pw.pairwise_ngrams_twogroup, {\"object_dict_1\":query_adj_only_full_preprocessing,\"object_dict_2\":descriptions_adj_only_full_preprocessing, \"metric\":\"cosine\", \"binary\":True, \"analyzer\":\"word\", \"ngram_range\":(1,1), \"max_features\":10000, \"tfidf\":True}, spatial.distance.cosine),\n",
    "    \n",
    "    # Methods that use terms inferred from automated annotation of the text.\n",
    "    (\"NOBLE Coder:Precise\", pw.pairwise_annotations_twogroup, {\"annotations_dict_1\":query_annotations_noblecoder_precise,\"annotations_dict_2\":annotations_noblecoder_precise, \"ontology\":ontology, \"binary\":True, \"metric\":\"jaccard\", \"tfidf\":False}, spatial.distance.jaccard),\n",
    "    (\"NOBLE Coder:Partial\", pw.pairwise_annotations_twogroup, {\"annotations_dict_1\":query_annotations_noblecoder_partial,\"annotations_dict_2\":annotations_noblecoder_partial, \"ontology\":ontology, \"binary\":True, \"metric\":\"jaccard\", \"tfidf\":False}, spatial.distance.jaccard),\n",
    "    (\"NOBLE Coder:Precise,TFIDF\", pw.pairwise_annotations_twogroup, {\"annotations_dict_1\":query_annotations_noblecoder_precise,\"annotations_dict_2\":annotations_noblecoder_precise, \"ontology\":ontology, \"binary\":True, \"metric\":\"cosine\", \"tfidf\":True}, spatial.distance.cosine),\n",
    "    (\"NOBLE Coder:Partial,TFIDF\", pw.pairwise_annotations_twogroup, {\"annotations_dict_1\":query_annotations_noblecoder_partial,\"annotations_dict_2\":annotations_noblecoder_partial, \"ontology\":ontology, \"binary\":True, \"metric\":\"cosine\", \"tfidf\":True}, spatial.distance.cosine),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc2Vec Wikipedia:Size=300                         00:00:09\n",
      "Doc2Vec PubMed:Size=100                            00:00:02\n",
      "N-Grams:Full,Words,1-grams,2-grams                 00:00:01\n",
      "N-Grams:Full,Words,1-grams,2-grams,Binary          00:00:01\n",
      "N-Grams:Full,Words,1-grams                         00:00:00\n",
      "N-Grams:Full,Words,1-grams,Binary                  00:00:00\n",
      "N-Grams:Full,Words,1-grams,2-grams,TFIDF           00:00:00\n",
      "N-Grams:Full,Words,1-grams,2-grams,Binary,TFIDF    00:00:00\n",
      "N-Grams:Full,Words,1-grams,TFIDF                   00:00:00\n",
      "N-Grams:Full,Words,1-grams,Binary,TFIDF            00:00:00\n",
      "N-Grams:simple,Words,1-grams,2-grams               00:00:01\n",
      "N-Grams:simple,Words,1-grams,2-grams,Binary        00:00:01\n",
      "N-Grams:simple,Words,1-grams                       00:00:00\n",
      "N-Grams:simple,Words,1-grams,Binary                00:00:00\n",
      "N-Grams:simple,Words,1-grams,2-grams,TFIDF         00:00:01\n",
      "N-Grams:simple,Words,1-grams,2-grams,Binary,TFIDF  00:00:01\n",
      "N-Grams:simple,Words,1-grams,TFIDF                 00:00:00\n",
      "N-Grams:simple,Words,1-grams,Binary,TFIDF          00:00:00\n",
      "N-Grams:Full,Nouns,1-grams                         00:00:00\n",
      "N-Grams:Full,Nouns,1-grams,Binary                  00:00:00\n",
      "N-Grams:Full,Nouns,1-grams,TFIDF                   00:00:00\n",
      "N-Grams:Full,Nouns,1-grams,Binary,TFIDF            00:00:00\n",
      "N-Grams:Full,Adjectives,1-grams                    00:00:00\n",
      "N-Grams:Full,Adjectives,1-grams,Binary             00:00:00\n",
      "N-Grams:Full,Adjectives,1-grams,TFIDF              00:00:00\n",
      "N-Grams:Full,Adjectives,1-grams,Binary,TFIDF       00:00:00\n",
      "NOBLE Coder:Precise                                00:00:00\n",
      "NOBLE Coder:Partial                                00:00:01\n",
      "NOBLE Coder:Precise,TFIDF                          00:00:00\n",
      "NOBLE Coder:Partial,TFIDF                          00:00:01\n"
     ]
    }
   ],
   "source": [
    "# Generate all the pairwise distance matrices (not in parallel).\n",
    "graphs = {}\n",
    "names = []\n",
    "durations = []\n",
    "for tup in name_function_args_tuples:\n",
    "    graph,duration = function_wrapper_with_duration(function=tup[1], args=tup[2])\n",
    "    graphs[tup[0]] = graph\n",
    "    names.append(tup[0])\n",
    "    durations.append(to_hms(duration))\n",
    "    print(\"{:50} {}\".format(tup[0],to_hms(duration)))\n",
    "durations_df = pd.DataFrame({\"method\":names,\"duration\":durations})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>from</th>\n",
       "      <th>to</th>\n",
       "      <th>Doc2Vec Wikipedia:Size=300</th>\n",
       "      <th>Doc2Vec PubMed:Size=100</th>\n",
       "      <th>N-Grams:Full,Words,1-grams,2-grams</th>\n",
       "      <th>N-Grams:Full,Words,1-grams,2-grams,Binary</th>\n",
       "      <th>N-Grams:Full,Words,1-grams</th>\n",
       "      <th>N-Grams:Full,Words,1-grams,Binary</th>\n",
       "      <th>N-Grams:Full,Words,1-grams,2-grams,TFIDF</th>\n",
       "      <th>N-Grams:Full,Words,1-grams,2-grams,Binary,TFIDF</th>\n",
       "      <th>N-Grams:Full,Words,1-grams,TFIDF</th>\n",
       "      <th>N-Grams:Full,Words,1-grams,Binary,TFIDF</th>\n",
       "      <th>N-Grams:simple,Words,1-grams,2-grams</th>\n",
       "      <th>N-Grams:simple,Words,1-grams,2-grams,Binary</th>\n",
       "      <th>N-Grams:simple,Words,1-grams</th>\n",
       "      <th>N-Grams:simple,Words,1-grams,Binary</th>\n",
       "      <th>N-Grams:simple,Words,1-grams,2-grams,TFIDF</th>\n",
       "      <th>N-Grams:simple,Words,1-grams,2-grams,Binary,TFIDF</th>\n",
       "      <th>N-Grams:simple,Words,1-grams,TFIDF</th>\n",
       "      <th>N-Grams:simple,Words,1-grams,Binary,TFIDF</th>\n",
       "      <th>N-Grams:Full,Nouns,1-grams</th>\n",
       "      <th>N-Grams:Full,Nouns,1-grams,Binary</th>\n",
       "      <th>N-Grams:Full,Nouns,1-grams,TFIDF</th>\n",
       "      <th>N-Grams:Full,Nouns,1-grams,Binary,TFIDF</th>\n",
       "      <th>N-Grams:Full,Adjectives,1-grams</th>\n",
       "      <th>N-Grams:Full,Adjectives,1-grams,Binary</th>\n",
       "      <th>N-Grams:Full,Adjectives,1-grams,TFIDF</th>\n",
       "      <th>N-Grams:Full,Adjectives,1-grams,Binary,TFIDF</th>\n",
       "      <th>NOBLE Coder:Precise</th>\n",
       "      <th>NOBLE Coder:Partial</th>\n",
       "      <th>NOBLE Coder:Precise,TFIDF</th>\n",
       "      <th>NOBLE Coder:Partial,TFIDF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.402668</td>\n",
       "      <td>0.096372</td>\n",
       "      <td>0.934962</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.917216</td>\n",
       "      <td>0.969231</td>\n",
       "      <td>0.975861</td>\n",
       "      <td>0.990633</td>\n",
       "      <td>0.958982</td>\n",
       "      <td>0.978215</td>\n",
       "      <td>0.944005</td>\n",
       "      <td>0.966887</td>\n",
       "      <td>0.925083</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.982520</td>\n",
       "      <td>0.982311</td>\n",
       "      <td>0.969876</td>\n",
       "      <td>0.964319</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.592233</td>\n",
       "      <td>0.676190</td>\n",
       "      <td>0.661614</td>\n",
       "      <td>0.820084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.347427</td>\n",
       "      <td>0.312569</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>0.819782</td>\n",
       "      <td>0.899158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0.405793</td>\n",
       "      <td>0.233833</td>\n",
       "      <td>0.874477</td>\n",
       "      <td>0.932515</td>\n",
       "      <td>0.836170</td>\n",
       "      <td>0.894231</td>\n",
       "      <td>0.952482</td>\n",
       "      <td>0.952371</td>\n",
       "      <td>0.926126</td>\n",
       "      <td>0.912557</td>\n",
       "      <td>0.913132</td>\n",
       "      <td>0.953586</td>\n",
       "      <td>0.890804</td>\n",
       "      <td>0.919708</td>\n",
       "      <td>0.963891</td>\n",
       "      <td>0.959358</td>\n",
       "      <td>0.945586</td>\n",
       "      <td>0.927150</td>\n",
       "      <td>0.896283</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.935968</td>\n",
       "      <td>0.920319</td>\n",
       "      <td>0.959107</td>\n",
       "      <td>0.968750</td>\n",
       "      <td>0.975273</td>\n",
       "      <td>0.961189</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.591160</td>\n",
       "      <td>0.521070</td>\n",
       "      <td>0.691006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0.335423</td>\n",
       "      <td>0.378854</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.886792</td>\n",
       "      <td>0.948276</td>\n",
       "      <td>0.951849</td>\n",
       "      <td>0.976353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.349960</td>\n",
       "      <td>0.387915</td>\n",
       "      <td>0.932209</td>\n",
       "      <td>0.950617</td>\n",
       "      <td>0.918350</td>\n",
       "      <td>0.931034</td>\n",
       "      <td>0.976083</td>\n",
       "      <td>0.970167</td>\n",
       "      <td>0.967422</td>\n",
       "      <td>0.951620</td>\n",
       "      <td>0.892376</td>\n",
       "      <td>0.970000</td>\n",
       "      <td>0.867401</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.979842</td>\n",
       "      <td>0.987146</td>\n",
       "      <td>0.972439</td>\n",
       "      <td>0.983640</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.913793</td>\n",
       "      <td>0.852901</td>\n",
       "      <td>0.844832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0.500701</td>\n",
       "      <td>0.157152</td>\n",
       "      <td>0.929649</td>\n",
       "      <td>0.968944</td>\n",
       "      <td>0.914879</td>\n",
       "      <td>0.954545</td>\n",
       "      <td>0.977744</td>\n",
       "      <td>0.980768</td>\n",
       "      <td>0.968528</td>\n",
       "      <td>0.966423</td>\n",
       "      <td>0.871389</td>\n",
       "      <td>0.968326</td>\n",
       "      <td>0.839376</td>\n",
       "      <td>0.953020</td>\n",
       "      <td>0.965681</td>\n",
       "      <td>0.980008</td>\n",
       "      <td>0.949264</td>\n",
       "      <td>0.968343</td>\n",
       "      <td>0.937006</td>\n",
       "      <td>0.955556</td>\n",
       "      <td>0.974367</td>\n",
       "      <td>0.971506</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.537500</td>\n",
       "      <td>0.703390</td>\n",
       "      <td>0.681654</td>\n",
       "      <td>0.810955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0.460424</td>\n",
       "      <td>0.404019</td>\n",
       "      <td>0.891072</td>\n",
       "      <td>0.944828</td>\n",
       "      <td>0.875748</td>\n",
       "      <td>0.923913</td>\n",
       "      <td>0.964049</td>\n",
       "      <td>0.964806</td>\n",
       "      <td>0.963395</td>\n",
       "      <td>0.951558</td>\n",
       "      <td>0.898805</td>\n",
       "      <td>0.956757</td>\n",
       "      <td>0.885062</td>\n",
       "      <td>0.940171</td>\n",
       "      <td>0.962875</td>\n",
       "      <td>0.966682</td>\n",
       "      <td>0.961412</td>\n",
       "      <td>0.958623</td>\n",
       "      <td>0.913431</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.960821</td>\n",
       "      <td>0.928015</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.482353</td>\n",
       "      <td>0.685714</td>\n",
       "      <td>0.584773</td>\n",
       "      <td>0.788256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0.422794</td>\n",
       "      <td>0.451070</td>\n",
       "      <td>0.850214</td>\n",
       "      <td>0.939560</td>\n",
       "      <td>0.818992</td>\n",
       "      <td>0.898990</td>\n",
       "      <td>0.927447</td>\n",
       "      <td>0.944878</td>\n",
       "      <td>0.899681</td>\n",
       "      <td>0.904329</td>\n",
       "      <td>0.837516</td>\n",
       "      <td>0.950758</td>\n",
       "      <td>0.793918</td>\n",
       "      <td>0.913669</td>\n",
       "      <td>0.934538</td>\n",
       "      <td>0.948441</td>\n",
       "      <td>0.904896</td>\n",
       "      <td>0.915488</td>\n",
       "      <td>0.925064</td>\n",
       "      <td>0.957447</td>\n",
       "      <td>0.958428</td>\n",
       "      <td>0.962241</td>\n",
       "      <td>0.912294</td>\n",
       "      <td>0.939394</td>\n",
       "      <td>0.928257</td>\n",
       "      <td>0.912213</td>\n",
       "      <td>0.525253</td>\n",
       "      <td>0.572864</td>\n",
       "      <td>0.520025</td>\n",
       "      <td>0.673403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0.299372</td>\n",
       "      <td>0.257639</td>\n",
       "      <td>0.898943</td>\n",
       "      <td>0.943396</td>\n",
       "      <td>0.865769</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.960424</td>\n",
       "      <td>0.965168</td>\n",
       "      <td>0.935772</td>\n",
       "      <td>0.936290</td>\n",
       "      <td>0.921893</td>\n",
       "      <td>0.967105</td>\n",
       "      <td>0.895672</td>\n",
       "      <td>0.946237</td>\n",
       "      <td>0.974324</td>\n",
       "      <td>0.973922</td>\n",
       "      <td>0.956986</td>\n",
       "      <td>0.952191</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.638554</td>\n",
       "      <td>0.440392</td>\n",
       "      <td>0.799154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0.316917</td>\n",
       "      <td>0.336396</td>\n",
       "      <td>0.881886</td>\n",
       "      <td>0.946237</td>\n",
       "      <td>0.849244</td>\n",
       "      <td>0.918033</td>\n",
       "      <td>0.951467</td>\n",
       "      <td>0.966149</td>\n",
       "      <td>0.926288</td>\n",
       "      <td>0.938760</td>\n",
       "      <td>0.873581</td>\n",
       "      <td>0.949153</td>\n",
       "      <td>0.834072</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.957137</td>\n",
       "      <td>0.967064</td>\n",
       "      <td>0.934049</td>\n",
       "      <td>0.947145</td>\n",
       "      <td>0.963630</td>\n",
       "      <td>0.965517</td>\n",
       "      <td>0.979878</td>\n",
       "      <td>0.966304</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.432836</td>\n",
       "      <td>0.657895</td>\n",
       "      <td>0.568844</td>\n",
       "      <td>0.779206</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   from  to  Doc2Vec Wikipedia:Size=300  Doc2Vec PubMed:Size=100  N-Grams:Full,Words,1-grams,2-grams  N-Grams:Full,Words,1-grams,2-grams,Binary  N-Grams:Full,Words,1-grams  N-Grams:Full,Words,1-grams,Binary  N-Grams:Full,Words,1-grams,2-grams,TFIDF  N-Grams:Full,Words,1-grams,2-grams,Binary,TFIDF  N-Grams:Full,Words,1-grams,TFIDF  N-Grams:Full,Words,1-grams,Binary,TFIDF  N-Grams:simple,Words,1-grams,2-grams  N-Grams:simple,Words,1-grams,2-grams,Binary  N-Grams:simple,Words,1-grams  N-Grams:simple,Words,1-grams,Binary  N-Grams:simple,Words,1-grams,2-grams,TFIDF  N-Grams:simple,Words,1-grams,2-grams,Binary,TFIDF  N-Grams:simple,Words,1-grams,TFIDF  N-Grams:simple,Words,1-grams,Binary,TFIDF  N-Grams:Full,Nouns,1-grams  N-Grams:Full,Nouns,1-grams,Binary  N-Grams:Full,Nouns,1-grams,TFIDF  N-Grams:Full,Nouns,1-grams,Binary,TFIDF  N-Grams:Full,Adjectives,1-grams  N-Grams:Full,Adjectives,1-grams,Binary  N-Grams:Full,Adjectives,1-grams,TFIDF  N-Grams:Full,Adjectives,1-grams,Binary,TFIDF  \\\n",
       "0     0   1                    0.402668                 0.096372                            0.934962                                   0.981132                    0.917216                           0.969231                                  0.975861                                         0.990633                          0.958982                                 0.978215                              0.944005                                     0.966887                      0.925083                             0.944444                                    0.982520                                           0.982311                            0.969876                                   0.964319                    1.000000                           1.000000                          1.000000                                 1.000000                         1.000000                                1.000000                               1.000000                                      1.000000   \n",
       "1     0   7                    0.347427                 0.312569                            1.000000                                   1.000000                    1.000000                           1.000000                                  1.000000                                         1.000000                          1.000000                                 1.000000                              1.000000                                     1.000000                      1.000000                             1.000000                                    1.000000                                           1.000000                            1.000000                                   1.000000                    1.000000                           1.000000                          1.000000                                 1.000000                         1.000000                                1.000000                               1.000000                                      1.000000   \n",
       "2     0   8                    0.405793                 0.233833                            0.874477                                   0.932515                    0.836170                           0.894231                                  0.952482                                         0.952371                          0.926126                                 0.912557                              0.913132                                     0.953586                      0.890804                             0.919708                                    0.963891                                           0.959358                            0.945586                                   0.927150                    0.896283                           0.909091                          0.935968                                 0.920319                         0.959107                                0.968750                               0.975273                                      0.961189   \n",
       "3     0   9                    0.335423                 0.378854                            1.000000                                   1.000000                    1.000000                           1.000000                                  1.000000                                         1.000000                          1.000000                                 1.000000                              1.000000                                     1.000000                      1.000000                             1.000000                                    1.000000                                           1.000000                            1.000000                                   1.000000                    1.000000                           1.000000                          1.000000                                 1.000000                         1.000000                                1.000000                               1.000000                                      1.000000   \n",
       "4     0  10                    0.349960                 0.387915                            0.932209                                   0.950617                    0.918350                           0.931034                                  0.976083                                         0.970167                          0.967422                                 0.951620                              0.892376                                     0.970000                      0.867401                             0.961538                                    0.979842                                           0.987146                            0.972439                                   0.983640                    1.000000                           1.000000                          1.000000                                 1.000000                         1.000000                                1.000000                               1.000000                                      1.000000   \n",
       "5     0  11                    0.500701                 0.157152                            0.929649                                   0.968944                    0.914879                           0.954545                                  0.977744                                         0.980768                          0.968528                                 0.966423                              0.871389                                     0.968326                      0.839376                             0.953020                                    0.965681                                           0.980008                            0.949264                                   0.968343                    0.937006                           0.955556                          0.974367                                 0.971506                         1.000000                                1.000000                               1.000000                                      1.000000   \n",
       "6     0  12                    0.460424                 0.404019                            0.891072                                   0.944828                    0.875748                           0.923913                                  0.964049                                         0.964806                          0.963395                                 0.951558                              0.898805                                     0.956757                      0.885062                             0.940171                                    0.962875                                           0.966682                            0.961412                                   0.958623                    0.913431                           0.909091                          0.960821                                 0.928015                         1.000000                                1.000000                               1.000000                                      1.000000   \n",
       "7     0  13                    0.422794                 0.451070                            0.850214                                   0.939560                    0.818992                           0.898990                                  0.927447                                         0.944878                          0.899681                                 0.904329                              0.837516                                     0.950758                      0.793918                             0.913669                                    0.934538                                           0.948441                            0.904896                                   0.915488                    0.925064                           0.957447                          0.958428                                 0.962241                         0.912294                                0.939394                               0.928257                                      0.912213   \n",
       "8     0  14                    0.299372                 0.257639                            0.898943                                   0.943396                    0.865769                           0.913043                                  0.960424                                         0.965168                          0.935772                                 0.936290                              0.921893                                     0.967105                      0.895672                             0.946237                                    0.974324                                           0.973922                            0.956986                                   0.952191                    1.000000                           1.000000                          1.000000                                 1.000000                         1.000000                                1.000000                               1.000000                                      1.000000   \n",
       "9     0  15                    0.316917                 0.336396                            0.881886                                   0.946237                    0.849244                           0.918033                                  0.951467                                         0.966149                          0.926288                                 0.938760                              0.873581                                     0.949153                      0.834072                             0.923077                                    0.957137                                           0.967064                            0.934049                                   0.947145                    0.963630                           0.965517                          0.979878                                 0.966304                         1.000000                                1.000000                               1.000000                                      1.000000   \n",
       "\n",
       "   NOBLE Coder:Precise  NOBLE Coder:Partial  NOBLE Coder:Precise,TFIDF  NOBLE Coder:Partial,TFIDF  \n",
       "0             0.592233             0.676190                   0.661614                   0.820084  \n",
       "1             0.818182             0.882353                   0.819782                   0.899158  \n",
       "2             0.400000             0.591160                   0.521070                   0.691006  \n",
       "3             0.886792             0.948276                   0.951849                   0.976353  \n",
       "4             0.833333             0.913793                   0.852901                   0.844832  \n",
       "5             0.537500             0.703390                   0.681654                   0.810955  \n",
       "6             0.482353             0.685714                   0.584773                   0.788256  \n",
       "7             0.525253             0.572864                   0.520025                   0.673403  \n",
       "8             0.529412             0.638554                   0.440392                   0.799154  \n",
       "9             0.432836             0.657895                   0.568844                   0.779206  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merging all of the edgelist dataframes together.\n",
    "metric_dict = {tup[0]:tup[3] for tup in name_function_args_tuples}\n",
    "methods = list(graphs.keys())\n",
    "edgelists = {k:v.edgelist for k,v in graphs.items()}\n",
    "df = pw.merge_edgelists(edgelists, default_value=0.000)\n",
    "df = pw.remove_self_loops(df)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>from</th>\n",
       "      <th>to</th>\n",
       "      <th>Doc2Vec Wikipedia:Size=300</th>\n",
       "      <th>Doc2Vec PubMed:Size=100</th>\n",
       "      <th>N-Grams:Full,Words,1-grams,2-grams</th>\n",
       "      <th>N-Grams:Full,Words,1-grams,2-grams,Binary</th>\n",
       "      <th>N-Grams:Full,Words,1-grams</th>\n",
       "      <th>N-Grams:Full,Words,1-grams,Binary</th>\n",
       "      <th>N-Grams:Full,Words,1-grams,2-grams,TFIDF</th>\n",
       "      <th>N-Grams:Full,Words,1-grams,2-grams,Binary,TFIDF</th>\n",
       "      <th>N-Grams:Full,Words,1-grams,TFIDF</th>\n",
       "      <th>N-Grams:Full,Words,1-grams,Binary,TFIDF</th>\n",
       "      <th>N-Grams:simple,Words,1-grams,2-grams</th>\n",
       "      <th>N-Grams:simple,Words,1-grams,2-grams,Binary</th>\n",
       "      <th>N-Grams:simple,Words,1-grams</th>\n",
       "      <th>N-Grams:simple,Words,1-grams,Binary</th>\n",
       "      <th>N-Grams:simple,Words,1-grams,2-grams,TFIDF</th>\n",
       "      <th>N-Grams:simple,Words,1-grams,2-grams,Binary,TFIDF</th>\n",
       "      <th>N-Grams:simple,Words,1-grams,TFIDF</th>\n",
       "      <th>N-Grams:simple,Words,1-grams,Binary,TFIDF</th>\n",
       "      <th>N-Grams:Full,Nouns,1-grams</th>\n",
       "      <th>N-Grams:Full,Nouns,1-grams,Binary</th>\n",
       "      <th>N-Grams:Full,Nouns,1-grams,TFIDF</th>\n",
       "      <th>N-Grams:Full,Nouns,1-grams,Binary,TFIDF</th>\n",
       "      <th>N-Grams:Full,Adjectives,1-grams</th>\n",
       "      <th>N-Grams:Full,Adjectives,1-grams,Binary</th>\n",
       "      <th>N-Grams:Full,Adjectives,1-grams,TFIDF</th>\n",
       "      <th>N-Grams:Full,Adjectives,1-grams,Binary,TFIDF</th>\n",
       "      <th>NOBLE Coder:Precise</th>\n",
       "      <th>NOBLE Coder:Partial</th>\n",
       "      <th>NOBLE Coder:Precise,TFIDF</th>\n",
       "      <th>NOBLE Coder:Partial,TFIDF</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3690</th>\n",
       "      <td>0</td>\n",
       "      <td>5223</td>\n",
       "      <td>46.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>26.5</td>\n",
       "      <td>133.5</td>\n",
       "      <td>51.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>164.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>495.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>642.0</td>\n",
       "      <td>44.5</td>\n",
       "      <td>177.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>189.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>427.5</td>\n",
       "      <td>96.5</td>\n",
       "      <td>438.0</td>\n",
       "      <td>509.0</td>\n",
       "      <td>753.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>805.0</td>\n",
       "      <td>720.0</td>\n",
       "      <td>264.5</td>\n",
       "      <td>27.0</td>\n",
       "      <td>903.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>267.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>0</td>\n",
       "      <td>394</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2417.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>70.5</td>\n",
       "      <td>123.0</td>\n",
       "      <td>140.5</td>\n",
       "      <td>33.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>84.5</td>\n",
       "      <td>48.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>415.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>381.0</td>\n",
       "      <td>372.0</td>\n",
       "      <td>394.0</td>\n",
       "      <td>40.5</td>\n",
       "      <td>325.0</td>\n",
       "      <td>439.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>811.5</td>\n",
       "      <td>544.0</td>\n",
       "      <td>396.0</td>\n",
       "      <td>267.716667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>0</td>\n",
       "      <td>392</td>\n",
       "      <td>659.0</td>\n",
       "      <td>662.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>55.5</td>\n",
       "      <td>137.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>232.0</td>\n",
       "      <td>18.5</td>\n",
       "      <td>210.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>447.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>416.0</td>\n",
       "      <td>389.0</td>\n",
       "      <td>485.0</td>\n",
       "      <td>40.5</td>\n",
       "      <td>443.0</td>\n",
       "      <td>436.0</td>\n",
       "      <td>1002.0</td>\n",
       "      <td>201.0</td>\n",
       "      <td>1341.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>274.383333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1215</th>\n",
       "      <td>0</td>\n",
       "      <td>1362</td>\n",
       "      <td>35.0</td>\n",
       "      <td>268.0</td>\n",
       "      <td>299.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>251.0</td>\n",
       "      <td>59.5</td>\n",
       "      <td>332.0</td>\n",
       "      <td>252.0</td>\n",
       "      <td>254.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>161.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>203.0</td>\n",
       "      <td>196.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>503.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>580.0</td>\n",
       "      <td>391.0</td>\n",
       "      <td>574.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>596.0</td>\n",
       "      <td>891.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>237.0</td>\n",
       "      <td>620.0</td>\n",
       "      <td>819.0</td>\n",
       "      <td>288.116667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3106</th>\n",
       "      <td>0</td>\n",
       "      <td>4639</td>\n",
       "      <td>195.0</td>\n",
       "      <td>239.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>176.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>107.5</td>\n",
       "      <td>178.0</td>\n",
       "      <td>253.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>248.5</td>\n",
       "      <td>34.0</td>\n",
       "      <td>275.0</td>\n",
       "      <td>35.5</td>\n",
       "      <td>102.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>419.0</td>\n",
       "      <td>486.0</td>\n",
       "      <td>461.0</td>\n",
       "      <td>911.0</td>\n",
       "      <td>512.0</td>\n",
       "      <td>73.5</td>\n",
       "      <td>589.0</td>\n",
       "      <td>670.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>791.5</td>\n",
       "      <td>832.0</td>\n",
       "      <td>217.0</td>\n",
       "      <td>291.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1818</th>\n",
       "      <td>0</td>\n",
       "      <td>2034</td>\n",
       "      <td>63.0</td>\n",
       "      <td>1421.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>275.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>18.5</td>\n",
       "      <td>69.0</td>\n",
       "      <td>231.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>310.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>336.0</td>\n",
       "      <td>715.0</td>\n",
       "      <td>527.5</td>\n",
       "      <td>193.0</td>\n",
       "      <td>576.0</td>\n",
       "      <td>727.0</td>\n",
       "      <td>468.0</td>\n",
       "      <td>982.0</td>\n",
       "      <td>1267.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>307.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>0</td>\n",
       "      <td>287</td>\n",
       "      <td>1988.0</td>\n",
       "      <td>1971.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>346.0</td>\n",
       "      <td>10.5</td>\n",
       "      <td>387.0</td>\n",
       "      <td>368.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>291.5</td>\n",
       "      <td>592.0</td>\n",
       "      <td>563.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>684.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>309.766667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1035</th>\n",
       "      <td>0</td>\n",
       "      <td>1149</td>\n",
       "      <td>240.0</td>\n",
       "      <td>1152.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>38.5</td>\n",
       "      <td>152.0</td>\n",
       "      <td>215.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>196.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>24.5</td>\n",
       "      <td>50.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>384.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>337.0</td>\n",
       "      <td>299.0</td>\n",
       "      <td>728.5</td>\n",
       "      <td>335.0</td>\n",
       "      <td>513.0</td>\n",
       "      <td>440.0</td>\n",
       "      <td>169.5</td>\n",
       "      <td>618.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>2643.0</td>\n",
       "      <td>327.033333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2211</th>\n",
       "      <td>0</td>\n",
       "      <td>2440</td>\n",
       "      <td>729.0</td>\n",
       "      <td>1083.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>321.0</td>\n",
       "      <td>933.0</td>\n",
       "      <td>314.0</td>\n",
       "      <td>466.0</td>\n",
       "      <td>322.0</td>\n",
       "      <td>16.5</td>\n",
       "      <td>316.0</td>\n",
       "      <td>318.0</td>\n",
       "      <td>2253.5</td>\n",
       "      <td>536.0</td>\n",
       "      <td>2044.0</td>\n",
       "      <td>411.0</td>\n",
       "      <td>337.816667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1237</th>\n",
       "      <td>0</td>\n",
       "      <td>1384</td>\n",
       "      <td>421.0</td>\n",
       "      <td>1372.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>161.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>306.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>383.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>573.5</td>\n",
       "      <td>79.0</td>\n",
       "      <td>287.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>463.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>47.5</td>\n",
       "      <td>803.0</td>\n",
       "      <td>551.0</td>\n",
       "      <td>673.5</td>\n",
       "      <td>87.0</td>\n",
       "      <td>662.0</td>\n",
       "      <td>473.0</td>\n",
       "      <td>551.5</td>\n",
       "      <td>191.0</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>351.233333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      from    to  Doc2Vec Wikipedia:Size=300  Doc2Vec PubMed:Size=100  N-Grams:Full,Words,1-grams,2-grams  N-Grams:Full,Words,1-grams,2-grams,Binary  N-Grams:Full,Words,1-grams  N-Grams:Full,Words,1-grams,Binary  N-Grams:Full,Words,1-grams,2-grams,TFIDF  N-Grams:Full,Words,1-grams,2-grams,Binary,TFIDF  N-Grams:Full,Words,1-grams,TFIDF  N-Grams:Full,Words,1-grams,Binary,TFIDF  N-Grams:simple,Words,1-grams,2-grams  N-Grams:simple,Words,1-grams,2-grams,Binary  N-Grams:simple,Words,1-grams  N-Grams:simple,Words,1-grams,Binary  N-Grams:simple,Words,1-grams,2-grams,TFIDF  N-Grams:simple,Words,1-grams,2-grams,Binary,TFIDF  N-Grams:simple,Words,1-grams,TFIDF  N-Grams:simple,Words,1-grams,Binary,TFIDF  N-Grams:Full,Nouns,1-grams  N-Grams:Full,Nouns,1-grams,Binary  N-Grams:Full,Nouns,1-grams,TFIDF  N-Grams:Full,Nouns,1-grams,Binary,TFIDF  N-Grams:Full,Adjectives,1-grams  N-Grams:Full,Adjectives,1-grams,Binary  N-Grams:Full,Adjectives,1-grams,TFIDF  N-Grams:Full,Adjectives,1-grams,Binary,TFIDF  \\\n",
       "3690     0  5223                        46.0                     67.0                               112.0                                       26.5                       133.5                               51.0                                     124.0                                             90.0                             164.0                                    160.0                                 495.0                                         36.0                         642.0                                 44.5                                       177.0                                               66.0                               189.0                                      102.0                       427.5                               96.5                             438.0                                    509.0                            753.0                                   193.0                                  805.0                                         720.0   \n",
       "346      0   394                         8.0                   2417.0                                79.0                                       70.5                       123.0                              140.5                                      33.0                                             66.0                              74.0                                    109.0                                  94.0                                         70.0                         118.0                                 84.5                                        48.0                                              105.0                                61.0                                       98.0                       415.0                               80.0                             381.0                                    372.0                            394.0                                    40.5                                  325.0                                         439.0   \n",
       "344      0   392                       659.0                    662.0                               162.0                                       55.5                       137.0                               65.0                                     105.0                                             69.0                              79.0                                     48.0                                 232.0                                         18.5                         210.0                                 11.0                                       130.0                                               76.0                                68.0                                       30.0                       447.0                               80.0                             416.0                                    389.0                            485.0                                    40.5                                  443.0                                         436.0   \n",
       "1215     0  1362                        35.0                    268.0                               299.0                                       96.0                       251.0                               59.5                                     332.0                                            252.0                             254.0                                    122.0                                 161.0                                         42.0                         135.0                                 16.0                                       203.0                                              196.0                               152.0                                       65.0                       503.0                               29.0                             580.0                                    391.0                            574.0                                   400.0                                  596.0                                         891.0   \n",
       "3106     0  4639                       195.0                    239.0                               130.0                                      176.0                       119.0                              107.5                                     178.0                                            253.0                             130.0                                    153.0                                 248.5                                         34.0                         275.0                                 35.5                                       102.0                                               54.0                               108.0                                       48.0                       419.0                              486.0                             461.0                                    911.0                            512.0                                    73.5                                  589.0                                         670.0   \n",
       "1818     0  2034                        63.0                   1421.0                                21.0                                      132.0                        22.0                               44.0                                      55.0                                            275.0                              40.0                                    126.0                                 108.0                                        126.0                          64.0                                 18.5                                        69.0                                              231.0                                44.0                                       73.0                       310.0                              128.0                             336.0                                    715.0                            527.5                                   193.0                                  576.0                                         727.0   \n",
       "245      0   287                      1988.0                   1971.0                                34.0                                       11.0                        49.0                                4.0                                      56.0                                             52.0                             119.0                                     57.0                                 195.0                                        141.0                         222.0                                 77.0                                        84.0                                               69.0                               106.0                                       57.0                       346.0                               10.5                             387.0                                    368.0                            666.0                                   291.5                                  592.0                                         563.0   \n",
       "1035     0  1149                       240.0                   1152.0                                97.0                                       38.5                       152.0                              215.0                                      24.0                                             10.0                              64.0                                     38.0                                 196.0                                         16.0                         200.0                                 24.5                                        50.0                                                9.0                                63.0                                       23.0                       384.0                               56.0                             337.0                                    299.0                            728.5                                   335.0                                  513.0                                         440.0   \n",
       "2211     0  2440                       729.0                   1083.0                                 3.0                                        3.0                         6.0                               25.0                                       2.0                                              6.0                               1.0                                      1.0                                   3.0                                          3.5                           3.0                                  5.0                                         2.0                                                6.0                                 1.0                                        1.0                       321.0                              933.0                             314.0                                    466.0                            322.0                                    16.5                                  316.0                                         318.0   \n",
       "1237     0  1384                       421.0                   1372.0                               101.0                                       15.0                       135.0                               36.0                                     161.0                                             62.0                             306.0                                    170.0                                 383.0                                         28.0                         573.5                                 79.0                                       287.0                                               53.0                               463.0                                      148.0                       565.0                               47.5                             803.0                                    551.0                            673.5                                    87.0                                  662.0                                         473.0   \n",
       "\n",
       "      NOBLE Coder:Precise  NOBLE Coder:Partial  NOBLE Coder:Precise,TFIDF  NOBLE Coder:Partial,TFIDF        rank  \n",
       "3690                264.5                 27.0                      903.0                      151.0  267.100000  \n",
       "346                  35.0                811.5                      544.0                      396.0  267.716667  \n",
       "344                1002.0                201.0                     1341.0                      134.0  274.383333  \n",
       "1215                 65.0                237.0                      620.0                      819.0  288.116667  \n",
       "3106                190.0                791.5                      832.0                      217.0  291.250000  \n",
       "1818                468.0                982.0                     1267.0                       75.0  307.900000  \n",
       "245                  11.0                 11.0                      684.0                       71.0  309.766667  \n",
       "1035                169.5                618.0                      676.0                     2643.0  327.033333  \n",
       "2211               2253.5                536.0                     2044.0                      411.0  337.816667  \n",
       "1237                551.5                191.0                     1001.0                      138.0  351.233333  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the mean rank of each gene for all the distance methods.\n",
    "df[methods] = df[methods].rank()\n",
    "df[\"rank\"] = df[methods].mean(axis=1)\n",
    "df = df.sort_values(by=\"rank\")\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>other</th>\n",
       "      <th>in_data</th>\n",
       "      <th>identifier</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>AT3G07525</td>\n",
       "      <td>AtATG10</td>\n",
       "      <td>True</td>\n",
       "      <td>2371</td>\n",
       "      <td>Early senescence. Late flowering. Reduced fert...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>AT3G49590</td>\n",
       "      <td>AtATG13a</td>\n",
       "      <td>True</td>\n",
       "      <td>4963</td>\n",
       "      <td>Premature senescence under a short-day photope...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>AT3G19190</td>\n",
       "      <td>AtATG2</td>\n",
       "      <td>True</td>\n",
       "      <td>4850</td>\n",
       "      <td>early senescence; accumulation of high levels ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>AT3G18770</td>\n",
       "      <td>AtATG13b</td>\n",
       "      <td>True</td>\n",
       "      <td>4845</td>\n",
       "      <td>Premature senescence under a short-day photope...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AT1G50030</td>\n",
       "      <td>TOR</td>\n",
       "      <td>True</td>\n",
       "      <td>914</td>\n",
       "      <td>Embryo defective-Preglobular / Globular. large...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>AT3G13970</td>\n",
       "      <td>AtATG12b</td>\n",
       "      <td>True</td>\n",
       "      <td>4201</td>\n",
       "      <td>Small plants and premature senescence under no...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>AT3G08850</td>\n",
       "      <td>RAPTOR B</td>\n",
       "      <td>True</td>\n",
       "      <td>888</td>\n",
       "      <td>Embryo defective-Preglobular. Heterozygotes sh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>AT5G01770</td>\n",
       "      <td>RAPTOR A</td>\n",
       "      <td>True</td>\n",
       "      <td>5386</td>\n",
       "      <td>Under non-limiting conditions of light, water,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>AT3G01090</td>\n",
       "      <td>KIN10</td>\n",
       "      <td>True</td>\n",
       "      <td>1755</td>\n",
       "      <td>Reduced starch transport under phosphate starv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>AT3G59950</td>\n",
       "      <td>AtATG4b</td>\n",
       "      <td>True</td>\n",
       "      <td>5034</td>\n",
       "      <td>Small plants and premature senescence under no...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>AT2G44140</td>\n",
       "      <td>AtATG4a</td>\n",
       "      <td>True</td>\n",
       "      <td>4651</td>\n",
       "      <td>Small plants and premature senescence under no...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>AT5G17290</td>\n",
       "      <td>AtATG5</td>\n",
       "      <td>True</td>\n",
       "      <td>467</td>\n",
       "      <td>Dwarf. Late flowering. Under a short-day photo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>AT5G45900</td>\n",
       "      <td>AtATG7</td>\n",
       "      <td>True</td>\n",
       "      <td>5645</td>\n",
       "      <td>The atg7-1 plants are hypersensitive to either...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AT2G31260</td>\n",
       "      <td>AtATG9</td>\n",
       "      <td>True</td>\n",
       "      <td>539</td>\n",
       "      <td>Early chlorosis under nitrogen starvation. Red...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>AT4G24690</td>\n",
       "      <td>NBR1</td>\n",
       "      <td>True</td>\n",
       "      <td>5252</td>\n",
       "      <td>Sensitivity to heat stress (45�C).</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>AT3G61710</td>\n",
       "      <td>AtATG6</td>\n",
       "      <td>True</td>\n",
       "      <td>300</td>\n",
       "      <td>Complete male gametophyte defective. Resistant...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AT1G60490</td>\n",
       "      <td>AtVPS34</td>\n",
       "      <td>True</td>\n",
       "      <td>4236</td>\n",
       "      <td>Mutants showed reduced endocytosis and little ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AT1G54210</td>\n",
       "      <td>AtATG12a</td>\n",
       "      <td>True</td>\n",
       "      <td>4201</td>\n",
       "      <td>Small plants and premature senescence under no...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>AT3G29160</td>\n",
       "      <td>KIN11</td>\n",
       "      <td>True</td>\n",
       "      <td>1755</td>\n",
       "      <td>Reduced starch transport under phosphate starv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>AT4G29380</td>\n",
       "      <td>AtVPS15</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>AT4G21980</td>\n",
       "      <td>AtATG8a</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AT1G03380</td>\n",
       "      <td>AtATG18g</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>AT4G30510</td>\n",
       "      <td>AtATG18b</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>AT4G04620</td>\n",
       "      <td>AtATG8b</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>AT5G05150</td>\n",
       "      <td>AtATG18e</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>AT5G53000</td>\n",
       "      <td>TAP46</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>AT5G54730</td>\n",
       "      <td>AtATG18f</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>AT5G61500</td>\n",
       "      <td>AtATG3</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>AT4G16520</td>\n",
       "      <td>AtATG8f</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>AT3G53930</td>\n",
       "      <td>AtATG1b</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>AT4G00355</td>\n",
       "      <td>ATI1</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>AT3G62770</td>\n",
       "      <td>AtATG18a</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>AT3G61960</td>\n",
       "      <td>AtATG1a</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>AT3G60640</td>\n",
       "      <td>AtATG8g</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>AT3G56440</td>\n",
       "      <td>AtATG18d</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>AT3G15580</td>\n",
       "      <td>AtATG8i</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>AT3G06420</td>\n",
       "      <td>AtATG8h</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>AT2G45170</td>\n",
       "      <td>AtATG8e</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>AT2G40810</td>\n",
       "      <td>AtATG18c</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AT2G37840</td>\n",
       "      <td>AtATG1c</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AT2G05630</td>\n",
       "      <td>AtATG8d</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AT1G62040</td>\n",
       "      <td>AtATG8c</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AT1G54710</td>\n",
       "      <td>AtATG18h</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>AT1G08320</td>\n",
       "      <td>TGA9</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         name     other  in_data identifier                                               text\n",
       "14  AT3G07525   AtATG10     True       2371  Early senescence. Late flowering. Reduced fert...\n",
       "21  AT3G49590  AtATG13a     True       4963  Premature senescence under a short-day photope...\n",
       "19  AT3G19190    AtATG2     True       4850  early senescence; accumulation of high levels ...\n",
       "18  AT3G18770  AtATG13b     True       4845  Premature senescence under a short-day photope...\n",
       "1   AT1G50030       TOR     True        914  Embryo defective-Preglobular / Globular. large...\n",
       "16  AT3G13970  AtATG12b     True       4201  Small plants and premature senescence under no...\n",
       "15  AT3G08850  RAPTOR B     True        888  Embryo defective-Preglobular. Heterozygotes sh...\n",
       "36  AT5G01770  RAPTOR A     True       5386  Under non-limiting conditions of light, water,...\n",
       "12  AT3G01090     KIN10     True       1755  Reduced starch transport under phosphate starv...\n",
       "24  AT3G59950   AtATG4b     True       5034  Small plants and premature senescence under no...\n",
       "10  AT2G44140   AtATG4a     True       4651  Small plants and premature senescence under no...\n",
       "38  AT5G17290    AtATG5     True        467  Dwarf. Late flowering. Under a short-day photo...\n",
       "39  AT5G45900    AtATG7     True       5645  The atg7-1 plants are hypersensitive to either...\n",
       "7   AT2G31260    AtATG9     True        539  Early chlorosis under nitrogen starvation. Red...\n",
       "33  AT4G24690      NBR1     True       5252                 Sensitivity to heat stress (45�C).\n",
       "26  AT3G61710    AtATG6     True        300  Complete male gametophyte defective. Resistant...\n",
       "4   AT1G60490   AtVPS34     True       4236  Mutants showed reduced endocytosis and little ...\n",
       "2   AT1G54210  AtATG12a     True       4201  Small plants and premature senescence under no...\n",
       "20  AT3G29160     KIN11     True       1755  Reduced starch transport under phosphate starv...\n",
       "34  AT4G29380   AtVPS15    False                                                              \n",
       "32  AT4G21980   AtATG8a    False                                                              \n",
       "0   AT1G03380  AtATG18g    False                                                              \n",
       "35  AT4G30510  AtATG18b    False                                                              \n",
       "30  AT4G04620   AtATG8b    False                                                              \n",
       "37  AT5G05150  AtATG18e    False                                                              \n",
       "40  AT5G53000     TAP46    False                                                              \n",
       "41  AT5G54730  AtATG18f    False                                                              \n",
       "42  AT5G61500    AtATG3    False                                                              \n",
       "31  AT4G16520   AtATG8f    False                                                              \n",
       "22  AT3G53930   AtATG1b    False                                                              \n",
       "29  AT4G00355      ATI1    False                                                              \n",
       "28  AT3G62770  AtATG18a    False                                                              \n",
       "27  AT3G61960   AtATG1a    False                                                              \n",
       "25  AT3G60640   AtATG8g    False                                                              \n",
       "23  AT3G56440  AtATG18d    False                                                              \n",
       "17  AT3G15580   AtATG8i    False                                                              \n",
       "13  AT3G06420   AtATG8h    False                                                              \n",
       "11  AT2G45170   AtATG8e    False                                                              \n",
       "9   AT2G40810  AtATG18c    False                                                              \n",
       "8   AT2G37840   AtATG1c    False                                                              \n",
       "6   AT2G05630   AtATG8d    False                                                              \n",
       "5   AT1G62040   AtATG8c    False                                                              \n",
       "3   AT1G54710  AtATG18h    False                                                              \n",
       "43  AT1G08320      TGA9    False                                                              "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finding out what from this table of provided genes is in the dataset already, and with what text.\n",
    "# Normalizing the gene names to lowercase doesn't impact how many are in the data.\n",
    "names_dict = dataset.get_name_to_id_dictionary(unambiguous=True)\n",
    "adf = pd.read_csv(\"~/Desktop/autophagy_related_genes.csv\",usecols=[0,1],names=[\"name\",\"other\"])\n",
    "adf[\"in_data\"] = adf[\"name\"].map(lambda x: (x in names_dict))\n",
    "adf[\"identifier\"] = adf[\"name\"].map(lambda x: (names_dict[x] if (x in names_dict) else \"\"))\n",
    "adf[\"text\"] = adf[\"identifier\"].map(lambda x: (descriptions[x] if (x is not \"\") else \"\"))\n",
    "adf.sort_values(\"in_data\",ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank</th>\n",
       "      <th>known</th>\n",
       "      <th>gene_name</th>\n",
       "      <th>phenotype</th>\n",
       "      <th>gene_aliases</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3690</th>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>AT4G22330</td>\n",
       "      <td>Irregular wax crystals, reduced stature, small...</td>\n",
       "      <td>ATCES1|AtACER|CERAMIDASE|T10I14.160|T10I14_160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>At1g66730</td>\n",
       "      <td>Delayed germination. Sensitive to low temperat...</td>\n",
       "      <td>LIG6|AT1G66730|AtLIG6|DNA LIGASE 6|F4N21.14|F4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>At5g40770</td>\n",
       "      <td>Curled rosette leaves. Delayed germination. Se...</td>\n",
       "      <td>PHB3|AT5G40770|ATPHB3|EER3|prohibitin 3|AT5G40...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1215</th>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>At1g20450</td>\n",
       "      <td>Abnormal seed shape. Low germination rate. Sen...</td>\n",
       "      <td>ERD10|AT1G20450|LTI29|LTI45|LOW TEMPERATURE IN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3106</th>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>AT2G42700</td>\n",
       "      <td>abnormally accumulated storage protein precurs...</td>\n",
       "      <td>MIP3|MAG2-interacting protein 3|F14N22.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      rank  known  gene_name                                          phenotype                                       gene_aliases\n",
       "3690     1  False  AT4G22330  Irregular wax crystals, reduced stature, small...     ATCES1|AtACER|CERAMIDASE|T10I14.160|T10I14_160\n",
       "346      2  False  At1g66730  Delayed germination. Sensitive to low temperat...  LIG6|AT1G66730|AtLIG6|DNA LIGASE 6|F4N21.14|F4...\n",
       "344      3  False  At5g40770  Curled rosette leaves. Delayed germination. Se...  PHB3|AT5G40770|ATPHB3|EER3|prohibitin 3|AT5G40...\n",
       "1215     4  False  At1g20450  Abnormal seed shape. Low germination rate. Sen...  ERD10|AT1G20450|LTI29|LTI45|LOW TEMPERATURE IN...\n",
       "3106     5  False  AT2G42700  abnormally accumulated storage protein precurs...           MIP3|MAG2-interacting protein 3|F14N22.4"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = df\n",
    "gene_dict = dataset.get_gene_dictionary()\n",
    "results[\"phenotype\"] = results[\"to\"].map(lambda x: descriptions[x])\n",
    "results[\"phenotype\"] = results[\"to\"].map(lambda x: descriptions[x])\n",
    "results[\"gene_name\"] = results[\"to\"].map(lambda x: concatenate_with_bar_delim(*gene_dict[x].names[0:1]))\n",
    "results[\"gene_aliases\"] = results[\"to\"].map(lambda x: concatenate_with_bar_delim(*gene_dict[x].names[1:]))\n",
    "results[\"known\"] = results[\"to\"].map(lambda x: (x in adf[\"identifier\"].values))\n",
    "results[\"rank\"] = np.arange(1, len(results)+1)\n",
    "results = results[[\"rank\",\"known\",\"gene_name\",\"phenotype\",\"gene_aliases\"]].head(50)\n",
    "results.to_csv(\"~/Desktop/autophagy_query.csv\",index=False)\n",
    "results.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
