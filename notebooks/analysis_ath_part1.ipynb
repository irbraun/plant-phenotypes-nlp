{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1. Protein-Protein Interactions in Arabidopsis Data\n",
    "The purpose of this notebook is to answer the question of how networks genereated using phenotypic-text similarity based approaches through either embedding, vocabulary presence, or ontology annotation compare to or relate to networks that specify known protein-protein interactions. The hypothesis that these networks are potentially related is based on the idea that if two proteins interact, they are likely to be acting in a common pathway with a common biological function. If the phenotypic outcome of this pathway is observable and documented, then similarites between text describing the mutant phenotype for these genes may coincide with direct protein-protein interactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import math\n",
    "import sys\n",
    "import gensim\n",
    "import os\n",
    "import warnings\n",
    "import itertools\n",
    "from collections import Counter, defaultdict\n",
    "from inspect import signature\n",
    "from scipy.stats import ks_2samp\n",
    "from sklearn.metrics import precision_recall_curve, f1_score, auc\n",
    "\n",
    "sys.path.append(\"../../oats\")\n",
    "from oats.utils.utils import save_to_pickle, load_from_pickle, merge_list_dicts\n",
    "from oats.datasets.dataset import Dataset\n",
    "from oats.datasets.groupings import Groupings\n",
    "from oats.datasets.string import get_stringdb_information\n",
    "from oats.annotation.ontology import Ontology\n",
    "from oats.annotation.annotation import write_annotations_to_tsv_file, read_annotations_from_tsv_file\n",
    "from oats.graphs.pairwise import pairwise_edgelist_doc2vec, pairwise_edgelist_counting, pairwise_edgelist_annotations\n",
    "from oats.graphs.pairwise import merge_edgelists, subset_edgelist_with_ids\n",
    "from oats.graphs.pairwise import remove_self_loops\n",
    "\n",
    "mpl.rcParams[\"figure.dpi\"] = 400\n",
    "warnings.simplefilter('ignore')\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nested dictionary to summarize output with shape dict[method][(tag,metric)] --> value\n",
    "TAG = \"protein-protein\"\n",
    "OUTPUT = defaultdict(dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Does the graph recapitulate known protein-protein interactions?\n",
    "The different sections in this notebook correspond to different ways of determining if the graphs based on similarity between text descriptions, encodings of text descriptions, or annotations derived from text descriptions at all correspond to known protein-protein interactions in this dataset. The knowledge source about the protein-protein interactions for genes in this dataset is the STRING database (https://string-db.org/). The available entries in the whole dataset are subset to include only the genes that correspond to proteins that are atleast mentioned in the STRING database. This ways if a protein-protein interaction is not specified between two of the remaining genes, it is not because no interactions at all are documented either of those genes. The following cells focus on setting up a dataframe which specifies edge lists specific to each similarity method, and also a protein-protein interaction score for the genes which correspond to those two given nodes in the graphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in the dataframe: 47151\n",
      "Number of unique IDs:            47151\n",
      "Number of unique descriptions:   16504\n",
      "Number of unique gene name sets: 47151\n",
      "Number of species represented:   6\n",
      "Number of rows in the dataframe: 5972\n",
      "Number of unique IDs:            5972\n",
      "Number of unique descriptions:   3635\n",
      "Number of unique gene name sets: 5972\n",
      "Number of species represented:   1\n"
     ]
    }
   ],
   "source": [
    "# Reading in the entire dataset, subsetting for Arabidopsis and all annotation types.\n",
    "dataset = load_from_pickle(\"../data/pickles/full_dataset.pickle\")\n",
    "dataset.describe()\n",
    "dataset.filter_by_species(\"ath\")\n",
    "dataset.collapse_by_all_gene_names()\n",
    "dataset.filter_has_description()\n",
    "dataset.filter_has_annotation()\n",
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in the dataframe: 1000\n",
      "Number of unique IDs:            1000\n",
      "Number of unique descriptions:   880\n",
      "Number of unique gene name sets: 1000\n",
      "Number of species represented:   1\n"
     ]
    }
   ],
   "source": [
    "# Reduce size of the dataset by removing genes not mentioned in the STRING.\n",
    "string_database_file = \"../data/group_related_files/string/3702.protein.links.detailed.v11.0.txt\"\n",
    "string_df, string_id_list = get_stringdb_information(string_database_file, dataset.get_name_to_id_dictionary())\n",
    "dataset.filter_with_ids(string_id_list)\n",
    "dataset.filter_random_k(1000)\n",
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "# Objects and dictionaries needed to build the list of edges for the full graph.\n",
    "doc2vec_model_filename = \"../gensim/enwiki_dbow/doc2vec.bin\"\n",
    "doc2vec_model = gensim.models.Doc2Vec.load(doc2vec_model_filename)\n",
    "ontology_filename = \"../ontologies/mo.obo\"\n",
    "ontology = Ontology(ontology_filename)\n",
    "descriptions = dataset.get_description_dictionary()\n",
    "annotations = dataset.get_annotations_dictionary()\n",
    "vocabulary = ontology.get_all_tokens_as_ordered_vocabulary()\n",
    "\n",
    "# Generating the pairwise edgelist for some vanilla methods.\n",
    "name_to_df_mapping = {}\n",
    "name_to_df_mapping[\"doc2vec\"] = pairwise_edgelist_doc2vec(doc2vec_model, descriptions, metric=\"cosine\")\n",
    "name_to_df_mapping[\"bagofwords\"] = pairwise_edgelist_counting(descriptions, binary=False, metric=\"cosine\") \n",
    "#name_to_df_mapping[\"setofwords\"] = pairwise_edgelist_counting(descriptions, binary=True, metric=\"cosine\")\n",
    "#name_to_df_mapping[\"ontology\"] = pairwise_edgelist_annotations(annotations, ontology, binary=True, metric=\"cosine\")\n",
    "print(len(name_to_df_mapping))\n",
    "\n",
    "# Generating the pairwise edgelists for some additional methods.\n",
    "#name_to_df_mapping[\"bag_w12gram\"] = pairwise_edgelist_counting(descriptions, metric=\"cosine\", binary=False, analyzer=\"word\", ngram_range=(1,2))\n",
    "#name_to_df_mapping[\"bag_c36gram\"] = pairwise_edgelist_counting(descriptions, metric=\"cosine\", binary=False, analyzer=\"char\", ngram_range=(3,6))\n",
    "#name_to_df_mapping[\"bag_reduced\"] = pairwise_edgelist_counting(descriptions, metric=\"cosine\", binary=False, vocabulary=vocabulary)\n",
    "#name_to_df_mapping[\"set_reduced\"] = pairwise_edgelist_counting(descriptions, metric=\"cosine\", binary=True, vocabulary=vocabulary)\n",
    "print(len(name_to_df_mapping))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    from     to   doc2vec  bagofwords\n",
      "1   1537  26576  0.608391    0.984615\n",
      "2   1537  16679  0.529723    1.000000\n",
      "3   1537   1070  0.493390    0.915366\n",
      "4   1537    618  0.543314    1.000000\n",
      "5   1537  21936  0.508886    0.926200\n",
      "6   1537    519  0.518746    0.972697\n",
      "7   1537   1237  0.630269    0.881972\n",
      "8   1537   6585  0.445488    0.865385\n",
      "9   1537   9007  0.639517    1.000000\n",
      "10  1537   1596  0.535616    1.000000\n",
      "499500\n"
     ]
    }
   ],
   "source": [
    "# Merging all of the edgelist dataframes together.\n",
    "df = merge_edgelists(name_to_df_mapping, default_value=0.000)\n",
    "df = remove_self_loops(df)\n",
    "print(df.head(10))\n",
    "print(df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   from     to   doc2vec  combined_score\n",
      "0  1537  26576  0.608391             0.0\n",
      "1  1537  16679  0.529723             0.0\n",
      "2  1537   1070  0.493390             0.0\n",
      "3  1537    618  0.543314             0.0\n",
      "4  1537  21936  0.508886             0.0\n",
      "5  1537    519  0.518746             0.0\n",
      "6  1537   1237  0.630269             0.0\n",
      "7  1537   6585  0.445488             0.0\n",
      "8  1537   9007  0.639517             0.0\n",
      "9  1537   1596  0.535616             0.0\n",
      "(500968, 5)\n"
     ]
    }
   ],
   "source": [
    "# Merging information from the protein-protein interaction database with this dataset.\n",
    "df = df.merge(right=string_df, how=\"left\", on=[\"from\",\"to\"])\n",
    "df.fillna(value=0,inplace=True)\n",
    "print(df[[\"from\",\"to\",\"doc2vec\",\"combined_score\"]].head(10))\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Do the edges joining interacting proteins come from a different distribution?\n",
    "This section uses a statistical test (Kolmogorov-Smirnov) to see if the distributions of edge weights which correspond to edges representing a known protein interaction come from a different distribution than the edge weights for edges that do not. This test was chosen because the sizes of the two samples can be different and there is no assumption of normality for the underlying distributions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use KS test to see if protein-protein interaction edges come from a unique distribution.\n",
    "METHODS = name_to_df_mapping.keys()\n",
    "ppi_pos_dict = {name:(df[df[\"combined_score\"] > 0.00][name].values) for name in METHODS}\n",
    "ppi_neg_dict = {name:(df[df[\"combined_score\"] == 0.00][name].values) for name in METHODS}\n",
    "results = {}\n",
    "for name in METHODS:\n",
    "    stat,p = ks_2samp(ppi_pos_dict[name],ppi_neg_dict[name])\n",
    "    pos_mean = np.average(ppi_pos_dict[name])\n",
    "    neg_mean = np.average(ppi_neg_dict[name])\n",
    "    pos_n = len(ppi_pos_dict[name])\n",
    "    neg_n = len(ppi_neg_dict[name])\n",
    "    results[name] = {\"mean_1\":\"{:.4f}\".format(pos_mean),\n",
    "                       \"mean_0\":\"{:.4f}\".format(neg_mean),\n",
    "                       \"n_1\":\"{:.0f}\".format(pos_n),\n",
    "                       \"n_0\":\"{:.0f}\".format(neg_n),\n",
    "                       \"ks\":\"{:.0f}\".format(stat),\n",
    "                       \"pval\":\"{:.0f}\".format(p)}\n",
    "                                                \n",
    "    OUTPUT[name].update({(TAG,\"mean_1\"):pos_mean, (TAG,\"mean_0\"):neg_mean, (TAG,\"n_1\"):stat, (TAG,\"n_0\"):stat})\n",
    "    OUTPUT[name].update({(TAG,\"ks\"):stat, (TAG,\"pval\"):stat, (TAG,\"n_1\"):stat, (TAG,\"n_0\"):stat})\n",
    "    \n",
    "print(pd.DataFrame(results).transpose())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 What do those distributions of edge weights in the graph look like?\n",
    "Visualization of the densities of the distributions that are tested in the previous cell. This is a check to see if the differences between the distribution of weights based on text-similarity corresponding to known protein-protein interactions are distinct enough those that do not to be practically useful in predicting interactions based on text-similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_plots, plots_per_row, row_width, row_height = (len(METHODS), 4, 14, 3)\n",
    "fig,axs = plt.subplots(math.ceil(num_plots/plots_per_row), plots_per_row, squeeze=False)\n",
    "for name,ax in zip(METHODS,axs.flatten()):\n",
    "    ax.set_title(name)\n",
    "    ax.set_xlabel(\"value\")\n",
    "    ax.set_ylabel(\"density\")\n",
    "    sns.kdeplot(ppi_pos_dict[name], color=\"black\", shade=False, alpha=1.0, ax=ax)\n",
    "    sns.kdeplot(ppi_neg_dict[name], color=\"black\", shade=True, alpha=0.1, ax=ax) \n",
    "    \n",
    "fig.set_size_inches(row_width, row_height*math.ceil(num_plots/plots_per_row))\n",
    "fig.tight_layout()\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Can we practically use the graph to predict known protein-protein interactions?\n",
    "This is a different question than above, because the false positive rate is a limiting factor in how practically useful it would be to generate predictions about real protein interactions. In the case of the statistical test above, the sample distribution could be significantly different than the whole distribution of edge values even if there are many high valued edges which look like they could come from the sample distribution. In other words, the sample distribution could be distinct because of a lack of low edge weight values, not there could still be many high edge weight values that are not positive edges in this case, which represent false positives)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the targe class values, 1 indicating interaction and 0 indicating no interaction.\n",
    "y_true_dict = {name:(np.where(df[\"combined_score\"] > 0.000, 1, 0)) for name in METHODS}\n",
    "y_prob_dict = {name:(1 - df[name].values) for name in METHODS}\n",
    "results = {}\n",
    "num_plots, plots_per_row, row_width, row_height = (len(METHODS), 4, 14, 3)\n",
    "fig,axs = plt.subplots(math.ceil(num_plots/plots_per_row), plots_per_row, squeeze=False)\n",
    "for name,ax in zip(METHODS, axs.flatten()):\n",
    "    \n",
    "    # Obtaining the values and metrics.\n",
    "    y_true, y_prob = y_true_dict[name], y_prob_dict[name]\n",
    "    n_pos, n_neg = Counter(y_true)[1], Counter(y_true)[0]\n",
    "    precision, recall, thresholds = precision_recall_curve(y_true, y_prob)\n",
    "    baseline = Counter(y_true)[1]/len(y_true) \n",
    "    area = auc(recall, precision)\n",
    "    auc_to_baseline_auc_ratio = area/baseline\n",
    "    results[name] = {\"auc\":\"{:.4f}\".format(area),\n",
    "                       \"baseline\":\"{:.4f}\".format(baseline),\n",
    "                       \"n_int\":\"{:.0f}\".format(n_pos),\n",
    "                       \"n_not\":\"{:.0f}\".format(n_neg)}\n",
    "    OUTPUT[name].update({(TAG,\"auc\"):area, (TAG,\"auc_bl\"):auc_to_baseline_auc_ratio})\n",
    "    \n",
    "    # Producing the precision recall curve.\n",
    "    step_kwargs = ({'step': 'post'} if 'step' in signature(plt.fill_between).parameters else {})\n",
    "    ax.step(recall, precision, color='black', alpha=0.2, where='post')\n",
    "    ax.fill_between(recall, precision, alpha=0.7, color='black', **step_kwargs)\n",
    "    ax.set_xlabel('Recall')\n",
    "    ax.set_ylabel('Precision')\n",
    "    ax.set_ylim([0.0, 1.05])\n",
    "    ax.set_xlim([0.0, 1.0])\n",
    "    ax.set_title(\"{0} PR Curve (Baseline={1:0.3f})\".format(name, baseline))\n",
    "    \n",
    "# Report the results and show the precision recall curves.\n",
    "print(pd.DataFrame(results).transpose())\n",
    "fig.set_size_inches(row_width, row_height*math.ceil(num_plots/plots_per_row))\n",
    "fig.tight_layout()\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Can the graph be queried with one gene to successfully return other genes that it interacts with?\n",
    "This question is similar (potentially overlapping) with a question asked above, which is to ask if genes in the network are connected by highly weighted edges to genes that gene interacts with in the protein-protein interaction data. If this is true, than we can query (return the nodes in order of greatest similarity to the query node) the network with one gene and get back genes that are likely to interact with it. The difference in how this is tested is that only the genes with atleast one known interaction partner are used as the queried proteins. This is mainly just a difference in the visualization? What's actually shown is where the interacting proteins are ranking against all the proteins in the dataset (which is just those proteins atleast mentioned in STRING for this species). When binning the ranks, the bin with the greatest count is the top ranks (1-10), but the ranks that fall in this bin are still a tiny fraction of the total number of returned ranks, so the answer to this question is effectively no."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        from     to   doc2vec  bagofwords  combined_score\n",
      "0       1537  26576  0.608391    0.984615             0.0\n",
      "1       1537  16679  0.529723    1.000000             0.0\n",
      "2       1537   1070  0.493390    0.915366             0.0\n",
      "3       1537    618  0.543314    1.000000             0.0\n",
      "4       1537  21936  0.508886    0.926200             0.0\n",
      "...      ...    ...       ...         ...             ...\n",
      "500963  2007   2203  0.438923    0.982771             0.0\n",
      "500964    25   2203  0.447021    0.960677             0.0\n",
      "500965  2007    315  0.549328    0.678902             0.0\n",
      "500966    25    315  0.539851    1.000000             0.0\n",
      "500967    25   2007  0.492661    1.000000             0.0\n",
      "\n",
      "[1001936 rows x 5 columns]\n",
      "      doc2vec  bagofwords\n",
      "from                     \n",
      "16         76          76\n",
      "22         54          54\n",
      "24         53          53\n",
      "25         31          31\n",
      "30        110         110\n",
      "32         78          78\n",
      "35        106         106\n",
      "36         21          21\n",
      "38         46          46\n",
      "41         41          41\n",
      "48         63          63\n",
      "49         35          35\n",
      "50        177         177\n",
      "51         18          18\n",
      "52         84          84\n",
      "      doc2vec  bagofwords\n",
      "from                     \n",
      "16       1000        1000\n",
      "22       1001        1001\n",
      "24       1001        1001\n",
      "25        999         999\n",
      "30       1003        1003\n",
      "32       1003        1003\n",
      "35       1002        1002\n",
      "36        999         999\n",
      "38       1000        1000\n",
      "41        999         999\n",
      "48       1002        1002\n",
      "49        999         999\n",
      "50       1059        1059\n",
      "51        999         999\n",
      "52       1003        1003\n"
     ]
    }
   ],
   "source": [
    "# Testing to see whether the number of binding partners returned in k closest nodes is greater than expected.\n",
    "dft = df[[\"from\",\"to\",\"doc2vec\",\"bagofwords\",\"combined_score\"]]\n",
    "\n",
    "\n",
    "# Unfortunately fastest way is to generate redundant directed version of the dataframe.\n",
    "# This is so that the \"from\" column can be used to quickly get all edges to nodes joining it\n",
    "# and won't miss the ones that were only specified from j,i instead of i,j.\n",
    "flipped_nodes = dft[[\"to\",\"from\",\"doc2vec\", \"bagofwords\", \"combined_score\"]]\n",
    "flipped_nodes.columns = [\"from\",\"to\", \"doc2vec\", \"bagofwords\", \"combined_score\"]\n",
    "dft = pd.concat([dft, flipped_nodes])\n",
    "dft.drop_duplicates(keep=\"first\", inplace=True)\n",
    "\n",
    "print(dft)\n",
    "\n",
    "\n",
    "# What's the number of partners ranked k or higher for each gene?\n",
    "k = 10\n",
    "dft[[\"doc2vec\",\"bagofwords\"]] = dft.groupby(\"from\")[\"doc2vec\",\"bagofwords\"].rank()\n",
    "#print(dft)\n",
    "meanranks_pos = dft[dft[\"combined_score\"]>0].groupby(\"from\")[\"doc2vec\",\"bagofwords\"].count()\n",
    "meanranks_all = dft.groupby(\"from\")[\"doc2vec\",\"bagofwords\"].count()\n",
    "\n",
    "\n",
    "\n",
    "print(meanranks_pos.head(15))\n",
    "print(meanranks_all.head(15))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#dft[\"newrank\"] = dft.groupby(by=[\"from\"])[\"bagofwords\"].rank()\n",
    "#a = dft.groupby(by=[\"from\"])[\"newrank\"].mean()\n",
    "#b = dft.groupby(by=[\"from\"])[\"newrank\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the list of gene IDs involved in interation with atleast one other protein in this dataset.\n",
    "genes_with_partners = pd.unique(string_df[[\"from\",\"to\"]].dropna().values.ravel('K'))\n",
    "partner_ranks_dict = {}\n",
    "\n",
    "# For each method, obtain a list of the rankings in terms of similarity as measured by that method, using each gene\n",
    "# iteratively as the query gene. The method of accessing the ranks is to first subset the edgelist dataframe to \n",
    "# contain only the rows where an edge involving the node of the query gene is specified, then the edge list is \n",
    "# sorted by the specific similarity score for that method, so that the indices of edges where the protein-protein\n",
    "# interaction score is non-zero will correspond directly to ranks.\n",
    "for name in METHODS:\n",
    "    partner_ranks = []\n",
    "    for gene_id in genes_with_partners:\n",
    "        merged_df = pd.concat([df[df[\"from\"]==gene_id],df[df[\"to\"]==gene_id]],ignore_index=True)\n",
    "        merged_df = merged_df.sort_values(by=[name]).reset_index(drop=True)\n",
    "        indices = merged_df.query(\"combined_score > 0.00\").index.tolist()\n",
    "        partner_ranks.extend(indices)\n",
    "    partner_ranks = [rank+1 for rank in partner_ranks]\n",
    "    partner_ranks_dict[name] = partner_ranks\n",
    "    print(\"finished with {}\".format(name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Set these values to be able to make the large (rightmost) bin an average of all encompassed smaller bins.\n",
    "# This way the size of that column can be reasonably compared to the columns to its left.\n",
    "max_rank = len(pd.unique(df[[\"from\",\"to\"]].values.ravel('K')))\n",
    "bins = [1,10,20,30,40,50,max_rank]\n",
    "small_bin_size = 10\n",
    "large_bin_size = (max_rank-50)\n",
    "ratio = large_bin_size/small_bin_size\n",
    "\n",
    "# Generate the barplots for each method.\n",
    "num_plots, plots_per_row, row_width, row_height = (len(METHODS), 4, 14, 3)\n",
    "fig,axs = plt.subplots(math.ceil(num_plots/plots_per_row), plots_per_row, squeeze=False)\n",
    "for name,ax in zip(METHODS,axs.flatten()):\n",
    "    partner_ranks = partner_ranks_dict[name]\n",
    "    ax.set_title(name)\n",
    "    ax.set_xlabel(\"rank bins\")\n",
    "    ax.set_ylabel(\"rank quantity\")\n",
    "    counts,bin_edges = np.histogram(partner_ranks, bins)\n",
    "    bin_labels = [\"{}-{}\".format(bin_edges[i],bin_edges[i+1]) for i in range(len(bin_edges)-1)]\n",
    "    counts[-1] = counts[-1]/ratio    # Adjust the large bin column to reflect average of encompassed smaller bins.\n",
    "    bin_labels[-1] = \"higher\\nmean\"  # Change the label of that bin to reflect this change.\n",
    "    sns.barplot(x=bin_labels,y=counts,linewidth=1.5,facecolor=\"white\",alpha=0.8,errcolor=\".2\",edgecolor=\"black\",ax=ax)\n",
    "\n",
    "fig.set_size_inches(row_width, row_height*math.ceil(num_plots/plots_per_row))\n",
    "fig.tight_layout()\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Summarizing the results for this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(OUTPUT).transpose()\n",
    "print(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
