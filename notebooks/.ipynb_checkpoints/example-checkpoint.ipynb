{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "sys.path.append(\"../.\")\n",
    "\n",
    "from phenolog.datasets.dataset import Dataset\n",
    "from phenolog.language.nlp import get_clean_description\n",
    "from phenolog.annotation.ontology import Ontology\n",
    "from phenolog.annotation.annotation import annotate_using_rabin_karp, annotate_using_noble_coder \n",
    "from phenolog.annotation.annotation import write_annotations_to_tsv_file, read_annotations_from_tsv_file\n",
    "\n",
    "from phenolog.graphs.similarity import get_similarity_df_using_fastsemsim\n",
    "from phenolog.graphs.similarity import get_similarity_df_using_doc2vec\n",
    "from phenolog.graphs.similarity import get_similarity_df_using_bagofwords\n",
    "from phenolog.graphs.similarity import get_similarity_df_using_setofwords\n",
    "from phenolog.graphs.similarity import get_similarity_df_using_annotations_unweighted_jaccard\n",
    "from phenolog.graphs.similarity import get_similarity_df_using_annotations_weighted_jaccard\n",
    "\n",
    "from phenolog.graphs.models import combine_dfs_with_name_dict\n",
    "from phenolog.graphs.models import apply_mean\n",
    "from phenolog.graphs.models import train_linear_regression_model\n",
    "from phenolog.graphs.models import apply_linear_regression_model\n",
    "from phenolog.graphs.models import train_random_forest_model\n",
    "from phenolog.graphs.models import apply_random_forest_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a dataset object and read in the prepared data files from different plant species\n",
    "The `Dataset.add_data()` method expects a pandas.DataFrame that must have atleast the columns (\"species\", \"description\", \"gene_names\", \"reference\"). Any other columns in a passed in dataframe are ignored. The gene names field from the dataframe should be delimited by the bar character (`|`). There are methods available in the `language.nlp` module to help with obtaining and formatting gene names to be consisent with what is expected for this method. The `describe()` method here provides basic information about what the contents of the dataset looks like. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Describing the Dataset object...\n",
      "Number of rows in the dataframe: 23918\n",
      "Number of unique IDs: 23918\n",
      "Number of unique descriptions: 10974\n",
      "Number of unique gene name sets: 10394\n",
      "Number of species represented: 6\n"
     ]
    }
   ],
   "source": [
    "dataset = Dataset()\n",
    "dataset.add_data(pd.read_csv(\"../data/reshaped/arabidopsis_phenotypes.csv\", lineterminator=\"\\n\"))\n",
    "dataset.add_data(pd.read_csv(\"../data/reshaped/maize_phenotypes.csv\", lineterminator=\"\\n\"))\n",
    "dataset.add_data(pd.read_csv(\"../data/reshaped/ppn_phenotypes.csv\", lineterminator=\"\\n\"))\n",
    "dataset.add_data(pd.read_csv(\"../data/reshaped/ppn_phenes.csv\", lineterminator=\"\\n\"))\n",
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Describing the Dataset object...\n",
      "Number of rows in the dataframe: 10\n",
      "Number of unique IDs: 10\n",
      "Number of unique descriptions: 10\n",
      "Number of unique gene name sets: 10\n",
      "Number of species represented: 3\n"
     ]
    }
   ],
   "source": [
    "# Subsample the data that is available.\n",
    "dataset.randomly_subsample_dataset(n=10)\n",
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare a dictionary of phenotype descriptions where each has a unique ID value.\n",
    "description_dict = dataset.get_description_dictionary()\n",
    "description_dict = {i:get_clean_description(d) for (i,d) in description_dict.items()}\n",
    "\n",
    "for identifier, description in description_dict.items():\n",
    "    print(\"{}\\t{}\".format(identifier, description[0:50]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_ontology_file = \"../ontologies/mo.obo\"\n",
    "annotations_file = \"../data/annotations/annotations_with_mo.tsv\"\n",
    "doc2vec_model_file = \"../gensim/apnews_dbow/doc2vec.bin\"\n",
    "\n",
    "mo = Ontology(merged_ontology_file)\n",
    "annotations = annotate_using_rabin_karp(description_dict, mo)\n",
    "write_annotations_to_tsv_file(annotations, annotations_file)\n",
    "\n",
    "for identifier, term_list in annotations.items():\n",
    "    print(\"{}\\t{}\".format(identifier, term_list[0:5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = get_similarity_df_using_fastsemsim(merged_ontology_file, annotations_file, description_dict)\n",
    "df2 = get_similarity_df_using_doc2vec(doc2vec_model_file, description_dict)\n",
    "df3 = get_similarity_df_using_bagofwords(description_dict)\n",
    "df4 = get_similarity_df_using_setofwords(description_dict)\n",
    "df5 = get_similarity_df_using_annotations_unweighted_jaccard(annotations, mo)\n",
    "df6 = get_similarity_df_using_annotations_weighted_jaccard(annotations, mo)\n",
    "dfs = [df1, df2, df3, df4, df5, df6]\n",
    "methods = [\"ontology\", \"doc2vec\", \"bagofwords\", \"setofwords\", \"onto_unwt\", \"onto_wt\"]\n",
    "method_to_df = {k:v for (k,v) in zip(methods,dfs)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = combine_dfs_with_name_dict(method_to_df)\n",
    "print(merged_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df = apply_mean(df=merged_df, predictor_columns=methods)\n",
    "print(output_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the different graphs by training and applying a linear regression model.\n",
    "merged_df[\"target_value\"] = np.random.sample(merged_df.shape[0]) # Target values are floats between 0 and 1.\n",
    "model = train_linear_regression_model(df=merged_df, predictor_columns=methods, target_column=\"target_value\")\n",
    "output_df = apply_linear_regression_model(df=merged_df, predictor_columns=methods, model=model)\n",
    "print(output_df.head(16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df[\"target_class\"] = np.random.randint(0,2,merged_df.shape[0]) # Target classes are 0 or 1, randomly.\n",
    "model = train_random_forest_model(df=merged_df, predictor_columns=methods, target_column=\"target_class\")\n",
    "output_df = apply_random_forest_model(df=merged_df, predictor_columns=methods, model=model)\n",
    "print(output_df.head(16))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
