{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "import pandas as pd\n",
    "import sys\n",
    "import time\n",
    "import os\n",
    "sys.path.append(\"../../oats\")\n",
    "from oats.pubmed.query import search, fetch_details\n",
    "from oats.utils.utils import save_to_pickle, load_from_pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the dataset of sentences related to Arabidopsis phenotypes.\n",
    "path = \"../data/corpus_related_files/brat_annotations_ath_corpus\"\n",
    "query = \"arabidopsis AND phenotype\"\n",
    "limit = 100\n",
    "results = search(query, limit)\n",
    "id_list = results[\"IdList\"]\n",
    "papers = fetch_details(id_list)\n",
    "\n",
    "# A list of the sentences and a list of the corresponding PubMed IDs of the same length.\n",
    "sentences = []\n",
    "pubmed_ids = []\n",
    "for i, paper in enumerate(papers['PubmedArticle']):\n",
    "    try:\n",
    "        abstract_text = paper['MedlineCitation']['Article']['Abstract'][\"AbstractText\"][0]\n",
    "        abstract_sentences = sent_tokenize(abstract_text)\n",
    "        for sentence in abstract_sentences:\n",
    "            sentences.append(sentence)\n",
    "            pubmed_ids.append(id_list[i])\n",
    "    except KeyError:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Produce a text file that can be annotated using brat.\n",
    "# The process of annotating with brat should then produce the ann file.\n",
    "deliminated_sentences = \"\\n[DELIM]\\n\".join(sentences)\n",
    "file_to_annotate = open(os.path.join(path,\"sentences.txt\"),\"w\")\n",
    "file_to_annotate.write(deliminated_sentences)\n",
    "file_to_annotate.close()\n",
    "save_to_pickle(obj=sentences, path=os.path.join(path,\"sentences.pickle\"))\n",
    "save_to_pickle(obj=pubmed_ids, path=os.path.join(path,\"pubmed_ids.pickle\"))\n",
    "save_to_pickle(obj=deliminated_sentences, path=os.path.join(path,\"delimited_sentences.pickle\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the dataset of sentences related to Arabidopsis phenotypes.\n",
    "path = \"../data/corpus_related_files/brat_annotations_zma_corpus\"\n",
    "query = \"maize AND phenotype\"\n",
    "limit = 100\n",
    "results = search(query, limit)\n",
    "id_list = results[\"IdList\"]\n",
    "papers = fetch_details(id_list)\n",
    "\n",
    "# A list of the sentences and a list of the corresponding PubMed IDs of the same length.\n",
    "sentences = []\n",
    "pubmed_ids = []\n",
    "for i, paper in enumerate(papers['PubmedArticle']):\n",
    "    try:\n",
    "        abstract_text = paper['MedlineCitation']['Article']['Abstract'][\"AbstractText\"][0]\n",
    "        abstract_sentences = sent_tokenize(abstract_text)\n",
    "        for sentence in abstract_sentences:\n",
    "            sentences.append(sentence)\n",
    "            pubmed_ids.append(id_list[i])\n",
    "    except KeyError:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Produce a text file that can be annotated using brat.\n",
    "# The process of annotating with brat should then produce the ann file.\n",
    "deliminated_sentences = \"\\n[DELIM]\\n\".join(sentences)\n",
    "file_to_annotate = open(os.path.join(path,\"sentences.txt\"),\"w\")\n",
    "file_to_annotate.write(deliminated_sentences)\n",
    "file_to_annotate.close()\n",
    "save_to_pickle(obj=sentences, path=os.path.join(path,\"sentences.pickle\"))\n",
    "save_to_pickle(obj=pubmed_ids, path=os.path.join(path,\"pubmed_ids.pickle\"))\n",
    "save_to_pickle(obj=deliminated_sentences, path=os.path.join(path,\"delimited_sentences.pickle\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
