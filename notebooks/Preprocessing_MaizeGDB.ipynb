{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading in data available through Maize GDB (Maize Genetics and Genomics Database)\n",
    "The purpose of this notebook is to read in and do a preliminary analysis of the data related to text descriptions that are available through Maize GDB. The data was provided in the form of the input file by a request through Maize GDB curators, rather than obtained through an already available file from the database. The data needs to be organized and also restructured into a standard format that will allow it to be easily combined with datasets from other resources.\n",
    "\n",
    "### Files read\n",
    "```\n",
    "phenologs-with-oats/data/gene_related_files/maizegdb/pheno_genes.txt\n",
    "phenologs-with-oats/data/gene_related_files/maizegdb/maize_v3.gold.gaf\n",
    "```\n",
    "\n",
    "\n",
    "### Files created\n",
    "```\n",
    "phenologs-with-oats/data/reshaped_files/zma_phenotypes.csv\n",
    "phenologs-with-oats/data/reshaped_files/zma_high_confidence_go_annotations.csv\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "import sys\n",
    "import os\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "sys.path.append(\"../../oats\")\n",
    "from oats.utils.constants import NCBI_TAG, UNIPROT_TAG\n",
    "from oats.utils.constants import EVIDENCE_CODES\n",
    "from oats.utils.utils import to_abbreviation\n",
    "from oats.nlp.preprocess import concatenate_with_bar_delim\n",
    "from oats.nlp.preprocess import other_delim_to_bar_delim\n",
    "from oats.nlp.preprocess import remove_punctuation\n",
    "from oats.nlp.preprocess import remove_enclosing_brackets\n",
    "from oats.nlp.preprocess import concatenate_descriptions\n",
    "from oats.nlp.preprocess import add_prefix\n",
    "\n",
    "mpl.rcParams[\"figure.dpi\"] = 200\n",
    "warnings.simplefilter('ignore')\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_DIR = \"../data/reshaped_files\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File with genes and phenotype descriptions (pheno_genes.txt)\n",
    "Note that fillna is being used here to replace missing values with an empty string. This is done so that the missing string will be quantified when checking for the number of occurences of unique values from different columns, see the analysis below. However this is not necessary as a preprocessing step because when the data is read in and appended to a dataset object later, any missing values or empty strings will be handled at that step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"../data/gene_related_files/maizegdb/pheno_genes.txt\"\n",
    "usecols = [\"phenotype_name\", \"phenotype_description\", \"locus_name\", \"alleles\", \"locus_synonyms\", \"v3_gene_model\", \"v4_gene_model\", \"uniprot_id\", \"ncbi_gene\"]\n",
    "df = pd.read_table(filename, usecols=usecols)\n",
    "df.fillna(\"\", inplace=True)\n",
    "print(df[[\"phenotype_name\",\"phenotype_description\"]].head(10))\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text information about the phenotypes are contained in both the phenotype name and phenotype description for these data. The can be concatenated and retained together in a new description column that contains all this information, or just the phenotype description could be retained, depending on which data should be used downstream for making similarity comparisons. This is different than for most of the other sources of text used. The next cell looks at how many unique values there are in this data for each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding out how many unique values there are for each column.\n",
    "unique_values = {col:len(pd.unique(df[col].values)) for col in df.columns}\n",
    "for k,v in unique_values.items():\n",
    "    print(\"{:24}{:8}\".format(k,v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a fairly small number of distinct phenotype descriptions (379) compared to the number of lines that are in the complete dataset (3,616). This means that the same descriptions is occuring many times. Look at which descriptions are occuring most often."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list sorted by number of occurences for each phenotype description.\n",
    "description_counts = df[\"phenotype_description\"].value_counts().to_dict()\n",
    "sorted_tuples = sorted(description_counts.items(), key = lambda x: x[1], reverse=True)\n",
    "for t in sorted_tuples[0:10]:\n",
    "    print(\"{:6}    {:20}\".format(t[1],t[0][:70]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The only description that occurs far more often than the next is an empty string, where this information is missing entirely. The next cell looks at how many phrases are included in the phenotype description values. Most have a single phrase, some have multiple. These look like they are mainly separated with semicolons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting distributions of number of phrases in each description.\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "ax1.set_title(\"Phenotype Descriptions\")\n",
    "ax2.set_title(\"Phenotype Descriptions\")\n",
    "ax1.set_xlabel(\"Number of phrases\")\n",
    "ax2.set_xlabel(\"Number of words\")\n",
    "x1 = [len(sent_tokenize(x)) for x in df[\"phenotype_description\"].values]\n",
    "x2 = [len(word_tokenize(x)) for x in df[\"phenotype_description\"].values]\n",
    "ax1.hist(x1, bins=15, range=(0,15), density=False, alpha=0.8, histtype='stepfilled', color=\"black\", edgecolor='none')\n",
    "ax2.hist(x2, bins=30, range=(0,150), density=False, alpha=0.8, histtype='stepfilled', color=\"black\", edgecolor='none')\n",
    "fig.set_size_inches(15,4)\n",
    "fig.tight_layout()\n",
    "fig.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restructuring the dataset to include all the expected column names.\n",
    "df[\"description\"] = np.vectorize(concatenate_descriptions)(df[\"phenotype_name\"], df[\"phenotype_description\"])\n",
    "df[\"uniprot_id\"] = df[\"uniprot_id\"].apply(add_prefix, prefix=UNIPROT_TAG)\n",
    "df[\"ncbi_gene\"] = df[\"ncbi_gene\"].apply(add_prefix, prefix=NCBI_TAG)\n",
    "df[\"gene_names\"] = np.vectorize(concatenate_with_bar_delim)(df[\"locus_name\"], df[\"alleles\"], df[\"locus_synonyms\"], df[\"v3_gene_model\"], df[\"v4_gene_model\"], df[\"uniprot_id\"], df[\"ncbi_gene\"])\n",
    "df[\"species\"] = \"zma\"\n",
    "df[\"term_ids\"] = \"\"\n",
    "df = df[[\"species\", \"gene_names\", \"description\", \"term_ids\"]]\n",
    "print(df[[\"species\",\"gene_names\"]].head(10))\n",
    "print(df[[\"species\",\"gene_names\"]].sample(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outputting the dataset of descriptions to a csv file.\n",
    "path = os.path.join(OUTPUT_DIR,\"zma_phenotypes.csv\")\n",
    "df.to_csv(path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File with high confidence gene ontology annotations (maize_v3.gold.gaf)\n",
    "This file was generated as part of the [Maize GAMER](https://onlinelibrary.wiley.com/doi/full/10.1002/pld3.52)  publication (Wimalanathan et al., 2018). The annotations include all of the associations between maize genes and ontology terms from GO where the terms have been experimentally confirmed to represent correct functional annotations for those genes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"../data/gene_related_files/maizegdb/maize_v3.gold.gaf\"\n",
    "df = pd.read_table(filename, skiprows=1)\n",
    "df.fillna(\"\", inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restructuring the dataset to include all the expected column names.\n",
    "df[\"description\"] = \"\"\n",
    "df[\"gene_names\"] = np.vectorize(concatenate_with_bar_delim)(df[\"db_object_id\"], df[\"db_object_symbol\"])\n",
    "df[\"species\"] = \"zma\"\n",
    "df[\"term_ids\"] = df[\"term_accession\"]\n",
    "df = df[[\"species\", \"gene_names\", \"description\", \"term_ids\"]]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outputting the dataset of annotations to a csv file.\n",
    "path = os.path.join(OUTPUT_DIR,\"zma_high_confidence_go_annotations.csv\")\n",
    "df.to_csv(path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
