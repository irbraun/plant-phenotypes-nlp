{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constructing a combined dataset from multiple sources\n",
    "Something here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import sys\n",
    "import os\n",
    "import gensim\n",
    "import warnings\n",
    "import itertools\n",
    "import multiprocessing as mp\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Other modules imported from the local package.\n",
    "sys.path.append(\"../../oats\")\n",
    "from oats.utils.utils import save_to_pickle, load_from_pickle\n",
    "from oats.utils.utils import function_wrapper, to_hms\n",
    "\n",
    "# Setting some options to make notebook output clearer.\n",
    "pd.set_option('mode.chained_assignment', None)\n",
    "pd.set_option('display.multi_sparse', False)\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in the dataframe: 5303\n",
      "Number of unique IDs:            5303\n",
      "Number of unique descriptions:   3085\n",
      "Number of unique gene name sets: 5303\n",
      "Number of species represented:   1\n"
     ]
    }
   ],
   "source": [
    "from oats.datasets.dataset import Dataset\n",
    "\n",
    "# Put together a complete dataset from files that have been formatted correctly in the other notebooks.\n",
    "dataset = Dataset()\n",
    "dataset.add_data(pd.read_csv(\"../data/reshaped_files/ath_tair_gene_text.csv\", lineterminator=\"\\n\"))\n",
    "#dataset.add_data(pd.read_csv(\"../data/reshaped_files/ath_tair_gene_annot_go.csv\", lineterminator=\"\\n\"))\n",
    "#dataset.add_data(pd.read_csv(\"../data/reshaped_files/ath_tair_gene_annot_po.csv\", lineterminator=\"\\n\"))\n",
    "dataset.collapse_by_first_gene_name()\n",
    "dataset.filter_has_description()\n",
    "#dataset.filter_has_annotation()\n",
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looking at what pathways or groups are represented by genes in that dataset\n",
    "something more here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Of the 5303 genes in the dataset, 663 are mapped to atleast one pathway.\n",
      "17      PWY-5080 PWY-7036\n",
      "19      PWY-6\n",
      "20      PWY-6733\n",
      "22      PWY-7270 ETHYL-PWY\n",
      "23      PWY-181\n",
      "25      PWY-5667 TRIGLSYN-PWY\n",
      "32      PWY-6295 PWY-6733 PWY-84\n",
      "37      PWY-282\n",
      "45      PWY-6898 PWY-7356 PWY-6908\n",
      "50      LEU-DEG2-PWY\n",
      "56      PWY-622\n",
      "58      HEME-BIOSYNTHESIS-II CHLOROPHYLL-SYN\n",
      "62      PWY-6745\n",
      "69      PWY-581 PWYDQC-4\n",
      "70      PWY-5080\n",
      "79      PWY-6446 PWY-6444 PWY-3181\n",
      "81      PWY-5136\n",
      "92      PWY-6363 PWY-6364\n",
      "93      PWY-5272 PWY-1782 PWY-1741\n",
      "94      PWY-6363 PWY-6364\n",
      "104     PWY-5136 PWY-6837\n",
      "106     PWY-6773\n",
      "107     PWY-5129\n",
      "108     PWY-5667 TRIGLSYN-PWY\n",
      "112     PWY-6475\n"
     ]
    }
   ],
   "source": [
    "from oats.datasets.groupings import Groupings\n",
    "from oats.utils.utils import merge_list_dicts\n",
    "\n",
    "\n",
    "genes = dataset.get_gene_dictionary()\n",
    "\n",
    "# Create/read in the different objects for organizing gene groupings.\n",
    "groupings_kegg = load_from_pickle(path=\"../data/pickles/kegg_pathways.pickle\")\n",
    "groupings_pmn = load_from_pickle(path=\"../data/pickles/pmn_pathways.pickle\")\n",
    "groupings_subset = load_from_pickle(path=\"../data/pickles/lloyd_subsets.pickle\")\n",
    "groupings_class = load_from_pickle(path=\"../data/pickles/lloyd_classes.pickle\")\n",
    "\n",
    "# Get mappings between object IDs and pathways IDs and the reverse.\n",
    "id_to_pathway_ids = merge_list_dicts(\n",
    "    groupings_kegg.get_forward_dict(genes),\n",
    "    groupings_pmn.get_forward_dict(genes),\n",
    "    groupings_subset.get_forward_dict(genes))\n",
    "\n",
    "# Show some mappings between IDs and groups where the ID belongs to atleast one.\n",
    "total = len(id_to_pathway_ids.keys())\n",
    "has_mapping = len([k for (k,v) in id_to_pathway_ids.items() if len(v)>0])\n",
    "print(\"Of the {} genes in the dataset, {} are mapped to atleast one pathway.\".format(total, has_mapping))\n",
    "for k,v in [(k,v) for (k,v) in id_to_pathway_ids.items() if len(v)>0][:25]:\n",
    "    print(\"{0:<8}{1:<}\".format(k,\" \".join(v)[:80]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Of the 422 groups in the dataset, 295 are mapped to atleast one gene.\n",
      "PWY-5080                      17 70 754 1142 1461 2056 2447 2624 2628 2848 3181\n",
      "PWY-7036                      17 754 1573 2056 2447 2539 2628 2848 3181\n",
      "PWY-6733                      20 32 328 523 671 695 724 875 969 1472 1711 1718 2260 2455 2617\n",
      "PWY-7270                      22 1724 1979 2132 2243 2273 2506 2675 3524\n",
      "ETHYL-PWY                     22 197 1724 1979 2132 2243 2273 2506 2675 3524\n",
      "PWY-181                       23 367 746 916 2678\n",
      "PWY-5667                      25 108 450 700 1641 2086 2121 2170 2561\n",
      "TRIGLSYN-PWY                  25 108 450 700 1047 1641 2086 2170 2561\n",
      "PWY-6295                      32 2635\n",
      "PWY-84                        32 2635\n",
      "PWY-282                       37 2617 3395\n",
      "PWY-7356                      45 361 2545 3098\n",
      "PWY-6908                      45 361 2545\n",
      "LEU-DEG2-PWY                  50 173 174 534 790 1150 1668 1722 1765 1931 1978 2620 2822 3084\n",
      "PWY-622                       56 194 459 1296 1349 2366 2477 2972 3046 3251 3306\n",
      "HEME-BIOSYNTHESIS-II          58 1202 3069\n",
      "CHLOROPHYLL-SYN               58 136 2370 2488 2889 3220\n",
      "PWY-6745                      62 2544 2701 3197\n",
      "PWY-581                       69 150 368 790 1089 1208 1209 1731 1921 2292 2479 2536 2590 2706 2824\n",
      "PWYDQC-4                      69 368 790 2292 2479 2536 2590 2862 3064 3192\n"
     ]
    }
   ],
   "source": [
    "# TODO why are their duplicates in the lists which are values in that dict????\n",
    "# Check why duplicates aren't being removed there.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Get a mapping that goes the other way, from pathway IDs to object IDs.\n",
    "pathway_id_to_ids = merge_list_dicts(\n",
    "    groupings_kegg.get_reverse_dict(genes),\n",
    "    groupings_pmn.get_reverse_dict(genes),\n",
    "    groupings_subset.get_reverse_dict(genes))\n",
    "\n",
    "pathway_id_to_ids = groupings_pmn.get_reverse_dict(genes)\n",
    "\n",
    "# Show some mappings between group IDs and IDs where the group has atleast two gene in the dataset.\n",
    "total = len(pathway_id_to_ids.keys())\n",
    "has_mapping = len([k for (k,v) in pathway_id_to_ids.items() if len(v)>1])\n",
    "print(\"Of the {} groups in the dataset, {} are mapped to atleast one gene.\".format(total, has_mapping))\n",
    "for k,v in [(k,v) for (k,v) in pathway_id_to_ids.items() if len(v)>1][:20]:\n",
    "    print(\"{0:<30}{1:<}\".format(k[:27],\" \".join([str(x) for x in v][:15])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2548\n"
     ]
    }
   ],
   "source": [
    "# How many occurences are there of a specific gene pair sharing atleast one pathway?\n",
    "unique_gene_id_pairs = set()\n",
    "for gene_id_list in pathway_id_to_ids.values():\n",
    "    gene_id_pairs = list(itertools.combinations(gene_id_list, 2))\n",
    "    sorted_gene_id_pairs = [tuple(sorted(x)) for x in gene_id_pairs]\n",
    "    unique_gene_id_pairs.update(sorted_gene_id_pairs)\n",
    "print(len(unique_gene_id_pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "19\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAEYCAYAAAAJeGK1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAcbklEQVR4nO3de5glVXnv8e+PiyI3ccJAWgYYNCQGjZqkw8HoQRSNJHJLIhFP0MGYQ1RiiPHCJRc0hqPGaIJRo0SNk6AgmRhgFI+SUSQaBBpU5CpEuYUeZgyHcEkCDrznj6rGTdO9Z8/07O7q7u/nefazq1ZV7fV2DfTba9Xaa6WqkCSpa7aa6wAkSZqKCUqS1EkmKElSJ5mgJEmdZIKSJHWSCUqS1EkmKGmIknw+yYo5qPeaJAfNdr3SlmSCUuclOTrJpUnuT7Ku3X59ksx1bABJTknyvST3Jbk9yacnjlXVL1bVyi1c381JXjSp7NgkX+2p9+lVddFGPmd5kkqyzZaMT9pSTFDqtCRvAk4H3gP8KLA78FrgucDjprlm61mMbwXwSuBFVbUjMAqsma36u8zEp5kyQamzkjwR+GPg9VW1qqrurcY3qurXq+qB9rxPJPmrJBckuR94QZInJvnbJOuT3JLkD5Js1Z7/tiRn9tTzqJZEkouSvDPJZUn+I8l5SZZME+bPAV+oqn8FqKq1VXVGz2dflOQ32+1vta2siVdNdMMlOSDJvyS5uz3voBneu0daWUn2TzKW5J4kdyZ5X3vaxe373W08z0myVXuvbmlbq3/b/jtMfO6r2mP/nuQPJ9XztiSrkpyZ5B7g2LbuS9qfazzJB5I8rufzqm0N35jk3iTvSPLU9pp7kpzTe74WFxOUuuw5wOOB8wY4938BpwE7AV8F/hJ4IvAU4PnAq4BXb0LdrwJ+A3gysAF4/zTnfR14VZK3JBnt13qrqmdV1Y5tS+v3gBuAK5PsAXwO+BNgCfBm4B+SLN2EePs5HTi9qnYGngqc05Yf2L7v0sZ1CXBs+3oBzb3bEfgAQJL9gA8Bvw6M0NzfPSbVdQSwCtgF+CTwEPBGYFeaf8+DgddPuuYQ4GeBA4C3Ame0dewJPAN4xQx+ds1jJih12a7A96tqw0RBTyvjv5Ic2HPueVX1tap6GPgB8HLg5LbVdTPwXpquuEH9XVVdXVX3A38I/NpUyaeqzgTeALwE+AqwLslJ/T44yfNoktHhVXUPcAxwQVVdUFUPV9WFwBjwS30+5tz2Ptyd5G6axDGdHwA/lmTXqrqvqr7e59xfB95XVd+tqvuAk4Gj29bly4DVVfXVqnoQ+CNg8mSel1TVue3P8V9VdUVVfb2qNrT/Dh+h+YOh17ur6p6quga4GvhiW/9/AJ8HfrpPvFrATFDqsn8Hdu19llFVP19Vu7THev/7va1ne1ea51O39JTdwmP/2u+n9/NuAbZtP/cxquqTVfUimlbDa4E/TvKSqc5NsidNC2ZFVX2nLd4bOGpSwnkeTStlOkdW1S4TLx7bKun1GuDHgeuTXJ7k0D7nPpnH3rdtaJ79PZme+1JV/0nz79Cr976R5MeTfDbJ2rbb7//w2Pt4Z8/2f02xv2OfeLWAmaDUZZcAD9B0G21M71/y36dpNezdU7YX8G/t9v3A9j3HfnSKz9tz0rU/aD93+gCqflBVfw9cRdM19ShJngCcC/xFVX2+59BtNC22XXpeO1TVu/rVN6iqurGqXgHsBrwbWJVkBx7b+gG4g8fetw00SWMcWDbp5/mRydVN2v8r4Hpg37aL8RSgE6Mv1X0mKHVWVd0NvB34UJKXJdmxfYj/bGCHPtc9RNNKOS3JTkn2pnnmMzEw4pvAgUn2agcAnDzFxxyTZL8k29MM1FjVfu6jpBne/dK2nq2S/CLwdODSKT7z48D1VfWnk8rPBA5L8pIkWyfZLslBSZZN8RmbLMkxSZa23Z93t8UPAeuBh2meNU04C3hjkn2S7EjT4vl02826qo3z59uBC29n48lmJ+Ae4L4kTwNetyV+Ji0OJih1WvvL/PdoHp6vo/lL/iPAicC/9Ln0DTQtpe/SDJr4FE2CoH3G82mals4VwGenuP7vgE8Aa4HtgN+Zpp57aFoFt9L88v9T4HVV9dUpzj0a+OVJI/n+Z1XdRtNKPIUmadwGvIUt9//nIcA1Se6jGTBxdFX9d9tFdxrwtbZr8QCae/R3NCP8vgf8N829pH1G9AbgbJrW1L00/yYP9Kn7zTQDWO4F/prmvksDiQsWSo+W5CLgzKr66FzH0mVtC+tumu677811PFp4bEFJGliSw5Js3z7D+jPg28DNcxuVFioTlKRNcQTNQIo7gH1pugvthtFQ2MUnSeokW1CSpE6a15M57rrrrrV8+fK5DkOSNANXXHHF96vqMVN7zesEtXz5csbGxuY6DEnSDCS5Zapyu/gkSZ1kgpIkdZIJSpLUSSYoSVInmaAkSZ1kgpIkdZIJSpLUSSYoSVInmaAkSZ00r2eS2BIOO+wwxsfHpz0+MjLC6tWrZzEiSRKYoBgfH+87XdLo6OgsRiNJmmAXnySpk0xQkqROMkFJkjrJBCVJ6iQTlCSpk0xQkqROGlqCSvLxJOuSXN1T9p4k1ye5Ksk/Jtml59jJSW5KckOSlwwrLknS/DDMFtQngEMmlV0IPKOqngl8BzgZIMl+wNHA09trPpRk6yHGJknquKElqKq6GLhrUtkXq2pDu/t1YFm7fQRwdlU9UFXfA24C9h9WbJKk7pvLZ1C/AXy+3d4DuK3n2O1t2WMkOS7JWJKx9evXDzlESdJcmZMEleT3gQ3AJyeKpjitprq2qs6oqtGqGl26dOmwQpQkzbFZn4svyQrgUODgqppIQrcDe/actgy4Y7ZjkyR1x6y2oJIcApwIHF5V/9lz6Hzg6CSPT7IPsC9w2WzGJknqlqG1oJKcBRwE7JrkduBUmlF7jwcuTALw9ap6bVVdk+Qc4Fqarr/jq+qhYcUmSeq+oSWoqnrFFMUf63P+acBpw4pHkjS/OJOEJKmTTFCSpE4yQUmSOskEJUnqJBOUJKmTTFCSpE4yQUmSOskEJUnqJBOUJKmTTFCSpE4yQUmSOskEJUnqJBOUJKmTTFCSpE4yQUmSOskEJUnqJBOUJKmTTFCSpE4yQUmSOskEJUnqJBOUJKmTTFCSpE4yQUmSOskEJUnqpKElqCQfT7IuydU9ZUuSXJjkxvb9ST3HTk5yU5IbkrxkWHFJkuaHYbagPgEcMqnsJGBNVe0LrGn3SbIfcDTw9PaaDyXZeoixSZI6bmgJqqouBu6aVHwEsLLdXgkc2VN+dlU9UFXfA24C9h9WbJKk7pvtZ1C7V9U4QPu+W1u+B3Bbz3m3t2WPkeS4JGNJxtavXz/UYCVJc6crgyQyRVlNdWJVnVFVo1U1unTp0iGHJUmaK7OdoO5MMgLQvq9ry28H9uw5bxlwxyzHJknqkNlOUOcDK9rtFcB5PeVHJ3l8kn2AfYHLZjk2SVKHbDOsD05yFnAQsGuS24FTgXcB5yR5DXArcBRAVV2T5BzgWmADcHxVPTSs2CRJ3Te0BFVVr5jm0MHTnH8acNqw4tlca9euZXR0dMpjIyMjrF69epYjkqTFYWgJaqGoKsbGxqY8Nl3ikiTNXFdG8UmS9CgmKElSJ5mgJEmdZIKSJHXSJiWoJFsl2XlYwUiSNGGjCSrJp5LsnGQHmu8p3ZDkLcMPTZK0mA3Sgtqvqu6hmXn8AmAv4JVDjUqStOgNkqC2TbItTYI6r6p+wDQTuUqStKUMkqA+AtwM7ABcnGRv4J5hBiVJ0kZnkqiq9wPv7ym6JckLhheSJEmDDZL4kSTvT3JlkiuSnA48cRZikyQtYoN08Z0NrAd+FXhZu/3pYQYlSdIgk8Uuqap39Oz/SZIjhxWQJEkwWAvqy0mObr+ku1WSXwM+N+zAJEmL2yAJ6reATwEPtq+zgd9Lcm8SR/NJkoZikFF8O81GIJIk9dpogkpy4FTlVXXxlg9HkqTGIIMkeufd2w7YH7gCeOFQIpIkicG6+A7r3U+yJ/CnQ4tIkiQ2bz2o24FnbOlAJEnqNcgzqL/kh5PDbgU8G/jWMIOSJGmQZ1BjPdsbgLOq6mtDikeSJGCwZ1ArkzwO+PG26IbhhiRJ0mCTxR4E3Ah8EPgQ8J3php4PKskbk1yT5OokZyXZLsmSJBcmubF9f9JM6pAkzW+DDJJ4L/ALVfX8qjoQeAnw55tbYZI9gN8BRqvqGcDWwNHAScCaqtoXWNPuS5IWqYFW1K2qR7r1quo7wLYzrHcb4AlJtgG2B+4AjgBWtsdX0qzgK0lapAZJUGNJPpbkoPb11zRf1N0sVfVvwJ8BtwLjwH9U1ReB3atqvD1nHNhtquuTHJdkLMnY+vXrNzcMSVLHDZKgXgdcQ9MtdwJwLfDaza2wfbZ0BLAP8GRghyTHDHp9VZ1RVaNVNbp06dLNDUOS1HF9R/El2Rr4WFUdA7xvC9X5IuB7VbW+reMzwM8DdyYZqarxJCPAui1UnyRpHurbgqqqh4Cl7TDzLeVW4IAk2ycJcDBwHXA+sKI9ZwVw3hasU5I0zwzyRd2bga8lOR+4f6KwqjarRVVVlyZZBVxJ88XfbwBnADsC5yR5DU0SO2pzPl+StDAMkqDuaF9bAVtkbaiqOhU4dVLxAzStKUmSBppJ4u2zEYgkSb2mfQaV5HlJXtWzvyrJl9qXa0FJkoaqXwvq7cAbevZ/AjgW2AE4BfjS8MKSJC12/Ubx7VxV1/bs31hVV7RLvW+RZ1GSJE2nX4LapXenqn6lZ3f34YQjSVKjX4K6PslLJxcmORSX3JAkDVm/Z1BvBD6X5GU031kC+FmaWR8OHXZgkqTFbdoWVFXdBDwT+Gdgefu6GHhmO6O5JElD0/d7UFX1APDxWYpFkqRHDDKbuSRJs84EJUnqpH4zSaxp3989e+FIktTo9wxqJMnzgcOTnA2k92BVXTn1ZZIkzVy/BPVHwEnAMh67WGEBzscnSRqaaRNUVa0CViX5w6p6xyzGJEnSQMttvCPJ4cCBbdFFVfXZ4YYlSVrsNjqKL8k7gROAa9vXCW2ZJElDM8iKui8Fnl1VDwMkWUmzTPvJwwxMkrS4Dfo9qN6ZzZ84jEAkSeo1SAvqncA3knyZZqj5gdh6kiQN2SCDJM5KchHwczQJ6sSqWjvswCRJi9sgLSiqahw4f8ixSJL0COfikyR1kglKktRJfRNUkq2SXL2lK02yS5JVSa5Pcl2S5yRZkuTCJDe270/a0vVKkuaPvgmq/e7Tt5LstYXrPR34v1X1NOBZwHU08/6tqap9gTXtviRpkRpkkMQIcE2Sy4D7Jwqr6vDNqTDJzjRD1Y9tP+dB4MEkRwAHtaetBC4CTtycOiRJ898gCertW7jOpwDrgb9J8izgCpqplHZvRwtSVeNJdpvq4iTHAccB7LXXlm7YbZq1a9cyOjo67fGRkRFWr149ixFJ0sIxyPegvpJkb2DfqvqnJNsDW8+wzp8B3lBVlyY5nU3ozquqM4AzAEZHR2sGccxYVTE2Njbt8X7JS5LU3yCTxf5vYBXwkbZoD+DcGdR5O3B7VV3a7q+iSVh3Jhlp6xwB1s2gDknSPDfIMPPjgecC9wBU1Y3AlN1vg2hnobgtyU+0RQfTzJJ+PrCiLVsBnLe5dUiS5r9BnkE9UFUPJs2K70m2oVlRdybeAHwyyeOA7wKvpkmW5yR5DXArcNQM65AkzWODJKivJDkFeEKSFwOvB2b05L+qvglM9YDm4Jl8riRp4Riki+8kmlF33wZ+C7gA+INhBiVJ0iCj+B5uFym8lKZr74aqmtPRc5KkhW+jCSrJS4EPA/9Ks9zGPkl+q6o+P+zgJEmL1yDPoN4LvKCqbgJI8lTgc4AJSpI0NIM8g1o3kZxa38XvKEmShmzaFlSSX2k3r0lyAXAOzTOoo4DLZyE2SdIi1q+L77Ce7TuB57fb6wGXwpAkDdW0CaqqXj2bgUiS1GuQUXz70Mz8sLz3/M1dbkOSpEEMMorvXOBjNLNHPDzccCRJagySoP67qt4/9EgkSeoxSII6PcmpwBeBByYKq+rKoUUlSVr0BklQPwW8EnghP+ziq3ZfkqShGCRB/TLwlKp6cNjBSJI0YZCZJL4F7DLsQCRJ6jVIC2p34Pokl/PoZ1AOM5ckDc0gCerUoUchSdIkg6wH9ZXZCESSpF6DzCRxL82oPYDHAdsC91fVzsMMTJK0uA3Sgtqpdz/JkcD+Q4toAVm7di2jo6NTHhsZGWH16tWzHJEkzR+DPIN6lKo6N8lJwwhmoakqxsbGpjw2XeKSJDUG6eL7lZ7drYBRftjlJ0nSUAzSgupdF2oDcDNwxFCikSSpNcgzKNeFkiTNun5Lvv9Rn+uqqt4xk4qTbA2MAf9WVYcmWQJ8mmbdqZuBX6uq/zeTOiRJ81e/qY7un+IF8BrgxC1Q9wnAdT37JwFrqmpfYE27L0lapKZNUFX13okXcAbwBODVwNnAU2ZSaZJlwEuBj/YUHwGsbLdXAkfOpA5J0vzWd7LYJEuS/AlwFU134M9U1YlVtW6G9f4F8FYevULv7lU1DtC+7zZNTMclGUsytn79+hmGIUnqqmkTVJL3AJcD9wI/VVVv2xLPhJIcCqyrqis25/qqOqOqRqtqdOnSpTMNR5LUUf1G8b2JZvbyPwB+P8lEeWgGSWzuVEfPBQ5P8kvAdsDOSc4E7kwyUlXjSUaAmbbSJEnzWL9nUFtV1ROqaqeq2rnntdNM5uGrqpOrallVLQeOBr5UVccA5wMr2tNWAOdtbh2SpPlvkAULZ8u7gBcnuRF4cbsvSVqkNnkuvi2pqi4CLmq3/x04eC7jkSR1R5daUJIkPcIEJUnqJBOUJKmTTFCSpE4yQUmSOskEJUnqJBOUJKmTTFCSpE4yQUmSOskEJUnqJBOUJKmTTFCSpE4yQUmSOskEJUnqJBOUJKmTTFCSpE4yQUmSOskEJUnqJBOUJKmTTFCSpE7aZq4DWKzWrl3L6OjotMdHRkZYvXr1LEYkSd1igpojVcXY2Ni0x/slL0laDOzikyR1kglKktRJs56gkuyZ5MtJrktyTZIT2vIlSS5McmP7/qTZjk2S1B1z0YLaALypqn4SOAA4Psl+wEnAmqraF1jT7kuSFqlZT1BVNV5VV7bb9wLXAXsARwAr29NWAkfOdmySpO6Y02dQSZYDPw1cCuxeVePQJDFgt2muOS7JWJKx9evXz1aokqRZNmcJKsmOwD8Av1tV9wx6XVWdUVWjVTW6dOnS4QUoSZpTc5KgkmxLk5w+WVWfaYvvTDLSHh8B1s1FbJKkbpiLUXwBPgZcV1Xv6zl0PrCi3V4BnDfbsUmSumMuZpJ4LvBK4NtJvtmWnQK8CzgnyWuAW4Gj5iA2SVJHzHqCqqqvApnm8MGzGYskqbucSUKS1EkmKElSJ5mgJEmdZIKSJHWSCUqS1EkuWNhR/VbcdbVdSYuBCaqj+q2462q7khYDu/gkSZ1kgpIkdZJdfIvMYYcdxvj4+JTHfLYlqUtMUPNQvwEU0D/RjI+P+2xL0rxggpqH+g2gABONpIXBZ1CSpE4yQUmSOskuPs0KB2dI2lQmKM0KB2dI2lR28UmSOskWlAZmN52k2WSC0sDsppM0m0xQC1C/L/KuW7dulqPZuJl88VjSwmWCWoD6fZF3jz32mOVoNs4vHkuaioMkJEmdZAtKj9hYV1sXuwclLVwmKD1iY11tXewelLRwdS5BJTkEOB3YGvhoVb1rjkPSAOaq9dVv6DvAXXfdxZIlS6Y85uALqds6laCSbA18EHgxcDtweZLzq+rauY1MGzNXra9+Q98n6p3u+LJly/omVZObNLc6laCA/YGbquq7AEnOBo4ATFDa4gZJqn7vS5o7XUtQewC39ezfDvyP3hOSHAcc1+7el+SGAT53V+D70x1M0vfifscX2rXtsWnv13z7eWbx2r7/jekxvF+bbiHfs72nKuxagprqt0E9aqfqDOCMTfrQZKyq/JN3QN6vTec92zTer023GO9Z174HdTuwZ8/+MuCOOYpFkjSHupagLgf2TbJPkscBRwPnz3FMkqQ50KkuvqrakOS3gS/QDDP/eFVdswU+epO6BOX92gzes03j/dp0i+6epao2fpYkSbOsa118kiQBJihJUkct6ASV5JAkNyS5KclJcx1PFyX5eJJ1Sa7uKVuS5MIkN7bvT5rLGLskyZ5JvpzkuiTXJDmhLfeeTSHJdkkuS/Kt9n69vS33fm1Ekq2TfCPJZ9v9RXfPFmyC6pk26ReB/YBXJNlvbqPqpE8Ah0wqOwlYU1X7AmvafTU2AG+qqp8EDgCOb/+78p5N7QHghVX1LODZwCFJDsD7NYgTgOt69hfdPVuwCYqeaZOq6kFgYtok9aiqi4G7JhUfAaxst1cCR85qUB1WVeNVdWW7fS/NL5A98J5NqRr3tbvbtq/C+9VXkmXAS4GP9hQvunu2kBPUVNMmuV7EYHavqnFofiEDu81xPJ2UZDnw08CleM+m1XZVfRNYB1xYVd6vjfsL4K3Awz1li+6eLeQEtdFpk6TNlWRH4B+A362qe+Y6ni6rqoeq6tk0M8Psn+QZcx1TlyU5FFhXVVfMdSxzbSEnKKdN2nx3JhkBaN9dSrdHkm1pktMnq+ozbbH3bCOq6m7gIppnnt6v6T0XODzJzTSPJl6Y5EwW4T1byAnKaZM23/nAinZ7BXDeHMbSKWmmMP8YcF1Vva/nkPdsCkmWJtml3X4C8CLgerxf06qqk6tqWVUtp/m99aWqOoZFeM8W9EwSSX6Jpi93Ytqk0+Y4pM5JchZwEM1U/ncCpwLnAucAewG3AkdV1eSBFItSkucB/wx8mx8+HziF5jmU92ySJM+keaC/Nc0fxOdU1R8n+RG8XxuV5CDgzVV16GK8Zws6QUmS5q+F3MUnSZrHTFCSpE4yQUmSOskEJUnqJBOUJKmTTFDSZkiye5JPJflukiuSXJLkl+cghs+2M4Vfm+SCtvzJSVbNZizSMDjMXNpE7Zd1/wVYWVUfbsv2Bg6vqr+cdO42VbVhSHF8BLi2qk5v959ZVVcNoy5pLtiCkjbdC4EHJ5ITQFXdMpGckhyb5O+TrAa+mMZ7klyd5NtJXt6ed9DEWj/t/geSHNtu35zk3e1aSpcl+bEp4hihmdJrIoar2muXT6zvleSjSb7ZvtYnObUtf0uSy5NcNbFGk9Q128x1ANI89HTgyo2c8xzgmVV1V5JfpVkL6Vk0M3ZcnuTiAeq5p6r2T/IqmhlRDp10/IPAp5P8NvBPwN9U1aPmm6yq34RHWnhfAD6R5BeAfWmWpAlwfpID26VXpM6wBSXNUJIPts+BLu8pvrBnGprnAWe1s3rfCXwF+LkBPvqsnvfnTD5YVV8AngL8NfA04BtJlk4R33bA3wO/XVW3AL/Qvr5Bk2ifRpOwpE6xBSVtumuAX53Yqarjk+wKjPWcc3/P9lRLv0CzOm/vH4nbTTpe02z/sLBJgp8CPtV2Fx4ITF6m4cPAZ6rqn3rieWdVfWSauKROsAUlbbovAdsleV1P2fZ9zr8YeHm7cN9SmiRyGXALsF+Sxyd5InDwpOte3vN+yeQPTfLCJNu32zsBT6WZRLT3nOOBnarqXT3FXwB+o13TiiR7JFnwi99p/rEFJW2iqqokRwJ/nuStwHqaFtOJ01zyjzRddN+iaQm9tarWAiQ5B7gKuJGmy63X45NcSvOH5Cum+NyfBT6QZKIl9tGqurxd6XfCm4EftCvaAny4qj6c5CeBS5oBidwHHMMiWF9I84vDzKUOaherG62q7891LNJcsYtPktRJtqAkSZ1kC0qS1EkmKElSJ5mgJEmdZIKSJHWSCUqS1En/H6Lo5VkBP+BAAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# What about the distributions of membership for each of the groupings?\n",
    "x = [len(v) for v in pathway_id_to_ids.values()]\n",
    "print(min(x))\n",
    "print(max(x))\n",
    "plt.hist(x, bins=45, range=(1,45), density=False, alpha=0.8, histtype='bar', color='white', edgecolor='black')\n",
    "plt.title(\"Group Size Histogram\")\n",
    "plt.xlabel(\"Group Size\")\n",
    "plt.ylabel(\"Number of Groups\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subsetting the dataset and looking at what information is present\n",
    "something more here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in the dataframe: 663\n",
      "Number of unique IDs:            663\n",
      "Number of unique descriptions:   589\n",
      "Number of unique gene name sets: 663\n",
      "Number of species represented:   1\n"
     ]
    }
   ],
   "source": [
    "# Subset the dataset to retain only the genes that are mapped to atleast one group.\n",
    "dataset.filter_with_ids([k for k,v in id_to_pathway_ids.items() if len(v)>0])\n",
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       AT1G01120\n",
      "1       AT1G01220\n",
      "2       AT1G01280\n",
      "3       AT1G01480\n",
      "4       AT1G01510\n",
      "5       AT1G01610\n",
      "6       AT1G02050\n",
      "7       AT1G02205\n",
      "8       AT1G02880\n",
      "9       AT1G03090\n"
     ]
    }
   ],
   "source": [
    "# Get mapping from IDs to gene objects.\n",
    "genes = dataset.get_gene_dictionary()\n",
    "for k,v in list(genes.items())[:10]:\n",
    "    print(\"{0:<8}{1:<}\".format(k,\" \".join(v.names)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       \n",
      "1       \n",
      "2       \n",
      "3       \n",
      "4       \n",
      "5       \n",
      "6       \n",
      "7       \n",
      "8       \n",
      "9       \n"
     ]
    }
   ],
   "source": [
    "# Get a mapping from IDs to annotations (lists of ontology terms).\n",
    "annotations = dataset.get_annotations_dictionary()\n",
    "for k,v in list(annotations.items())[:10]:\n",
    "    print(\"{0:<8}{1:<}\".format(k,\" \".join(v)[:88])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       thin stems sensitive to low humidity\n",
      "1       fkgp1 mutants have about 40 times more lfucose than wild type arabidopsis plants\n",
      "2       slightly longer inflorescences an extended period of blooming a reduced number o\n",
      "3       enhanced hypocotyl length in lightgrown seedlings enlarged cotyledons increased \n",
      "4       lacks trichomes on stems and leaves some rudimentary trichomes in leaf margins n\n",
      "5       this double knockout mutant has a 6070 overall decrease in cutin monomer content\n",
      "6       abnormal exine patterning pollen has a more extensively covered surface with bro\n",
      "7       very bright green stems and siliques complete absence of lobed plates and tubesh\n",
      "8       the attpk1ko single mutant does not have any obvious aberrant phenotypes but the\n",
      "9       seeds have high levels of free branchedchain amino acids ile leu and val also hi\n"
     ]
    }
   ],
   "source": [
    "from oats.nlp.preprocess import get_clean_description\n",
    "\n",
    "# Get a mapping from IDs to text descriptions.\n",
    "descriptions = dataset.get_description_dictionary()\n",
    "descriptions = {i:get_clean_description(d) for (i,d) in descriptions.items()}\n",
    "for k,v in list(descriptions.items())[:10]:\n",
    "    print(\"{0:<8}{1:<}\".format(k,v[:80]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the pairwise similarity matrices\n",
    "Something description here about how this is done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from oats.annotation.ontology import Ontology\n",
    "from oats.annotation.annotation import write_annotations_to_tsv_file, read_annotations_from_tsv_file\n",
    "from oats.graphs.pairwise import get_edgelist_with_doc2vec\n",
    "from oats.graphs.pairwise import get_edgelist_with_bagofwords\n",
    "from oats.graphs.pairwise import get_edgelist_with_setofwords\n",
    "from oats.graphs.pairwise import get_edgelist_with_annotations\n",
    "from oats.graphs.pairwise import merge_edgelists, subset_edgelist_with_ids\n",
    "\n",
    "\n",
    "\n",
    "# Setup some of the preliminary ontology and document embeddings stuff.\n",
    "merged_ontology_file = \"../ontologies/mo.obo\"\n",
    "doc2vec_model_file = \"../gensim/enwiki_dbow/doc2vec.bin\"\n",
    "doc2vec_model = gensim.models.Doc2Vec.load(doc2vec_model_file)\n",
    "mo = Ontology(merged_ontology_file)\n",
    "annotations = dataset.get_annotations_dictionary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    from  to   doc2vec  bagofwords  setofwords\n",
      "0      0   0  0.000000    0.000000    0.000000\n",
      "1      0   1  0.487537    0.973022    0.978723\n",
      "2      0   2  0.421716    0.949363    0.973684\n",
      "3      0   3  0.436324    0.899581    1.000000\n",
      "4      0   4  0.570359    0.901715    0.993506\n",
      "5      0   5  0.432823    0.947729    0.977273\n",
      "6      0   6  0.379772    1.000000    1.000000\n",
      "7      0   7  0.271333    0.756568    0.878788\n",
      "8      0   8  0.575590    0.964331    0.982759\n",
      "9      0   9  0.521403    0.944444    0.960000\n",
      "10     0  10  0.569148    0.938396    0.993464\n",
      "11     0  11  0.412088    1.000000    1.000000\n",
      "12     0  12  0.462024    0.894591    1.000000\n",
      "13     0  13  0.350682    0.816691    1.000000\n",
      "14     0  14  0.384398    1.000000    1.000000\n",
      "15     0  15  0.550912    1.000000    1.000000\n",
      "16     0  16  0.392067    1.000000    1.000000\n",
      "17     0  17  0.532064    0.864518    1.000000\n",
      "18     0  18  0.447545    0.914408    1.000000\n",
      "19     0  19  0.555802    0.944315    1.000000\n",
      "(220116, 5)\n"
     ]
    }
   ],
   "source": [
    "# Creating one edge list for each method, then merging them into a single dataframe.\n",
    "name_to_df_mapping = {}\n",
    "name_to_df_mapping[\"doc2vec\"] = get_edgelist_with_doc2vec(doc2vec_model, descriptions)\n",
    "name_to_df_mapping[\"bagofwords\"] = get_edgelist_with_bagofwords(descriptions)             \n",
    "name_to_df_mapping[\"setofwords\"] = get_edgelist_with_setofwords(descriptions)\n",
    "#name_to_df_mapping[\"setofterms\"] = get_edgelist_with_annotations(annotations, mo)\n",
    "\n",
    "df = merge_edgelists(name_to_df_mapping, default_value=0.000)\n",
    "print(df.head(20))\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What do the similarity distributions look like for each of the methods of assessing what the value\n",
    "# of the edges between the nodes is?\n",
    "# Make sure that all are either similarity of distance functions but not a mixture of both.\n",
    "# Look into ways that these could be standardized for using the same metric to compare each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'protein1'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-4ad50e8080e4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0moats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInteractions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0minter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInteractions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/Users/irbraun/Downloads/3702.protein.links.detailed.v11.0.txt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/oats/oats/datasets/string.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filename, genes)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmapping\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_id_to_string_protein_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/oats/oats/datasets/string.py\u001b[0m in \u001b[0;36m_get_id_to_string_protein_dict\u001b[0;34m(self, genes)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0mstring_protein_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mstring_protein_names\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotein1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m             \u001b[0mstring_protein_names\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotein2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mstring_protein_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring_protein_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/envs/phenolog/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5178\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5179\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5180\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5182\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'protein1'"
     ]
    }
   ],
   "source": [
    "from oats.datasets.string import Interactions\n",
    "\n",
    "inter = Interactions(\"/Users/irbraun/Downloads/3702.protein.links.detailed.v11.0.txt\", genes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"interact\"] = np.vectorize(inter.check_interaction)(df[\"from\"], df[\"to\"])\n",
    "print(df)\n",
    "print(pd.unique(df[\"interact\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kolmogorov-Smirnov Test \n",
    "Something else about why this test is being run here and what we can potentially conclude from it, or what the result is atleast suggesting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Within group similarity stuff.\n",
    "# Where do the within group similarity values fall for each metric for the groups that have lots of genes in them?\n",
    "# That should be a quartile relative to each distribution?\n",
    "# Or p-value saying it's higher than the mean for that distribution or something?\n",
    "\n",
    "# Functions for evaluting graphs based on some objective functions.\n",
    "from oats.objectives.functions import classification\n",
    "from oats.objectives.functions import consistency_index\n",
    "from oats.graphs.indexed import IndexedGraph\n",
    "from oats.objectives.functions import pr\n",
    "\n",
    "pathway_id_to_ids = groupings_kegg.get_reverse_dict(genes)\n",
    "\n",
    "\n",
    "g = IndexedGraph(df=df, value=\"doc2vec\")\n",
    "\n",
    "\n",
    "# Kolmogorov-Smirnov test to compare the distributions of within-group sample and all-group sample.\n",
    "from scipy.stats import ks_2samp\n",
    "dist = df[\"doc2vec\"].values\n",
    "for pathway_id, id_list in pathway_id_to_ids.items():\n",
    "    if len(id_list)>1:\n",
    "        pairs = list(itertools.combinations(id_list, 2))\n",
    "        d = [g.get_value(int(pair[0]),int(pair[1])) for pair in pairs]\n",
    "        D,p_value =  ks_2samp(d,dist)\n",
    "        print(\"{0:<22}{1:<22}{2:<12}\".format(pathway_id, D, p_value))\n",
    "        #print(\"{}{}{}\".format(pathway_id, D, p_value))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting whether or not two genes share atleast one common pathway/group\n",
    "What about using the similary values present in the graph to try and predict whether or not two genes are going to be sharing a pathway? What does that look like from a precision and recall standpoint? This is essentially classifying edges in the network as either joining two nodes which are genes that share a common grouping or pathway, or joining two nodes that are not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:,\"class\"] = [int(len(set(id_to_pathway_ids[id1]).intersection(set(id_to_pathway_ids[id2])))>0) for (id1,id2) in zip(df[\"from\"].values,df[\"to\"].values)]\n",
    "#print(df.head(5))\n",
    "#print(pd.unique(df[\"class\"]))\n",
    "\n",
    "df[\"new\"] = 1-df[\"bagofwords\"]\n",
    "\n",
    "# Make sure to remove the self edges, these are not valid positive examples because we can\n",
    "# already assume that they belong to the exact same groupings or pathways.\n",
    "df_sub = df[df[\"from\"] != df[\"to\"]]\n",
    "\n",
    "\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import average_precision_score\n",
    "y_true = df_sub[\"class\"].values\n",
    "y_scores = df_sub[\"new\"].values\n",
    "\n",
    "\n",
    "# Subsetting and seeing if things improve.\n",
    "pos_tuples = [(t,s) for t,s in zip(y_true,y_scores) if t==1]\n",
    "neg_tuples = [(t,s) for t,s in zip(y_true,y_scores) if t==0]\n",
    "max_pos_samples = 600000\n",
    "max_neg_samples = 1000\n",
    "pos_tuples = pos_tuples[:max_pos_samples]\n",
    "neg_tuples = neg_tuples[:max_neg_samples]\n",
    "print(len(pos_tuples))\n",
    "print(len(neg_tuples))\n",
    "\n",
    "#https://stats.stackexchange.com/questions/251175/what-is-baseline-in-precision-recall-curve\n",
    "baseline = len(pos_tuples)/(len(pos_tuples)+len(neg_tuples))\n",
    "print(\"Basline is {}\".format(baseline))\n",
    "                           \n",
    "pos_tuples.extend(neg_tuples)\n",
    "all_tuples = pos_tuples\n",
    "y_true = [x[0] for x in all_tuples]\n",
    "y_scores = [x[1] for x in all_tuples]\n",
    "precision, recall, thresholds = precision_recall_curve(y_true, y_scores)\n",
    "\n",
    "average_precision = average_precision_score(y_true, y_scores)\n",
    "\n",
    "print('Average precision-recall score: {0:0.2f}'.format(average_precision))\n",
    "\n",
    "#for i,j in zip(y_true,y_scores):\n",
    "#    print(i, j)\n",
    "\n",
    "from inspect import signature\n",
    "\n",
    "precision, recall, _ = precision_recall_curve(y_true, y_scores)\n",
    "\n",
    "# In matplotlib < 1.5, plt.fill_between does not have a 'step' argument\n",
    "step_kwargs = ({'step': 'post'}\n",
    "               if 'step' in signature(plt.fill_between).parameters\n",
    "               else {})\n",
    "plt.step(recall, precision, color='b', alpha=0.2,\n",
    "         where='post')\n",
    "plt.fill_between(recall, precision, alpha=0.2, color='b', **step_kwargs)\n",
    "\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.title('2-class Precision-Recall curve: AP={0:0.2f}'.format(average_precision))\n",
    "\n",
    "area = auc(recall, precision)\n",
    "print(\"area is\",area)\n",
    "print(\"baseline area is\",baseline) # the area under teh baseline is just width (1) x height (basline).\n",
    "print(\"ratio =\", area/baseline)\n",
    "\n",
    "# Make sure self-edges are being removed? Those are not valid positive samples.\n",
    "# Are they in there?\n",
    "\n",
    "# The precision recall curve looks like the things that are predictable are very easily predictable, and \n",
    "# everything else is impossible-ish to predict without tanking the precision.\n",
    "# i.e., a big percentage of cases where two things are mapped to the same pathway is when they are just identical.\n",
    "# And when they are not identical, then they are impsossible to distinguish from random pairings of genes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting which pathway(s) each gene belong to\n",
    "pathway_id_to_ids = groupings_kegg.get_reverse_dict(genes)This is for classifying nodes in the network as belonging to certain classes or not, rather than classifying edges between the nodes. There are multiple ways that this could be done. The way we used before was just a function over the average similarity to nodes that are known to belong to a specific class (leave-one-out prediction). That takes into account the edges that are in the graph itself, but not information about the node. For example, could a neural network that learns a mapping directly between an embedding as in the input and a class membership vector do any better here? The average similarity thing should be the baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_to_pathway_ids = groupings_kegg.get_forward_dict(genes)\n",
    "print(\"done getting pathways dictionary\")\n",
    "\n",
    "df.loc[:,\"class\"] = [int(len(set(id_to_pathway_ids[id1]).intersection(set(id_to_pathway_ids[id2])))>0) for (id1,id2) in zip(df[\"from\"].values,df[\"to\"].values)]\n",
    "df[\"new\"] = 1-df[\"bagofwords\"]\n",
    "g = IndexedGraph(df=df, value=\"new\")\n",
    "print(\"done making the graph\")\n",
    "y_true, y_scores = classification(g, id_to_pathway_ids)\n",
    "print(\"done doing the classifying\")\n",
    "\n",
    "from inspect import signature\n",
    "\n",
    "precision, recall, _ = precision_recall_curve(y_true, y_scores)\n",
    "\n",
    "# In matplotlib < 1.5, plt.fill_between does not have a 'step' argument\n",
    "step_kwargs = ({'step': 'post'}\n",
    "               if 'step' in signature(plt.fill_between).parameters\n",
    "               else {})\n",
    "plt.step(recall, precision, color='b', alpha=0.2,\n",
    "         where='post')\n",
    "plt.fill_between(recall, precision, alpha=0.2, color='b', **step_kwargs)\n",
    "\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.title('2-class Precision-Recall curve: AP={0:0.2f}'.format(average_precision))\n",
    "\n",
    "area = auc(recall, precision)\n",
    "print(\"area is\",area)\n",
    "print(\"baseline area is\",baseline) # the area under teh baseline is just width (1) x height (basline).\n",
    "print(\"ratio =\", area/baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = train_test_split(df, test_size=0.25)\n",
    "print(df_train.shape)\n",
    "print(df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.loc[:,\"class\"] = [int(len(set(id_to_pathway_ids[id1]).intersection(set(id_to_pathway_ids[id2])))>0) for (id1,id2) in zip(df_train[\"from\"].values,df_train[\"to\"].values)]\n",
    "print(df_train.head(20))\n",
    "print(len(df_train[df_train[\"class\"]==0]))\n",
    "print(len(df_train[df_train[\"class\"]==1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes about different types of analysis for predicting membership or interactions based on text\n",
    "The representative approach takes the encoding for each individual gene's associated text or annotations (bag of words, list of terms, vector embedding, etc), and then constructs a similar object for each grouping or function of interest (concatenates text of all members, takes union of the annotations, maybe throwing out low frequency things, etc, document embedding for concatenated text rather than the individual ones. Then the graph has edges between nodes which are genes and nodes which are representative of groups, and the similarity of a given gene to any group can be thresholded to see if it's a member. \n",
    "\n",
    "The question is is this actually different than doing the mean similarity of a node to all other nodes that members of a particular group, thing that was done in the last analysis? It's still just a measure of how similar is this thing to all the other things that are in that group. Slightly different approach but in concept it seems very similar. Does this approach have any advantages at all? It allows for taking in the actual data and annotations itself into account before the scores are given, so that low frequency terms or whatever are thrown out. More control? In the other way, all this information is masked and the only input to work with is a list of edge values from one node to a group of nodes representing a group.\n",
    "\n",
    "The only other approach could be to learn an arbitrary function between some vector embedding representing the gene (only from doc2vec or also including terms with binary input vector or something like onto2vec?) and an output vector of size k where k is the number of groups and the values are the probability of membership in that group. Not a lot of data to train this on, maybe like 4000 or so samples in the whole dataset for arabidopsis, which is the most abundant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "def get_df(filename):\n",
    "    #columns = [\"protein1\",\"protein2\",\"combined_score\"]\n",
    "    df = pd.read_table(filename, delim_whitespace=True)\n",
    "    return(df)\n",
    "\n",
    "sdf = get_df(\"/Users/irbraun/Downloads/3702.protein.links.detailed.v11.0.txt\")\n",
    "print(sdf.head())\n",
    "print(sdf.dtypes)\n",
    "\n",
    "# The score columns are all ints, they are just 0 in cases where there is not valuable information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show this does not include all the pairwise interactions possible, it's just the ones there's data for in STRING.\n",
    "# ie there are implicit negatives in this dataset.\n",
    "print(len(pd.unique(sdf.protein1)))\n",
    "print(len(pd.unique(sdf.protein2)))\n",
    "print(len(sdf))\n",
    "print(len(pd.unique(sdf.protein1))*len(pd.unique(sdf.protein1))/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_species_code(s):\n",
    "    s = s.replace(\"3702.\", \"\")\n",
    "    s = s.replace(\".1\", \"\")\n",
    "    return(s)\n",
    "\n",
    "# Also look at this, do we need to account for display names?\n",
    "# https://string-db.org/mapping_files/STRING_display_names/\n",
    "\n",
    "\n",
    "def get_id_to_string_protein_dict(string_df, genes):\n",
    "\n",
    "    id_to_string_protein_name = {}\n",
    "\n",
    "    string_protein_names = set()\n",
    "    string_protein_names.update(pd.unique(string_df.protein1))\n",
    "    string_protein_names.update(pd.unique(string_df.protein2))\n",
    "    string_protein_names = list(string_protein_names)\n",
    "    string_protein_names = [remove_species_code(s) for s in string_protein_names]\n",
    "\n",
    "    for (identifer, gene_obj) in genes.items():\n",
    "\n",
    "        matches = set()\n",
    "        for name in gene_obj.names:\n",
    "            if name in string_protein_names:\n",
    "                matches.add(name)\n",
    "        matches = list(matches)\n",
    "        if len(matches) == 0:\n",
    "            id_to_string_protein_name[identifer] = None\n",
    "        elif len(matches) == 1:\n",
    "            id_to_string_protein_name[identifer] = matches[0]\n",
    "        else:\n",
    "            print(len(matches))\n",
    "            raise KeyError(\"multiple matches in STRING for gene with names: {}\".format(\" \".join(matches)))\n",
    "            \n",
    "    return(id_to_string_protein_name)\n",
    "\n",
    "#from oats.datasets.string import get_id_to_string_protein_dict\n",
    "mapping = get_id_to_string_protein_dict(sdf, genes)\n",
    "\n",
    "#for k,v in mapping.items():\n",
    "#    print(k,v)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_interaction(string_df, mapping, id1, id2):\n",
    "    # String df is an indexed DF (multiindex of protein1 and protein2)\n",
    "    # mapping is the same as the ones in the previous.\n",
    "    # id1 and id2 are ID's of objects from the datset.\n",
    "    \n",
    "    id1 = mapping[id1]\n",
    "    id2 = mapping[id2]\n",
    "    \n",
    "    try:\n",
    "        return(string_df.loc[(id1,id2)][\"combined_score\"])\n",
    "    except(KeyError, TypeError):\n",
    "        pass\n",
    "    try: \n",
    "        return(string_df.loc[(id2,id1)][\"combined_score\"])\n",
    "    except(KeyError, TypeError):\n",
    "        return(-1)\n",
    "        #raise KeyError(\"no value in STRING for this pair of IDs\")\n",
    "\n",
    "        \n",
    "        \n",
    "    # Make the protein1 and protein2 columns the index (MultiIndex)\n",
    "indexed_df = sdf.set_index([\"protein1\",\"protein2\"], inplace=False)     \n",
    "\n",
    "\n",
    "print(check_interaction(indexed_df, mapping, 1,2))\n",
    "print(check_interaction(indexed_df, mapping, 21,2))\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing out using this information from STRING to add columns to the created dataframe.\n",
    "print(df.head(10))\n",
    "a = df.head(100)\n",
    "a[\"interaction\"] = np.vectorize(check_interaction)(a[\"from\"], a[\"to\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from oats.datasets.string import Interactions\n",
    "\n",
    "inter = Interactions(\"/Users/irbraun/Downloads/3702.protein.links.detailed.v11.0.txt\", genes)\n",
    "print(\"Doen\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
