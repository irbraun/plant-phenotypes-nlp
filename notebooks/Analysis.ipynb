{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "\n",
    "- [Introduction](#introduction)\n",
    "\n",
    "- [Links of Interest](#links)\n",
    "\n",
    "- [Part 1. Loading and Filtering Data](#part_1)\n",
    "    - [Reading in arguments](#args)\n",
    "    - [Setting input and output paths](#paths)\n",
    "    - [Reading in genes, annotations, and phenotype descriptions](#read_text_data)\n",
    "    - [Relating genes in this dataset to other biological datasets](#relating)\n",
    "    - [KEGG](#kegg)\n",
    "    - [PlantCyc](#plantcyc)\n",
    "    - [Lloyd and Meinke (2012) phenotype subsets](#subsets)\n",
    "    - [Lloyd and Meinke (2012) phenotype classes](#classes)\n",
    "    - [Oellrich, Walls et al., (2015) EQ statements](#eqs)\n",
    "    - [Protein associations from STRING](#string)\n",
    "    - [Ortholog relationships from PANTHER](#panther)\n",
    "    - [Filtering the dataset to include relevant genes](#filtering)\n",
    "     \n",
    "- [Part 2. NLP Models](#part_2)\n",
    "    - [Word2Vec and Doc2Vec](#word2vec_doc2vec)\n",
    "    - [BERT and BioBERT](#bert_biobert)\n",
    "    - [Loading models](#load_models)\n",
    "\n",
    "- [Part 3. NLP Choices](#part_3)\n",
    "    - [Preprocessing descriptions](#preprocessing)\n",
    "    - [POS Tagging](#pos_tagging)\n",
    "    - [Reducing vocabulary size](#vocab)\n",
    "    - [Annotating with biological ontologies](#annotation)\n",
    "    - [Splitting into phene descriptions](#phenes)\n",
    "        \n",
    "- [Part 4. Generating Vectors and Distance Matrices](#part_4)\n",
    "    - [Defining methods to use](#methods)\n",
    "    - [Running all methods](#running)\n",
    "    - [Merging distances into an edgelist](#merging)\n",
    "      \n",
    "- [Part 5. Biological Questions](#part_5)\n",
    "    - [Using pathways as the objective](#pathway_objective)\n",
    "    - [Using phenotype subsets as the objective](#subset_objective)\n",
    "    - [Using protein associations as the objective](#association_objective)\n",
    "    - [Using orthology as the objective](#ortholog_objective)\n",
    "    - [Adding EQ similarity values](#eq_sim)\n",
    "    - [Noting whether gene pairs have curated data](#curated)\n",
    "    - [Noting whether gene pairs refer to the same species](#species)\n",
    "    - [Determining the number of genes and pairs involved in each question](#n_values)\n",
    "    - [Determining how similar the biological questions are to one another](#objective_similarities)\n",
    "    \n",
    "- [Part 6. Results](#part_6)\n",
    "    - [Distributions of distance values](#ks)\n",
    "    - [Within-group distance values](#within)\n",
    "    - [Predictions and AUC for shared pathways or interactions](#auc)\n",
    "    - [Tests for querying to recover related genes](#y)\n",
    "    - [Producing output summary table](#output)\n",
    "\n",
    "- [Part 7. Clustering Analysis](#part_7)\n",
    "    - [Topic modeling](#topic_modeling)\n",
    "    - [Agglomerative clustering](#clustering)\n",
    "    - [Phenologs for OMIM disease phenotypes](#phenologs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"introduction\"></a>\n",
    "### Introduction: Text Mining Analysis of Phenotype Descriptions in Plants\n",
    "The purpose of this notebook is to evaluate what can be learned from a natural language processing approach to analyzing free-text descriptions of phenotype descriptions of plants. The approach is to generate pairwise distances matrices between a set of plant phenotype descriptions across different species, sourced from academic papers and online model organism databases. These pairwise distance matrices can be constructed using any vectorization method that can be applied to natural language. In this notebook, we specifically evaluate the use of n-gram and bag-of-words techniques, word and document embedding using Word2Vec and Doc2Vec, context-dependent word-embeddings using BERT and BioBERT, and ontology term annotations with automated annotation tools such as NOBLE Coder.\n",
    "\n",
    "Loading, manipulation, and filtering of the dataset of phenotype descriptions associated with genes across different plant species is largely handled through a Python package created for this purpose called OATS (Ontology Annotation and Text Similarity) which is available [here](https://github.com/irbraun/oats). Preprocessing of the descriptions, mapping the dataset to additional resources such as protein-protein interaction databases and biochemical pathway databases are handled in this notebook using that package as well. In the evaluation of each of these natural language processing approaches to analyzing this dataset of descriptions, we compare performance against a dataset generated through manual annotation of a similar dataset in Oellrich Walls et al. (2015) and against manual annotations with experimentally determined terms from the Gene Ontology (PO) and the Plant Ontology (PO).\n",
    "\n",
    "<a id=\"links\"></a>\n",
    "### Relevant links of interest:\n",
    "- Paper describing comparison of NLP and ontology annotation approaches to curation: [Braun, Lawrence-Dill (2019)](https://doi.org/10.3389/fpls.2019.01629)\n",
    "- Paper describing results of manual phenotype description curation: [Oellrich, Walls et al. (2015](https://plantmethods.biomedcentral.com/articles/10.1186/s13007-015-0053-y)\n",
    "- Plant databases with phenotype description text data available: [TAIR](https://www.arabidopsis.org/), [SGN](https://solgenomics.net/), [MaizeGDB](https://www.maizegdb.org/)\n",
    "- Python package for working with phenotype descriptions: [OATS](https://github.com/irbraun/oats)\n",
    "- Python package used for general NLP functions: [NLTK](https://www.nltk.org/), [Gensim](https://radimrehurek.com/gensim/auto_examples/index.html)\n",
    "- Python package used for working with biological ontologies: [Pronto](https://pronto.readthedocs.io/en/latest/)\n",
    "- Python package for loading pretrained BERT models: [PyTorch Pretrained BERT](https://pypi.org/project/pytorch-pretrained-bert/)\n",
    "- For BERT Models pretrained on PubMed and PMC: [BioBERT Paper](https://arxiv.org/abs/1901.08746), [BioBERT Models](https://github.com/naver/biobert-pretrained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warming up PyWSD (takes ~10 secs)... took 6.566920042037964 secs.\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import math\n",
    "import sys\n",
    "import gensim\n",
    "import os\n",
    "import warnings\n",
    "import torch\n",
    "import itertools\n",
    "import argparse\n",
    "import shlex\n",
    "import random\n",
    "import multiprocessing as mp\n",
    "from collections import Counter, defaultdict\n",
    "from inspect import signature\n",
    "from scipy.stats import ks_2samp, hypergeom, pearsonr, spearmanr\n",
    "from sklearn.metrics import precision_recall_curve, f1_score, auc\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from scipy import spatial, stats\n",
    "from statsmodels.sandbox.stats.multicomp import multipletests\n",
    "from pytorch_pretrained_bert import BertTokenizer, BertModel, BertForMaskedLM\n",
    "from gensim.parsing.preprocessing import strip_non_alphanum, stem_text, preprocess_string, remove_stopwords\n",
    "from gensim.utils import simple_preprocess\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.decomposition import LatentDirichletAllocation as LDA\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "from nltk.corpus import brown, stopwords\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "nltk.download('stopwords', quiet=True)\n",
    "nltk.download('wordnet', quiet=True)\n",
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('brown', quiet=True)\n",
    "nltk.download('averaged_perceptron_tagger', quiet=True)\n",
    "\n",
    "sys.path.append(\"../../oats\")\n",
    "from oats.utils.utils import save_to_pickle, load_from_pickle, merge_list_dicts, flatten, to_hms\n",
    "from oats.utils.utils import function_wrapper_with_duration, remove_duplicates_retain_order\n",
    "from oats.biology.dataset import Dataset\n",
    "from oats.biology.groupings import Groupings\n",
    "from oats.biology.relationships import ProteinInteractions, AnyInteractions\n",
    "from oats.annotation.ontology import Ontology\n",
    "from oats.annotation.annotation import annotate_using_noble_coder\n",
    "from oats.distances import pairwise as pw\n",
    "from oats.distances.edgelists import merge_edgelists, make_undirected, remove_self_loops, subset_with_ids\n",
    "from oats.nlp.vocabulary import get_overrepresented_tokens, get_vocab_from_tokens\n",
    "from oats.nlp.vocabulary import reduce_vocab_connected_components, reduce_vocab_linares_pontes\n",
    "from oats.nlp.preprocess import concatenate_with_bar_delim\n",
    "\n",
    "from _utils import Method\n",
    "from _utils import IndexedGraph\n",
    "\n",
    "mpl.rcParams[\"figure.dpi\"] = 400\n",
    "warnings.simplefilter('ignore')\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a = {1:\"asdfasdf\", 2:\"asd as asdfadf\"}\n",
    "#tt = [\"asd\", \"asdfasdf\", \"asdfas\", \"asdfa\"]\n",
    "#g = pw.pairwise_square_ngrams(ids_to_texts = a, metric=\"cosine\", training_texts=tt, tfidf=True)\n",
    "#g.array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"part_1\"></a>\n",
    "# Part 1. Loading and Filtering Data\n",
    "This section defines some constants which are used for creating a uniquely named directory to contain all the outputs from running this instance of this notebook. The naming scheme is based on the time that the notebook is run. All the input and output file paths for loading datasets or models are also contained within this cell, so that if anything is moved the directories and file names should only have to be changed at this point and nowhere else further into the notebook. If additional files are added to the notebook cells they should be put here as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"args\"></a>\n",
    "### Reading in arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "NOTEBOOK = True\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--learning\", dest=\"learning\", required=False, action='store_true', help=\"use the approaches that involve neural networks\")\n",
    "parser.add_argument(\"--noblecoder\", dest=\"noblecoder\", required=False, action='store_true', help=\"use the approaches that involve computational annotation\")\n",
    "parser.add_argument(\"--lda\", dest=\"lda\", required=False, action='store_true', help=\"use the approaches that involve topic modeling\")\n",
    "parser.add_argument(\"--nmf\", dest=\"nmf\", required=False, action='store_true', help=\"use the approaches that involve topic modeling\")\n",
    "parser.add_argument(\"--vanilla\", dest=\"vanilla\", required=False, action='store_true', help=\"use the n-grams (bag-of-words) approach\")\n",
    "parser.add_argument(\"--vocab\", dest=\"vocab\", required=False, action='store_true', help=\"using the n-grams approach but with modified vocabularies\")\n",
    "parser.add_argument(\"--annotations\", dest=\"annotations\", required=False, action='store_true', help=\"use the curated annotations\")\n",
    "\n",
    "if NOTEBOOK:\n",
    "    arg_string = \"--learning --noblecoder --lda --nmf --vanilla --vocab --annotations\"\n",
    "    args = parser.parse_args(shlex.split(arg_string))\n",
    "else:\n",
    "    args = parser.parse_args()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"paths\"></a>\n",
    "### Defining the input file paths and creating output directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and name an output directory according to when the notebooks or script was run.\n",
    "OUTPUT_DIR = os.path.join(\"../outputs\",\"{}_r{}\".format(datetime.datetime.now().strftime('%m_%d_%Y_h%Hm%Ms%S'),random.randrange(1000,9999)))\n",
    "os.mkdir(OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset_filename = \"../data/pickles/gene_phenotype_dataset_all_text_and_annotations.pickle\"          # The full dataset pickle.\n",
    "kegg_pathways_filename = \"../data/pickles/groupings_from_kegg_pathways.pickle\"                       # The pathway groupings from KEGG.\n",
    "pmn_pathways_filename = \"../data/pickles/groupings_from_pmn_pathways.pickle\"                         # The pahway groupings from Plant Metabolic Network.\n",
    "lloyd_subsets_filename = \"../data/pickles/groupings_from_lloyd_subsets.pickle\"                       # The functional subsets defined by Lloyd and Meinke (2012).\n",
    "lloyd_classes_filename = \"../data/pickles/groupings_from_lloyd_classes.pickle\"                       # The functional classes defined by Lloyd and Meinke (2012).\n",
    "background_corpus_filename = \"../data/corpus_related_files/untagged_text_corpora/background.txt\"     # Text file with background content.\n",
    "phenotypes_corpus_filename = \"../data/corpus_related_files/untagged_text_corpora/phenotypes_all.txt\" # Text file with specific content.\n",
    "doc2vec_pubmed_filename = \"../gensim/pubmed_dbow/doc2vec_2.bin\"                                      # File holding saved Doc2Vec model trained on PubMed.\n",
    "doc2vec_wikipedia_filename = \"../gensim/enwiki_dbow/doc2vec.bin\"                                     # File holding saved Doc2Vec model trained on Wikipedia.\n",
    "word2vec_model_filename = \"../gensim/wiki_sg/word2vec.bin\"                                           # File holding saved Word2Vec model trained on Wikipedia.\n",
    "go_filename = \"../ontologies/go.obo\"                                                                 # Gene Ontology file in OBO format.\n",
    "po_filename = \"../ontologies/po.obo\"                                                                 # Plant Ontology file in OBO format.\n",
    "pato_filename = \"../ontologies/pato.obo\"                                                             # Phenotype and Trait Ontology file in OBO format.\n",
    "noblecoder_jarfile_path = \"../lib/NobleCoder-1.0.jar\"                                                # Jar for NOBLE Coder annotation tool.\n",
    "biobert_pmc_path = \"../gensim/biobert_v1.0_pmc/pytorch_model\"                                        # Path for PyTorch BioBERT model.\n",
    "biobert_pubmed_path = \"../gensim/biobert_v1.0_pubmed/pytorch_model\"                                  # Path for PyTorch BioBERT model.\n",
    "biobert_pubmed_pmc_path = \"../gensim/biobert_v1.0_pubmed_pmc/pytorch_model\"                          # Path for PyTorch BioBERT model.\n",
    "panther_to_omim_filename = \"../data/orthology_related_files/ath_to_hsa/pantherdb_omim_df.csv\"        # File with mappings to human orthologs and disease phenotypes.\n",
    "pppn_edgelist_path = \"../data/supplemental_files_oellrich_walls/13007_2015_53_MOESM9_ESM.txt\"\n",
    "ortholog_file_path = \"../data/orthology_related_files/pantherdb/PlantGenomeOrthologs_IRB_Modified.txt\"\n",
    "paired_phenotypes_path = \"../data/corpus_related_files/phenotype_pairs/scored.csv\"\n",
    "lloyd_function_hierarchy_path = \"../data/group_related_files/lloyd/lloyd_function_hierarchy_irb_cleaned.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"read_text_data\"></a>\n",
    "### Reading in the dataset of genes and their associated phenotype descriptions and annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>species</th>\n",
       "      <th>num_genes</th>\n",
       "      <th>unique_descriptions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ath</td>\n",
       "      <td>5851</td>\n",
       "      <td>3527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gmx</td>\n",
       "      <td>30</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mtr</td>\n",
       "      <td>37</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>osa</td>\n",
       "      <td>92</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sly</td>\n",
       "      <td>70</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>zma</td>\n",
       "      <td>1405</td>\n",
       "      <td>811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>total</td>\n",
       "      <td>7485</td>\n",
       "      <td>4553</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  species  num_genes  unique_descriptions\n",
       "0     ath       5851                 3527\n",
       "1     gmx         30                   24\n",
       "2     mtr         37                   36\n",
       "3     osa         92                   85\n",
       "4     sly         70                   70\n",
       "5     zma       1405                  811\n",
       "6   total       7485                 4553"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_from_pickle(dataset_filename)\n",
    "dataset.filter_has_description()\n",
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"relating\"></a>\n",
    "### Relating the dataset of genes to the dataset of groupings or categories\n",
    "This section generates tables that indicate how the genes present in the dataset were mapped to the defined pathways or groups. This includes a summary table that indicates how many genes by species were succcessfully mapped to atleast one pathway or group, as well as a more detailed table describing how many genes from each species were mapped to each particular pathway or group. Additionally, a pairwise group similarity matrix is also generated, where the similarity is given as the Jaccard similarity between two groups based on whether genes are shared by those groups or not. The function defined in this section returns a groupings object that can be re-used, as well as the IDs of the genes in the full dataset that were found to be relevant to those particular groupings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_in_groupings_object_and_write_summary_tables(dataset, groupings_filename, name):\n",
    "\n",
    "    # Load the groupings object.\n",
    "    groups = load_from_pickle(groupings_filename)\n",
    "    id_to_group_ids = groups.get_id_to_group_ids_dict(dataset.get_gene_dictionary())\n",
    "    group_id_to_ids = groups.get_group_id_to_ids_dict(dataset.get_gene_dictionary())\n",
    "    group_mapped_ids = [k for (k,v) in id_to_group_ids.items() if len(v)>0]\n",
    "    groups.to_csv(os.path.join(OUTPUT_DIR,\"part_1_{}_groupings.csv\".format(name)))\n",
    "\n",
    "    # Generate a table describing how many of the genes input from each species map to atleast one group.\n",
    "    summary = defaultdict(dict)\n",
    "    species_dict = dataset.get_species_dictionary()\n",
    "    for species in dataset.get_species():\n",
    "        summary[species][\"input\"] = len([x for x in dataset.get_ids() if species_dict[x]==species])\n",
    "        summary[species][\"mapped\"] = len([x for x in group_mapped_ids if species_dict[x]==species])\n",
    "    table = pd.DataFrame(summary).transpose()\n",
    "    table.loc[\"total\"]= table.sum()\n",
    "    table[\"fraction\"] = table.apply(lambda row: \"{:0.4f}\".format(row[\"mapped\"]/row[\"input\"]), axis=1)\n",
    "    table = table.reset_index(inplace=False)\n",
    "    table = table.rename({\"index\":\"species\"}, axis=\"columns\")\n",
    "    table.to_csv(os.path.join(OUTPUT_DIR,\"part_1_{}_mappings_summary.csv\".format(name)), index=False)\n",
    "\n",
    "    \n",
    "    # Generate a table describing how many genes from each species map to which particular group.\n",
    "    summary = defaultdict(dict)\n",
    "    for group_id,ids in group_id_to_ids.items():\n",
    "        summary[group_id].update({species:len([x for x in ids if species_dict[x]==species]) for species in dataset.get_species()})\n",
    "        summary[group_id][\"total\"] = len([x for x in ids])\n",
    "    table = pd.DataFrame(summary).transpose()\n",
    "    table = table.sort_values(by=\"total\", ascending=False)\n",
    "    table = table.reset_index(inplace=False)\n",
    "    table = table.rename({\"index\":\"pathway_id\"}, axis=\"columns\")\n",
    "    table[\"pathway_name\"] = table[\"pathway_id\"].map(groups.get_long_name)\n",
    "    table.loc[\"total\"] = table.sum()\n",
    "    table.loc[\"total\",\"pathway_id\"] = \"total\"\n",
    "    table.loc[\"total\",\"pathway_name\"] = \"total\"\n",
    "    table = table[table.columns.tolist()[-1:] + table.columns.tolist()[:-1]]\n",
    "    table.to_csv(os.path.join(OUTPUT_DIR,\"part_1_{}_mappings_by_group.csv\".format(name)), index=False)\n",
    "    \n",
    "    \n",
    "    # What are the similarites between the groups for the genes present in this dataset?\n",
    "    group_sims = defaultdict(dict)\n",
    "    for group_id_1,ids_1 in group_id_to_ids.items():\n",
    "        for group_id_2,ids_2 in group_id_to_ids.items():\n",
    "            jaccard_sim = len(set(ids_1).intersection(set(ids_2)))/len(set(ids_1).union(set(ids_2)))\n",
    "            group_sims[group_id_1][group_id_2] = jaccard_sim\n",
    "    table = pd.DataFrame(group_sims)\n",
    "    \n",
    "    \n",
    "    # Changing the order of the Lloyd, Meinke phenotype subsets to match other figures for consistency, special case.\n",
    "    if name == \"subsets\":\n",
    "        filename = \"../data/group_related_files/lloyd/lloyd_function_hierarchy_irb_cleaned.csv\"\n",
    "        lmtm_df = pd.read_csv(filename)    \n",
    "        subsets_in_order = [col for col in lmtm_df[\"Subset Symbol\"].values if col in table.columns]\n",
    "        table = table[subsets_in_order]\n",
    "        table = table.reindex(subsets_in_order)\n",
    "        \n",
    "        \n",
    "    # Formatting the column names for this table correctly and outputting to a file.\n",
    "    table = table.reset_index(drop=False).rename({\"index\":\"group\"},axis=1).reset_index(drop=False).rename({\"index\":\"order\"},axis=1)\n",
    "    table.to_csv(os.path.join(OUTPUT_DIR,\"part_1_{}_similarity_matrix.csv\".format(name)), index=False)\n",
    "    \n",
    "\n",
    "    # Returning the groupings object and the list of IDs for genes that were mapped to one or more groups.\n",
    "    return(groups, group_mapped_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"kegg\"></a>\n",
    "### Reading in and relating the pathways from KEGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>species</th>\n",
       "      <th>pathway_id</th>\n",
       "      <th>pathway_name</th>\n",
       "      <th>gene_names</th>\n",
       "      <th>ncbi_id</th>\n",
       "      <th>uniprot_id</th>\n",
       "      <th>ko_number</th>\n",
       "      <th>ec_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ath</td>\n",
       "      <td>ko00010</td>\n",
       "      <td>path:ath00010\\tGlycolysis / Gluconeogenesis - ...</td>\n",
       "      <td>hkl3|hexokinase-like 3</td>\n",
       "      <td>at4g37840</td>\n",
       "      <td></td>\n",
       "      <td>KO:K00844</td>\n",
       "      <td>EC:2.7.1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ath</td>\n",
       "      <td>ko00010</td>\n",
       "      <td>path:ath00010\\tGlycolysis / Gluconeogenesis - ...</td>\n",
       "      <td>hxk3|hexokinase 3</td>\n",
       "      <td>at1g47840</td>\n",
       "      <td></td>\n",
       "      <td>KO:K00844</td>\n",
       "      <td>EC:2.7.1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ath</td>\n",
       "      <td>ko00010</td>\n",
       "      <td>path:ath00010\\tGlycolysis / Gluconeogenesis - ...</td>\n",
       "      <td>hxk2|hexokinase 2</td>\n",
       "      <td>at2g19860</td>\n",
       "      <td></td>\n",
       "      <td>KO:K00844</td>\n",
       "      <td>EC:2.7.1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ath</td>\n",
       "      <td>ko00010</td>\n",
       "      <td>path:ath00010\\tGlycolysis / Gluconeogenesis - ...</td>\n",
       "      <td>hxk1|hexokinase 1</td>\n",
       "      <td>at4g29130</td>\n",
       "      <td></td>\n",
       "      <td>KO:K00844</td>\n",
       "      <td>EC:2.7.1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ath</td>\n",
       "      <td>ko00010</td>\n",
       "      <td>path:ath00010\\tGlycolysis / Gluconeogenesis - ...</td>\n",
       "      <td>hkl1|hexokinase-like 1</td>\n",
       "      <td>at1g50460</td>\n",
       "      <td></td>\n",
       "      <td>KO:K00844</td>\n",
       "      <td>EC:2.7.1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ath</td>\n",
       "      <td>ko00010</td>\n",
       "      <td>path:ath00010\\tGlycolysis / Gluconeogenesis - ...</td>\n",
       "      <td>athxk4|hexokinase</td>\n",
       "      <td>at3g20040</td>\n",
       "      <td></td>\n",
       "      <td>KO:K00844</td>\n",
       "      <td>EC:2.7.1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ath</td>\n",
       "      <td>ko00010</td>\n",
       "      <td>path:ath00010\\tGlycolysis / Gluconeogenesis - ...</td>\n",
       "      <td>pgi1|phosphoglucose isomerase 1</td>\n",
       "      <td>at4g24620</td>\n",
       "      <td></td>\n",
       "      <td>KO:K01810</td>\n",
       "      <td>EC:5.3.1.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ath</td>\n",
       "      <td>ko00010</td>\n",
       "      <td>path:ath00010\\tGlycolysis / Gluconeogenesis - ...</td>\n",
       "      <td>sugar isomerase (sis) family protein</td>\n",
       "      <td>at5g42740</td>\n",
       "      <td></td>\n",
       "      <td>KO:K01810</td>\n",
       "      <td>EC:5.3.1.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ath</td>\n",
       "      <td>ko00010</td>\n",
       "      <td>path:ath00010\\tGlycolysis / Gluconeogenesis - ...</td>\n",
       "      <td>pfk6|phosphofructokinase 6</td>\n",
       "      <td>at4g32840</td>\n",
       "      <td></td>\n",
       "      <td>KO:K00850</td>\n",
       "      <td>EC:2.7.1.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ath</td>\n",
       "      <td>ko00010</td>\n",
       "      <td>path:ath00010\\tGlycolysis / Gluconeogenesis - ...</td>\n",
       "      <td>pfk7|phosphofructokinase 7</td>\n",
       "      <td>at5g56630</td>\n",
       "      <td></td>\n",
       "      <td>KO:K00850</td>\n",
       "      <td>EC:2.7.1.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ath</td>\n",
       "      <td>ko00010</td>\n",
       "      <td>path:ath00010\\tGlycolysis / Gluconeogenesis - ...</td>\n",
       "      <td>pfk4|phosphofructokinase 4</td>\n",
       "      <td>at5g61580</td>\n",
       "      <td></td>\n",
       "      <td>KO:K00850</td>\n",
       "      <td>EC:2.7.1.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ath</td>\n",
       "      <td>ko00010</td>\n",
       "      <td>path:ath00010\\tGlycolysis / Gluconeogenesis - ...</td>\n",
       "      <td>pfk1|phosphofructokinase 1</td>\n",
       "      <td>at4g29220</td>\n",
       "      <td></td>\n",
       "      <td>KO:K00850</td>\n",
       "      <td>EC:2.7.1.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ath</td>\n",
       "      <td>ko00010</td>\n",
       "      <td>path:ath00010\\tGlycolysis / Gluconeogenesis - ...</td>\n",
       "      <td>pfk5|phosphofructokinase 5</td>\n",
       "      <td>at2g22480</td>\n",
       "      <td></td>\n",
       "      <td>KO:K00850</td>\n",
       "      <td>EC:2.7.1.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ath</td>\n",
       "      <td>ko00010</td>\n",
       "      <td>path:ath00010\\tGlycolysis / Gluconeogenesis - ...</td>\n",
       "      <td>pfk3|phosphofructokinase 3</td>\n",
       "      <td>at4g26270</td>\n",
       "      <td></td>\n",
       "      <td>KO:K00850</td>\n",
       "      <td>EC:2.7.1.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ath</td>\n",
       "      <td>ko00010</td>\n",
       "      <td>path:ath00010\\tGlycolysis / Gluconeogenesis - ...</td>\n",
       "      <td>pfk2|phosphofructokinase 2</td>\n",
       "      <td>at5g47810</td>\n",
       "      <td></td>\n",
       "      <td>KO:K00850</td>\n",
       "      <td>EC:2.7.1.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ath</td>\n",
       "      <td>ko00010</td>\n",
       "      <td>path:ath00010\\tGlycolysis / Gluconeogenesis - ...</td>\n",
       "      <td>phosphofructokinase family protein</td>\n",
       "      <td>at1g76550</td>\n",
       "      <td></td>\n",
       "      <td>KO:K00895</td>\n",
       "      <td>EC:2.7.1.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ath</td>\n",
       "      <td>ko00010</td>\n",
       "      <td>path:ath00010\\tGlycolysis / Gluconeogenesis - ...</td>\n",
       "      <td>mee51|phosphofructokinase family protein</td>\n",
       "      <td>at4g04040</td>\n",
       "      <td></td>\n",
       "      <td>KO:K00895</td>\n",
       "      <td>EC:2.7.1.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ath</td>\n",
       "      <td>ko00010</td>\n",
       "      <td>path:ath00010\\tGlycolysis / Gluconeogenesis - ...</td>\n",
       "      <td>phosphofructokinase family protein</td>\n",
       "      <td>at1g12000</td>\n",
       "      <td></td>\n",
       "      <td>KO:K00895</td>\n",
       "      <td>EC:2.7.1.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ath</td>\n",
       "      <td>ko00010</td>\n",
       "      <td>path:ath00010\\tGlycolysis / Gluconeogenesis - ...</td>\n",
       "      <td>phosphofructokinase family protein</td>\n",
       "      <td>at1g20950</td>\n",
       "      <td></td>\n",
       "      <td>KO:K00895</td>\n",
       "      <td>EC:2.7.1.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ath</td>\n",
       "      <td>ko00010</td>\n",
       "      <td>path:ath00010\\tGlycolysis / Gluconeogenesis - ...</td>\n",
       "      <td>fbp|inositol monophosphatase family protein</td>\n",
       "      <td>at1g43670</td>\n",
       "      <td></td>\n",
       "      <td>KO:K03841</td>\n",
       "      <td>EC:3.1.3.11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   species pathway_id                                       pathway_name                                   gene_names    ncbi_id uniprot_id  ko_number    ec_number\n",
       "0      ath    ko00010  path:ath00010\\tGlycolysis / Gluconeogenesis - ...                       hkl3|hexokinase-like 3  at4g37840             KO:K00844   EC:2.7.1.1\n",
       "1      ath    ko00010  path:ath00010\\tGlycolysis / Gluconeogenesis - ...                            hxk3|hexokinase 3  at1g47840             KO:K00844   EC:2.7.1.1\n",
       "2      ath    ko00010  path:ath00010\\tGlycolysis / Gluconeogenesis - ...                            hxk2|hexokinase 2  at2g19860             KO:K00844   EC:2.7.1.1\n",
       "3      ath    ko00010  path:ath00010\\tGlycolysis / Gluconeogenesis - ...                            hxk1|hexokinase 1  at4g29130             KO:K00844   EC:2.7.1.1\n",
       "4      ath    ko00010  path:ath00010\\tGlycolysis / Gluconeogenesis - ...                       hkl1|hexokinase-like 1  at1g50460             KO:K00844   EC:2.7.1.1\n",
       "5      ath    ko00010  path:ath00010\\tGlycolysis / Gluconeogenesis - ...                            athxk4|hexokinase  at3g20040             KO:K00844   EC:2.7.1.1\n",
       "6      ath    ko00010  path:ath00010\\tGlycolysis / Gluconeogenesis - ...              pgi1|phosphoglucose isomerase 1  at4g24620             KO:K01810   EC:5.3.1.9\n",
       "7      ath    ko00010  path:ath00010\\tGlycolysis / Gluconeogenesis - ...         sugar isomerase (sis) family protein  at5g42740             KO:K01810   EC:5.3.1.9\n",
       "8      ath    ko00010  path:ath00010\\tGlycolysis / Gluconeogenesis - ...                   pfk6|phosphofructokinase 6  at4g32840             KO:K00850  EC:2.7.1.11\n",
       "9      ath    ko00010  path:ath00010\\tGlycolysis / Gluconeogenesis - ...                   pfk7|phosphofructokinase 7  at5g56630             KO:K00850  EC:2.7.1.11\n",
       "10     ath    ko00010  path:ath00010\\tGlycolysis / Gluconeogenesis - ...                   pfk4|phosphofructokinase 4  at5g61580             KO:K00850  EC:2.7.1.11\n",
       "11     ath    ko00010  path:ath00010\\tGlycolysis / Gluconeogenesis - ...                   pfk1|phosphofructokinase 1  at4g29220             KO:K00850  EC:2.7.1.11\n",
       "12     ath    ko00010  path:ath00010\\tGlycolysis / Gluconeogenesis - ...                   pfk5|phosphofructokinase 5  at2g22480             KO:K00850  EC:2.7.1.11\n",
       "13     ath    ko00010  path:ath00010\\tGlycolysis / Gluconeogenesis - ...                   pfk3|phosphofructokinase 3  at4g26270             KO:K00850  EC:2.7.1.11\n",
       "14     ath    ko00010  path:ath00010\\tGlycolysis / Gluconeogenesis - ...                   pfk2|phosphofructokinase 2  at5g47810             KO:K00850  EC:2.7.1.11\n",
       "15     ath    ko00010  path:ath00010\\tGlycolysis / Gluconeogenesis - ...           phosphofructokinase family protein  at1g76550             KO:K00895  EC:2.7.1.90\n",
       "16     ath    ko00010  path:ath00010\\tGlycolysis / Gluconeogenesis - ...     mee51|phosphofructokinase family protein  at4g04040             KO:K00895  EC:2.7.1.90\n",
       "17     ath    ko00010  path:ath00010\\tGlycolysis / Gluconeogenesis - ...           phosphofructokinase family protein  at1g12000             KO:K00895  EC:2.7.1.90\n",
       "18     ath    ko00010  path:ath00010\\tGlycolysis / Gluconeogenesis - ...           phosphofructokinase family protein  at1g20950             KO:K00895  EC:2.7.1.90\n",
       "19     ath    ko00010  path:ath00010\\tGlycolysis / Gluconeogenesis - ...  fbp|inositol monophosphatase family protein  at1g43670             KO:K03841  EC:3.1.3.11"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Readin in the dataset of groupings for pathways in KEGG.\n",
    "kegg_groups, kegg_mapped_ids = read_in_groupings_object_and_write_summary_tables(dataset, kegg_pathways_filename, \"kegg\")\n",
    "kegg_groups.to_pandas().head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"plantcyc\"></a>\n",
    "### Reading in and relating the pathways from PlantCyc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>species</th>\n",
       "      <th>pathway_id</th>\n",
       "      <th>pathway_name</th>\n",
       "      <th>gene_names</th>\n",
       "      <th>ec_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ath</td>\n",
       "      <td>PWY-5272</td>\n",
       "      <td>abscisic acid degradation by glucosylation</td>\n",
       "      <td>at1g52400-monomer|abscisic acid glucose ester ...</td>\n",
       "      <td>EC-3.2.1.175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ath</td>\n",
       "      <td>PWY-5272</td>\n",
       "      <td>abscisic acid degradation by glucosylation</td>\n",
       "      <td>at4g15550-monomer|abscisate &amp;beta;-glucosyltra...</td>\n",
       "      <td>EC-2.4.1.263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ath</td>\n",
       "      <td>PWY-5272</td>\n",
       "      <td>abscisic acid degradation by glucosylation</td>\n",
       "      <td>at4g15260-monomer|abscisate &amp;beta;-glucosyltra...</td>\n",
       "      <td>EC-2.4.1.263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ath</td>\n",
       "      <td>PWY-5272</td>\n",
       "      <td>abscisic acid degradation by glucosylation</td>\n",
       "      <td>at3g21790-monomer|abscisate &amp;beta;-glucosyltra...</td>\n",
       "      <td>EC-2.4.1.263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ath</td>\n",
       "      <td>PWY-5272</td>\n",
       "      <td>abscisic acid degradation by glucosylation</td>\n",
       "      <td>at3g21760-monomer|abscisate &amp;beta;-glucosyltra...</td>\n",
       "      <td>EC-2.4.1.263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ath</td>\n",
       "      <td>PWY-5272</td>\n",
       "      <td>abscisic acid degradation by glucosylation</td>\n",
       "      <td>at2g23210-monomer|abscisate &amp;beta;-glucosyltra...</td>\n",
       "      <td>EC-2.4.1.263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ath</td>\n",
       "      <td>PWY-5272</td>\n",
       "      <td>abscisic acid degradation by glucosylation</td>\n",
       "      <td>at1g05530-monomer|abscisic acid glucosyltransf...</td>\n",
       "      <td>EC-2.4.1.263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ath</td>\n",
       "      <td>PWY-5272</td>\n",
       "      <td>abscisic acid degradation by glucosylation</td>\n",
       "      <td>at1g05560-monomer|abscisic acid glucosyltransf...</td>\n",
       "      <td>EC-2.4.1.263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ath</td>\n",
       "      <td>PWY-5272</td>\n",
       "      <td>abscisic acid degradation by glucosylation</td>\n",
       "      <td>at4g34138-monomer|abscisic acid glucosyltransf...</td>\n",
       "      <td>EC-2.4.1.263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ath</td>\n",
       "      <td>PWY-5272</td>\n",
       "      <td>abscisic acid degradation by glucosylation</td>\n",
       "      <td>at2g23250-monomer|abscisic acid glucosyltransf...</td>\n",
       "      <td>EC-2.4.1.263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ath</td>\n",
       "      <td>PWY-5272</td>\n",
       "      <td>abscisic acid degradation by glucosylation</td>\n",
       "      <td>at2g23260-monomer|abscisic acid glucosyltransf...</td>\n",
       "      <td>EC-2.4.1.263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ath</td>\n",
       "      <td>PWY-5272</td>\n",
       "      <td>abscisic acid degradation by glucosylation</td>\n",
       "      <td>at3g21780-monomer|abscisic acid glycosyltransf...</td>\n",
       "      <td>EC-2.4.1.263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ath</td>\n",
       "      <td>OXIDATIVEPENT-PWY</td>\n",
       "      <td>pentose phosphate pathway (oxidative branch) I</td>\n",
       "      <td>at1g09420-monomer|glucose-6-phosphate dehydrog...</td>\n",
       "      <td>EC-1.1.1.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ath</td>\n",
       "      <td>OXIDATIVEPENT-PWY</td>\n",
       "      <td>pentose phosphate pathway (oxidative branch) I</td>\n",
       "      <td>at5g35790-monomer|glucose-6-phosphate 1-dehydr...</td>\n",
       "      <td>EC-1.1.1.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ath</td>\n",
       "      <td>OXIDATIVEPENT-PWY</td>\n",
       "      <td>pentose phosphate pathway (oxidative branch) I</td>\n",
       "      <td>at5g13110-monomer|glucose-6-phosphate 1-dehydr...</td>\n",
       "      <td>EC-1.1.1.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ath</td>\n",
       "      <td>OXIDATIVEPENT-PWY</td>\n",
       "      <td>pentose phosphate pathway (oxidative branch) I</td>\n",
       "      <td>at5g40760-monomer|glucose-6-phosphate 1-dehydr...</td>\n",
       "      <td>EC-1.1.1.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ath</td>\n",
       "      <td>OXIDATIVEPENT-PWY</td>\n",
       "      <td>pentose phosphate pathway (oxidative branch) I</td>\n",
       "      <td>at3g27300-monomer|glucose-6-phosphate 1-dehydr...</td>\n",
       "      <td>EC-1.1.1.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ath</td>\n",
       "      <td>OXIDATIVEPENT-PWY</td>\n",
       "      <td>pentose phosphate pathway (oxidative branch) I</td>\n",
       "      <td>at1g24280-monomer|glucose-6-phosphate 1-dehydr...</td>\n",
       "      <td>EC-1.1.1.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ath</td>\n",
       "      <td>OXIDATIVEPENT-PWY</td>\n",
       "      <td>pentose phosphate pathway (oxidative branch) I</td>\n",
       "      <td>at5g41670-monomer|phosphogluconate dehydrogena...</td>\n",
       "      <td>EC-1.1.1.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ath</td>\n",
       "      <td>OXIDATIVEPENT-PWY</td>\n",
       "      <td>pentose phosphate pathway (oxidative branch) I</td>\n",
       "      <td>at1g64190-monomer|phosphogluconate dehydrogena...</td>\n",
       "      <td>EC-1.1.1.44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   species         pathway_id                                    pathway_name                                         gene_names     ec_number\n",
       "0      ath           PWY-5272      abscisic acid degradation by glucosylation  at1g52400-monomer|abscisic acid glucose ester ...  EC-3.2.1.175\n",
       "1      ath           PWY-5272      abscisic acid degradation by glucosylation  at4g15550-monomer|abscisate &beta;-glucosyltra...  EC-2.4.1.263\n",
       "2      ath           PWY-5272      abscisic acid degradation by glucosylation  at4g15260-monomer|abscisate &beta;-glucosyltra...  EC-2.4.1.263\n",
       "3      ath           PWY-5272      abscisic acid degradation by glucosylation  at3g21790-monomer|abscisate &beta;-glucosyltra...  EC-2.4.1.263\n",
       "4      ath           PWY-5272      abscisic acid degradation by glucosylation  at3g21760-monomer|abscisate &beta;-glucosyltra...  EC-2.4.1.263\n",
       "5      ath           PWY-5272      abscisic acid degradation by glucosylation  at2g23210-monomer|abscisate &beta;-glucosyltra...  EC-2.4.1.263\n",
       "6      ath           PWY-5272      abscisic acid degradation by glucosylation  at1g05530-monomer|abscisic acid glucosyltransf...  EC-2.4.1.263\n",
       "7      ath           PWY-5272      abscisic acid degradation by glucosylation  at1g05560-monomer|abscisic acid glucosyltransf...  EC-2.4.1.263\n",
       "8      ath           PWY-5272      abscisic acid degradation by glucosylation  at4g34138-monomer|abscisic acid glucosyltransf...  EC-2.4.1.263\n",
       "9      ath           PWY-5272      abscisic acid degradation by glucosylation  at2g23250-monomer|abscisic acid glucosyltransf...  EC-2.4.1.263\n",
       "10     ath           PWY-5272      abscisic acid degradation by glucosylation  at2g23260-monomer|abscisic acid glucosyltransf...  EC-2.4.1.263\n",
       "11     ath           PWY-5272      abscisic acid degradation by glucosylation  at3g21780-monomer|abscisic acid glycosyltransf...  EC-2.4.1.263\n",
       "12     ath  OXIDATIVEPENT-PWY  pentose phosphate pathway (oxidative branch) I  at1g09420-monomer|glucose-6-phosphate dehydrog...   EC-1.1.1.49\n",
       "13     ath  OXIDATIVEPENT-PWY  pentose phosphate pathway (oxidative branch) I  at5g35790-monomer|glucose-6-phosphate 1-dehydr...   EC-1.1.1.49\n",
       "14     ath  OXIDATIVEPENT-PWY  pentose phosphate pathway (oxidative branch) I  at5g13110-monomer|glucose-6-phosphate 1-dehydr...   EC-1.1.1.49\n",
       "15     ath  OXIDATIVEPENT-PWY  pentose phosphate pathway (oxidative branch) I  at5g40760-monomer|glucose-6-phosphate 1-dehydr...   EC-1.1.1.49\n",
       "16     ath  OXIDATIVEPENT-PWY  pentose phosphate pathway (oxidative branch) I  at3g27300-monomer|glucose-6-phosphate 1-dehydr...   EC-1.1.1.49\n",
       "17     ath  OXIDATIVEPENT-PWY  pentose phosphate pathway (oxidative branch) I  at1g24280-monomer|glucose-6-phosphate 1-dehydr...   EC-1.1.1.49\n",
       "18     ath  OXIDATIVEPENT-PWY  pentose phosphate pathway (oxidative branch) I  at5g41670-monomer|phosphogluconate dehydrogena...   EC-1.1.1.44\n",
       "19     ath  OXIDATIVEPENT-PWY  pentose phosphate pathway (oxidative branch) I  at1g64190-monomer|phosphogluconate dehydrogena...   EC-1.1.1.44"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading in the dataset of groupings for pathways in PlantCyc.\n",
    "pmn_groups, pmn_mapped_ids = read_in_groupings_object_and_write_summary_tables(dataset, pmn_pathways_filename, \"pmn\")\n",
    "pmn_groups.to_pandas().head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"subsets\"></a>\n",
    "###  Reading in and relating the phenotype subsets from Lloyd and Meinke (2012)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>species</th>\n",
       "      <th>group_id</th>\n",
       "      <th>gene_names</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ath</td>\n",
       "      <td>FSM</td>\n",
       "      <td>at1g01030|nga3|top1|ngatha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ath</td>\n",
       "      <td>EMB|FSM|OVP|SRF</td>\n",
       "      <td>at1g01040|sus1|dcl1|sin1|caf|abnormal suspensor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ath</td>\n",
       "      <td>CDR|LIT</td>\n",
       "      <td>at1g01060|lhy|late elongated hypocotyl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ath</td>\n",
       "      <td>IST|WAT</td>\n",
       "      <td>at1g01120|kcs1|3-ketoacyl-coa synthase defective</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ath</td>\n",
       "      <td>OVP|SRF</td>\n",
       "      <td>at1g01280|cyp703a2|cytochrome p450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ath</td>\n",
       "      <td>EMB</td>\n",
       "      <td>at1g01370|cenh3|centromere-specific histone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ath</td>\n",
       "      <td>CHS</td>\n",
       "      <td>at1g01460|pipk11|phosphatidylinositol phosphat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ath</td>\n",
       "      <td>NLS|GRS|IST</td>\n",
       "      <td>at1g01480|acs2|aminocyclopropane carboxylate s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ath</td>\n",
       "      <td>LEF|FSM</td>\n",
       "      <td>at1g01510|an|angustifolia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ath</td>\n",
       "      <td>SRL|ROT|LEF|MSL|STT|RTH|TCM|TMP</td>\n",
       "      <td>at1g01550|bps1|bypass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ath</td>\n",
       "      <td>SRF</td>\n",
       "      <td>at1g01690|prd3|putative recombination initiati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ath</td>\n",
       "      <td>TMP</td>\n",
       "      <td>at1g01860|pfc1|paleface</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ath</td>\n",
       "      <td>ROT</td>\n",
       "      <td>at1g01950|ark2|armadillo repeat kinesin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ath</td>\n",
       "      <td>OVP</td>\n",
       "      <td>at1g02050|lap6|pksa|less adhesive pollen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ath</td>\n",
       "      <td>SRF</td>\n",
       "      <td>at1g02065|spl8|squamosa promoter binding prote...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ath</td>\n",
       "      <td>PIG|LIT</td>\n",
       "      <td>at1g02090|fus5|cop15|fusca</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ath</td>\n",
       "      <td>MSL|PTH</td>\n",
       "      <td>at1g02120|vad1|vascular-associated death</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ath</td>\n",
       "      <td>GAM</td>\n",
       "      <td>at1g02140|hap1|mago|mee63|hapless</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ath</td>\n",
       "      <td>IST|FSM|WAT</td>\n",
       "      <td>at1g02205|cer1|eceriferum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ath</td>\n",
       "      <td>PIG</td>\n",
       "      <td>at1g02280|ppi1|toc33|plastid protein import</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   species                         group_id                                         gene_names\n",
       "0      ath                              FSM                         at1g01030|nga3|top1|ngatha\n",
       "1      ath                  EMB|FSM|OVP|SRF    at1g01040|sus1|dcl1|sin1|caf|abnormal suspensor\n",
       "2      ath                          CDR|LIT             at1g01060|lhy|late elongated hypocotyl\n",
       "3      ath                          IST|WAT   at1g01120|kcs1|3-ketoacyl-coa synthase defective\n",
       "4      ath                          OVP|SRF                 at1g01280|cyp703a2|cytochrome p450\n",
       "5      ath                              EMB        at1g01370|cenh3|centromere-specific histone\n",
       "6      ath                              CHS  at1g01460|pipk11|phosphatidylinositol phosphat...\n",
       "7      ath                      NLS|GRS|IST  at1g01480|acs2|aminocyclopropane carboxylate s...\n",
       "8      ath                          LEF|FSM                          at1g01510|an|angustifolia\n",
       "9      ath  SRL|ROT|LEF|MSL|STT|RTH|TCM|TMP                              at1g01550|bps1|bypass\n",
       "10     ath                              SRF  at1g01690|prd3|putative recombination initiati...\n",
       "11     ath                              TMP                            at1g01860|pfc1|paleface\n",
       "12     ath                              ROT            at1g01950|ark2|armadillo repeat kinesin\n",
       "13     ath                              OVP           at1g02050|lap6|pksa|less adhesive pollen\n",
       "14     ath                              SRF  at1g02065|spl8|squamosa promoter binding prote...\n",
       "15     ath                          PIG|LIT                         at1g02090|fus5|cop15|fusca\n",
       "16     ath                          MSL|PTH           at1g02120|vad1|vascular-associated death\n",
       "17     ath                              GAM                  at1g02140|hap1|mago|mee63|hapless\n",
       "18     ath                      IST|FSM|WAT                          at1g02205|cer1|eceriferum\n",
       "19     ath                              PIG        at1g02280|ppi1|toc33|plastid protein import"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading in the datasets of phenotype subset classifications from the Lloyd, Meinke 2012 paper.\n",
    "phe_subsets_groups, subsets_mapped_ids = read_in_groupings_object_and_write_summary_tables(dataset, lloyd_subsets_filename, \"subsets\")\n",
    "phe_subsets_groups.to_pandas().head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"classes\"></a>\n",
    "### Reading in and relating the phenotype subsets from Lloyd and Meinke (2012)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>species</th>\n",
       "      <th>group_id</th>\n",
       "      <th>gene_names</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ath</td>\n",
       "      <td>R</td>\n",
       "      <td>at1g01030|nga3|top1|ngatha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ath</td>\n",
       "      <td>S</td>\n",
       "      <td>at1g01040|sus1|dcl1|sin1|caf|abnormal suspensor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ath</td>\n",
       "      <td>T</td>\n",
       "      <td>at1g01060|lhy|late elongated hypocotyl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ath</td>\n",
       "      <td>V</td>\n",
       "      <td>at1g01120|kcs1|3-ketoacyl-coa synthase defective</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ath</td>\n",
       "      <td>R</td>\n",
       "      <td>at1g01280|cyp703a2|cytochrome p450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ath</td>\n",
       "      <td>S</td>\n",
       "      <td>at1g01370|cenh3|centromere-specific histone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ath</td>\n",
       "      <td>H</td>\n",
       "      <td>at1g01460|pipk11|phosphatidylinositol phosphat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ath</td>\n",
       "      <td>V</td>\n",
       "      <td>at1g01480|acs2|aminocyclopropane carboxylate s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ath</td>\n",
       "      <td>V</td>\n",
       "      <td>at1g01510|an|angustifolia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ath</td>\n",
       "      <td>L</td>\n",
       "      <td>at1g01550|bps1|bypass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ath</td>\n",
       "      <td>R</td>\n",
       "      <td>at1g01690|prd3|putative recombination initiati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ath</td>\n",
       "      <td>P</td>\n",
       "      <td>at1g01860|pfc1|paleface</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ath</td>\n",
       "      <td>V</td>\n",
       "      <td>at1g01950|ark2|armadillo repeat kinesin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ath</td>\n",
       "      <td>R</td>\n",
       "      <td>at1g02050|lap6|pksa|less adhesive pollen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ath</td>\n",
       "      <td>R</td>\n",
       "      <td>at1g02065|spl8|squamosa promoter binding prote...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ath</td>\n",
       "      <td>V</td>\n",
       "      <td>at1g02090|fus5|cop15|fusca</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ath</td>\n",
       "      <td>V</td>\n",
       "      <td>at1g02120|vad1|vascular-associated death</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ath</td>\n",
       "      <td>G</td>\n",
       "      <td>at1g02140|hap1|mago|mee63|hapless</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ath</td>\n",
       "      <td>V</td>\n",
       "      <td>at1g02205|cer1|eceriferum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ath</td>\n",
       "      <td>V</td>\n",
       "      <td>at1g02280|ppi1|toc33|plastid protein import</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   species group_id                                         gene_names\n",
       "0      ath        R                         at1g01030|nga3|top1|ngatha\n",
       "1      ath        S    at1g01040|sus1|dcl1|sin1|caf|abnormal suspensor\n",
       "2      ath        T             at1g01060|lhy|late elongated hypocotyl\n",
       "3      ath        V   at1g01120|kcs1|3-ketoacyl-coa synthase defective\n",
       "4      ath        R                 at1g01280|cyp703a2|cytochrome p450\n",
       "5      ath        S        at1g01370|cenh3|centromere-specific histone\n",
       "6      ath        H  at1g01460|pipk11|phosphatidylinositol phosphat...\n",
       "7      ath        V  at1g01480|acs2|aminocyclopropane carboxylate s...\n",
       "8      ath        V                          at1g01510|an|angustifolia\n",
       "9      ath        L                              at1g01550|bps1|bypass\n",
       "10     ath        R  at1g01690|prd3|putative recombination initiati...\n",
       "11     ath        P                            at1g01860|pfc1|paleface\n",
       "12     ath        V            at1g01950|ark2|armadillo repeat kinesin\n",
       "13     ath        R           at1g02050|lap6|pksa|less adhesive pollen\n",
       "14     ath        R  at1g02065|spl8|squamosa promoter binding prote...\n",
       "15     ath        V                         at1g02090|fus5|cop15|fusca\n",
       "16     ath        V           at1g02120|vad1|vascular-associated death\n",
       "17     ath        G                  at1g02140|hap1|mago|mee63|hapless\n",
       "18     ath        V                          at1g02205|cer1|eceriferum\n",
       "19     ath        V        at1g02280|ppi1|toc33|plastid protein import"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading in the datasets of phenotype class classifications from the Lloyd, Meinke 2012 paper.\n",
    "phe_classes_groups, classes_mapped_ids = read_in_groupings_object_and_write_summary_tables(dataset, lloyd_classes_filename, \"classes\")\n",
    "phe_classes_groups.to_pandas().head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relating pairs of genes to information about network edges from other sources\n",
    "This is done to only include genes (and the corresponding phenotype descriptions and annotations) which are useful for the current analysis. In this case we want to only retain genes that are mentioned atleast one time in the STRING database for a given species. If a gene is not mentioned at all in STRING, there is no information available for whether or not it interacts with any other proteins in the dataset so choose to not include it in the analysis. Only genes that have atleast one true positive are included because these are the only ones for which the missing information (negatives) is meaningful. This should be run instead of the subsequent cell, or the other way around, based on whether or not protein-protein interactions is the prediction goal for the current analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"eqs\"></a>\n",
    "### EQ-based similarities from Oellrich, Walls et al., (2015)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>from</th>\n",
       "      <th>to</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1812</td>\n",
       "      <td>1777</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1812</td>\n",
       "      <td>1818</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1812</td>\n",
       "      <td>440</td>\n",
       "      <td>0.926471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1812</td>\n",
       "      <td>1745</td>\n",
       "      <td>0.516393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1812</td>\n",
       "      <td>1816</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1812</td>\n",
       "      <td>2011</td>\n",
       "      <td>0.954545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1812</td>\n",
       "      <td>2035</td>\n",
       "      <td>0.417219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1812</td>\n",
       "      <td>1773</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1812</td>\n",
       "      <td>1872</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1812</td>\n",
       "      <td>502</td>\n",
       "      <td>0.900000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   from    to     value\n",
       "0  1812  1777  1.000000\n",
       "1  1812  1818  1.000000\n",
       "2  1812   440  0.926471\n",
       "3  1812  1745  0.516393\n",
       "4  1812  1816  1.000000\n",
       "5  1812  2011  0.954545\n",
       "6  1812  2035  0.417219\n",
       "7  1812  1773  1.000000\n",
       "8  1812  1872  1.000000\n",
       "9  1812   502  0.900000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ow_edgelist = AnyInteractions(dataset.get_name_to_id_dictionary(), pppn_edgelist_path)\n",
    "ow_edgelist.df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"string\"></a>\n",
    "### Protein associations from STRING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>from</th>\n",
       "      <th>to</th>\n",
       "      <th>known_associations</th>\n",
       "      <th>predicted_associations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>73.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>161</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>73.0</td>\n",
       "      <td>937.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>73.0</td>\n",
       "      <td>4705.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>73.0</td>\n",
       "      <td>4364.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>73.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>73.0</td>\n",
       "      <td>4185.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>73.0</td>\n",
       "      <td>470.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>73.0</td>\n",
       "      <td>5132.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>73.0</td>\n",
       "      <td>5415.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>73.0</td>\n",
       "      <td>4410.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     from      to  known_associations  predicted_associations\n",
       "346  73.0    49.0                 161                       0\n",
       "348  73.0   937.0                   0                       0\n",
       "351  73.0  4705.0                   0                       0\n",
       "352  73.0  4364.0                   0                       0\n",
       "353  73.0   131.0                   0                       0\n",
       "355  73.0  4185.0                   0                       0\n",
       "357  73.0   470.0                   0                       0\n",
       "358  73.0  5132.0                   0                       0\n",
       "359  73.0  5415.0                   0                       0\n",
       "360  73.0  4410.0                   0                       0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naming_file = \"../data/group_related_files/string/all_organisms.name_2_string.tsv\"\n",
    "interaction_files = [\n",
    "    \"../data/group_related_files/string/3702.protein.links.detailed.v11.0.txt\", # Arabidopsis\n",
    "    \"../data/group_related_files/string/4577.protein.links.detailed.v11.0.txt\", # Maize\n",
    "    \"../data/group_related_files/string/4530.protein.links.detailed.v11.0.txt\", # Tomato \n",
    "    \"../data/group_related_files/string/4081.protein.links.detailed.v11.0.txt\", # Medicago\n",
    "    \"../data/group_related_files/string/3880.protein.links.detailed.v11.0.txt\", # Rice \n",
    "    \"../data/group_related_files/string/3847.protein.links.detailed.v11.0.txt\", # Soybean\n",
    "]\n",
    "genes = dataset.get_gene_dictionary()\n",
    "string_edgelist = ProteinInteractions(genes, naming_file, *interaction_files)\n",
    "string_edgelist.df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"panther\"></a>\n",
    "### Orthologous genes from PANTHER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>from</th>\n",
       "      <th>to</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>692</th>\n",
       "      <td>565.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788</th>\n",
       "      <td>1075.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179180</th>\n",
       "      <td>1876.0</td>\n",
       "      <td>1876.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190004</th>\n",
       "      <td>3006.0</td>\n",
       "      <td>2382.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192404</th>\n",
       "      <td>1665.0</td>\n",
       "      <td>1845.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198820</th>\n",
       "      <td>3832.0</td>\n",
       "      <td>4542.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413820</th>\n",
       "      <td>3847.0</td>\n",
       "      <td>425.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415020</th>\n",
       "      <td>2532.0</td>\n",
       "      <td>1142.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431292</th>\n",
       "      <td>3620.0</td>\n",
       "      <td>2199.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470160</th>\n",
       "      <td>2520.0</td>\n",
       "      <td>571.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          from      to  value\n",
       "692      565.0    23.0    1.0\n",
       "788     1075.0    23.0    1.0\n",
       "179180  1876.0  1876.0    1.0\n",
       "190004  3006.0  2382.0    1.0\n",
       "192404  1665.0  1845.0    1.0\n",
       "198820  3832.0  4542.0    1.0\n",
       "413820  3847.0   425.0    1.0\n",
       "415020  2532.0  1142.0    1.0\n",
       "431292  3620.0  2199.0    1.0\n",
       "470160  2520.0   571.0    1.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "panther_edgelist = AnyInteractions(dataset.get_name_to_id_dictionary(), ortholog_file_path)\n",
    "panther_edgelist.df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"filtering\"></a>\n",
    "### Subsetting the dataset to include only genes with relevance to any of the biological questions\n",
    "This is done to only include genes (and the corresponding phenotype descriptions and annotations) which are useful for the current analysis. In this case we want to only retain genes that are mapped to atleast one pathway in whatever the source of pathway membership we are using is (KEGG, Plant Metabolic Network, etc). This is because for these genes, it will be impossible to correctly predict their pathway membership, and we have no evidence that they belong or do not belong in certain pathways so they can not be identified as being true or false negatives in any case. This should not actually be necessary if the dataset used to start the notebook analysis has already be subset for just the genes that either have pathway information of phenotype classification information, this should just be used to double check that the numbers make sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the list of all the IDs in this dataset that have any relevant mapping at all to the biological questions.\n",
    "ids_with_any_mapping = list(set(flatten([\n",
    "    kegg_mapped_ids,\n",
    "    pmn_mapped_ids,\n",
    "    subsets_mapped_ids,\n",
    "    classes_mapped_ids,\n",
    "    string_edgelist.ids,\n",
    "    panther_edgelist.ids\n",
    "])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the list of all the IDs in this dataset that have all of types of curated values we want to look at. \n",
    "annots = dataset.get_annotations_dictionary()\n",
    "go_mapped_ids = [i for i in dataset.get_ids() if \"GO\" in annots[i]]\n",
    "po_mapped_ids = [i for i in dataset.get_ids() if \"PO\" in annots[i]]\n",
    "ids_with_all_annotations = list(set(flatten([\n",
    "    go_mapped_ids,\n",
    "    po_mapped_ids,\n",
    "    ow_edgelist.ids\n",
    "])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>species</th>\n",
       "      <th>num_genes</th>\n",
       "      <th>unique_descriptions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ath</td>\n",
       "      <td>259</td>\n",
       "      <td>232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mtr</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>osa</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>zma</td>\n",
       "      <td>29</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>total</td>\n",
       "      <td>300</td>\n",
       "      <td>272</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  species  num_genes  unique_descriptions\n",
       "0     ath        259                  232\n",
       "1     mtr          3                    3\n",
       "2     osa          9                    9\n",
       "3     zma         29                   28\n",
       "4   total        300                  272"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.filter_with_ids(ids_with_any_mapping)\n",
    "#dataset.filter_random_k(300)\n",
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"part_2\"></a>\n",
    "# Part 2. NLP Models\n",
    "\n",
    "\n",
    "<a id=\"word2vec_doc2vec\"></a>\n",
    "### Word2Vec and Doc2Vec\n",
    "Word2Vec is a word embedding technique using a neural network trained on a so-called *false task*, namely either predicting a missing word from within a sequence of context words drawn from a sentence or phrase, or predicting which contexts words surround some given input word drawn from a sentence or phrase. Each of these tasks are supervised (the correct answer is fixed and known), but can be generated from unlabelled text data such as a collection of books or wikipedia articles, meaning that even though the task itself is supervised the training data can be generated automatically, enabling the creation of enormous training sets. The internal representation for particular words learned during the training process contain semantically informative features related to that given word, and can therefore be used as embeddings used downstream for tasks such as finding similarity between words or as input into additional models. Doc2Vec is an extension of this technique that determines vector embeddings for entire documents (strings containing multiple words, could be sentences, paragraphs, or documents).\n",
    "\n",
    "\n",
    "<a id=\"bert_biobert\"></a>\n",
    "### BERT and BioBERT\n",
    "BERT ('Bidirectional Encoder Representations from Transformers') is another neueral network-based model trained on two different false tasks, namely predicting the subsequent sentence given some input sentence, or predicting the identity of a set of words masked from an input sentence. Like Word2Vec, this architecture can be used to generate vector embeddings for a particular input word by extracting values from a subset of the encoder layers that correspond to that input word. Practically, a major difference is that because the input word is input in the context of its surrounding sentence, the embedding reflects the meaning of a particular word in a particular context (such as the difference in the meaning of *root* in the phrases *plant root* and *root of the problem*. BioBERT refers to a set of BERT models which have been finetuned on the PubMed and PMC corpora. See the list of relevant links for the publications and pages associated with these models.\n",
    "\n",
    "<a id=\"load_models\"></a>\n",
    "### Loading trained and saved models\n",
    "Versions of the architectures discussed above which have been saved as trained models are loaded here. Some of these models are loaded as pretrained models from the work of other groups, and some were trained on data specific to this notebook and loaded here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Files and models related to the machine learning text embedding methods used here.\n",
    "doc2vec_wiki_model = gensim.models.Doc2Vec.load(doc2vec_wikipedia_filename)\n",
    "doc2vec_pubmed_model = gensim.models.Doc2Vec.load(doc2vec_pubmed_filename)\n",
    "word2vec_model = gensim.models.Word2Vec.load(word2vec_model_filename)\n",
    "bert_tokenizer_base = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "bert_tokenizer_pmc = BertTokenizer.from_pretrained(biobert_pmc_path)\n",
    "bert_tokenizer_pubmed = BertTokenizer.from_pretrained(biobert_pubmed_path)\n",
    "bert_tokenizer_pubmed_pmc = BertTokenizer.from_pretrained(biobert_pubmed_pmc_path)\n",
    "bert_model_base = BertModel.from_pretrained('bert-base-uncased')\n",
    "bert_model_pmc = BertModel.from_pretrained(biobert_pmc_path)\n",
    "bert_model_pubmed = BertModel.from_pretrained(biobert_pubmed_path)\n",
    "bert_model_pubmed_pmc = BertModel.from_pretrained(biobert_pubmed_pmc_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading in the descriptions from hand-picked dataset of phenotype pairs\n",
    "See the other notebook for the creation of this dataset. This is included in this notebook instead of a separated notebook because we want the treatment of the individual phenotype text instances to be the same as is done for the descriptions from the real dataset of plant phenotypes. The list of computational approaches being evaluated for this task is the same in both cases so all of the cells between the point where the descriptions are read in and when the distance matrices are found using all those methods are the same for this task as any of the biological questions that this notebook is focused on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the table of similarity scored phenotype pairs that was prepared from random selection.\n",
    "num_pairs = 50\n",
    "mupdata = pd.read_csv(paired_phenotypes_path)\n",
    "assert num_pairs == mupdata.shape[0]\n",
    "paired_descriptions = mupdata[\"Phenotype 1\"].values.tolist()\n",
    "paired_descriptions.extend(mupdata[\"Phenotype 2\"].values.tolist())\n",
    "first_paired_id = 0\n",
    "paired_descriptions = {i:description for i,description in enumerate(paired_descriptions, first_paired_id)}\n",
    "pair_to_score = {(i,i+num_pairs):s for i,s in enumerate(mupdata[\"Score\"].values, first_paired_id)}\n",
    "paired_ids = list(paired_descriptions.keys())\n",
    "\n",
    "# Set the descriptions to be used to be these from the paired phenotypes dataset.\n",
    "# This will only matter if running this in the context of the notebook and skipping the other steps.\n",
    "# Otherwise the descriptions dictionary will be reset to be the descriptions from the full dataset.\n",
    "descriptions = paired_descriptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"part_3\"></a>\n",
    "# Part 3. NLP Choices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain a mapping between IDs and the raw text descriptions associated with that ID from the dataset.\n",
    "descriptions = dataset.get_description_dictionary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_id_to_unique_ids_mappings = defaultdict(lambda: defaultdict(list))\n",
    "unique_id_to_gene_ids_mappings = defaultdict(lambda: defaultdict(list))\n",
    "\n",
    "# NOTE THAT FOR THE UNTOKENIZED (WHOLE DOC) ONES, THERE SHOULD ONLY BE ONE ENTRY IN THE LIST\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# THESE NEED TO BE POPULATED. THESE ARE USED WAY BELOW AFTER THE DISTANCE MATRICES ARE GENERATED AND THROUGHOUT.\n",
    "#gene_id_to_whole_unique_id = {}\n",
    "#gene_id_to_tokenized_unique_id_list = defaultdict(list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mapping to unique text strings for whole genes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a mapping between a new unique identifier and unique description strings that are not sentence tokenized.\n",
    "unique_id_to_unique_text = {i:text for i,text in enumerate(list(set(descriptions.values())))}\n",
    "_reverse_of_that_mapping = {text:i for i,text in unique_id_to_unique_text.items()}\n",
    "\n",
    "# Get a mapping between the original gene IDs from this dataset and the corresponding ID for unique text strings.\n",
    "gene_id_to_unique_ids_mappings[\"whole_texts\"] = {i:[_reverse_of_that_mapping[text]] for i,text in descriptions.items()}\n",
    "whole_unique_ids = list(unique_id_to_unique_text.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mapping to unique text strings that have been tokenized by sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_tokenized_descriptions = {i:sent_tokenize(d) for i,d in descriptions.items()}\n",
    "unique_sents = list(set(flatten(sent_tokenized_descriptions.values())))\n",
    "largest_whole_unique_id = max(whole_unique_ids)\n",
    "unique_id_to_unique_sent = {i:text for i,text in enumerate(unique_sents,largest_whole_unique_id+1)}\n",
    "_reverse_of_that_mapping = {text:i for i,text in unique_id_to_unique_sent.items()}\n",
    "\n",
    "for i, sent_list in sent_tokenized_descriptions.items():\n",
    "    for sent in sent_list:\n",
    "        gene_id_to_unique_ids_mappings[\"sent_tokens\"][i].append(_reverse_of_that_mapping[sent])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Establishing which dictionaries will be used for preprocessing text next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What should 'descriptions' be for the sake of doing batch pre-processing?\n",
    "descriptions = {}\n",
    "descriptions.update(unique_id_to_unique_text)\n",
    "descriptions.update(unique_id_to_unique_sent)\n",
    "assert len(descriptions) == len(unique_id_to_unique_text) + len(unique_id_to_unique_sent)\n",
    "\n",
    "# Which of the IDs that were created for unique text strings are for whole descriptions, and which are for sentences?\n",
    "unique_whole_ids = list(unique_id_to_unique_text.keys())\n",
    "unique_tokenized_ids = list(unique_id_to_unique_sent.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"preprocessing\"></a>\n",
    "### Preprocessing text descriptions\n",
    "The preprocessing methods applied to the phenotype descriptions are a choice which impacts the subsequent vectorization and similarity methods which construct the pairwise distance matrix from each of these descriptions. The preprocessing methods that make sense are also highly dependent on the vectorization method or embedding method that is to be applied. For example, stemming (which is part of the full proprocessing done below using the Gensim preprocessing function) is useful for the n-grams and bag-of-words methods but not for the document embeddings methods which need each token to be in the vocabulary that was constructed and used when the model was trained. For this reason, embedding methods with pretrained models where the vocabulary is fixed should have a lighter degree of preprocessing not involving stemming or lemmatization but should involve things like removal of non-alphanumerics and normalizing case. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Applying canned prepreprocessing approaches to the descriptions.\n",
    "processed = defaultdict(dict)\n",
    "processed[\"simple\"] = {i:\" \".join(simple_preprocess(d)) for i,d in descriptions.items()}\n",
    "processed[\"simple_no_stops\"] = {i:remove_stopwords(\" \".join(simple_preprocess(d))) for i,d in descriptions.items()}\n",
    "processed[\"full\"] = {i:\" \".join(preprocess_string(d)) for i,d in descriptions.items()}\n",
    "\n",
    "# Set of stopwords, used later for checking it tokens in a list are stopwords or not.\n",
    "stop_words = set(stopwords.words('english')) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"pos_tagging\"></a>\n",
    "### POS tagging the phenotype descriptions for nouns and adjectives\n",
    "Note that preprocessing of the descriptions should be done after part-of-speech tagging, because tokens that are removed during preprocessing before n-gram analysis contain information that the parser needs to accurately call parts-of-speech. This step should be done on the raw descriptions and then the resulting bags of words can be subset using additional preprocesssing steps before input in one of the vectorization methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_pos_tokens = lambda text,pos: \" \".join([t[0] for t in nltk.pos_tag(word_tokenize(text)) if t[1].lower()==pos.lower()])\n",
    "processed[\"nouns\"] =  {i:get_pos_tokens(d,\"NN\") for i,d in descriptions.items()}\n",
    "processed[\"nouns_full\"] = {i:\" \".join(preprocess_string(d)) for i,d in processed[\"nouns\"].items()}\n",
    "processed[\"nouns_simple\"] = {i:\" \".join(simple_preprocess(d)) for i,d in processed[\"nouns\"].items()}\n",
    "processed[\"adjectives\"] =  {i:get_pos_tokens(d,\"JJ\") for i,d in descriptions.items()}\n",
    "processed[\"adjectives_full\"] = {i:\" \".join(preprocess_string(d)) for i,d in processed[\"adjectives\"].items()}\n",
    "processed[\"adjectives_simple\"] = {i:\" \".join(simple_preprocess(d)) for i,d in processed[\"adjectives\"].items()}\n",
    "processed[\"nouns_adjectives\"] = {i:\"{} {}\".format(processed[\"nouns\"][i],processed[\"adjectives\"][i]) for i in descriptions.keys()}\n",
    "processed[\"nouns_adjectives_full\"] = {i:\"{} {}\".format(processed[\"nouns_full\"][i],processed[\"adjectives_full\"][i]) for i in descriptions.keys()}\n",
    "processed[\"nouns_adjectives_simple\"] = {i:\"{} {}\".format(processed[\"nouns_simple\"][i],processed[\"adjectives_simple\"][i]) for i in descriptions.keys()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reducing vocabulary size based on identifying important words\n",
    "These approcahes for reducing the vocabulary size of the dataset work by identifying which words in the descriptions are likely to be the most important for identifying differences between the phenotypes and meaning of the descriptions. One approach is to determine which words occur at a higher rate in text of interest such as articles about plant phenotypes as compared to their rates in more general texts such as a corpus of news articles. These approaches do not create modified versions of the descriptions but rather provide vocabulary objects that can be passed to the sklearn vectorizer or constructors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create ontology objects for all the biological ontologies being used.\n",
    "pato = Ontology(pato_filename)\n",
    "po = Ontology(po_filename)\n",
    "go = Ontology(go_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting sets of tokens that are part of bio ontology term labels or synonyms.\n",
    "bio_ontology_tokens = list(set(po.tokens()).union(set(go.tokens())))\n",
    "bio_ontology_tokens = [t for t in bio_ontology_tokens if t not in stop_words]\n",
    "bio_ontology_tokens_simple = flatten([simple_preprocess(t) for t in bio_ontology_tokens])\n",
    "bio_ontology_tokens_full = flatten([preprocess_string(t) for t in bio_ontology_tokens])\n",
    "with open(os.path.join(OUTPUT_DIR,\"part_3_bio_ontology_vocab_size_{}.txt\".format(len(bio_ontology_tokens))),\"w\") as f:\n",
    "    f.write(\" \".join(bio_ontology_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting sets of tokens that are overprepresented in plant phenotype papers as compared to some background corpus.\n",
    "maximum_number_of_tokens = 10000\n",
    "background_corpus = open(background_corpus_filename,\"r\").read()\n",
    "phenotypes_corpus = open(phenotypes_corpus_filename,\"r\").read()\n",
    "ppp_overrepresented_tokens = get_overrepresented_tokens(phenotypes_corpus, background_corpus, max_features=maximum_number_of_tokens)\n",
    "ppp_overrepresented_tokens = [t for t in ppp_overrepresented_tokens if t not in stop_words]\n",
    "ppp_overrepresented_tokens_simple = flatten([simple_preprocess(t) for t in ppp_overrepresented_tokens])\n",
    "ppp_overrepresented_tokens_full = flatten([preprocess_string(t) for t in ppp_overrepresented_tokens])\n",
    "with open(os.path.join(OUTPUT_DIR,\"part_3_plant_phenotype_vocab_size_{}.txt\".format(len(ppp_overrepresented_tokens))), \"w\") as f:\n",
    "    f.write(\" \".join(ppp_overrepresented_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating processed description entries by subsetting tokens to only include ones from these vocabularies.\n",
    "ppp_overrepresented_tokens_full_set = set(ppp_overrepresented_tokens_full)\n",
    "bio_ontology_tokens_full_set = set(bio_ontology_tokens_full)\n",
    "processed[\"plant_overrepresented_tokens\"] = {i:\" \".join([token for token in word_tokenize(text) if token in ppp_overrepresented_tokens_full_set]) for i,text in processed[\"full\"].items()}\n",
    "processed[\"bio_ontology_tokens\"] = {i:\" \".join([token for token in word_tokenize(text) if token in bio_ontology_tokens_full_set]) for i,text in processed[\"full\"].items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"vocab\"></a>\n",
    "### Reducing the vocabulary size using a word distance matrix\n",
    "These approaches for reducing the vocabulary size of the dataset work by replacing multiple words that occur throughout the dataset of descriptions with an identical word that is representative of this larger group of words. The total number of unique words across all descriptions is therefore reduced, and when observing n-gram overlaps between vector representations of these descriptions, overlaps will now occur between descriptions that included different but similar words. These methods work by actually generating versions of these descriptions that have the word replacements present. The returned objects for these methods are the revised description dictionary, a dictionary mapping tokens in the full vocabulary to tokens in the reduced vocabulary, and a dictionary mapping tokens in the reduced vocabulary to a list of tokens in the full vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Generate a pairwise distance matrix object using the oats subpackage, and create an appropriately shaped matrix,\n",
    "# making sure that the tokens list is in the same order as the indices representing each word in the distance matrix.\n",
    "# This is currently triviala because the IDs that are used are ordered integers 0 to n, but this might not always be\n",
    "# the case so it's not directly assumed here.\n",
    "tokens = list(set([w for w in flatten(d.split() for d in processed[\"simple\"].values())]))\n",
    "tokens_dict = {i:w for i,w in enumerate(tokens)}\n",
    "graph = pw.pairwise_square_word2vec(word2vec_model, tokens_dict, \"cosine\")\n",
    "distance_matrix = graph.array\n",
    "tokens = [tokens_dict[graph.index_to_id[index]] for index in np.arange(distance_matrix.shape[0])]\n",
    "\n",
    "# The other argument that the Linares Pontes algorithm needs is a value for n, see paper or description above.\n",
    "n = 3\n",
    "processed[\"linares_pontes\"], reduce_lp, unreduce_lp = reduce_vocab_linares_pontes(processed[\"simple\"], tokens, distance_matrix, n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"annotation\"></a>\n",
    "### Annotating descriptions with ontology terms\n",
    "This section generates dictionaries that map gene IDs from the dataset to lists of strings, where those strings are ontology term IDs. How the term IDs are found for each gene entry with its corresponding phenotype description depends on the cell below. Firstly, the terms are found by using the NOBLE Coder annotation tool through these wrapper functions to identify the terms by looking for instances of the term's label or synonyms in the actual text of the phenotype descriptions. Secondly, the next cell just draws the terms directly from the dataset itself. In this case, these are high-confidence annotations done by curators for a comparison against what can be accomplished through computational analysis of the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the NOBLE Coder annotator over the raw input text descriptions, which handles things like case normalization.\n",
    "direct_annots_nc_go_precise = annotate_using_noble_coder(descriptions, noblecoder_jarfile_path, \"go\", precise=1)\n",
    "direct_annots_nc_go_partial = annotate_using_noble_coder(descriptions, noblecoder_jarfile_path, \"go\", precise=0)\n",
    "direct_annots_nc_po_precise = annotate_using_noble_coder(descriptions, noblecoder_jarfile_path, \"po\", precise=1)\n",
    "direct_annots_nc_po_partial = annotate_using_noble_coder(descriptions, noblecoder_jarfile_path, \"po\", precise=0)\n",
    "direct_annots_nc_pato_precise = annotate_using_noble_coder(descriptions, noblecoder_jarfile_path, \"pato\", precise=1)\n",
    "direct_annots_nc_pato_partial = annotate_using_noble_coder(descriptions, noblecoder_jarfile_path, \"pato\", precise=0)\n",
    "\n",
    "# Use the ontology hierarchies to add terms that are inherited by the terms that were annotated to the text.\n",
    "inherited_annots_nc_go_precise = {i:go.inherited(term_id_list) for i,term_id_list in direct_annots_nc_go_precise.items()}\n",
    "inherited_annots_nc_go_partial = {i:go.inherited(term_id_list) for i,term_id_list in direct_annots_nc_go_partial.items()}\n",
    "inherited_annots_nc_po_precise = {i:po.inherited(term_id_list) for i,term_id_list in direct_annots_nc_po_precise.items()}\n",
    "inherited_annots_nc_po_partial = {i:po.inherited(term_id_list) for i,term_id_list in direct_annots_nc_po_partial.items()}\n",
    "inherited_annots_nc_pato_precise = {i:pato.inherited(term_id_list) for i,term_id_list in direct_annots_nc_pato_precise.items()}\n",
    "inherited_annots_nc_pato_partial = {i:pato.inherited(term_id_list) for i,term_id_list in direct_annots_nc_pato_partial.items()}\n",
    "\n",
    "# Merge the ontology term annotations for each descritpion into a single dictionary for the precise and partial levels.\n",
    "all_precise_annotations = {i:flatten([inherited_annots_nc_go_precise[i],inherited_annots_nc_po_precise[i],inherited_annots_nc_pato_precise[i]]) for i in descriptions.keys()}\n",
    "all_partial_annotations = {i:flatten([inherited_annots_nc_go_partial[i],inherited_annots_nc_po_partial[i],inherited_annots_nc_pato_partial[i]]) for i in descriptions.keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treating these sets of inherited ontology terms as tokens so that they can be used as n-grams.\n",
    "processed[\"precise_annotations\"] = {i:\" \".join(annots) for i,annots in all_precise_annotations.items()}\n",
    "processed[\"partial_annotations\"] = {i:\" \".join(annots) for i,annots in all_partial_annotations.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create description strings with all ontology term anntotations concatenated to the end of the descriptions.\n",
    "processed[\"simple_plus_precise_annotations\"] = {i:\" \".join(flatten([text,all_precise_annotations[i]])) for i,text in processed[\"simple\"].items()}\n",
    "processed[\"simple_plus_partial_annotations\"] = {i:\" \".join(flatten([text,all_partial_annotations[i]])) for i,text in processed[\"simple\"].items()}\n",
    "processed[\"full_plus_precise_annotations\"] = {i:\" \".join(flatten([text,all_precise_annotations[i]])) for i,text in processed[\"full\"].items()}\n",
    "processed[\"full_plus_partial_annotations\"] = {i:\" \".join(flatten([text,all_partial_annotations[i]])) for i,text in processed[\"full\"].items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create ontology term annotations dictionaries for all the high confidence annotations present in the dataset.\n",
    "curated_go_annotations = dataset.get_annotations_dictionary(\"GO\")\n",
    "curated_po_annotations = dataset.get_annotations_dictionary(\"PO\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize GO and PO curator annotated ontology terms and map from those to gene identifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a mapping between GO term IDs (like GO:0001234) and the list of gene IDs in this dataset they were annotated to.\n",
    "go_term_to_gene_ids = defaultdict(list)\n",
    "for gene_id, term_list, in curated_go_annotations.items():\n",
    "    for term in term_list: \n",
    "        go_term_to_gene_ids[term].append(gene_id)\n",
    "        \n",
    "# Create a mapping between a new unique identifer for each unique term used and a list with one item, the given term.\n",
    "individual_curated_go_terms = {i:[t] for i,t in enumerate(go_term_to_gene_ids.keys())}  \n",
    "_reverse_mapping = {t[0]:i for i,t in individual_curated_go_terms.items()}\n",
    "gene_id_to_unique_ids_mappings[\"go_terms\"] = {i:[_reverse_mapping[t] for t in terms] for i,terms in curated_go_annotations.items()}\n",
    "\n",
    "# What about genes that don't have any GO terms annotated to them by a curator? That should be accounted for.\n",
    "unique_id_for_emtpy_annotation_list = max(list(individual_curated_go_terms.keys()))+1\n",
    "individual_curated_go_terms[unique_id_for_emtpy_annotation_list] = []\n",
    "for gene_id,uid_list in gene_id_to_unique_ids_mappings[\"go_terms\"].items():\n",
    "    if len(uid_list) == 0:\n",
    "        gene_id_to_unique_ids_mappings[\"go_terms\"][gene_id].append(unique_id_for_emtpy_annotation_list)\n",
    "        \n",
    "        \n",
    "# Make the dictionary reflect inherited terms as well and be a string not a list.\n",
    "individual_curated_go_term_strings = {i:\" \".join(go.inherited(terms)) for i,terms in individual_curated_go_terms.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a mapping between PO term IDs (like PO:0001234) and the list of gene IDs in this dataset they were annotated to.\n",
    "po_term_to_gene_ids = defaultdict(list)\n",
    "for gene_id, term_list, in curated_po_annotations.items():\n",
    "    for term in term_list: \n",
    "        po_term_to_gene_ids[term].append(gene_id)\n",
    "        \n",
    "# Create a mapping between a new unique identifer for each unique term used and a list with one item, the given term.\n",
    "individual_curated_po_terms = {i:[t] for i,t in enumerate(po_term_to_gene_ids.keys())}  \n",
    "_reverse_mapping = {t[0]:i for i,t in individual_curated_po_terms.items()}\n",
    "gene_id_to_unique_ids_mappings[\"po_terms\"] = {i:[_reverse_mapping[t] for t in terms] for i,terms in curated_po_annotations.items()}\n",
    "\n",
    "# What about genes that don't have any GO terms annotated to them by a curator? That should be accounted for.\n",
    "unique_id_for_emtpy_annotation_list = max(list(individual_curated_po_terms.keys()))+1\n",
    "individual_curated_po_terms[unique_id_for_emtpy_annotation_list] = []\n",
    "for gene_id,uid_list in gene_id_to_unique_ids_mappings[\"po_terms\"].items():\n",
    "    if len(uid_list) == 0:\n",
    "        gene_id_to_unique_ids_mappings[\"po_terms\"][gene_id].append(unique_id_for_emtpy_annotation_list)\n",
    "\n",
    "        \n",
    "# Make the dictionary reflect inherited terms as well and be a string not a list.\n",
    "individual_curated_po_term_strings = {i:\" \".join(po.inherited(terms)) for i,terms in individual_curated_po_terms.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "212"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gene_id_to_unique_ids_mappings[\"po_terms\"]\n",
    "unique_id_for_emtpy_annotation_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What about for the union set of GO and PO terms that were annotated by curators?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The goal here is obtain the set of unique term sets, with a mapping from/back to gene IDs, to avoid reduncancy.\n",
    "curated_go_annotation_strings_sorted = {i:\" \".join(sorted(go.inherited(terms))) for i,terms in curated_go_annotations.items()}\n",
    "unique_go_annotation_set_strings = [s for s in list(set(curated_go_annotation_strings_sorted.values()))]\n",
    "unique_id_to_unique_go_annotation_strings = {i:s for i,s in enumerate(unique_go_annotation_set_strings)}\n",
    "_reverse_mapping = {s:i for i,s in unique_id_to_unique_go_annotation_strings.items()}\n",
    "gene_id_to_unique_ids_mappings[\"go_term_sets\"] = {i:[_reverse_mapping[s]] for i,s in curated_go_annotation_strings_sorted.items()}\n",
    "\n",
    "#unique_id_to_unique_go_annotation_strings\n",
    "\n",
    "# The goal here is to obtain the set of unique term sets, with a mapping from/back to gene IDs, to avoid redundancy.\n",
    "#curated_go_annotations_sorted = {i:sorted(l) for i,l in curated_go_annotations.items()}\n",
    "#curated_go_annotations_strings = {i:\" \".join(l) for i,l in curated_go_annotations.items()}\n",
    "#unique_go_annotation_set_strings = [s for s in list(set(curated_go_annotations_strings.values()))]\n",
    "#unique_id_to_unique_go_annotation_strings = {i:s for i,s in enumerate(unique_go_annotation_set_strings)}\n",
    "#unique_id_to_unique_go_annotations = {i:s.split() for i,s in unique_id_to_unique_go_annotation_strings.items()}\n",
    "#_reverse_mapping = {s:i for i,s in unique_id_to_unique_go_annotation_strings.items()}\n",
    "#gene_id_to_unique_ids_mappings[\"go_term_sets\"] = {i:[_reverse_mapping[s]] for i,s in curated_go_annotations_strings.items()}\n",
    "\n",
    "# Data structures generated here that will be referenced later:\n",
    "# unique_id_to_unique_go_annotations: Maps arbitrary unique IDs to unique lists of term IDs and can be passed to oats.\n",
    "# gene_id_to_union_of_go_terms_unique_id: Needed for getting from gene IDs in this dataset to those arbitrary IDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The goal here is to obtain the set of unique term sets, with a mapping from/back to gene IDs, to avoid redundancy.\n",
    "curated_po_annotation_strings_sorted = {i:\" \".join(sorted(po.inherited(terms))) for i,terms in curated_po_annotations.items()}\n",
    "unique_po_annotation_set_strings = [s for s in list(set(curated_po_annotation_strings_sorted.values()))]\n",
    "unique_id_to_unique_po_annotation_strings = {i:s for i,s in enumerate(unique_po_annotation_set_strings)}\n",
    "_reverse_mapping = {s:i for i,s in unique_id_to_unique_po_annotation_strings.items()}\n",
    "gene_id_to_unique_ids_mappings[\"po_term_sets\"] = {i:[_reverse_mapping[s]] for i,s in curated_po_annotation_strings_sorted.items()}\n",
    "\n",
    "#unique_id_to_unique_po_annotation_strings\n",
    "\n",
    "#curated_po_annotations_sorted = {i:sorted(l) for i,l in curated_po_annotations.items()}\n",
    "#curated_po_annotations_strings = {i:\" \".join(l) for i,l in curated_po_annotations.items()}\n",
    "#unique_po_annotation_set_strings = [s for s in list(set(curated_po_annotations_strings.values()))]\n",
    "#unique_id_to_unique_po_annotation_strings = {i:s for i,s in enumerate(unique_po_annotation_set_strings)}\n",
    "#unique_id_to_unique_po_annotations = {i:s.split() for i,s in unique_id_to_unique_po_annotation_strings.items()}\n",
    "#_reverse_mapping = {s:i for i,s in unique_id_to_unique_po_annotation_strings.items()}\n",
    "#gene_id_to_unique_ids_mappings[\"po_term_sets\"] = {i:[_reverse_mapping[s]] for i,s in curated_po_annotations_strings.items()}\n",
    "\n",
    "# Data structures generated here that will be referenced later:\n",
    "# unique_id_to_unique_po_annotations: Maps arbitrary unique IDs to unique lists of term IDs and can be passed to oats.\n",
    "# gene_id_to_union_of_po_terms_unique_id: Needed for getting from gene IDs in this dataset to those arbitrary IDs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"todo\"></a>\n",
    "### Splitting dictionaries back into phenotype and phene specific dictionaries\n",
    "As a preprocessing step, split into a new set of descriptions that's larger. Note that phenotypes are split into phenes, and the phenes that are identical are retained as separate entries in the dataset. This makes the distance matrix calculation more needlessly expensive, because vectors need to be found for the same string more than once, but it simplifies converting the edgelist back to having IDs that reference the genes (full phenotypes) instead of the smaller phenes. If anything, that problem should be addressed in the pairwise functions, not here. (The package should handle it, not when creating input data for those methods)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve dictionaries that refer just to either unique raw whole texts, or unique raw sentences tokenized out.\n",
    "descriptions = unique_id_to_unique_text\n",
    "phenes = unique_id_to_unique_sent\n",
    "\n",
    "# Create the processed text dictionaries that have the same keys are those two, named accordingly for each.\n",
    "processes = list(processed.keys())\n",
    "unmerged = defaultdict(dict)\n",
    "for process,di in processed.items():\n",
    "    unmerged[process] = {i:text for i,text in di.items() if i in unique_whole_ids}\n",
    "    unmerged[\"{}_phenes\".format(process)] = {i:text for i,text in di.items() if i in unique_tokenized_ids}\n",
    "processed = unmerged\n",
    "\n",
    "# Checking to make sure the size of each dictionary is as expected.\n",
    "for process in processes:\n",
    "    assert len(unique_whole_ids) == len(processed[process].keys())\n",
    "    assert len(unique_tokenized_ids) == len(processed[\"{}_phenes\".format(process)].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These should be to sets not lists, don't need the duplicate references.\n",
    "for dtype,mapping in gene_id_to_unique_ids_mappings.items():\n",
    "    for gene_id,unique_ids in mapping.items():\n",
    "        gene_id_to_unique_ids_mappings[dtype][gene_id] = list(set(unique_ids))\n",
    "\n",
    "\n",
    "# What about the mapping from unique IDs of all kinds back to the gene IDs they came from?\n",
    "for dtype,mapping in gene_id_to_unique_ids_mappings.items():\n",
    "    for gene_id,unique_ids in mapping.items():\n",
    "        for unique_id in unique_ids:\n",
    "            unique_id_to_gene_ids_mappings[dtype][unique_id].append(gene_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each of the gene IDs should map to a list of exactly one ID referencing to a unique whole text, or set of terms.\n",
    "assert all([len(unique_ids)==1 for gene_id,unique_ids in gene_id_to_unique_ids_mappings[\"whole_texts\"].items()])\n",
    "assert all([len(unique_ids)==1 for gene_id,unique_ids in gene_id_to_unique_ids_mappings[\"go_term_sets\"].items()])\n",
    "assert all([len(unique_ids)==1 for gene_id,unique_ids in gene_id_to_unique_ids_mappings[\"po_term_sets\"].items()])\n",
    "\n",
    "# For the IDs that reference individual unique sentence tokens or ontology terms, a gene can map to one or more.\n",
    "assert all([len(unique_ids)>=1 for gene_id,unique_ids in gene_id_to_unique_ids_mappings[\"sent_tokens\"].items()])\n",
    "assert all([len(unique_ids)>=1 for gene_id,unique_ids in gene_id_to_unique_ids_mappings[\"go_terms\"].items()])\n",
    "assert all([len(unique_ids)>=1 for gene_id,unique_ids in gene_id_to_unique_ids_mappings[\"po_terms\"].items()])\n",
    "\n",
    "# In those cases, the list of IDs referencing unique terms of strings shouldn't contain any duplicates.\n",
    "assert all([len(unique_ids)==len(set(unique_ids)) for gene_id,unique_ids in gene_id_to_unique_ids_mappings[\"sent_tokens\"].items()])\n",
    "assert all([len(unique_ids)==len(set(unique_ids)) for gene_id,unique_ids in gene_id_to_unique_ids_mappings[\"go_terms\"].items()])\n",
    "assert all([len(unique_ids)==len(set(unique_ids)) for gene_id,unique_ids in gene_id_to_unique_ids_mappings[\"po_terms\"].items()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"part_4\"></a>\n",
    "# Part 4. Generating vector representations and pairwise distances matrices\n",
    "This section uses the text descriptions, preprocessed text descriptions, or ontology term annotations created or read in the previous sections to generate a vector representation for each gene and build a pairwise distance matrix for the whole dataset. Each method specified is a unique combination of a method of vectorization (bag-of-words, n-grams, document embedding model, etc) and distance metric (Euclidean, Jaccard, cosine, etc) applied to those vectors in constructing the pairwise matrix. The method of vectorization here is equivalent to feature selection, so the task is to figure out which type of vectors will encode features that are useful (n-grams, full words, only words from a certain vocabulary, etc).\n",
    "\n",
    "<a id=\"methods\"></a>\n",
    "### Specifying a list of NLP methods to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['something in the dataset three times',\n",
       " 'something in the dataset three times',\n",
       " 'something in the dataset three times',\n",
       " 'something in the dataset only once']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Returns a list of texts, this is necessary for weighting because inverse document frequency won't make sense\n",
    "# unless the texts that appear more than once in the actual dataset are actually account for, rather than treating\n",
    "# them as just one unique text (which is what is done as far as the distance matrix is concerned, in order to save\n",
    "# memory for the really large datasets like sentence tokens).\n",
    "def get_raw_texts_for_term_weighting(documents, unique_id_to_real_ids):\n",
    "    texts = flatten([[text]*len(unique_id_to_real_ids[i]) for i,text in documents.items()])\n",
    "    return(texts)\n",
    "\n",
    "# Quick test for the above method.\n",
    "test_unique_id_to_real_ids = {1:[1,2345,34564], 2:[1332]}\n",
    "test_documents = {1:\"something in the dataset three times\", 2:\"something in the dataset only once\"}\n",
    "get_raw_texts_for_term_weighting(test_documents, test_unique_id_to_real_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2vec_and_word2vec_approaches = [    \n",
    "    Method(\"Doc2Vec\", \"Wikipedia,Size=300\", pw.pairwise_square_doc2vec, {\"model\":doc2vec_wiki_model, \"ids_to_texts\":descriptions, \"metric\":\"cosine\"}, spatial.distance.cosine, tag=\"whole_texts\"),\n",
    "    Method(\"Word2Vec\", \"Wikipedia,Size=300,Mean\", pw.pairwise_square_word2vec, {\"model\":word2vec_model, \"ids_to_texts\":descriptions, \"metric\":\"cosine\", \"method\":\"mean\"}, spatial.distance.cosine, tag=\"whole_texts\"),\n",
    "    Method(\"Word2Vec\", \"Wikipedia,Size=300,Max\", pw.pairwise_square_word2vec, {\"model\":word2vec_model, \"ids_to_texts\":descriptions, \"metric\":\"cosine\", \"method\":\"max\"}, spatial.distance.cosine, tag=\"whole_texts\"),\n",
    "    Method(\"Doc2Vec Phenes\", \"Wikipedia,Size=300\", pw.pairwise_square_doc2vec, {\"model\":doc2vec_wiki_model, \"ids_to_texts\":phenes, \"metric\":\"cosine\"}, spatial.distance.cosine, tag=\"sent_tokens\"),\n",
    "    Method(\"Word2Vec Phenes\", \"Wikipedia,Size=300,Mean\", pw.pairwise_square_word2vec, {\"model\":word2vec_model, \"ids_to_texts\":phenes, \"metric\":\"cosine\", \"method\":\"mean\"}, spatial.distance.cosine, tag=\"sent_tokens\"),\n",
    "    Method(\"Word2Vec Phenes\", \"Wikipedia,Size=300,Max\", pw.pairwise_square_word2vec, {\"model\":word2vec_model, \"ids_to_texts\":phenes, \"metric\":\"cosine\", \"method\":\"max\"}, spatial.distance.cosine, tag=\"sent_tokens\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "automated_annotation_approaches = [\n",
    "    Method(\"NOBLE Coder\", \"Precise,TFIDF\", pw.pairwise_square_ngrams, {\"ids_to_texts\":processed[\"precise_annotations\"], \"binary\":True, \"analyzer\":\"word\", \"ngram_range\":(1,1), \"max_features\":10000, \"min_df\":2, \"max_df\":0.9, \"metric\":\"cosine\", \"tfidf\":True, \"training_texts\":get_raw_texts_for_term_weighting(processed[\"precise_annotations\"], unique_id_to_gene_ids_mappings[\"whole_texts\"])}, spatial.distance.cosine, tag=\"whole_texts\"),\n",
    "    Method(\"NOBLE Coder\", \"Partial,TFIDF\", pw.pairwise_square_ngrams, {\"ids_to_texts\":processed[\"partial_annotations\"], \"binary\":True, \"analyzer\":\"word\", \"ngram_range\":(1,1), \"max_features\":10000, \"min_df\":2, \"max_df\":0.9, \"metric\":\"cosine\", \"tfidf\":True, \"training_texts\":get_raw_texts_for_term_weighting(processed[\"partial_annotations\"], unique_id_to_gene_ids_mappings[\"whole_texts\"])}, spatial.distance.cosine, tag=\"whole_texts\"),    \n",
    "    Method(\"NOBLE Coder Phenes\", \"Precise,TFIDF\", pw.pairwise_square_ngrams, {\"ids_to_texts\":processed[\"precise_annotations_phenes\"], \"binary\":True, \"analyzer\":\"word\", \"ngram_range\":(1,1), \"max_features\":10000, \"min_df\":2, \"max_df\":0.9, \"metric\":\"cosine\", \"tfidf\":True, \"training_texts\":get_raw_texts_for_term_weighting(processed[\"precise_annotations_phenes\"], unique_id_to_gene_ids_mappings[\"sent_tokens\"])}, spatial.distance.cosine, tag=\"sent_tokens\"),\n",
    "    Method(\"NOBLE Coder Phenes\", \"Partial,TFIDF\", pw.pairwise_square_ngrams, {\"ids_to_texts\":processed[\"partial_annotations_phenes\"], \"binary\":True, \"analyzer\":\"word\", \"ngram_range\":(1,1), \"max_features\":10000, \"min_df\":2, \"max_df\":0.9, \"metric\":\"cosine\", \"tfidf\":True, \"training_texts\":get_raw_texts_for_term_weighting(processed[\"partial_annotations_phenes\"], unique_id_to_gene_ids_mappings[\"sent_tokens\"])}, spatial.distance.cosine, tag=\"sent_tokens\"),   \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf_topic_modeling_approaches = [\n",
    "    Method(\"Topic Models\", \"NMF,Full,Topics=50\", pw.pairwise_square_topic_model, {\"ids_to_texts\":processed[\"full\"], \"metric\":\"cosine\", \"num_topics\":50, \"algorithm\":\"nmf\", \"training_texts\":get_raw_texts_for_term_weighting(processed[\"full\"], unique_id_to_gene_ids_mappings[\"whole_texts\"])}, spatial.distance.cosine, tag=\"whole_texts\"),\n",
    "    Method(\"Topic Models\", \"NMF,Full,Topics=100\", pw.pairwise_square_topic_model, {\"ids_to_texts\":processed[\"full\"], \"metric\":\"cosine\", \"num_topics\":100, \"algorithm\":\"nmf\", \"training_texts\":get_raw_texts_for_term_weighting(processed[\"full\"], unique_id_to_gene_ids_mappings[\"whole_texts\"])}, spatial.distance.cosine, tag=\"whole_texts\"),\n",
    "    Method(\"Topic Models Phenes\", \"NMF,Full,Topics=50\", pw.pairwise_square_topic_model, {\"ids_to_texts\":processed[\"full_phenes\"], \"metric\":\"cosine\", \"num_topics\":50, \"algorithm\":\"nmf\", \"training_texts\":get_raw_texts_for_term_weighting(processed[\"full_phenes\"], unique_id_to_gene_ids_mappings[\"sent_tokens\"])}, spatial.distance.cosine, tag=\"sent_tokens\"),\n",
    "    Method(\"Topic Models Phenes\", \"NMF,Full,Topics=100\", pw.pairwise_square_topic_model, {\"ids_to_texts\":processed[\"full_phenes\"], \"metric\":\"cosine\", \"num_topics\":100, \"algorithm\":\"nmf\", \"training_texts\":get_raw_texts_for_term_weighting(processed[\"full_phenes\"], unique_id_to_gene_ids_mappings[\"sent_tokens\"])}, spatial.distance.cosine, tag=\"sent_tokens\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_topic_modeling_approaches = [\n",
    "    Method(\"Topic Models\", \"LDA,Full,Topics=50\", pw.pairwise_square_topic_model, {\"ids_to_texts\":processed[\"full\"], \"metric\":\"cosine\", \"num_topics\":50, \"algorithm\":\"lda\", \"training_texts\":get_raw_texts_for_term_weighting(processed[\"full\"], unique_id_to_gene_ids_mappings[\"whole_texts\"])}, spatial.distance.cosine, tag=\"whole_texts\"),\n",
    "    Method(\"Topic Models\", \"LDA,Full,Topics=100\", pw.pairwise_square_topic_model, {\"ids_to_texts\":processed[\"full\"], \"metric\":\"cosine\", \"num_topics\":100, \"algorithm\":\"lda\", \"training_texts\":get_raw_texts_for_term_weighting(processed[\"full\"], unique_id_to_gene_ids_mappings[\"whole_texts\"])}, spatial.distance.cosine, tag=\"whole_texts\"),\n",
    "    Method(\"Topic Models Phenes\", \"LDA,Full,Topics=50\", pw.pairwise_square_topic_model, {\"ids_to_texts\":processed[\"full_phenes\"], \"metric\":\"cosine\", \"num_topics\":50, \"algorithm\":\"lda\", \"training_texts\":get_raw_texts_for_term_weighting(processed[\"full_phenes\"], unique_id_to_gene_ids_mappings[\"sent_tokens\"])}, spatial.distance.cosine, tag=\"sent_tokens\"),\n",
    "    Method(\"Topic Models Phenes\", \"LDA,Full,Topics=100\", pw.pairwise_square_topic_model, {\"ids_to_texts\":processed[\"full_phenes\"], \"metric\":\"cosine\", \"num_topics\":100, \"algorithm\":\"lda\", \"training_texts\":get_raw_texts_for_term_weighting(processed[\"full_phenes\"], unique_id_to_gene_ids_mappings[\"sent_tokens\"])}, spatial.distance.cosine, tag=\"sent_tokens\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "vanilla_ngrams_approaches = [\n",
    "    Method(\"N-Grams\", \"Full,Words,1-grams,TFIDF\", pw.pairwise_square_ngrams, {\"ids_to_texts\":processed[\"full\"], \"metric\":\"cosine\", \"binary\":False, \"analyzer\":\"word\", \"ngram_range\":(1,1), \"max_features\":10000, \"min_df\":2, \"max_df\":0.9, \"tfidf\":True, \"training_texts\":get_raw_texts_for_term_weighting(processed[\"full\"], unique_id_to_gene_ids_mappings[\"whole_texts\"])}, spatial.distance.cosine, tag=\"whole_texts\"),\n",
    "    Method(\"N-Grams\", \"Full,Words,1-grams,2-grams,TFIDF\", pw.pairwise_square_ngrams, {\"ids_to_texts\":processed[\"full\"], \"metric\":\"cosine\", \"binary\":False, \"analyzer\":\"word\", \"ngram_range\":(1,2), \"max_features\":10000, \"min_df\":2, \"max_df\":0.9, \"tfidf\":True, \"training_texts\":get_raw_texts_for_term_weighting(processed[\"full\"], unique_id_to_gene_ids_mappings[\"whole_texts\"])}, spatial.distance.cosine, tag=\"whole_texts\"),\n",
    "    Method(\"N-Grams Phenes\", \"Full,Words,1-grams,TFIDF\", pw.pairwise_square_ngrams, {\"ids_to_texts\":processed[\"full_phenes\"], \"metric\":\"cosine\", \"binary\":False, \"analyzer\":\"word\", \"ngram_range\":(1,1), \"max_features\":10000, \"min_df\":2, \"max_df\":0.9, \"tfidf\":True, \"training_texts\":get_raw_texts_for_term_weighting(processed[\"full_phenes\"], unique_id_to_gene_ids_mappings[\"sent_tokens\"])}, spatial.distance.cosine, tag=\"sent_tokens\"),\n",
    "    Method(\"N-Grams Phenes\", \"Full,Words,1-grams,2-grams,TFIDF\", pw.pairwise_square_ngrams, {\"ids_to_texts\":processed[\"full_phenes\"], \"metric\":\"cosine\", \"binary\":False, \"analyzer\":\"word\", \"ngram_range\":(1,2), \"max_features\":10000, \"min_df\":2, \"max_df\":0.9, \"tfidf\":True, \"training_texts\":get_raw_texts_for_term_weighting(processed[\"full_phenes\"], unique_id_to_gene_ids_mappings[\"sent_tokens\"])}, spatial.distance.cosine, tag=\"sent_tokens\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "modified_vocab_approaches = [\n",
    "    \n",
    "    Method(\"N-Grams\", \"Full,Nouns,Adjectives,1-grams\", pw.pairwise_square_ngrams, {\"ids_to_texts\":processed[\"nouns_adjectives_full\"], \"metric\":\"cosine\", \"binary\":False, \"analyzer\":\"word\", \"ngram_range\":(1,1), \"max_features\":10000, \"min_df\":2, \"max_df\":0.9, \"tfidf\":True, \"training_texts\":get_raw_texts_for_term_weighting(processed[\"nouns_adjectives_full\"], unique_id_to_gene_ids_mappings[\"whole_texts\"])}, spatial.distance.cosine, tag=\"whole_texts\"),\n",
    "    Method(\"N-Grams\", \"Linares_Pontes,Words,1-grams\", pw.pairwise_square_ngrams, {\"ids_to_texts\":processed[\"linares_pontes\"], \"metric\":\"cosine\", \"binary\":False, \"analyzer\":\"word\", \"ngram_range\":(1,1), \"max_features\":10000, \"min_df\":2, \"max_df\":0.9, \"tfidf\":True, \"training_texts\":get_raw_texts_for_term_weighting(processed[\"linares_pontes\"], unique_id_to_gene_ids_mappings[\"whole_texts\"])}, spatial.distance.cosine, tag=\"whole_texts\"),\n",
    "    Method(\"N-Grams\", \"Full,Precise_Annotations,Words,1-grams\", pw.pairwise_square_ngrams, {\"ids_to_texts\":processed[\"full_plus_precise_annotations\"], \"metric\":\"cosine\", \"binary\":False, \"analyzer\":\"word\", \"ngram_range\":(1,1), \"max_features\":10000, \"min_df\":2, \"max_df\":0.9, \"tfidf\":True, \"training_texts\":get_raw_texts_for_term_weighting(processed[\"full_plus_precise_annotations\"], unique_id_to_gene_ids_mappings[\"whole_texts\"])}, spatial.distance.cosine, tag=\"whole_texts\"),\n",
    "    Method(\"N-Grams\", \"Full,Partial_Annotations,Words,1-grams\", pw.pairwise_square_ngrams, {\"ids_to_texts\":processed[\"full_plus_partial_annotations\"], \"metric\":\"cosine\", \"binary\":False, \"analyzer\":\"word\", \"ngram_range\":(1,1), \"max_features\":10000, \"min_df\":2, \"max_df\":0.9, \"tfidf\":True, \"training_texts\":get_raw_texts_for_term_weighting(processed[\"full_plus_partial_annotations\"], unique_id_to_gene_ids_mappings[\"whole_texts\"])}, spatial.distance.cosine, tag=\"whole_texts\"),\n",
    "    Method(\"N-Grams\", \"Full,Plant Overrepresented Tokens,1-grams\", pw.pairwise_square_ngrams, {\"ids_to_texts\":processed[\"plant_overrepresented_tokens\"], \"metric\":\"cosine\", \"binary\":False, \"analyzer\":\"word\", \"ngram_range\":(1,1), \"max_features\":10000, \"min_df\":2, \"max_df\":0.9, \"tfidf\":True, \"training_texts\":get_raw_texts_for_term_weighting(processed[\"plant_overrepresented_tokens\"], unique_id_to_gene_ids_mappings[\"whole_texts\"])}, spatial.distance.cosine, tag=\"whole_texts\"),\n",
    "    Method(\"N-Grams\", \"Full,Bio Ontology Tokens,1-grams\", pw.pairwise_square_ngrams, {\"ids_to_texts\":processed[\"bio_ontology_tokens\"], \"metric\":\"cosine\", \"binary\":False, \"analyzer\":\"word\", \"ngram_range\":(1,1), \"max_features\":10000, \"min_df\":2, \"max_df\":0.9, \"tfidf\":True, \"training_texts\":get_raw_texts_for_term_weighting(processed[\"bio_ontology_tokens\"], unique_id_to_gene_ids_mappings[\"whole_texts\"])}, spatial.distance.cosine, tag=\"whole_texts\"),\n",
    "    \n",
    "    Method(\"N-Grams Phenes\", \"Full,Nouns,Adjectives,1-grams\", pw.pairwise_square_ngrams, {\"ids_to_texts\":processed[\"nouns_adjectives_full_phenes\"], \"metric\":\"cosine\", \"binary\":False, \"analyzer\":\"word\", \"ngram_range\":(1,1), \"max_features\":10000, \"min_df\":2, \"max_df\":0.9, \"tfidf\":True,  \"training_texts\":get_raw_texts_for_term_weighting(processed[\"nouns_adjectives_full_phenes\"], unique_id_to_gene_ids_mappings[\"sent_tokens\"])}, spatial.distance.cosine, tag=\"sent_tokens\"),\n",
    "    Method(\"N-Grams Phenes\", \"Linares_Pontes,Words,1-grams\", pw.pairwise_square_ngrams, {\"ids_to_texts\":processed[\"linares_pontes_phenes\"], \"metric\":\"cosine\", \"binary\":False, \"analyzer\":\"word\", \"ngram_range\":(1,1), \"max_features\":10000, \"min_df\":2, \"max_df\":0.9, \"tfidf\":True, \"training_texts\":get_raw_texts_for_term_weighting(processed[\"linares_pontes_phenes\"], unique_id_to_gene_ids_mappings[\"sent_tokens\"])}, spatial.distance.cosine, tag=\"sent_tokens\"),\n",
    "    Method(\"N-Grams Phenes\", \"Full,Precise_Annotations,Words,1-grams\", pw.pairwise_square_ngrams, {\"ids_to_texts\":processed[\"full_plus_precise_annotations_phenes\"], \"metric\":\"cosine\", \"binary\":False, \"analyzer\":\"word\", \"ngram_range\":(1,1), \"max_features\":10000, \"min_df\":2, \"max_df\":0.9, \"tfidf\":True, \"training_texts\":get_raw_texts_for_term_weighting(processed[\"full_plus_precise_annotations_phenes\"], unique_id_to_gene_ids_mappings[\"sent_tokens\"])}, spatial.distance.cosine, tag=\"sent_tokens\"),\n",
    "    Method(\"N-Grams Phenes\", \"Full,Partial_Annotations,Words,1-grams\", pw.pairwise_square_ngrams, {\"ids_to_texts\":processed[\"full_plus_partial_annotations_phenes\"], \"metric\":\"cosine\", \"binary\":False, \"analyzer\":\"word\", \"ngram_range\":(1,1), \"max_features\":10000, \"min_df\":2, \"max_df\":0.9, \"tfidf\":True, \"training_texts\":get_raw_texts_for_term_weighting(processed[\"full_plus_partial_annotations_phenes\"], unique_id_to_gene_ids_mappings[\"sent_tokens\"])}, spatial.distance.cosine, tag=\"sent_tokens\"),\n",
    "    Method(\"N-Grams Phenes\", \"Full,Plant Overrepresented Tokens,1-grams\", pw.pairwise_square_ngrams, {\"ids_to_texts\":processed[\"plant_overrepresented_tokens_phenes\"], \"metric\":\"cosine\", \"binary\":False, \"analyzer\":\"word\", \"ngram_range\":(1,1), \"max_features\":10000, \"min_df\":2, \"max_df\":0.9, \"tfidf\":True, \"training_texts\":get_raw_texts_for_term_weighting(processed[\"plant_overrepresented_tokens_phenes\"], unique_id_to_gene_ids_mappings[\"sent_tokens\"])}, spatial.distance.cosine, tag=\"sent_tokens\"),\n",
    "    Method(\"N-Grams Phenes\", \"Full,Bio Ontology Tokens,1-grams\", pw.pairwise_square_ngrams, {\"ids_to_texts\":processed[\"bio_ontology_tokens_phenes\"], \"metric\":\"cosine\", \"binary\":False, \"analyzer\":\"word\", \"ngram_range\":(1,1), \"max_features\":10000, \"min_df\":2, \"max_df\":0.9, \"tfidf\":True, \"training_texts\":get_raw_texts_for_term_weighting(processed[\"bio_ontology_tokens_phenes\"], unique_id_to_gene_ids_mappings[\"sent_tokens\"])}, spatial.distance.cosine, tag=\"sent_tokens\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_annotation_approaches = [\n",
    "    Method(\"GO\", \"Union\", pw.pairwise_square_ngrams, {\"ids_to_texts\":unique_id_to_unique_go_annotation_strings,  \"metric\":\"cosine\", \"max_features\":10000, \"min_df\":2, \"max_df\":0.9, \"binary\":False, \"analyzer\":\"word\", \"ngram_range\":(1,1), \"tfidf\":True, \"training_texts\":get_raw_texts_for_term_weighting(unique_id_to_unique_go_annotation_strings, unique_id_to_gene_ids_mappings[\"go_term_sets\"])}, spatial.distance.cosine, tag=\"go_term_sets\"),\n",
    "    Method(\"PO\", \"Union\", pw.pairwise_square_ngrams, {\"ids_to_texts\":unique_id_to_unique_po_annotation_strings, \"metric\":\"cosine\", \"max_features\":10000, \"min_df\":2, \"max_df\":0.9, \"binary\":False, \"analyzer\":\"word\", \"ngram_range\":(1,1), \"tfidf\":True, \"training_texts\":get_raw_texts_for_term_weighting(unique_id_to_unique_po_annotation_strings, unique_id_to_gene_ids_mappings[\"po_term_sets\"])}, spatial.distance.cosine, tag=\"po_term_sets\"),\n",
    "    Method(\"GO\", \"Maximum\", pw.pairwise_square_ngrams, {\"ids_to_texts\":individual_curated_go_term_strings, \"metric\":\"cosine\", \"max_features\":10000, \"min_df\":2, \"max_df\":0.9, \"binary\":False, \"analyzer\":\"word\", \"ngram_range\":(1,1), \"tfidf\":True, \"training_texts\":get_raw_texts_for_term_weighting(individual_curated_go_term_strings, unique_id_to_gene_ids_mappings[\"go_terms\"])}, spatial.distance.cosine, tag=\"go_terms\"),\n",
    "    Method(\"PO\", \"Maximum\", pw.pairwise_square_ngrams, {\"ids_to_texts\":individual_curated_po_term_strings, \"metric\":\"cosine\", \"max_features\":10000, \"min_df\":2, \"max_df\":0.9, \"binary\":False, \"analyzer\":\"word\", \"ngram_range\":(1,1), \"tfidf\":True, \"training_texts\":get_raw_texts_for_term_weighting(individual_curated_po_term_strings, unique_id_to_gene_ids_mappings[\"po_terms\"])},spatial.distance.cosine, tag=\"po_terms\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding lists of approaches to the complete set to be run, this is useful when running the notebook as a script.\n",
    "methods = []\n",
    "if args.learning: methods.extend(doc2vec_and_word2vec_approaches)\n",
    "if args.noblecoder: methods.extend(automated_annotation_approaches)\n",
    "if args.nmf: methods.extend(nmf_topic_modeling_approaches)\n",
    "if args.lda: methods.extend(lda_topic_modeling_approaches)\n",
    "if args.vanilla: methods.extend(vanilla_ngrams_approaches)\n",
    "if args.vocab: methods.extend(modified_vocab_approaches)\n",
    "if args.annotations: methods.extend(manual_annotation_approaches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"running\"></a>\n",
    "### Running all of the methods to generate distance matrices\n",
    "Notes- Instead of passing in similarity function like cosine distance that will get evaluated for every possible i,j pair of vetors that are created (this is very big when splitting by phenes), don't use a specific similarity function, but instead let the object use a KNN classifier. pass in some limit for k like 100. then the object uses some more efficient (not brute force) algorithm to set the similarity of some vector v to its 100 nearest neighbors as those 100 probabilities, and sets everything else to 0. This would need to be implemented as a matching but separate function from the get_square_matrix_from_vectors thing. And then this would need to be noted in the similarity function that was used for these in the big table of methods. This won't work because the faster (not brute force algorithms) are not for sparse vectors like n-grams, and the non-sparse embeddings aren't really the problem here because those vectors are relatively much short, even when concatenating BERT encoder layers thats only up to around length of ~1000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc2Vec:Wikipedia,Size=300                                   00:00:00          300        272\n",
      "Word2Vec:Wikipedia,Size=300,Mean                             00:00:00          300        272\n",
      "Word2Vec:Wikipedia,Size=300,Max                              00:00:00          300        272\n",
      "Doc2Vec Phenes:Wikipedia,Size=300                            00:00:02          300       1459\n",
      "Word2Vec Phenes:Wikipedia,Size=300,Mean                      00:00:01          300       1459\n",
      "Word2Vec Phenes:Wikipedia,Size=300,Max                       00:00:01          300       1459\n",
      "NOBLE Coder:Precise,TFIDF                                    00:00:00          635        272\n",
      "NOBLE Coder:Partial,TFIDF                                    00:00:01        10000        272\n",
      "NOBLE Coder Phenes:Precise,TFIDF                             00:00:01          729       1459\n",
      "NOBLE Coder Phenes:Partial,TFIDF                             00:00:15        10000       1459\n",
      "Topic Models:NMF,Full,Topics=50                              00:00:01           50        272\n",
      "Topic Models:NMF,Full,Topics=100                             00:00:04          100        272\n",
      "Topic Models Phenes:NMF,Full,Topics=50                       00:00:01           50       1459\n",
      "Topic Models Phenes:NMF,Full,Topics=100                      00:00:06          100       1459\n",
      "Topic Models:LDA,Full,Topics=50                              00:00:00           50        272\n",
      "Topic Models:LDA,Full,Topics=100                             00:00:00          100        272\n",
      "Topic Models Phenes:LDA,Full,Topics=50                       00:00:02           50       1459\n",
      "Topic Models Phenes:LDA,Full,Topics=100                      00:00:02          100       1459\n",
      "N-Grams:Full,Words,1-grams,TFIDF                             00:00:00          750        272\n",
      "N-Grams:Full,Words,1-grams,2-grams,TFIDF                     00:00:00         1710        272\n",
      "N-Grams Phenes:Full,Words,1-grams,TFIDF                      00:00:01          941       1459\n",
      "N-Grams Phenes:Full,Words,1-grams,2-grams,TFIDF              00:00:03         2275       1459\n",
      "N-Grams:Full,Nouns,Adjectives,1-grams                        00:00:00          522        272\n",
      "N-Grams:Linares_Pontes,Words,1-grams                         00:00:00          665        272\n",
      "N-Grams:Full,Precise_Annotations,Words,1-grams               00:00:00         1385        272\n",
      "N-Grams:Full,Partial_Annotations,Words,1-grams               00:00:00        10000        272\n",
      "N-Grams:Full,Plant Overrepresented Tokens,1-grams            00:00:00          660        272\n",
      "N-Grams:Full,Bio Ontology Tokens,1-grams                     00:00:00          545        272\n",
      "N-Grams Phenes:Full,Nouns,Adjectives,1-grams                 00:00:01          684       1459\n",
      "N-Grams Phenes:Linares_Pontes,Words,1-grams                  00:00:01          728       1459\n",
      "N-Grams Phenes:Full,Precise_Annotations,Words,1-grams        00:00:02         1670       1459\n",
      "N-Grams Phenes:Full,Partial_Annotations,Words,1-grams        00:00:13        10000       1459\n",
      "N-Grams Phenes:Full,Plant Overrepresented Tokens,1-grams     00:00:01          795       1459\n",
      "N-Grams Phenes:Full,Bio Ontology Tokens,1-grams              00:00:01          653       1459\n",
      "GO:Union                                                     00:00:00          841        215\n",
      "PO:Union                                                     00:00:00          210        214\n",
      "GO:Maximum                                                   00:00:00          868        594\n",
      "PO:Maximum                                                   00:00:00          213        213\n"
     ]
    }
   ],
   "source": [
    "# Generate all the pairwise distance matrices (not in parallel).\n",
    "graphs = {}\n",
    "names = []\n",
    "durations = []\n",
    "vector_lengths = []\n",
    "array_lengths = []\n",
    "for method in methods:\n",
    "    graph,duration = function_wrapper_with_duration(function=method.function, args=method.kwargs)\n",
    "    graphs[method.name_with_hyperparameters] = graph\n",
    "    names.append(method.name_with_hyperparameters)\n",
    "    durations.append(to_hms(duration))\n",
    "    vector_length = len(list(graph.vector_dictionary.values())[0])\n",
    "    array_length = graph.array.shape[0]\n",
    "    vector_lengths.append(vector_length)\n",
    "    array_lengths.append(array_length)\n",
    "    print(\"{:60} {:10} {:10} {:10}\".format(method.name_with_hyperparameters, to_hms(duration), vector_length, array_length))\n",
    "approaches_df = pd.DataFrame({\"method\":names, \"duration\":durations, \"vector_length\":vector_lengths, \"arr_length\":array_lengths})\n",
    "approaches_df.to_csv(os.path.join(OUTPUT_DIR,\"part_4_approaches.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging all the edgelists together.\n",
    "metric_dict = {method.name_with_hyperparameters:method.metric for method in methods}\n",
    "tags_dict = {method.name_with_hyperparameters:method.tag for method in methods}\n",
    "names = list(graphs.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = dataset.get_ids()\n",
    "from_to_id_pairs = [(i,j) for (i,j) in itertools.combinations(ids, 2)]\n",
    "df = pd.DataFrame(from_to_id_pairs, columns=[\"from\",\"to\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When multiple indices within the array could be part of the data for one particular gene (sentence tokenized).\n",
    "def get_min_of_distances(gene_id_1, gene_id_2, gene_id_to_uids, uid_to_array_index, array):\n",
    "    uids_list_1 = gene_id_to_uids[gene_id_1]\n",
    "    uids_list_2 = gene_id_to_uids[gene_id_2]\n",
    "    possible_uid_combinations = itertools.product(uids_list_1, uids_list_2)\n",
    "    distance = min([array[uid_to_array_index[i],uid_to_array_index[j]] for (i,j) in possible_uid_combinations])\n",
    "    return(distance)\n",
    "\n",
    "\n",
    "# When a single index within the array has to represent entirely the data for one gene (not sentence tokenized).\n",
    "def lookup_distance(gene_id_1, gene_id_2, gene_id_to_uids, uid_to_array_index, array):\n",
    "    assert len(gene_id_to_uids[gene_id_1]) == 1\n",
    "    assert len(gene_id_to_uids[gene_id_2]) == 1\n",
    "    uid_1 = gene_id_to_uids[gene_id_1][0]\n",
    "    uid_2 = gene_id_to_uids[gene_id_2][0]\n",
    "    distance = array[uid_to_array_index[uid_1],uid_to_array_index[uid_2]]\n",
    "    return(distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc2Vec:Wikipedia,Size=300\n",
      "Word2Vec:Wikipedia,Size=300,Mean\n",
      "Word2Vec:Wikipedia,Size=300,Max\n",
      "Doc2Vec Phenes:Wikipedia,Size=300\n",
      "Word2Vec Phenes:Wikipedia,Size=300,Mean\n",
      "Word2Vec Phenes:Wikipedia,Size=300,Max\n",
      "NOBLE Coder:Precise,TFIDF\n",
      "NOBLE Coder:Partial,TFIDF\n",
      "NOBLE Coder Phenes:Precise,TFIDF\n",
      "NOBLE Coder Phenes:Partial,TFIDF\n",
      "Topic Models:NMF,Full,Topics=50\n",
      "Topic Models:NMF,Full,Topics=100\n",
      "Topic Models Phenes:NMF,Full,Topics=50\n",
      "Topic Models Phenes:NMF,Full,Topics=100\n",
      "Topic Models:LDA,Full,Topics=50\n",
      "Topic Models:LDA,Full,Topics=100\n",
      "Topic Models Phenes:LDA,Full,Topics=50\n",
      "Topic Models Phenes:LDA,Full,Topics=100\n",
      "N-Grams:Full,Words,1-grams,TFIDF\n",
      "N-Grams:Full,Words,1-grams,2-grams,TFIDF\n",
      "N-Grams Phenes:Full,Words,1-grams,TFIDF\n",
      "N-Grams Phenes:Full,Words,1-grams,2-grams,TFIDF\n",
      "N-Grams:Full,Nouns,Adjectives,1-grams\n",
      "N-Grams:Linares_Pontes,Words,1-grams\n",
      "N-Grams:Full,Precise_Annotations,Words,1-grams\n",
      "N-Grams:Full,Partial_Annotations,Words,1-grams\n",
      "N-Grams:Full,Plant Overrepresented Tokens,1-grams\n",
      "N-Grams:Full,Bio Ontology Tokens,1-grams\n",
      "N-Grams Phenes:Full,Nouns,Adjectives,1-grams\n",
      "N-Grams Phenes:Linares_Pontes,Words,1-grams\n",
      "N-Grams Phenes:Full,Precise_Annotations,Words,1-grams\n",
      "N-Grams Phenes:Full,Partial_Annotations,Words,1-grams\n",
      "N-Grams Phenes:Full,Plant Overrepresented Tokens,1-grams\n",
      "N-Grams Phenes:Full,Bio Ontology Tokens,1-grams\n",
      "GO:Union\n",
      "PO:Union\n",
      "GO:Maximum\n",
      "PO:Maximum\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>from</th>\n",
       "      <th>to</th>\n",
       "      <th>Doc2Vec:Wikipedia,Size=300</th>\n",
       "      <th>Word2Vec:Wikipedia,Size=300,Mean</th>\n",
       "      <th>Word2Vec:Wikipedia,Size=300,Max</th>\n",
       "      <th>Doc2Vec Phenes:Wikipedia,Size=300</th>\n",
       "      <th>Word2Vec Phenes:Wikipedia,Size=300,Mean</th>\n",
       "      <th>Word2Vec Phenes:Wikipedia,Size=300,Max</th>\n",
       "      <th>NOBLE Coder:Precise,TFIDF</th>\n",
       "      <th>NOBLE Coder:Partial,TFIDF</th>\n",
       "      <th>NOBLE Coder Phenes:Precise,TFIDF</th>\n",
       "      <th>NOBLE Coder Phenes:Partial,TFIDF</th>\n",
       "      <th>Topic Models:NMF,Full,Topics=50</th>\n",
       "      <th>Topic Models:NMF,Full,Topics=100</th>\n",
       "      <th>Topic Models Phenes:NMF,Full,Topics=50</th>\n",
       "      <th>Topic Models Phenes:NMF,Full,Topics=100</th>\n",
       "      <th>Topic Models:LDA,Full,Topics=50</th>\n",
       "      <th>Topic Models:LDA,Full,Topics=100</th>\n",
       "      <th>Topic Models Phenes:LDA,Full,Topics=50</th>\n",
       "      <th>Topic Models Phenes:LDA,Full,Topics=100</th>\n",
       "      <th>N-Grams:Full,Words,1-grams,TFIDF</th>\n",
       "      <th>N-Grams:Full,Words,1-grams,2-grams,TFIDF</th>\n",
       "      <th>N-Grams Phenes:Full,Words,1-grams,TFIDF</th>\n",
       "      <th>N-Grams Phenes:Full,Words,1-grams,2-grams,TFIDF</th>\n",
       "      <th>N-Grams:Full,Nouns,Adjectives,1-grams</th>\n",
       "      <th>N-Grams:Linares_Pontes,Words,1-grams</th>\n",
       "      <th>N-Grams:Full,Precise_Annotations,Words,1-grams</th>\n",
       "      <th>N-Grams:Full,Partial_Annotations,Words,1-grams</th>\n",
       "      <th>N-Grams:Full,Plant Overrepresented Tokens,1-grams</th>\n",
       "      <th>N-Grams:Full,Bio Ontology Tokens,1-grams</th>\n",
       "      <th>N-Grams Phenes:Full,Nouns,Adjectives,1-grams</th>\n",
       "      <th>N-Grams Phenes:Linares_Pontes,Words,1-grams</th>\n",
       "      <th>N-Grams Phenes:Full,Precise_Annotations,Words,1-grams</th>\n",
       "      <th>N-Grams Phenes:Full,Partial_Annotations,Words,1-grams</th>\n",
       "      <th>N-Grams Phenes:Full,Plant Overrepresented Tokens,1-grams</th>\n",
       "      <th>N-Grams Phenes:Full,Bio Ontology Tokens,1-grams</th>\n",
       "      <th>GO:Union</th>\n",
       "      <th>PO:Union</th>\n",
       "      <th>GO:Maximum</th>\n",
       "      <th>PO:Maximum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>1145</td>\n",
       "      <td>0.504560</td>\n",
       "      <td>0.503235</td>\n",
       "      <td>0.263459</td>\n",
       "      <td>0.414963</td>\n",
       "      <td>0.478481</td>\n",
       "      <td>0.288674</td>\n",
       "      <td>0.857573</td>\n",
       "      <td>0.928872</td>\n",
       "      <td>0.796288</td>\n",
       "      <td>0.900807</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.995888</td>\n",
       "      <td>0.980399</td>\n",
       "      <td>0.990102</td>\n",
       "      <td>9.668565e-01</td>\n",
       "      <td>0.981963</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.836855</td>\n",
       "      <td>0.566964</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.586272</td>\n",
       "      <td>0.428988</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.917046</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.646146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100</td>\n",
       "      <td>4114</td>\n",
       "      <td>0.309927</td>\n",
       "      <td>0.260014</td>\n",
       "      <td>0.185656</td>\n",
       "      <td>0.276678</td>\n",
       "      <td>0.270105</td>\n",
       "      <td>0.180168</td>\n",
       "      <td>0.932399</td>\n",
       "      <td>0.962904</td>\n",
       "      <td>0.910822</td>\n",
       "      <td>0.957076</td>\n",
       "      <td>0.999785</td>\n",
       "      <td>0.999297</td>\n",
       "      <td>0.999941</td>\n",
       "      <td>0.999121</td>\n",
       "      <td>0.983668</td>\n",
       "      <td>0.991767</td>\n",
       "      <td>9.684386e-01</td>\n",
       "      <td>0.982268</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.977206</td>\n",
       "      <td>0.797835</td>\n",
       "      <td>0.406689</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.977423</td>\n",
       "      <td>0.741544</td>\n",
       "      <td>0.422529</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>231</td>\n",
       "      <td>0.435983</td>\n",
       "      <td>0.279231</td>\n",
       "      <td>0.185035</td>\n",
       "      <td>0.299665</td>\n",
       "      <td>0.271672</td>\n",
       "      <td>0.188429</td>\n",
       "      <td>0.872037</td>\n",
       "      <td>0.922563</td>\n",
       "      <td>0.817956</td>\n",
       "      <td>0.916699</td>\n",
       "      <td>0.733982</td>\n",
       "      <td>0.715878</td>\n",
       "      <td>0.797588</td>\n",
       "      <td>0.900100</td>\n",
       "      <td>0.977441</td>\n",
       "      <td>0.990781</td>\n",
       "      <td>9.554953e-01</td>\n",
       "      <td>0.971250</td>\n",
       "      <td>0.934402</td>\n",
       "      <td>0.969146</td>\n",
       "      <td>0.883653</td>\n",
       "      <td>0.928505</td>\n",
       "      <td>0.920096</td>\n",
       "      <td>0.880906</td>\n",
       "      <td>0.529131</td>\n",
       "      <td>0.490530</td>\n",
       "      <td>0.934402</td>\n",
       "      <td>0.915424</td>\n",
       "      <td>0.812598</td>\n",
       "      <td>0.863527</td>\n",
       "      <td>0.376286</td>\n",
       "      <td>0.415109</td>\n",
       "      <td>0.883653</td>\n",
       "      <td>0.853920</td>\n",
       "      <td>0.224368</td>\n",
       "      <td>0.700841</td>\n",
       "      <td>0.905412</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100</td>\n",
       "      <td>5244</td>\n",
       "      <td>0.551568</td>\n",
       "      <td>0.602756</td>\n",
       "      <td>0.363885</td>\n",
       "      <td>0.404959</td>\n",
       "      <td>0.607823</td>\n",
       "      <td>0.362408</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.958144</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.945128</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.990909</td>\n",
       "      <td>0.905914</td>\n",
       "      <td>0.976078</td>\n",
       "      <td>0.983010</td>\n",
       "      <td>9.529703e-01</td>\n",
       "      <td>0.974258</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.978320</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.897213</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.355641</td>\n",
       "      <td>0.629555</td>\n",
       "      <td>0.689286</td>\n",
       "      <td>0.476599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100</td>\n",
       "      <td>733</td>\n",
       "      <td>0.508654</td>\n",
       "      <td>0.270065</td>\n",
       "      <td>0.181497</td>\n",
       "      <td>0.355532</td>\n",
       "      <td>0.293558</td>\n",
       "      <td>0.170425</td>\n",
       "      <td>0.893924</td>\n",
       "      <td>0.927862</td>\n",
       "      <td>0.797668</td>\n",
       "      <td>0.919038</td>\n",
       "      <td>0.999892</td>\n",
       "      <td>0.998867</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999008</td>\n",
       "      <td>0.974111</td>\n",
       "      <td>0.988849</td>\n",
       "      <td>9.546172e-01</td>\n",
       "      <td>0.971961</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.865899</td>\n",
       "      <td>0.796603</td>\n",
       "      <td>0.284657</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.850601</td>\n",
       "      <td>0.593352</td>\n",
       "      <td>0.247837</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.188509</td>\n",
       "      <td>0.575006</td>\n",
       "      <td>0.689286</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>100</td>\n",
       "      <td>3896</td>\n",
       "      <td>0.518026</td>\n",
       "      <td>0.536171</td>\n",
       "      <td>0.298879</td>\n",
       "      <td>0.428593</td>\n",
       "      <td>0.590710</td>\n",
       "      <td>0.391840</td>\n",
       "      <td>0.970234</td>\n",
       "      <td>0.972461</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.967205</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.976449</td>\n",
       "      <td>0.988082</td>\n",
       "      <td>9.620776e-01</td>\n",
       "      <td>0.961087</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.912374</td>\n",
       "      <td>0.338805</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.841140</td>\n",
       "      <td>0.310185</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>100</td>\n",
       "      <td>4572</td>\n",
       "      <td>0.498664</td>\n",
       "      <td>0.326860</td>\n",
       "      <td>0.179187</td>\n",
       "      <td>0.349483</td>\n",
       "      <td>0.341777</td>\n",
       "      <td>0.209361</td>\n",
       "      <td>0.948135</td>\n",
       "      <td>0.927444</td>\n",
       "      <td>0.939123</td>\n",
       "      <td>0.925689</td>\n",
       "      <td>0.998685</td>\n",
       "      <td>0.986242</td>\n",
       "      <td>0.988918</td>\n",
       "      <td>0.640430</td>\n",
       "      <td>0.982011</td>\n",
       "      <td>0.990924</td>\n",
       "      <td>9.532030e-01</td>\n",
       "      <td>0.978660</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.908057</td>\n",
       "      <td>0.713808</td>\n",
       "      <td>0.345801</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.899051</td>\n",
       "      <td>0.600257</td>\n",
       "      <td>0.263837</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.425165</td>\n",
       "      <td>0.556259</td>\n",
       "      <td>0.925314</td>\n",
       "      <td>0.476599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>100</td>\n",
       "      <td>2823</td>\n",
       "      <td>0.542816</td>\n",
       "      <td>0.272979</td>\n",
       "      <td>0.187657</td>\n",
       "      <td>0.296875</td>\n",
       "      <td>0.278486</td>\n",
       "      <td>0.199103</td>\n",
       "      <td>0.887384</td>\n",
       "      <td>0.909117</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.885990</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.639737</td>\n",
       "      <td>0.740649</td>\n",
       "      <td>0.980833</td>\n",
       "      <td>0.990628</td>\n",
       "      <td>2.500710e-09</td>\n",
       "      <td>0.788591</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.970817</td>\n",
       "      <td>0.724138</td>\n",
       "      <td>0.247397</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.949335</td>\n",
       "      <td>0.548854</td>\n",
       "      <td>0.229812</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>100</td>\n",
       "      <td>1592</td>\n",
       "      <td>0.453901</td>\n",
       "      <td>0.438724</td>\n",
       "      <td>0.198668</td>\n",
       "      <td>0.296394</td>\n",
       "      <td>0.365019</td>\n",
       "      <td>0.222920</td>\n",
       "      <td>0.902751</td>\n",
       "      <td>0.926640</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.905401</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999490</td>\n",
       "      <td>0.984330</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.973381</td>\n",
       "      <td>0.991938</td>\n",
       "      <td>9.606524e-01</td>\n",
       "      <td>0.971783</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.945727</td>\n",
       "      <td>0.815585</td>\n",
       "      <td>0.329073</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.889008</td>\n",
       "      <td>0.732580</td>\n",
       "      <td>0.247194</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.215764</td>\n",
       "      <td>0.644082</td>\n",
       "      <td>0.488195</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>100</td>\n",
       "      <td>1185</td>\n",
       "      <td>0.437521</td>\n",
       "      <td>0.197340</td>\n",
       "      <td>0.151455</td>\n",
       "      <td>0.280486</td>\n",
       "      <td>0.232980</td>\n",
       "      <td>0.155569</td>\n",
       "      <td>0.901545</td>\n",
       "      <td>0.921714</td>\n",
       "      <td>0.654037</td>\n",
       "      <td>0.911570</td>\n",
       "      <td>0.995473</td>\n",
       "      <td>0.992384</td>\n",
       "      <td>0.375339</td>\n",
       "      <td>0.979698</td>\n",
       "      <td>0.983954</td>\n",
       "      <td>0.992425</td>\n",
       "      <td>9.599578e-01</td>\n",
       "      <td>0.970949</td>\n",
       "      <td>0.971604</td>\n",
       "      <td>0.987393</td>\n",
       "      <td>0.880267</td>\n",
       "      <td>0.948704</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.857459</td>\n",
       "      <td>0.699810</td>\n",
       "      <td>0.319292</td>\n",
       "      <td>0.971132</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.808575</td>\n",
       "      <td>0.420889</td>\n",
       "      <td>0.275842</td>\n",
       "      <td>0.854551</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.200531</td>\n",
       "      <td>0.796364</td>\n",
       "      <td>0.898161</td>\n",
       "      <td>0.538176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>100</td>\n",
       "      <td>883</td>\n",
       "      <td>0.433015</td>\n",
       "      <td>0.601558</td>\n",
       "      <td>0.872109</td>\n",
       "      <td>0.345507</td>\n",
       "      <td>0.597342</td>\n",
       "      <td>0.807199</td>\n",
       "      <td>0.840931</td>\n",
       "      <td>0.933173</td>\n",
       "      <td>0.797668</td>\n",
       "      <td>0.922610</td>\n",
       "      <td>0.999966</td>\n",
       "      <td>0.999663</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.976885</td>\n",
       "      <td>0.988305</td>\n",
       "      <td>9.519369e-01</td>\n",
       "      <td>0.973318</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.889686</td>\n",
       "      <td>0.281991</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.714460</td>\n",
       "      <td>0.247837</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.297119</td>\n",
       "      <td>0.765555</td>\n",
       "      <td>0.918007</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>100</td>\n",
       "      <td>2456</td>\n",
       "      <td>0.506571</td>\n",
       "      <td>0.186860</td>\n",
       "      <td>0.160455</td>\n",
       "      <td>0.196499</td>\n",
       "      <td>0.194339</td>\n",
       "      <td>0.160468</td>\n",
       "      <td>0.885565</td>\n",
       "      <td>0.871551</td>\n",
       "      <td>0.635296</td>\n",
       "      <td>0.668224</td>\n",
       "      <td>0.768235</td>\n",
       "      <td>0.762891</td>\n",
       "      <td>0.685551</td>\n",
       "      <td>0.309989</td>\n",
       "      <td>0.987835</td>\n",
       "      <td>0.987893</td>\n",
       "      <td>9.538829e-01</td>\n",
       "      <td>0.713962</td>\n",
       "      <td>0.887148</td>\n",
       "      <td>0.937832</td>\n",
       "      <td>0.820744</td>\n",
       "      <td>0.906416</td>\n",
       "      <td>0.892741</td>\n",
       "      <td>0.778592</td>\n",
       "      <td>0.641168</td>\n",
       "      <td>0.268298</td>\n",
       "      <td>0.879809</td>\n",
       "      <td>0.859276</td>\n",
       "      <td>0.718486</td>\n",
       "      <td>0.784513</td>\n",
       "      <td>0.323591</td>\n",
       "      <td>0.215743</td>\n",
       "      <td>0.817136</td>\n",
       "      <td>0.794983</td>\n",
       "      <td>0.143607</td>\n",
       "      <td>0.642601</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>100</td>\n",
       "      <td>5326</td>\n",
       "      <td>0.490244</td>\n",
       "      <td>0.380940</td>\n",
       "      <td>0.186081</td>\n",
       "      <td>0.408533</td>\n",
       "      <td>0.426500</td>\n",
       "      <td>0.226843</td>\n",
       "      <td>0.896534</td>\n",
       "      <td>0.762814</td>\n",
       "      <td>0.820543</td>\n",
       "      <td>0.518491</td>\n",
       "      <td>0.918731</td>\n",
       "      <td>0.987538</td>\n",
       "      <td>0.866146</td>\n",
       "      <td>0.939288</td>\n",
       "      <td>0.978446</td>\n",
       "      <td>0.375235</td>\n",
       "      <td>9.540923e-01</td>\n",
       "      <td>0.967144</td>\n",
       "      <td>0.923487</td>\n",
       "      <td>0.969880</td>\n",
       "      <td>0.855463</td>\n",
       "      <td>0.937715</td>\n",
       "      <td>0.911106</td>\n",
       "      <td>0.915145</td>\n",
       "      <td>0.706214</td>\n",
       "      <td>0.257861</td>\n",
       "      <td>0.919181</td>\n",
       "      <td>0.909812</td>\n",
       "      <td>0.832597</td>\n",
       "      <td>0.838619</td>\n",
       "      <td>0.626924</td>\n",
       "      <td>0.214428</td>\n",
       "      <td>0.828453</td>\n",
       "      <td>0.812806</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.848694</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>100</td>\n",
       "      <td>1389</td>\n",
       "      <td>0.449655</td>\n",
       "      <td>0.173582</td>\n",
       "      <td>0.152193</td>\n",
       "      <td>0.190415</td>\n",
       "      <td>0.158163</td>\n",
       "      <td>0.123656</td>\n",
       "      <td>0.695581</td>\n",
       "      <td>0.822994</td>\n",
       "      <td>0.157983</td>\n",
       "      <td>0.388861</td>\n",
       "      <td>0.643811</td>\n",
       "      <td>0.472842</td>\n",
       "      <td>0.488442</td>\n",
       "      <td>0.177004</td>\n",
       "      <td>0.980936</td>\n",
       "      <td>0.988426</td>\n",
       "      <td>1.762766e-05</td>\n",
       "      <td>0.050712</td>\n",
       "      <td>0.809310</td>\n",
       "      <td>0.889343</td>\n",
       "      <td>0.293965</td>\n",
       "      <td>0.517576</td>\n",
       "      <td>0.851223</td>\n",
       "      <td>0.738997</td>\n",
       "      <td>0.534355</td>\n",
       "      <td>0.254799</td>\n",
       "      <td>0.803128</td>\n",
       "      <td>0.766201</td>\n",
       "      <td>0.388563</td>\n",
       "      <td>0.290308</td>\n",
       "      <td>0.130693</td>\n",
       "      <td>0.113132</td>\n",
       "      <td>0.293965</td>\n",
       "      <td>0.202365</td>\n",
       "      <td>0.134726</td>\n",
       "      <td>0.756770</td>\n",
       "      <td>0.557407</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>100</td>\n",
       "      <td>5153</td>\n",
       "      <td>0.498049</td>\n",
       "      <td>0.255375</td>\n",
       "      <td>0.205944</td>\n",
       "      <td>0.346341</td>\n",
       "      <td>0.248265</td>\n",
       "      <td>0.204870</td>\n",
       "      <td>0.907639</td>\n",
       "      <td>0.946790</td>\n",
       "      <td>0.714735</td>\n",
       "      <td>0.935742</td>\n",
       "      <td>0.999952</td>\n",
       "      <td>0.998964</td>\n",
       "      <td>0.946267</td>\n",
       "      <td>0.993401</td>\n",
       "      <td>0.982195</td>\n",
       "      <td>0.990205</td>\n",
       "      <td>9.602068e-01</td>\n",
       "      <td>0.971601</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.897559</td>\n",
       "      <td>0.648575</td>\n",
       "      <td>0.346042</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.869588</td>\n",
       "      <td>0.493623</td>\n",
       "      <td>0.301690</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.236706</td>\n",
       "      <td>0.725834</td>\n",
       "      <td>0.889163</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>100</td>\n",
       "      <td>1975</td>\n",
       "      <td>0.517766</td>\n",
       "      <td>0.246333</td>\n",
       "      <td>0.155104</td>\n",
       "      <td>0.365803</td>\n",
       "      <td>0.262292</td>\n",
       "      <td>0.171215</td>\n",
       "      <td>0.847666</td>\n",
       "      <td>0.844332</td>\n",
       "      <td>0.714735</td>\n",
       "      <td>0.735052</td>\n",
       "      <td>0.998707</td>\n",
       "      <td>0.991175</td>\n",
       "      <td>0.897693</td>\n",
       "      <td>0.943254</td>\n",
       "      <td>0.977903</td>\n",
       "      <td>0.993223</td>\n",
       "      <td>7.340050e-01</td>\n",
       "      <td>0.788591</td>\n",
       "      <td>0.977303</td>\n",
       "      <td>0.987493</td>\n",
       "      <td>0.930794</td>\n",
       "      <td>0.962515</td>\n",
       "      <td>0.966581</td>\n",
       "      <td>0.874183</td>\n",
       "      <td>0.652770</td>\n",
       "      <td>0.307714</td>\n",
       "      <td>0.976264</td>\n",
       "      <td>0.967525</td>\n",
       "      <td>0.894120</td>\n",
       "      <td>0.879221</td>\n",
       "      <td>0.386746</td>\n",
       "      <td>0.281545</td>\n",
       "      <td>0.924241</td>\n",
       "      <td>0.908044</td>\n",
       "      <td>0.185603</td>\n",
       "      <td>0.757168</td>\n",
       "      <td>0.839198</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>100</td>\n",
       "      <td>705</td>\n",
       "      <td>0.372423</td>\n",
       "      <td>0.466228</td>\n",
       "      <td>0.296158</td>\n",
       "      <td>0.355532</td>\n",
       "      <td>0.485242</td>\n",
       "      <td>0.402482</td>\n",
       "      <td>0.765789</td>\n",
       "      <td>0.937770</td>\n",
       "      <td>0.694703</td>\n",
       "      <td>0.920472</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>0.995581</td>\n",
       "      <td>0.986567</td>\n",
       "      <td>0.997620</td>\n",
       "      <td>0.980992</td>\n",
       "      <td>0.987018</td>\n",
       "      <td>9.519369e-01</td>\n",
       "      <td>0.973318</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.727823</td>\n",
       "      <td>0.278443</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.497310</td>\n",
       "      <td>0.247837</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.161334</td>\n",
       "      <td>0.755283</td>\n",
       "      <td>0.694804</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>100</td>\n",
       "      <td>2465</td>\n",
       "      <td>0.400593</td>\n",
       "      <td>0.496899</td>\n",
       "      <td>0.300016</td>\n",
       "      <td>0.359965</td>\n",
       "      <td>0.486943</td>\n",
       "      <td>0.300016</td>\n",
       "      <td>0.938961</td>\n",
       "      <td>0.966689</td>\n",
       "      <td>0.920880</td>\n",
       "      <td>0.955600</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.976880</td>\n",
       "      <td>0.988303</td>\n",
       "      <td>9.550776e-01</td>\n",
       "      <td>0.981918</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.957711</td>\n",
       "      <td>0.885079</td>\n",
       "      <td>0.981948</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.949175</td>\n",
       "      <td>0.827598</td>\n",
       "      <td>0.859332</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.231866</td>\n",
       "      <td>0.744921</td>\n",
       "      <td>0.919836</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>100</td>\n",
       "      <td>4826</td>\n",
       "      <td>0.455674</td>\n",
       "      <td>0.314752</td>\n",
       "      <td>0.164622</td>\n",
       "      <td>0.285976</td>\n",
       "      <td>0.263800</td>\n",
       "      <td>0.141633</td>\n",
       "      <td>0.862357</td>\n",
       "      <td>0.829606</td>\n",
       "      <td>0.686363</td>\n",
       "      <td>0.696630</td>\n",
       "      <td>0.821795</td>\n",
       "      <td>0.697329</td>\n",
       "      <td>0.349369</td>\n",
       "      <td>0.179964</td>\n",
       "      <td>0.987204</td>\n",
       "      <td>0.988050</td>\n",
       "      <td>9.478470e-01</td>\n",
       "      <td>0.967856</td>\n",
       "      <td>0.901601</td>\n",
       "      <td>0.952641</td>\n",
       "      <td>0.800605</td>\n",
       "      <td>0.915722</td>\n",
       "      <td>0.921890</td>\n",
       "      <td>0.843335</td>\n",
       "      <td>0.630609</td>\n",
       "      <td>0.228930</td>\n",
       "      <td>0.893790</td>\n",
       "      <td>0.867906</td>\n",
       "      <td>0.824654</td>\n",
       "      <td>0.740736</td>\n",
       "      <td>0.508417</td>\n",
       "      <td>0.181875</td>\n",
       "      <td>0.800605</td>\n",
       "      <td>0.774736</td>\n",
       "      <td>0.196729</td>\n",
       "      <td>0.753039</td>\n",
       "      <td>0.926500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>100</td>\n",
       "      <td>4361</td>\n",
       "      <td>0.245022</td>\n",
       "      <td>0.156215</td>\n",
       "      <td>0.192543</td>\n",
       "      <td>0.210180</td>\n",
       "      <td>0.221758</td>\n",
       "      <td>0.182364</td>\n",
       "      <td>0.786647</td>\n",
       "      <td>0.825674</td>\n",
       "      <td>0.721867</td>\n",
       "      <td>0.800733</td>\n",
       "      <td>0.760857</td>\n",
       "      <td>0.743708</td>\n",
       "      <td>0.612054</td>\n",
       "      <td>0.321660</td>\n",
       "      <td>0.977733</td>\n",
       "      <td>0.988820</td>\n",
       "      <td>9.693904e-01</td>\n",
       "      <td>0.983416</td>\n",
       "      <td>0.858266</td>\n",
       "      <td>0.944924</td>\n",
       "      <td>0.834894</td>\n",
       "      <td>0.933571</td>\n",
       "      <td>0.803079</td>\n",
       "      <td>0.691092</td>\n",
       "      <td>0.555945</td>\n",
       "      <td>0.308838</td>\n",
       "      <td>0.858266</td>\n",
       "      <td>0.831412</td>\n",
       "      <td>0.746720</td>\n",
       "      <td>0.598453</td>\n",
       "      <td>0.370800</td>\n",
       "      <td>0.266747</td>\n",
       "      <td>0.834894</td>\n",
       "      <td>0.813473</td>\n",
       "      <td>0.234463</td>\n",
       "      <td>0.688798</td>\n",
       "      <td>0.305225</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    from    to  Doc2Vec:Wikipedia,Size=300  Word2Vec:Wikipedia,Size=300,Mean  Word2Vec:Wikipedia,Size=300,Max  Doc2Vec Phenes:Wikipedia,Size=300  Word2Vec Phenes:Wikipedia,Size=300,Mean  Word2Vec Phenes:Wikipedia,Size=300,Max  NOBLE Coder:Precise,TFIDF  NOBLE Coder:Partial,TFIDF  NOBLE Coder Phenes:Precise,TFIDF  NOBLE Coder Phenes:Partial,TFIDF  Topic Models:NMF,Full,Topics=50  Topic Models:NMF,Full,Topics=100  Topic Models Phenes:NMF,Full,Topics=50  Topic Models Phenes:NMF,Full,Topics=100  Topic Models:LDA,Full,Topics=50  Topic Models:LDA,Full,Topics=100  Topic Models Phenes:LDA,Full,Topics=50  Topic Models Phenes:LDA,Full,Topics=100  N-Grams:Full,Words,1-grams,TFIDF  N-Grams:Full,Words,1-grams,2-grams,TFIDF  N-Grams Phenes:Full,Words,1-grams,TFIDF  N-Grams Phenes:Full,Words,1-grams,2-grams,TFIDF  N-Grams:Full,Nouns,Adjectives,1-grams  N-Grams:Linares_Pontes,Words,1-grams  N-Grams:Full,Precise_Annotations,Words,1-grams  N-Grams:Full,Partial_Annotations,Words,1-grams  \\\n",
       "0    100  1145                    0.504560                          0.503235                         0.263459                           0.414963                                 0.478481                                0.288674                   0.857573                   0.928872                          0.796288                          0.900807                         1.000000                          1.000000                                1.000000                                 0.995888                         0.980399                          0.990102                            9.668565e-01                                 0.981963                          1.000000                                  1.000000                                 1.000000                                         1.000000                               1.000000                              1.000000                                        0.836855                                        0.566964   \n",
       "1    100  4114                    0.309927                          0.260014                         0.185656                           0.276678                                 0.270105                                0.180168                   0.932399                   0.962904                          0.910822                          0.957076                         0.999785                          0.999297                                0.999941                                 0.999121                         0.983668                          0.991767                            9.684386e-01                                 0.982268                          1.000000                                  1.000000                                 1.000000                                         1.000000                               1.000000                              0.977206                                        0.797835                                        0.406689   \n",
       "2    100   231                    0.435983                          0.279231                         0.185035                           0.299665                                 0.271672                                0.188429                   0.872037                   0.922563                          0.817956                          0.916699                         0.733982                          0.715878                                0.797588                                 0.900100                         0.977441                          0.990781                            9.554953e-01                                 0.971250                          0.934402                                  0.969146                                 0.883653                                         0.928505                               0.920096                              0.880906                                        0.529131                                        0.490530   \n",
       "3    100  5244                    0.551568                          0.602756                         0.363885                           0.404959                                 0.607823                                0.362408                   1.000000                   0.958144                          1.000000                          0.945128                         1.000000                          1.000000                                0.990909                                 0.905914                         0.976078                          0.983010                            9.529703e-01                                 0.974258                          1.000000                                  1.000000                                 1.000000                                         1.000000                               1.000000                              1.000000                                        1.000000                                        0.978320   \n",
       "4    100   733                    0.508654                          0.270065                         0.181497                           0.355532                                 0.293558                                0.170425                   0.893924                   0.927862                          0.797668                          0.919038                         0.999892                          0.998867                                1.000000                                 0.999008                         0.974111                          0.988849                            9.546172e-01                                 0.971961                          1.000000                                  1.000000                                 1.000000                                         1.000000                               1.000000                              0.865899                                        0.796603                                        0.284657   \n",
       "5    100  3896                    0.518026                          0.536171                         0.298879                           0.428593                                 0.590710                                0.391840                   0.970234                   0.972461                          1.000000                          0.967205                         1.000000                          1.000000                                1.000000                                 1.000000                         0.976449                          0.988082                            9.620776e-01                                 0.961087                          1.000000                                  1.000000                                 1.000000                                         1.000000                               1.000000                              1.000000                                        0.912374                                        0.338805   \n",
       "6    100  4572                    0.498664                          0.326860                         0.179187                           0.349483                                 0.341777                                0.209361                   0.948135                   0.927444                          0.939123                          0.925689                         0.998685                          0.986242                                0.988918                                 0.640430                         0.982011                          0.990924                            9.532030e-01                                 0.978660                          1.000000                                  1.000000                                 1.000000                                         1.000000                               1.000000                              0.908057                                        0.713808                                        0.345801   \n",
       "7    100  2823                    0.542816                          0.272979                         0.187657                           0.296875                                 0.278486                                0.199103                   0.887384                   0.909117                          1.000000                          0.885990                         1.000000                          1.000000                                0.639737                                 0.740649                         0.980833                          0.990628                            2.500710e-09                                 0.788591                          1.000000                                  1.000000                                 1.000000                                         1.000000                               1.000000                              0.970817                                        0.724138                                        0.247397   \n",
       "8    100  1592                    0.453901                          0.438724                         0.198668                           0.296394                                 0.365019                                0.222920                   0.902751                   0.926640                          1.000000                          0.905401                         1.000000                          0.999490                                0.984330                                 1.000000                         0.973381                          0.991938                            9.606524e-01                                 0.971783                          1.000000                                  1.000000                                 1.000000                                         1.000000                               1.000000                              0.945727                                        0.815585                                        0.329073   \n",
       "9    100  1185                    0.437521                          0.197340                         0.151455                           0.280486                                 0.232980                                0.155569                   0.901545                   0.921714                          0.654037                          0.911570                         0.995473                          0.992384                                0.375339                                 0.979698                         0.983954                          0.992425                            9.599578e-01                                 0.970949                          0.971604                                  0.987393                                 0.880267                                         0.948704                               1.000000                              0.857459                                        0.699810                                        0.319292   \n",
       "10   100   883                    0.433015                          0.601558                         0.872109                           0.345507                                 0.597342                                0.807199                   0.840931                   0.933173                          0.797668                          0.922610                         0.999966                          0.999663                                1.000000                                 1.000000                         0.976885                          0.988305                            9.519369e-01                                 0.973318                          1.000000                                  1.000000                                 1.000000                                         1.000000                               1.000000                              1.000000                                        0.889686                                        0.281991   \n",
       "11   100  2456                    0.506571                          0.186860                         0.160455                           0.196499                                 0.194339                                0.160468                   0.885565                   0.871551                          0.635296                          0.668224                         0.768235                          0.762891                                0.685551                                 0.309989                         0.987835                          0.987893                            9.538829e-01                                 0.713962                          0.887148                                  0.937832                                 0.820744                                         0.906416                               0.892741                              0.778592                                        0.641168                                        0.268298   \n",
       "12   100  5326                    0.490244                          0.380940                         0.186081                           0.408533                                 0.426500                                0.226843                   0.896534                   0.762814                          0.820543                          0.518491                         0.918731                          0.987538                                0.866146                                 0.939288                         0.978446                          0.375235                            9.540923e-01                                 0.967144                          0.923487                                  0.969880                                 0.855463                                         0.937715                               0.911106                              0.915145                                        0.706214                                        0.257861   \n",
       "13   100  1389                    0.449655                          0.173582                         0.152193                           0.190415                                 0.158163                                0.123656                   0.695581                   0.822994                          0.157983                          0.388861                         0.643811                          0.472842                                0.488442                                 0.177004                         0.980936                          0.988426                            1.762766e-05                                 0.050712                          0.809310                                  0.889343                                 0.293965                                         0.517576                               0.851223                              0.738997                                        0.534355                                        0.254799   \n",
       "14   100  5153                    0.498049                          0.255375                         0.205944                           0.346341                                 0.248265                                0.204870                   0.907639                   0.946790                          0.714735                          0.935742                         0.999952                          0.998964                                0.946267                                 0.993401                         0.982195                          0.990205                            9.602068e-01                                 0.971601                          1.000000                                  1.000000                                 1.000000                                         1.000000                               1.000000                              0.897559                                        0.648575                                        0.346042   \n",
       "15   100  1975                    0.517766                          0.246333                         0.155104                           0.365803                                 0.262292                                0.171215                   0.847666                   0.844332                          0.714735                          0.735052                         0.998707                          0.991175                                0.897693                                 0.943254                         0.977903                          0.993223                            7.340050e-01                                 0.788591                          0.977303                                  0.987493                                 0.930794                                         0.962515                               0.966581                              0.874183                                        0.652770                                        0.307714   \n",
       "16   100   705                    0.372423                          0.466228                         0.296158                           0.355532                                 0.485242                                0.402482                   0.765789                   0.937770                          0.694703                          0.920472                         0.999997                          0.995581                                0.986567                                 0.997620                         0.980992                          0.987018                            9.519369e-01                                 0.973318                          1.000000                                  1.000000                                 1.000000                                         1.000000                               1.000000                              1.000000                                        0.727823                                        0.278443   \n",
       "17   100  2465                    0.400593                          0.496899                         0.300016                           0.359965                                 0.486943                                0.300016                   0.938961                   0.966689                          0.920880                          0.955600                         1.000000                          1.000000                                1.000000                                 1.000000                         0.976880                          0.988303                            9.550776e-01                                 0.981918                          1.000000                                  1.000000                                 1.000000                                         1.000000                               1.000000                              0.957711                                        0.885079                                        0.981948   \n",
       "18   100  4826                    0.455674                          0.314752                         0.164622                           0.285976                                 0.263800                                0.141633                   0.862357                   0.829606                          0.686363                          0.696630                         0.821795                          0.697329                                0.349369                                 0.179964                         0.987204                          0.988050                            9.478470e-01                                 0.967856                          0.901601                                  0.952641                                 0.800605                                         0.915722                               0.921890                              0.843335                                        0.630609                                        0.228930   \n",
       "19   100  4361                    0.245022                          0.156215                         0.192543                           0.210180                                 0.221758                                0.182364                   0.786647                   0.825674                          0.721867                          0.800733                         0.760857                          0.743708                                0.612054                                 0.321660                         0.977733                          0.988820                            9.693904e-01                                 0.983416                          0.858266                                  0.944924                                 0.834894                                         0.933571                               0.803079                              0.691092                                        0.555945                                        0.308838   \n",
       "\n",
       "    N-Grams:Full,Plant Overrepresented Tokens,1-grams  N-Grams:Full,Bio Ontology Tokens,1-grams  N-Grams Phenes:Full,Nouns,Adjectives,1-grams  N-Grams Phenes:Linares_Pontes,Words,1-grams  N-Grams Phenes:Full,Precise_Annotations,Words,1-grams  N-Grams Phenes:Full,Partial_Annotations,Words,1-grams  N-Grams Phenes:Full,Plant Overrepresented Tokens,1-grams  N-Grams Phenes:Full,Bio Ontology Tokens,1-grams  GO:Union  PO:Union  GO:Maximum  PO:Maximum  \n",
       "0                                            1.000000                                  1.000000                                      1.000000                                     1.000000                                           0.586272                                               0.428988                                               1.000000                                                1.000000  1.000000  0.917046    1.000000    0.646146  \n",
       "1                                            1.000000                                  1.000000                                      1.000000                                     0.977423                                           0.741544                                               0.422529                                               1.000000                                                1.000000  1.000000  1.000000    1.000000    1.000000  \n",
       "2                                            0.934402                                  0.915424                                      0.812598                                     0.863527                                           0.376286                                               0.415109                                               0.883653                                                0.853920  0.224368  0.700841    0.905412    0.000000  \n",
       "3                                            1.000000                                  1.000000                                      1.000000                                     1.000000                                           1.000000                                               0.897213                                               1.000000                                                1.000000  0.355641  0.629555    0.689286    0.476599  \n",
       "4                                            1.000000                                  1.000000                                      1.000000                                     0.850601                                           0.593352                                               0.247837                                               1.000000                                                1.000000  0.188509  0.575006    0.689286    0.000000  \n",
       "5                                            1.000000                                  1.000000                                      1.000000                                     1.000000                                           0.841140                                               0.310185                                               1.000000                                                1.000000  1.000000  1.000000    1.000000    1.000000  \n",
       "6                                            1.000000                                  1.000000                                      1.000000                                     0.899051                                           0.600257                                               0.263837                                               1.000000                                                1.000000  0.425165  0.556259    0.925314    0.476599  \n",
       "7                                            1.000000                                  1.000000                                      1.000000                                     0.949335                                           0.548854                                               0.229812                                               1.000000                                                1.000000  1.000000  1.000000    1.000000    1.000000  \n",
       "8                                            1.000000                                  1.000000                                      1.000000                                     0.889008                                           0.732580                                               0.247194                                               1.000000                                                1.000000  0.215764  0.644082    0.488195    0.000000  \n",
       "9                                            0.971132                                  1.000000                                      1.000000                                     0.808575                                           0.420889                                               0.275842                                               0.854551                                                1.000000  0.200531  0.796364    0.898161    0.538176  \n",
       "10                                           1.000000                                  1.000000                                      1.000000                                     1.000000                                           0.714460                                               0.247837                                               1.000000                                                1.000000  0.297119  0.765555    0.918007    0.000000  \n",
       "11                                           0.879809                                  0.859276                                      0.718486                                     0.784513                                           0.323591                                               0.215743                                               0.817136                                                0.794983  0.143607  0.642601    0.000000    0.000000  \n",
       "12                                           0.919181                                  0.909812                                      0.832597                                     0.838619                                           0.626924                                               0.214428                                               0.828453                                                0.812806  1.000000  0.848694    1.000000    0.000000  \n",
       "13                                           0.803128                                  0.766201                                      0.388563                                     0.290308                                           0.130693                                               0.113132                                               0.293965                                                0.202365  0.134726  0.756770    0.557407    0.000000  \n",
       "14                                           1.000000                                  1.000000                                      1.000000                                     0.869588                                           0.493623                                               0.301690                                               1.000000                                                1.000000  0.236706  0.725834    0.889163    0.000000  \n",
       "15                                           0.976264                                  0.967525                                      0.894120                                     0.879221                                           0.386746                                               0.281545                                               0.924241                                                0.908044  0.185603  0.757168    0.839198    0.000000  \n",
       "16                                           1.000000                                  1.000000                                      1.000000                                     1.000000                                           0.497310                                               0.247837                                               1.000000                                                1.000000  0.161334  0.755283    0.694804    0.000000  \n",
       "17                                           1.000000                                  1.000000                                      1.000000                                     0.949175                                           0.827598                                               0.859332                                               1.000000                                                1.000000  0.231866  0.744921    0.919836    0.000000  \n",
       "18                                           0.893790                                  0.867906                                      0.824654                                     0.740736                                           0.508417                                               0.181875                                               0.800605                                                0.774736  0.196729  0.753039    0.926500    0.000000  \n",
       "19                                           0.858266                                  0.831412                                      0.746720                                     0.598453                                           0.370800                                               0.266747                                               0.834894                                                0.813473  0.234463  0.688798    0.305225    0.000000  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Depending on what the IDs in the dictionaries for each approach were referencing, the distance values in the\n",
    "# arrays that were returned mean different things. In some cases, the IDs might refer to unique text strings parsed\n",
    "# from the whole descriptions, or tokenized strings referring to single sentences, or they might be referring to \n",
    "# particular unique gene ontology terms that were used in the curated annotations, or to unique whole sets of terms\n",
    "# that were used in the annotations. This dictionary maps tags associated with each approach to which function and \n",
    "# dictionary for translating between ID types in order to handle each approach appropriately.\n",
    "\n",
    "function_and_mapping_to_use = {\n",
    "    \"sent_tokens\":(get_min_of_distances, gene_id_to_unique_ids_mappings[\"sent_tokens\"]),\n",
    "    \"whole_texts\":(lookup_distance, gene_id_to_unique_ids_mappings[\"whole_texts\"]),\n",
    "    \"go_term_sets\":(lookup_distance, gene_id_to_unique_ids_mappings[\"go_term_sets\"]),\n",
    "    \"po_term_sets\":(lookup_distance, gene_id_to_unique_ids_mappings[\"po_term_sets\"]),\n",
    "    \"go_terms\":(get_min_of_distances, gene_id_to_unique_ids_mappings[\"go_terms\"]),\n",
    "    \"po_terms\":(get_min_of_distances, gene_id_to_unique_ids_mappings[\"po_terms\"])}\n",
    "\n",
    "\n",
    "# Create one new column in the edge list dataframe for each of the approaches that were used.\n",
    "for name,graph in graphs.items():\n",
    "    print(name)\n",
    "    function, mapping = function_and_mapping_to_use[tags_dict[name]]\n",
    "    df[name] = df.apply(lambda x: function(x[\"from\"], x[\"to\"], mapping, graph.id_to_index, graph.array), axis=1)\n",
    "        \n",
    "\n",
    "# Memory cleanup for the extremely large objects returned by the distance matrix generating functions.\n",
    "graphs = None\n",
    "\n",
    "\n",
    "# Because cosine similarity and distance functions are used, vectors with all zeroes will have undefined similarity\n",
    "# to other vectors. This results when empty strings or empty lists are passed to the methods that generate vectors\n",
    "# and distances matrices over this dataset. Therefore those NaNs that result are replaced here with the maximum\n",
    "# distance value, which is set 1 because the range of all the distance functions used is 0 to 1.\n",
    "df.fillna(value=1.000, inplace=True)\n",
    "\n",
    "\n",
    "# Make sure that the edge list contains the expected data types before moving forward.\n",
    "df[\"from\"] = df[\"from\"].astype(\"int64\")\n",
    "df[\"to\"] = df[\"to\"].astype(\"int64\")\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"merging\"></a>\n",
    "### Merging all of the distance matrices into a single dataframe specifying edges\n",
    "This section also handles replacing IDs from the individual methods that are references individual phenes that are part of a larger phenotype, and replacing those IDs with IDs referencing the full phenotypes (one-to-one relationship between phenotypes and genes). In this case, the minimum distance found between any two phenes from those two phenotypes represents the distance between that pair of phenotypes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"ensemble\"></a>\n",
    "### Combining multiple distances measurements into summarizing distance values\n",
    "The purpose of this section is to iteratively train models on subsections of the dataset using simple regression or machine learning approaches to predict a value from zero to one indicating indicating how likely is it that two genes share atleast one of the specified groups in common. The information input to these models is the distance scores provided by each method in some set of all the methods used in this notebook. The purpose is to see whether or not a function of these similarity scores specifically trained to the task of predicting common groupings is better able to used the distance metric information to report a score for this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>from</th>\n",
       "      <th>to</th>\n",
       "      <th>Doc2Vec:Wikipedia,Size=300</th>\n",
       "      <th>Word2Vec:Wikipedia,Size=300,Mean</th>\n",
       "      <th>Word2Vec:Wikipedia,Size=300,Max</th>\n",
       "      <th>Doc2Vec Phenes:Wikipedia,Size=300</th>\n",
       "      <th>Word2Vec Phenes:Wikipedia,Size=300,Mean</th>\n",
       "      <th>Word2Vec Phenes:Wikipedia,Size=300,Max</th>\n",
       "      <th>NOBLE Coder:Precise,TFIDF</th>\n",
       "      <th>NOBLE Coder:Partial,TFIDF</th>\n",
       "      <th>NOBLE Coder Phenes:Precise,TFIDF</th>\n",
       "      <th>NOBLE Coder Phenes:Partial,TFIDF</th>\n",
       "      <th>Topic Models:NMF,Full,Topics=50</th>\n",
       "      <th>Topic Models:NMF,Full,Topics=100</th>\n",
       "      <th>Topic Models Phenes:NMF,Full,Topics=50</th>\n",
       "      <th>Topic Models Phenes:NMF,Full,Topics=100</th>\n",
       "      <th>Topic Models:LDA,Full,Topics=50</th>\n",
       "      <th>Topic Models:LDA,Full,Topics=100</th>\n",
       "      <th>Topic Models Phenes:LDA,Full,Topics=50</th>\n",
       "      <th>Topic Models Phenes:LDA,Full,Topics=100</th>\n",
       "      <th>N-Grams:Full,Words,1-grams,TFIDF</th>\n",
       "      <th>N-Grams:Full,Words,1-grams,2-grams,TFIDF</th>\n",
       "      <th>N-Grams Phenes:Full,Words,1-grams,TFIDF</th>\n",
       "      <th>N-Grams Phenes:Full,Words,1-grams,2-grams,TFIDF</th>\n",
       "      <th>N-Grams:Full,Nouns,Adjectives,1-grams</th>\n",
       "      <th>N-Grams:Linares_Pontes,Words,1-grams</th>\n",
       "      <th>N-Grams:Full,Precise_Annotations,Words,1-grams</th>\n",
       "      <th>N-Grams:Full,Partial_Annotations,Words,1-grams</th>\n",
       "      <th>N-Grams:Full,Plant Overrepresented Tokens,1-grams</th>\n",
       "      <th>N-Grams:Full,Bio Ontology Tokens,1-grams</th>\n",
       "      <th>N-Grams Phenes:Full,Nouns,Adjectives,1-grams</th>\n",
       "      <th>N-Grams Phenes:Linares_Pontes,Words,1-grams</th>\n",
       "      <th>N-Grams Phenes:Full,Precise_Annotations,Words,1-grams</th>\n",
       "      <th>N-Grams Phenes:Full,Partial_Annotations,Words,1-grams</th>\n",
       "      <th>N-Grams Phenes:Full,Plant Overrepresented Tokens,1-grams</th>\n",
       "      <th>N-Grams Phenes:Full,Bio Ontology Tokens,1-grams</th>\n",
       "      <th>GO:Union</th>\n",
       "      <th>PO:Union</th>\n",
       "      <th>GO:Maximum</th>\n",
       "      <th>PO:Maximum</th>\n",
       "      <th>Mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>1145</td>\n",
       "      <td>0.504560</td>\n",
       "      <td>0.503235</td>\n",
       "      <td>0.263459</td>\n",
       "      <td>0.414963</td>\n",
       "      <td>0.478481</td>\n",
       "      <td>0.288674</td>\n",
       "      <td>0.857573</td>\n",
       "      <td>0.928872</td>\n",
       "      <td>0.796288</td>\n",
       "      <td>0.900807</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.995888</td>\n",
       "      <td>0.980399</td>\n",
       "      <td>0.990102</td>\n",
       "      <td>9.668565e-01</td>\n",
       "      <td>0.981963</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.836855</td>\n",
       "      <td>0.566964</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.586272</td>\n",
       "      <td>0.428988</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.917046</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.646146</td>\n",
       "      <td>0.720441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100</td>\n",
       "      <td>4114</td>\n",
       "      <td>0.309927</td>\n",
       "      <td>0.260014</td>\n",
       "      <td>0.185656</td>\n",
       "      <td>0.276678</td>\n",
       "      <td>0.270105</td>\n",
       "      <td>0.180168</td>\n",
       "      <td>0.932399</td>\n",
       "      <td>0.962904</td>\n",
       "      <td>0.910822</td>\n",
       "      <td>0.957076</td>\n",
       "      <td>0.999785</td>\n",
       "      <td>0.999297</td>\n",
       "      <td>0.999941</td>\n",
       "      <td>0.999121</td>\n",
       "      <td>0.983668</td>\n",
       "      <td>0.991767</td>\n",
       "      <td>9.684386e-01</td>\n",
       "      <td>0.982268</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.977206</td>\n",
       "      <td>0.797835</td>\n",
       "      <td>0.406689</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.977423</td>\n",
       "      <td>0.741544</td>\n",
       "      <td>0.422529</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.656684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>231</td>\n",
       "      <td>0.435983</td>\n",
       "      <td>0.279231</td>\n",
       "      <td>0.185035</td>\n",
       "      <td>0.299665</td>\n",
       "      <td>0.271672</td>\n",
       "      <td>0.188429</td>\n",
       "      <td>0.872037</td>\n",
       "      <td>0.922563</td>\n",
       "      <td>0.817956</td>\n",
       "      <td>0.916699</td>\n",
       "      <td>0.733982</td>\n",
       "      <td>0.715878</td>\n",
       "      <td>0.797588</td>\n",
       "      <td>0.900100</td>\n",
       "      <td>0.977441</td>\n",
       "      <td>0.990781</td>\n",
       "      <td>9.554953e-01</td>\n",
       "      <td>0.971250</td>\n",
       "      <td>0.934402</td>\n",
       "      <td>0.969146</td>\n",
       "      <td>0.883653</td>\n",
       "      <td>0.928505</td>\n",
       "      <td>0.920096</td>\n",
       "      <td>0.880906</td>\n",
       "      <td>0.529131</td>\n",
       "      <td>0.490530</td>\n",
       "      <td>0.934402</td>\n",
       "      <td>0.915424</td>\n",
       "      <td>0.812598</td>\n",
       "      <td>0.863527</td>\n",
       "      <td>0.376286</td>\n",
       "      <td>0.415109</td>\n",
       "      <td>0.883653</td>\n",
       "      <td>0.853920</td>\n",
       "      <td>0.224368</td>\n",
       "      <td>0.700841</td>\n",
       "      <td>0.905412</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.392922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100</td>\n",
       "      <td>5244</td>\n",
       "      <td>0.551568</td>\n",
       "      <td>0.602756</td>\n",
       "      <td>0.363885</td>\n",
       "      <td>0.404959</td>\n",
       "      <td>0.607823</td>\n",
       "      <td>0.362408</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.958144</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.945128</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.990909</td>\n",
       "      <td>0.905914</td>\n",
       "      <td>0.976078</td>\n",
       "      <td>0.983010</td>\n",
       "      <td>9.529703e-01</td>\n",
       "      <td>0.974258</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.978320</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.897213</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.355641</td>\n",
       "      <td>0.629555</td>\n",
       "      <td>0.689286</td>\n",
       "      <td>0.476599</td>\n",
       "      <td>0.775899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100</td>\n",
       "      <td>733</td>\n",
       "      <td>0.508654</td>\n",
       "      <td>0.270065</td>\n",
       "      <td>0.181497</td>\n",
       "      <td>0.355532</td>\n",
       "      <td>0.293558</td>\n",
       "      <td>0.170425</td>\n",
       "      <td>0.893924</td>\n",
       "      <td>0.927862</td>\n",
       "      <td>0.797668</td>\n",
       "      <td>0.919038</td>\n",
       "      <td>0.999892</td>\n",
       "      <td>0.998867</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999008</td>\n",
       "      <td>0.974111</td>\n",
       "      <td>0.988849</td>\n",
       "      <td>9.546172e-01</td>\n",
       "      <td>0.971961</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.865899</td>\n",
       "      <td>0.796603</td>\n",
       "      <td>0.284657</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.850601</td>\n",
       "      <td>0.593352</td>\n",
       "      <td>0.247837</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.188509</td>\n",
       "      <td>0.575006</td>\n",
       "      <td>0.689286</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.604054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>100</td>\n",
       "      <td>3896</td>\n",
       "      <td>0.518026</td>\n",
       "      <td>0.536171</td>\n",
       "      <td>0.298879</td>\n",
       "      <td>0.428593</td>\n",
       "      <td>0.590710</td>\n",
       "      <td>0.391840</td>\n",
       "      <td>0.970234</td>\n",
       "      <td>0.972461</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.967205</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.976449</td>\n",
       "      <td>0.988082</td>\n",
       "      <td>9.620776e-01</td>\n",
       "      <td>0.961087</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.912374</td>\n",
       "      <td>0.338805</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.841140</td>\n",
       "      <td>0.310185</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.764766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>100</td>\n",
       "      <td>4572</td>\n",
       "      <td>0.498664</td>\n",
       "      <td>0.326860</td>\n",
       "      <td>0.179187</td>\n",
       "      <td>0.349483</td>\n",
       "      <td>0.341777</td>\n",
       "      <td>0.209361</td>\n",
       "      <td>0.948135</td>\n",
       "      <td>0.927444</td>\n",
       "      <td>0.939123</td>\n",
       "      <td>0.925689</td>\n",
       "      <td>0.998685</td>\n",
       "      <td>0.986242</td>\n",
       "      <td>0.988918</td>\n",
       "      <td>0.640430</td>\n",
       "      <td>0.982011</td>\n",
       "      <td>0.990924</td>\n",
       "      <td>9.532030e-01</td>\n",
       "      <td>0.978660</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.908057</td>\n",
       "      <td>0.713808</td>\n",
       "      <td>0.345801</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.899051</td>\n",
       "      <td>0.600257</td>\n",
       "      <td>0.263837</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.425165</td>\n",
       "      <td>0.556259</td>\n",
       "      <td>0.925314</td>\n",
       "      <td>0.476599</td>\n",
       "      <td>0.618412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>100</td>\n",
       "      <td>2823</td>\n",
       "      <td>0.542816</td>\n",
       "      <td>0.272979</td>\n",
       "      <td>0.187657</td>\n",
       "      <td>0.296875</td>\n",
       "      <td>0.278486</td>\n",
       "      <td>0.199103</td>\n",
       "      <td>0.887384</td>\n",
       "      <td>0.909117</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.885990</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.639737</td>\n",
       "      <td>0.740649</td>\n",
       "      <td>0.980833</td>\n",
       "      <td>0.990628</td>\n",
       "      <td>2.500710e-09</td>\n",
       "      <td>0.788591</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.970817</td>\n",
       "      <td>0.724138</td>\n",
       "      <td>0.247397</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.949335</td>\n",
       "      <td>0.548854</td>\n",
       "      <td>0.229812</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.580942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>100</td>\n",
       "      <td>1592</td>\n",
       "      <td>0.453901</td>\n",
       "      <td>0.438724</td>\n",
       "      <td>0.198668</td>\n",
       "      <td>0.296394</td>\n",
       "      <td>0.365019</td>\n",
       "      <td>0.222920</td>\n",
       "      <td>0.902751</td>\n",
       "      <td>0.926640</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.905401</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999490</td>\n",
       "      <td>0.984330</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.973381</td>\n",
       "      <td>0.991938</td>\n",
       "      <td>9.606524e-01</td>\n",
       "      <td>0.971783</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.945727</td>\n",
       "      <td>0.815585</td>\n",
       "      <td>0.329073</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.889008</td>\n",
       "      <td>0.732580</td>\n",
       "      <td>0.247194</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.215764</td>\n",
       "      <td>0.644082</td>\n",
       "      <td>0.488195</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.648037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>100</td>\n",
       "      <td>1185</td>\n",
       "      <td>0.437521</td>\n",
       "      <td>0.197340</td>\n",
       "      <td>0.151455</td>\n",
       "      <td>0.280486</td>\n",
       "      <td>0.232980</td>\n",
       "      <td>0.155569</td>\n",
       "      <td>0.901545</td>\n",
       "      <td>0.921714</td>\n",
       "      <td>0.654037</td>\n",
       "      <td>0.911570</td>\n",
       "      <td>0.995473</td>\n",
       "      <td>0.992384</td>\n",
       "      <td>0.375339</td>\n",
       "      <td>0.979698</td>\n",
       "      <td>0.983954</td>\n",
       "      <td>0.992425</td>\n",
       "      <td>9.599578e-01</td>\n",
       "      <td>0.970949</td>\n",
       "      <td>0.971604</td>\n",
       "      <td>0.987393</td>\n",
       "      <td>0.880267</td>\n",
       "      <td>0.948704</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.857459</td>\n",
       "      <td>0.699810</td>\n",
       "      <td>0.319292</td>\n",
       "      <td>0.971132</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.808575</td>\n",
       "      <td>0.420889</td>\n",
       "      <td>0.275842</td>\n",
       "      <td>0.854551</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.200531</td>\n",
       "      <td>0.796364</td>\n",
       "      <td>0.898161</td>\n",
       "      <td>0.538176</td>\n",
       "      <td>0.467105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>100</td>\n",
       "      <td>883</td>\n",
       "      <td>0.433015</td>\n",
       "      <td>0.601558</td>\n",
       "      <td>0.872109</td>\n",
       "      <td>0.345507</td>\n",
       "      <td>0.597342</td>\n",
       "      <td>0.807199</td>\n",
       "      <td>0.840931</td>\n",
       "      <td>0.933173</td>\n",
       "      <td>0.797668</td>\n",
       "      <td>0.922610</td>\n",
       "      <td>0.999966</td>\n",
       "      <td>0.999663</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.976885</td>\n",
       "      <td>0.988305</td>\n",
       "      <td>9.519369e-01</td>\n",
       "      <td>0.973318</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.889686</td>\n",
       "      <td>0.281991</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.714460</td>\n",
       "      <td>0.247837</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.297119</td>\n",
       "      <td>0.765555</td>\n",
       "      <td>0.918007</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.699790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>100</td>\n",
       "      <td>2456</td>\n",
       "      <td>0.506571</td>\n",
       "      <td>0.186860</td>\n",
       "      <td>0.160455</td>\n",
       "      <td>0.196499</td>\n",
       "      <td>0.194339</td>\n",
       "      <td>0.160468</td>\n",
       "      <td>0.885565</td>\n",
       "      <td>0.871551</td>\n",
       "      <td>0.635296</td>\n",
       "      <td>0.668224</td>\n",
       "      <td>0.768235</td>\n",
       "      <td>0.762891</td>\n",
       "      <td>0.685551</td>\n",
       "      <td>0.309989</td>\n",
       "      <td>0.987835</td>\n",
       "      <td>0.987893</td>\n",
       "      <td>9.538829e-01</td>\n",
       "      <td>0.713962</td>\n",
       "      <td>0.887148</td>\n",
       "      <td>0.937832</td>\n",
       "      <td>0.820744</td>\n",
       "      <td>0.906416</td>\n",
       "      <td>0.892741</td>\n",
       "      <td>0.778592</td>\n",
       "      <td>0.641168</td>\n",
       "      <td>0.268298</td>\n",
       "      <td>0.879809</td>\n",
       "      <td>0.859276</td>\n",
       "      <td>0.718486</td>\n",
       "      <td>0.784513</td>\n",
       "      <td>0.323591</td>\n",
       "      <td>0.215743</td>\n",
       "      <td>0.817136</td>\n",
       "      <td>0.794983</td>\n",
       "      <td>0.143607</td>\n",
       "      <td>0.642601</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.289605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>100</td>\n",
       "      <td>5326</td>\n",
       "      <td>0.490244</td>\n",
       "      <td>0.380940</td>\n",
       "      <td>0.186081</td>\n",
       "      <td>0.408533</td>\n",
       "      <td>0.426500</td>\n",
       "      <td>0.226843</td>\n",
       "      <td>0.896534</td>\n",
       "      <td>0.762814</td>\n",
       "      <td>0.820543</td>\n",
       "      <td>0.518491</td>\n",
       "      <td>0.918731</td>\n",
       "      <td>0.987538</td>\n",
       "      <td>0.866146</td>\n",
       "      <td>0.939288</td>\n",
       "      <td>0.978446</td>\n",
       "      <td>0.375235</td>\n",
       "      <td>9.540923e-01</td>\n",
       "      <td>0.967144</td>\n",
       "      <td>0.923487</td>\n",
       "      <td>0.969880</td>\n",
       "      <td>0.855463</td>\n",
       "      <td>0.937715</td>\n",
       "      <td>0.911106</td>\n",
       "      <td>0.915145</td>\n",
       "      <td>0.706214</td>\n",
       "      <td>0.257861</td>\n",
       "      <td>0.919181</td>\n",
       "      <td>0.909812</td>\n",
       "      <td>0.832597</td>\n",
       "      <td>0.838619</td>\n",
       "      <td>0.626924</td>\n",
       "      <td>0.214428</td>\n",
       "      <td>0.828453</td>\n",
       "      <td>0.812806</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.848694</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.404818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>100</td>\n",
       "      <td>1389</td>\n",
       "      <td>0.449655</td>\n",
       "      <td>0.173582</td>\n",
       "      <td>0.152193</td>\n",
       "      <td>0.190415</td>\n",
       "      <td>0.158163</td>\n",
       "      <td>0.123656</td>\n",
       "      <td>0.695581</td>\n",
       "      <td>0.822994</td>\n",
       "      <td>0.157983</td>\n",
       "      <td>0.388861</td>\n",
       "      <td>0.643811</td>\n",
       "      <td>0.472842</td>\n",
       "      <td>0.488442</td>\n",
       "      <td>0.177004</td>\n",
       "      <td>0.980936</td>\n",
       "      <td>0.988426</td>\n",
       "      <td>1.762766e-05</td>\n",
       "      <td>0.050712</td>\n",
       "      <td>0.809310</td>\n",
       "      <td>0.889343</td>\n",
       "      <td>0.293965</td>\n",
       "      <td>0.517576</td>\n",
       "      <td>0.851223</td>\n",
       "      <td>0.738997</td>\n",
       "      <td>0.534355</td>\n",
       "      <td>0.254799</td>\n",
       "      <td>0.803128</td>\n",
       "      <td>0.766201</td>\n",
       "      <td>0.388563</td>\n",
       "      <td>0.290308</td>\n",
       "      <td>0.130693</td>\n",
       "      <td>0.113132</td>\n",
       "      <td>0.293965</td>\n",
       "      <td>0.202365</td>\n",
       "      <td>0.134726</td>\n",
       "      <td>0.756770</td>\n",
       "      <td>0.557407</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.150919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>100</td>\n",
       "      <td>5153</td>\n",
       "      <td>0.498049</td>\n",
       "      <td>0.255375</td>\n",
       "      <td>0.205944</td>\n",
       "      <td>0.346341</td>\n",
       "      <td>0.248265</td>\n",
       "      <td>0.204870</td>\n",
       "      <td>0.907639</td>\n",
       "      <td>0.946790</td>\n",
       "      <td>0.714735</td>\n",
       "      <td>0.935742</td>\n",
       "      <td>0.999952</td>\n",
       "      <td>0.998964</td>\n",
       "      <td>0.946267</td>\n",
       "      <td>0.993401</td>\n",
       "      <td>0.982195</td>\n",
       "      <td>0.990205</td>\n",
       "      <td>9.602068e-01</td>\n",
       "      <td>0.971601</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.897559</td>\n",
       "      <td>0.648575</td>\n",
       "      <td>0.346042</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.869588</td>\n",
       "      <td>0.493623</td>\n",
       "      <td>0.301690</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.236706</td>\n",
       "      <td>0.725834</td>\n",
       "      <td>0.889163</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.603780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>100</td>\n",
       "      <td>1975</td>\n",
       "      <td>0.517766</td>\n",
       "      <td>0.246333</td>\n",
       "      <td>0.155104</td>\n",
       "      <td>0.365803</td>\n",
       "      <td>0.262292</td>\n",
       "      <td>0.171215</td>\n",
       "      <td>0.847666</td>\n",
       "      <td>0.844332</td>\n",
       "      <td>0.714735</td>\n",
       "      <td>0.735052</td>\n",
       "      <td>0.998707</td>\n",
       "      <td>0.991175</td>\n",
       "      <td>0.897693</td>\n",
       "      <td>0.943254</td>\n",
       "      <td>0.977903</td>\n",
       "      <td>0.993223</td>\n",
       "      <td>7.340050e-01</td>\n",
       "      <td>0.788591</td>\n",
       "      <td>0.977303</td>\n",
       "      <td>0.987493</td>\n",
       "      <td>0.930794</td>\n",
       "      <td>0.962515</td>\n",
       "      <td>0.966581</td>\n",
       "      <td>0.874183</td>\n",
       "      <td>0.652770</td>\n",
       "      <td>0.307714</td>\n",
       "      <td>0.976264</td>\n",
       "      <td>0.967525</td>\n",
       "      <td>0.894120</td>\n",
       "      <td>0.879221</td>\n",
       "      <td>0.386746</td>\n",
       "      <td>0.281545</td>\n",
       "      <td>0.924241</td>\n",
       "      <td>0.908044</td>\n",
       "      <td>0.185603</td>\n",
       "      <td>0.757168</td>\n",
       "      <td>0.839198</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.428290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>100</td>\n",
       "      <td>705</td>\n",
       "      <td>0.372423</td>\n",
       "      <td>0.466228</td>\n",
       "      <td>0.296158</td>\n",
       "      <td>0.355532</td>\n",
       "      <td>0.485242</td>\n",
       "      <td>0.402482</td>\n",
       "      <td>0.765789</td>\n",
       "      <td>0.937770</td>\n",
       "      <td>0.694703</td>\n",
       "      <td>0.920472</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>0.995581</td>\n",
       "      <td>0.986567</td>\n",
       "      <td>0.997620</td>\n",
       "      <td>0.980992</td>\n",
       "      <td>0.987018</td>\n",
       "      <td>9.519369e-01</td>\n",
       "      <td>0.973318</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.727823</td>\n",
       "      <td>0.278443</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.497310</td>\n",
       "      <td>0.247837</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.161334</td>\n",
       "      <td>0.755283</td>\n",
       "      <td>0.694804</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.632151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>100</td>\n",
       "      <td>2465</td>\n",
       "      <td>0.400593</td>\n",
       "      <td>0.496899</td>\n",
       "      <td>0.300016</td>\n",
       "      <td>0.359965</td>\n",
       "      <td>0.486943</td>\n",
       "      <td>0.300016</td>\n",
       "      <td>0.938961</td>\n",
       "      <td>0.966689</td>\n",
       "      <td>0.920880</td>\n",
       "      <td>0.955600</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.976880</td>\n",
       "      <td>0.988303</td>\n",
       "      <td>9.550776e-01</td>\n",
       "      <td>0.981918</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.957711</td>\n",
       "      <td>0.885079</td>\n",
       "      <td>0.981948</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.949175</td>\n",
       "      <td>0.827598</td>\n",
       "      <td>0.859332</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.231866</td>\n",
       "      <td>0.744921</td>\n",
       "      <td>0.919836</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.741689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>100</td>\n",
       "      <td>4826</td>\n",
       "      <td>0.455674</td>\n",
       "      <td>0.314752</td>\n",
       "      <td>0.164622</td>\n",
       "      <td>0.285976</td>\n",
       "      <td>0.263800</td>\n",
       "      <td>0.141633</td>\n",
       "      <td>0.862357</td>\n",
       "      <td>0.829606</td>\n",
       "      <td>0.686363</td>\n",
       "      <td>0.696630</td>\n",
       "      <td>0.821795</td>\n",
       "      <td>0.697329</td>\n",
       "      <td>0.349369</td>\n",
       "      <td>0.179964</td>\n",
       "      <td>0.987204</td>\n",
       "      <td>0.988050</td>\n",
       "      <td>9.478470e-01</td>\n",
       "      <td>0.967856</td>\n",
       "      <td>0.901601</td>\n",
       "      <td>0.952641</td>\n",
       "      <td>0.800605</td>\n",
       "      <td>0.915722</td>\n",
       "      <td>0.921890</td>\n",
       "      <td>0.843335</td>\n",
       "      <td>0.630609</td>\n",
       "      <td>0.228930</td>\n",
       "      <td>0.893790</td>\n",
       "      <td>0.867906</td>\n",
       "      <td>0.824654</td>\n",
       "      <td>0.740736</td>\n",
       "      <td>0.508417</td>\n",
       "      <td>0.181875</td>\n",
       "      <td>0.800605</td>\n",
       "      <td>0.774736</td>\n",
       "      <td>0.196729</td>\n",
       "      <td>0.753039</td>\n",
       "      <td>0.926500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.307623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>100</td>\n",
       "      <td>4361</td>\n",
       "      <td>0.245022</td>\n",
       "      <td>0.156215</td>\n",
       "      <td>0.192543</td>\n",
       "      <td>0.210180</td>\n",
       "      <td>0.221758</td>\n",
       "      <td>0.182364</td>\n",
       "      <td>0.786647</td>\n",
       "      <td>0.825674</td>\n",
       "      <td>0.721867</td>\n",
       "      <td>0.800733</td>\n",
       "      <td>0.760857</td>\n",
       "      <td>0.743708</td>\n",
       "      <td>0.612054</td>\n",
       "      <td>0.321660</td>\n",
       "      <td>0.977733</td>\n",
       "      <td>0.988820</td>\n",
       "      <td>9.693904e-01</td>\n",
       "      <td>0.983416</td>\n",
       "      <td>0.858266</td>\n",
       "      <td>0.944924</td>\n",
       "      <td>0.834894</td>\n",
       "      <td>0.933571</td>\n",
       "      <td>0.803079</td>\n",
       "      <td>0.691092</td>\n",
       "      <td>0.555945</td>\n",
       "      <td>0.308838</td>\n",
       "      <td>0.858266</td>\n",
       "      <td>0.831412</td>\n",
       "      <td>0.746720</td>\n",
       "      <td>0.598453</td>\n",
       "      <td>0.370800</td>\n",
       "      <td>0.266747</td>\n",
       "      <td>0.834894</td>\n",
       "      <td>0.813473</td>\n",
       "      <td>0.234463</td>\n",
       "      <td>0.688798</td>\n",
       "      <td>0.305225</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.281980</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    from    to  Doc2Vec:Wikipedia,Size=300  Word2Vec:Wikipedia,Size=300,Mean  Word2Vec:Wikipedia,Size=300,Max  Doc2Vec Phenes:Wikipedia,Size=300  Word2Vec Phenes:Wikipedia,Size=300,Mean  Word2Vec Phenes:Wikipedia,Size=300,Max  NOBLE Coder:Precise,TFIDF  NOBLE Coder:Partial,TFIDF  NOBLE Coder Phenes:Precise,TFIDF  NOBLE Coder Phenes:Partial,TFIDF  Topic Models:NMF,Full,Topics=50  Topic Models:NMF,Full,Topics=100  Topic Models Phenes:NMF,Full,Topics=50  Topic Models Phenes:NMF,Full,Topics=100  Topic Models:LDA,Full,Topics=50  Topic Models:LDA,Full,Topics=100  Topic Models Phenes:LDA,Full,Topics=50  Topic Models Phenes:LDA,Full,Topics=100  N-Grams:Full,Words,1-grams,TFIDF  N-Grams:Full,Words,1-grams,2-grams,TFIDF  N-Grams Phenes:Full,Words,1-grams,TFIDF  N-Grams Phenes:Full,Words,1-grams,2-grams,TFIDF  N-Grams:Full,Nouns,Adjectives,1-grams  N-Grams:Linares_Pontes,Words,1-grams  N-Grams:Full,Precise_Annotations,Words,1-grams  N-Grams:Full,Partial_Annotations,Words,1-grams  \\\n",
       "0    100  1145                    0.504560                          0.503235                         0.263459                           0.414963                                 0.478481                                0.288674                   0.857573                   0.928872                          0.796288                          0.900807                         1.000000                          1.000000                                1.000000                                 0.995888                         0.980399                          0.990102                            9.668565e-01                                 0.981963                          1.000000                                  1.000000                                 1.000000                                         1.000000                               1.000000                              1.000000                                        0.836855                                        0.566964   \n",
       "1    100  4114                    0.309927                          0.260014                         0.185656                           0.276678                                 0.270105                                0.180168                   0.932399                   0.962904                          0.910822                          0.957076                         0.999785                          0.999297                                0.999941                                 0.999121                         0.983668                          0.991767                            9.684386e-01                                 0.982268                          1.000000                                  1.000000                                 1.000000                                         1.000000                               1.000000                              0.977206                                        0.797835                                        0.406689   \n",
       "2    100   231                    0.435983                          0.279231                         0.185035                           0.299665                                 0.271672                                0.188429                   0.872037                   0.922563                          0.817956                          0.916699                         0.733982                          0.715878                                0.797588                                 0.900100                         0.977441                          0.990781                            9.554953e-01                                 0.971250                          0.934402                                  0.969146                                 0.883653                                         0.928505                               0.920096                              0.880906                                        0.529131                                        0.490530   \n",
       "3    100  5244                    0.551568                          0.602756                         0.363885                           0.404959                                 0.607823                                0.362408                   1.000000                   0.958144                          1.000000                          0.945128                         1.000000                          1.000000                                0.990909                                 0.905914                         0.976078                          0.983010                            9.529703e-01                                 0.974258                          1.000000                                  1.000000                                 1.000000                                         1.000000                               1.000000                              1.000000                                        1.000000                                        0.978320   \n",
       "4    100   733                    0.508654                          0.270065                         0.181497                           0.355532                                 0.293558                                0.170425                   0.893924                   0.927862                          0.797668                          0.919038                         0.999892                          0.998867                                1.000000                                 0.999008                         0.974111                          0.988849                            9.546172e-01                                 0.971961                          1.000000                                  1.000000                                 1.000000                                         1.000000                               1.000000                              0.865899                                        0.796603                                        0.284657   \n",
       "5    100  3896                    0.518026                          0.536171                         0.298879                           0.428593                                 0.590710                                0.391840                   0.970234                   0.972461                          1.000000                          0.967205                         1.000000                          1.000000                                1.000000                                 1.000000                         0.976449                          0.988082                            9.620776e-01                                 0.961087                          1.000000                                  1.000000                                 1.000000                                         1.000000                               1.000000                              1.000000                                        0.912374                                        0.338805   \n",
       "6    100  4572                    0.498664                          0.326860                         0.179187                           0.349483                                 0.341777                                0.209361                   0.948135                   0.927444                          0.939123                          0.925689                         0.998685                          0.986242                                0.988918                                 0.640430                         0.982011                          0.990924                            9.532030e-01                                 0.978660                          1.000000                                  1.000000                                 1.000000                                         1.000000                               1.000000                              0.908057                                        0.713808                                        0.345801   \n",
       "7    100  2823                    0.542816                          0.272979                         0.187657                           0.296875                                 0.278486                                0.199103                   0.887384                   0.909117                          1.000000                          0.885990                         1.000000                          1.000000                                0.639737                                 0.740649                         0.980833                          0.990628                            2.500710e-09                                 0.788591                          1.000000                                  1.000000                                 1.000000                                         1.000000                               1.000000                              0.970817                                        0.724138                                        0.247397   \n",
       "8    100  1592                    0.453901                          0.438724                         0.198668                           0.296394                                 0.365019                                0.222920                   0.902751                   0.926640                          1.000000                          0.905401                         1.000000                          0.999490                                0.984330                                 1.000000                         0.973381                          0.991938                            9.606524e-01                                 0.971783                          1.000000                                  1.000000                                 1.000000                                         1.000000                               1.000000                              0.945727                                        0.815585                                        0.329073   \n",
       "9    100  1185                    0.437521                          0.197340                         0.151455                           0.280486                                 0.232980                                0.155569                   0.901545                   0.921714                          0.654037                          0.911570                         0.995473                          0.992384                                0.375339                                 0.979698                         0.983954                          0.992425                            9.599578e-01                                 0.970949                          0.971604                                  0.987393                                 0.880267                                         0.948704                               1.000000                              0.857459                                        0.699810                                        0.319292   \n",
       "10   100   883                    0.433015                          0.601558                         0.872109                           0.345507                                 0.597342                                0.807199                   0.840931                   0.933173                          0.797668                          0.922610                         0.999966                          0.999663                                1.000000                                 1.000000                         0.976885                          0.988305                            9.519369e-01                                 0.973318                          1.000000                                  1.000000                                 1.000000                                         1.000000                               1.000000                              1.000000                                        0.889686                                        0.281991   \n",
       "11   100  2456                    0.506571                          0.186860                         0.160455                           0.196499                                 0.194339                                0.160468                   0.885565                   0.871551                          0.635296                          0.668224                         0.768235                          0.762891                                0.685551                                 0.309989                         0.987835                          0.987893                            9.538829e-01                                 0.713962                          0.887148                                  0.937832                                 0.820744                                         0.906416                               0.892741                              0.778592                                        0.641168                                        0.268298   \n",
       "12   100  5326                    0.490244                          0.380940                         0.186081                           0.408533                                 0.426500                                0.226843                   0.896534                   0.762814                          0.820543                          0.518491                         0.918731                          0.987538                                0.866146                                 0.939288                         0.978446                          0.375235                            9.540923e-01                                 0.967144                          0.923487                                  0.969880                                 0.855463                                         0.937715                               0.911106                              0.915145                                        0.706214                                        0.257861   \n",
       "13   100  1389                    0.449655                          0.173582                         0.152193                           0.190415                                 0.158163                                0.123656                   0.695581                   0.822994                          0.157983                          0.388861                         0.643811                          0.472842                                0.488442                                 0.177004                         0.980936                          0.988426                            1.762766e-05                                 0.050712                          0.809310                                  0.889343                                 0.293965                                         0.517576                               0.851223                              0.738997                                        0.534355                                        0.254799   \n",
       "14   100  5153                    0.498049                          0.255375                         0.205944                           0.346341                                 0.248265                                0.204870                   0.907639                   0.946790                          0.714735                          0.935742                         0.999952                          0.998964                                0.946267                                 0.993401                         0.982195                          0.990205                            9.602068e-01                                 0.971601                          1.000000                                  1.000000                                 1.000000                                         1.000000                               1.000000                              0.897559                                        0.648575                                        0.346042   \n",
       "15   100  1975                    0.517766                          0.246333                         0.155104                           0.365803                                 0.262292                                0.171215                   0.847666                   0.844332                          0.714735                          0.735052                         0.998707                          0.991175                                0.897693                                 0.943254                         0.977903                          0.993223                            7.340050e-01                                 0.788591                          0.977303                                  0.987493                                 0.930794                                         0.962515                               0.966581                              0.874183                                        0.652770                                        0.307714   \n",
       "16   100   705                    0.372423                          0.466228                         0.296158                           0.355532                                 0.485242                                0.402482                   0.765789                   0.937770                          0.694703                          0.920472                         0.999997                          0.995581                                0.986567                                 0.997620                         0.980992                          0.987018                            9.519369e-01                                 0.973318                          1.000000                                  1.000000                                 1.000000                                         1.000000                               1.000000                              1.000000                                        0.727823                                        0.278443   \n",
       "17   100  2465                    0.400593                          0.496899                         0.300016                           0.359965                                 0.486943                                0.300016                   0.938961                   0.966689                          0.920880                          0.955600                         1.000000                          1.000000                                1.000000                                 1.000000                         0.976880                          0.988303                            9.550776e-01                                 0.981918                          1.000000                                  1.000000                                 1.000000                                         1.000000                               1.000000                              0.957711                                        0.885079                                        0.981948   \n",
       "18   100  4826                    0.455674                          0.314752                         0.164622                           0.285976                                 0.263800                                0.141633                   0.862357                   0.829606                          0.686363                          0.696630                         0.821795                          0.697329                                0.349369                                 0.179964                         0.987204                          0.988050                            9.478470e-01                                 0.967856                          0.901601                                  0.952641                                 0.800605                                         0.915722                               0.921890                              0.843335                                        0.630609                                        0.228930   \n",
       "19   100  4361                    0.245022                          0.156215                         0.192543                           0.210180                                 0.221758                                0.182364                   0.786647                   0.825674                          0.721867                          0.800733                         0.760857                          0.743708                                0.612054                                 0.321660                         0.977733                          0.988820                            9.693904e-01                                 0.983416                          0.858266                                  0.944924                                 0.834894                                         0.933571                               0.803079                              0.691092                                        0.555945                                        0.308838   \n",
       "\n",
       "    N-Grams:Full,Plant Overrepresented Tokens,1-grams  N-Grams:Full,Bio Ontology Tokens,1-grams  N-Grams Phenes:Full,Nouns,Adjectives,1-grams  N-Grams Phenes:Linares_Pontes,Words,1-grams  N-Grams Phenes:Full,Precise_Annotations,Words,1-grams  N-Grams Phenes:Full,Partial_Annotations,Words,1-grams  N-Grams Phenes:Full,Plant Overrepresented Tokens,1-grams  N-Grams Phenes:Full,Bio Ontology Tokens,1-grams  GO:Union  PO:Union  GO:Maximum  PO:Maximum      Mean  \n",
       "0                                            1.000000                                  1.000000                                      1.000000                                     1.000000                                           0.586272                                               0.428988                                               1.000000                                                1.000000  1.000000  0.917046    1.000000    0.646146  0.720441  \n",
       "1                                            1.000000                                  1.000000                                      1.000000                                     0.977423                                           0.741544                                               0.422529                                               1.000000                                                1.000000  1.000000  1.000000    1.000000    1.000000  0.656684  \n",
       "2                                            0.934402                                  0.915424                                      0.812598                                     0.863527                                           0.376286                                               0.415109                                               0.883653                                                0.853920  0.224368  0.700841    0.905412    0.000000  0.392922  \n",
       "3                                            1.000000                                  1.000000                                      1.000000                                     1.000000                                           1.000000                                               0.897213                                               1.000000                                                1.000000  0.355641  0.629555    0.689286    0.476599  0.775899  \n",
       "4                                            1.000000                                  1.000000                                      1.000000                                     0.850601                                           0.593352                                               0.247837                                               1.000000                                                1.000000  0.188509  0.575006    0.689286    0.000000  0.604054  \n",
       "5                                            1.000000                                  1.000000                                      1.000000                                     1.000000                                           0.841140                                               0.310185                                               1.000000                                                1.000000  1.000000  1.000000    1.000000    1.000000  0.764766  \n",
       "6                                            1.000000                                  1.000000                                      1.000000                                     0.899051                                           0.600257                                               0.263837                                               1.000000                                                1.000000  0.425165  0.556259    0.925314    0.476599  0.618412  \n",
       "7                                            1.000000                                  1.000000                                      1.000000                                     0.949335                                           0.548854                                               0.229812                                               1.000000                                                1.000000  1.000000  1.000000    1.000000    1.000000  0.580942  \n",
       "8                                            1.000000                                  1.000000                                      1.000000                                     0.889008                                           0.732580                                               0.247194                                               1.000000                                                1.000000  0.215764  0.644082    0.488195    0.000000  0.648037  \n",
       "9                                            0.971132                                  1.000000                                      1.000000                                     0.808575                                           0.420889                                               0.275842                                               0.854551                                                1.000000  0.200531  0.796364    0.898161    0.538176  0.467105  \n",
       "10                                           1.000000                                  1.000000                                      1.000000                                     1.000000                                           0.714460                                               0.247837                                               1.000000                                                1.000000  0.297119  0.765555    0.918007    0.000000  0.699790  \n",
       "11                                           0.879809                                  0.859276                                      0.718486                                     0.784513                                           0.323591                                               0.215743                                               0.817136                                                0.794983  0.143607  0.642601    0.000000    0.000000  0.289605  \n",
       "12                                           0.919181                                  0.909812                                      0.832597                                     0.838619                                           0.626924                                               0.214428                                               0.828453                                                0.812806  1.000000  0.848694    1.000000    0.000000  0.404818  \n",
       "13                                           0.803128                                  0.766201                                      0.388563                                     0.290308                                           0.130693                                               0.113132                                               0.293965                                                0.202365  0.134726  0.756770    0.557407    0.000000  0.150919  \n",
       "14                                           1.000000                                  1.000000                                      1.000000                                     0.869588                                           0.493623                                               0.301690                                               1.000000                                                1.000000  0.236706  0.725834    0.889163    0.000000  0.603780  \n",
       "15                                           0.976264                                  0.967525                                      0.894120                                     0.879221                                           0.386746                                               0.281545                                               0.924241                                                0.908044  0.185603  0.757168    0.839198    0.000000  0.428290  \n",
       "16                                           1.000000                                  1.000000                                      1.000000                                     1.000000                                           0.497310                                               0.247837                                               1.000000                                                1.000000  0.161334  0.755283    0.694804    0.000000  0.632151  \n",
       "17                                           1.000000                                  1.000000                                      1.000000                                     0.949175                                           0.827598                                               0.859332                                               1.000000                                                1.000000  0.231866  0.744921    0.919836    0.000000  0.741689  \n",
       "18                                           0.893790                                  0.867906                                      0.824654                                     0.740736                                           0.508417                                               0.181875                                               0.800605                                                0.774736  0.196729  0.753039    0.926500    0.000000  0.307623  \n",
       "19                                           0.858266                                  0.831412                                      0.746720                                     0.598453                                           0.370800                                               0.266747                                               0.834894                                                0.813473  0.234463  0.688798    0.305225    0.000000  0.281980  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the average distance percentile as a means of combining multiple scores.\n",
    "name = \"Mean\"\n",
    "names_to_use_for_mean = [name for name in names if (\"GO:\" not in name) and (\"PO:\" not in name)]\n",
    "df[name] = df[names_to_use_for_mean].rank(pct=True).mean(axis=1)\n",
    "names.append(name)\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc2Vec:Wikipedia,Size=300\n",
      "Word2Vec:Wikipedia,Size=300,Mean\n",
      "Word2Vec:Wikipedia,Size=300,Max\n",
      "Doc2Vec Phenes:Wikipedia,Size=300\n",
      "Word2Vec Phenes:Wikipedia,Size=300,Mean\n",
      "Word2Vec Phenes:Wikipedia,Size=300,Max\n",
      "NOBLE Coder:Precise,TFIDF\n",
      "NOBLE Coder:Partial,TFIDF\n",
      "NOBLE Coder Phenes:Precise,TFIDF\n",
      "NOBLE Coder Phenes:Partial,TFIDF\n",
      "Topic Models:NMF,Full,Topics=50\n",
      "Topic Models:NMF,Full,Topics=100\n",
      "Topic Models Phenes:NMF,Full,Topics=50\n",
      "Topic Models Phenes:NMF,Full,Topics=100\n",
      "Topic Models:LDA,Full,Topics=50\n",
      "Topic Models:LDA,Full,Topics=100\n",
      "Topic Models Phenes:LDA,Full,Topics=50\n",
      "Topic Models Phenes:LDA,Full,Topics=100\n",
      "N-Grams:Full,Words,1-grams,TFIDF\n",
      "N-Grams:Full,Words,1-grams,2-grams,TFIDF\n",
      "N-Grams Phenes:Full,Words,1-grams,TFIDF\n",
      "N-Grams Phenes:Full,Words,1-grams,2-grams,TFIDF\n",
      "N-Grams:Full,Nouns,Adjectives,1-grams\n",
      "N-Grams:Linares_Pontes,Words,1-grams\n",
      "N-Grams:Full,Precise_Annotations,Words,1-grams\n",
      "N-Grams:Full,Partial_Annotations,Words,1-grams\n",
      "N-Grams:Full,Plant Overrepresented Tokens,1-grams\n",
      "N-Grams:Full,Bio Ontology Tokens,1-grams\n",
      "N-Grams Phenes:Full,Nouns,Adjectives,1-grams\n",
      "N-Grams Phenes:Linares_Pontes,Words,1-grams\n",
      "N-Grams Phenes:Full,Precise_Annotations,Words,1-grams\n",
      "N-Grams Phenes:Full,Partial_Annotations,Words,1-grams\n",
      "N-Grams Phenes:Full,Plant Overrepresented Tokens,1-grams\n",
      "N-Grams Phenes:Full,Bio Ontology Tokens,1-grams\n",
      "GO:Union\n",
      "PO:Union\n",
      "GO:Maximum\n",
      "PO:Maximum\n",
      "Mean\n"
     ]
    }
   ],
   "source": [
    "# Normalizing all of the array representations of the graphs so they can be combined. Then this version of the arrays\n",
    "# should be used by any other cells that need all of the arrays, rather than the arrays accessed from the graph\n",
    "# objects. This is necessary for this analysis because the distances matrices created and put in the graph objects use\n",
    "# IDs that don't actually reference the genes like the IDs used as nodes in the edgelist dataframe do, they reference \n",
    "# other types of subsets of that data which are smaller for that processing step. This section is included just to \n",
    "# produce a standardized list of arrays which exactly represent the data in the edgelist dataframe. It is redundant,\n",
    "# and could be removed later if necessary for memory constraints, but it is useful to be able to reference this\n",
    "# information sometimes using numpy instead of pandas only.\n",
    "\n",
    "name_to_array = {}\n",
    "ids = dataset.get_ids()\n",
    "n = len(ids)\n",
    "id_to_array_index = {i:idx for idx,i in enumerate(ids)}\n",
    "array_index_to_id = {idx:i for i,idx in id_to_array_index.items()}\n",
    "for name in names:\n",
    "    print(name)\n",
    "    idx = list(df.columns).index(name)+1\n",
    "    arr = np.ones((n, n))\n",
    "    for row in df.itertuples():\n",
    "        arr[id_to_array_index[row[1]]][id_to_array_index[row[2]]] = row[idx]\n",
    "        arr[id_to_array_index[row[2]]][id_to_array_index[row[1]]] = row[idx]\n",
    "    np.fill_diagonal(arr, 0.000) \n",
    "    name_to_array[name] = arr    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding correlations between human and computational approaches for hand-picked phenotype pairs\n",
    "This is only meant to be run in the context of the notebook, and should never be run automatically in the script. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if NOTEBOOK:\n",
    "    small_table = defaultdict(dict)\n",
    "    for name in names:\n",
    "        values = []\n",
    "        scores = []\n",
    "        for tup,score in pair_to_score.items():\n",
    "            i = id_to_array_index[tup[0]]\n",
    "            j = id_to_array_index[tup[1]]\n",
    "            value = 1 - name_to_array[name][i,j]\n",
    "            values.append(value)\n",
    "            scores.append(score)\n",
    "        rho,pval = spearmanr(values,scores)\n",
    "        small_table[name] = {\"rho\":rho,\"pval\":pval}\n",
    "    pd.DataFrame(small_table).transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"part_5\"></a>\n",
    "# Part 5. Biological Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>from</th>\n",
       "      <th>to</th>\n",
       "      <th>Doc2Vec:Wikipedia,Size=300</th>\n",
       "      <th>Word2Vec:Wikipedia,Size=300,Mean</th>\n",
       "      <th>Word2Vec:Wikipedia,Size=300,Max</th>\n",
       "      <th>Doc2Vec Phenes:Wikipedia,Size=300</th>\n",
       "      <th>Word2Vec Phenes:Wikipedia,Size=300,Mean</th>\n",
       "      <th>Word2Vec Phenes:Wikipedia,Size=300,Max</th>\n",
       "      <th>NOBLE Coder:Precise,TFIDF</th>\n",
       "      <th>NOBLE Coder:Partial,TFIDF</th>\n",
       "      <th>NOBLE Coder Phenes:Precise,TFIDF</th>\n",
       "      <th>NOBLE Coder Phenes:Partial,TFIDF</th>\n",
       "      <th>Topic Models:NMF,Full,Topics=50</th>\n",
       "      <th>Topic Models:NMF,Full,Topics=100</th>\n",
       "      <th>Topic Models Phenes:NMF,Full,Topics=50</th>\n",
       "      <th>Topic Models Phenes:NMF,Full,Topics=100</th>\n",
       "      <th>Topic Models:LDA,Full,Topics=50</th>\n",
       "      <th>Topic Models:LDA,Full,Topics=100</th>\n",
       "      <th>Topic Models Phenes:LDA,Full,Topics=50</th>\n",
       "      <th>Topic Models Phenes:LDA,Full,Topics=100</th>\n",
       "      <th>N-Grams:Full,Words,1-grams,TFIDF</th>\n",
       "      <th>N-Grams:Full,Words,1-grams,2-grams,TFIDF</th>\n",
       "      <th>N-Grams Phenes:Full,Words,1-grams,TFIDF</th>\n",
       "      <th>N-Grams Phenes:Full,Words,1-grams,2-grams,TFIDF</th>\n",
       "      <th>N-Grams:Full,Nouns,Adjectives,1-grams</th>\n",
       "      <th>N-Grams:Linares_Pontes,Words,1-grams</th>\n",
       "      <th>N-Grams:Full,Precise_Annotations,Words,1-grams</th>\n",
       "      <th>N-Grams:Full,Partial_Annotations,Words,1-grams</th>\n",
       "      <th>N-Grams:Full,Plant Overrepresented Tokens,1-grams</th>\n",
       "      <th>N-Grams:Full,Bio Ontology Tokens,1-grams</th>\n",
       "      <th>N-Grams Phenes:Full,Nouns,Adjectives,1-grams</th>\n",
       "      <th>N-Grams Phenes:Linares_Pontes,Words,1-grams</th>\n",
       "      <th>N-Grams Phenes:Full,Precise_Annotations,Words,1-grams</th>\n",
       "      <th>N-Grams Phenes:Full,Partial_Annotations,Words,1-grams</th>\n",
       "      <th>N-Grams Phenes:Full,Plant Overrepresented Tokens,1-grams</th>\n",
       "      <th>N-Grams Phenes:Full,Bio Ontology Tokens,1-grams</th>\n",
       "      <th>GO:Union</th>\n",
       "      <th>PO:Union</th>\n",
       "      <th>GO:Maximum</th>\n",
       "      <th>PO:Maximum</th>\n",
       "      <th>Mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>1145</td>\n",
       "      <td>0.504560</td>\n",
       "      <td>0.503235</td>\n",
       "      <td>0.263459</td>\n",
       "      <td>0.414963</td>\n",
       "      <td>0.478481</td>\n",
       "      <td>0.288674</td>\n",
       "      <td>0.857573</td>\n",
       "      <td>0.928872</td>\n",
       "      <td>0.796288</td>\n",
       "      <td>0.900807</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.995888</td>\n",
       "      <td>0.980399</td>\n",
       "      <td>0.990102</td>\n",
       "      <td>9.668565e-01</td>\n",
       "      <td>0.981963</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.836855</td>\n",
       "      <td>0.566964</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.586272</td>\n",
       "      <td>0.428988</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.917046</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.646146</td>\n",
       "      <td>0.720441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100</td>\n",
       "      <td>4114</td>\n",
       "      <td>0.309927</td>\n",
       "      <td>0.260014</td>\n",
       "      <td>0.185656</td>\n",
       "      <td>0.276678</td>\n",
       "      <td>0.270105</td>\n",
       "      <td>0.180168</td>\n",
       "      <td>0.932399</td>\n",
       "      <td>0.962904</td>\n",
       "      <td>0.910822</td>\n",
       "      <td>0.957076</td>\n",
       "      <td>0.999785</td>\n",
       "      <td>0.999297</td>\n",
       "      <td>0.999941</td>\n",
       "      <td>0.999121</td>\n",
       "      <td>0.983668</td>\n",
       "      <td>0.991767</td>\n",
       "      <td>9.684386e-01</td>\n",
       "      <td>0.982268</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.977206</td>\n",
       "      <td>0.797835</td>\n",
       "      <td>0.406689</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.977423</td>\n",
       "      <td>0.741544</td>\n",
       "      <td>0.422529</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.656684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>231</td>\n",
       "      <td>0.435983</td>\n",
       "      <td>0.279231</td>\n",
       "      <td>0.185035</td>\n",
       "      <td>0.299665</td>\n",
       "      <td>0.271672</td>\n",
       "      <td>0.188429</td>\n",
       "      <td>0.872037</td>\n",
       "      <td>0.922563</td>\n",
       "      <td>0.817956</td>\n",
       "      <td>0.916699</td>\n",
       "      <td>0.733982</td>\n",
       "      <td>0.715878</td>\n",
       "      <td>0.797588</td>\n",
       "      <td>0.900100</td>\n",
       "      <td>0.977441</td>\n",
       "      <td>0.990781</td>\n",
       "      <td>9.554953e-01</td>\n",
       "      <td>0.971250</td>\n",
       "      <td>0.934402</td>\n",
       "      <td>0.969146</td>\n",
       "      <td>0.883653</td>\n",
       "      <td>0.928505</td>\n",
       "      <td>0.920096</td>\n",
       "      <td>0.880906</td>\n",
       "      <td>0.529131</td>\n",
       "      <td>0.490530</td>\n",
       "      <td>0.934402</td>\n",
       "      <td>0.915424</td>\n",
       "      <td>0.812598</td>\n",
       "      <td>0.863527</td>\n",
       "      <td>0.376286</td>\n",
       "      <td>0.415109</td>\n",
       "      <td>0.883653</td>\n",
       "      <td>0.853920</td>\n",
       "      <td>0.224368</td>\n",
       "      <td>0.700841</td>\n",
       "      <td>0.905412</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.392922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100</td>\n",
       "      <td>5244</td>\n",
       "      <td>0.551568</td>\n",
       "      <td>0.602756</td>\n",
       "      <td>0.363885</td>\n",
       "      <td>0.404959</td>\n",
       "      <td>0.607823</td>\n",
       "      <td>0.362408</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.958144</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.945128</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.990909</td>\n",
       "      <td>0.905914</td>\n",
       "      <td>0.976078</td>\n",
       "      <td>0.983010</td>\n",
       "      <td>9.529703e-01</td>\n",
       "      <td>0.974258</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.978320</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.897213</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.355641</td>\n",
       "      <td>0.629555</td>\n",
       "      <td>0.689286</td>\n",
       "      <td>0.476599</td>\n",
       "      <td>0.775899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100</td>\n",
       "      <td>733</td>\n",
       "      <td>0.508654</td>\n",
       "      <td>0.270065</td>\n",
       "      <td>0.181497</td>\n",
       "      <td>0.355532</td>\n",
       "      <td>0.293558</td>\n",
       "      <td>0.170425</td>\n",
       "      <td>0.893924</td>\n",
       "      <td>0.927862</td>\n",
       "      <td>0.797668</td>\n",
       "      <td>0.919038</td>\n",
       "      <td>0.999892</td>\n",
       "      <td>0.998867</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999008</td>\n",
       "      <td>0.974111</td>\n",
       "      <td>0.988849</td>\n",
       "      <td>9.546172e-01</td>\n",
       "      <td>0.971961</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.865899</td>\n",
       "      <td>0.796603</td>\n",
       "      <td>0.284657</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.850601</td>\n",
       "      <td>0.593352</td>\n",
       "      <td>0.247837</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.188509</td>\n",
       "      <td>0.575006</td>\n",
       "      <td>0.689286</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.604054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>100</td>\n",
       "      <td>3896</td>\n",
       "      <td>0.518026</td>\n",
       "      <td>0.536171</td>\n",
       "      <td>0.298879</td>\n",
       "      <td>0.428593</td>\n",
       "      <td>0.590710</td>\n",
       "      <td>0.391840</td>\n",
       "      <td>0.970234</td>\n",
       "      <td>0.972461</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.967205</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.976449</td>\n",
       "      <td>0.988082</td>\n",
       "      <td>9.620776e-01</td>\n",
       "      <td>0.961087</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.912374</td>\n",
       "      <td>0.338805</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.841140</td>\n",
       "      <td>0.310185</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.764766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>100</td>\n",
       "      <td>4572</td>\n",
       "      <td>0.498664</td>\n",
       "      <td>0.326860</td>\n",
       "      <td>0.179187</td>\n",
       "      <td>0.349483</td>\n",
       "      <td>0.341777</td>\n",
       "      <td>0.209361</td>\n",
       "      <td>0.948135</td>\n",
       "      <td>0.927444</td>\n",
       "      <td>0.939123</td>\n",
       "      <td>0.925689</td>\n",
       "      <td>0.998685</td>\n",
       "      <td>0.986242</td>\n",
       "      <td>0.988918</td>\n",
       "      <td>0.640430</td>\n",
       "      <td>0.982011</td>\n",
       "      <td>0.990924</td>\n",
       "      <td>9.532030e-01</td>\n",
       "      <td>0.978660</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.908057</td>\n",
       "      <td>0.713808</td>\n",
       "      <td>0.345801</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.899051</td>\n",
       "      <td>0.600257</td>\n",
       "      <td>0.263837</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.425165</td>\n",
       "      <td>0.556259</td>\n",
       "      <td>0.925314</td>\n",
       "      <td>0.476599</td>\n",
       "      <td>0.618412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>100</td>\n",
       "      <td>2823</td>\n",
       "      <td>0.542816</td>\n",
       "      <td>0.272979</td>\n",
       "      <td>0.187657</td>\n",
       "      <td>0.296875</td>\n",
       "      <td>0.278486</td>\n",
       "      <td>0.199103</td>\n",
       "      <td>0.887384</td>\n",
       "      <td>0.909117</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.885990</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.639737</td>\n",
       "      <td>0.740649</td>\n",
       "      <td>0.980833</td>\n",
       "      <td>0.990628</td>\n",
       "      <td>2.500710e-09</td>\n",
       "      <td>0.788591</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.970817</td>\n",
       "      <td>0.724138</td>\n",
       "      <td>0.247397</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.949335</td>\n",
       "      <td>0.548854</td>\n",
       "      <td>0.229812</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.580942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>100</td>\n",
       "      <td>1592</td>\n",
       "      <td>0.453901</td>\n",
       "      <td>0.438724</td>\n",
       "      <td>0.198668</td>\n",
       "      <td>0.296394</td>\n",
       "      <td>0.365019</td>\n",
       "      <td>0.222920</td>\n",
       "      <td>0.902751</td>\n",
       "      <td>0.926640</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.905401</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999490</td>\n",
       "      <td>0.984330</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.973381</td>\n",
       "      <td>0.991938</td>\n",
       "      <td>9.606524e-01</td>\n",
       "      <td>0.971783</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.945727</td>\n",
       "      <td>0.815585</td>\n",
       "      <td>0.329073</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.889008</td>\n",
       "      <td>0.732580</td>\n",
       "      <td>0.247194</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.215764</td>\n",
       "      <td>0.644082</td>\n",
       "      <td>0.488195</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.648037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>100</td>\n",
       "      <td>1185</td>\n",
       "      <td>0.437521</td>\n",
       "      <td>0.197340</td>\n",
       "      <td>0.151455</td>\n",
       "      <td>0.280486</td>\n",
       "      <td>0.232980</td>\n",
       "      <td>0.155569</td>\n",
       "      <td>0.901545</td>\n",
       "      <td>0.921714</td>\n",
       "      <td>0.654037</td>\n",
       "      <td>0.911570</td>\n",
       "      <td>0.995473</td>\n",
       "      <td>0.992384</td>\n",
       "      <td>0.375339</td>\n",
       "      <td>0.979698</td>\n",
       "      <td>0.983954</td>\n",
       "      <td>0.992425</td>\n",
       "      <td>9.599578e-01</td>\n",
       "      <td>0.970949</td>\n",
       "      <td>0.971604</td>\n",
       "      <td>0.987393</td>\n",
       "      <td>0.880267</td>\n",
       "      <td>0.948704</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.857459</td>\n",
       "      <td>0.699810</td>\n",
       "      <td>0.319292</td>\n",
       "      <td>0.971132</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.808575</td>\n",
       "      <td>0.420889</td>\n",
       "      <td>0.275842</td>\n",
       "      <td>0.854551</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.200531</td>\n",
       "      <td>0.796364</td>\n",
       "      <td>0.898161</td>\n",
       "      <td>0.538176</td>\n",
       "      <td>0.467105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>100</td>\n",
       "      <td>883</td>\n",
       "      <td>0.433015</td>\n",
       "      <td>0.601558</td>\n",
       "      <td>0.872109</td>\n",
       "      <td>0.345507</td>\n",
       "      <td>0.597342</td>\n",
       "      <td>0.807199</td>\n",
       "      <td>0.840931</td>\n",
       "      <td>0.933173</td>\n",
       "      <td>0.797668</td>\n",
       "      <td>0.922610</td>\n",
       "      <td>0.999966</td>\n",
       "      <td>0.999663</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.976885</td>\n",
       "      <td>0.988305</td>\n",
       "      <td>9.519369e-01</td>\n",
       "      <td>0.973318</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.889686</td>\n",
       "      <td>0.281991</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.714460</td>\n",
       "      <td>0.247837</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.297119</td>\n",
       "      <td>0.765555</td>\n",
       "      <td>0.918007</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.699790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>100</td>\n",
       "      <td>2456</td>\n",
       "      <td>0.506571</td>\n",
       "      <td>0.186860</td>\n",
       "      <td>0.160455</td>\n",
       "      <td>0.196499</td>\n",
       "      <td>0.194339</td>\n",
       "      <td>0.160468</td>\n",
       "      <td>0.885565</td>\n",
       "      <td>0.871551</td>\n",
       "      <td>0.635296</td>\n",
       "      <td>0.668224</td>\n",
       "      <td>0.768235</td>\n",
       "      <td>0.762891</td>\n",
       "      <td>0.685551</td>\n",
       "      <td>0.309989</td>\n",
       "      <td>0.987835</td>\n",
       "      <td>0.987893</td>\n",
       "      <td>9.538829e-01</td>\n",
       "      <td>0.713962</td>\n",
       "      <td>0.887148</td>\n",
       "      <td>0.937832</td>\n",
       "      <td>0.820744</td>\n",
       "      <td>0.906416</td>\n",
       "      <td>0.892741</td>\n",
       "      <td>0.778592</td>\n",
       "      <td>0.641168</td>\n",
       "      <td>0.268298</td>\n",
       "      <td>0.879809</td>\n",
       "      <td>0.859276</td>\n",
       "      <td>0.718486</td>\n",
       "      <td>0.784513</td>\n",
       "      <td>0.323591</td>\n",
       "      <td>0.215743</td>\n",
       "      <td>0.817136</td>\n",
       "      <td>0.794983</td>\n",
       "      <td>0.143607</td>\n",
       "      <td>0.642601</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.289605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>100</td>\n",
       "      <td>5326</td>\n",
       "      <td>0.490244</td>\n",
       "      <td>0.380940</td>\n",
       "      <td>0.186081</td>\n",
       "      <td>0.408533</td>\n",
       "      <td>0.426500</td>\n",
       "      <td>0.226843</td>\n",
       "      <td>0.896534</td>\n",
       "      <td>0.762814</td>\n",
       "      <td>0.820543</td>\n",
       "      <td>0.518491</td>\n",
       "      <td>0.918731</td>\n",
       "      <td>0.987538</td>\n",
       "      <td>0.866146</td>\n",
       "      <td>0.939288</td>\n",
       "      <td>0.978446</td>\n",
       "      <td>0.375235</td>\n",
       "      <td>9.540923e-01</td>\n",
       "      <td>0.967144</td>\n",
       "      <td>0.923487</td>\n",
       "      <td>0.969880</td>\n",
       "      <td>0.855463</td>\n",
       "      <td>0.937715</td>\n",
       "      <td>0.911106</td>\n",
       "      <td>0.915145</td>\n",
       "      <td>0.706214</td>\n",
       "      <td>0.257861</td>\n",
       "      <td>0.919181</td>\n",
       "      <td>0.909812</td>\n",
       "      <td>0.832597</td>\n",
       "      <td>0.838619</td>\n",
       "      <td>0.626924</td>\n",
       "      <td>0.214428</td>\n",
       "      <td>0.828453</td>\n",
       "      <td>0.812806</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.848694</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.404818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>100</td>\n",
       "      <td>1389</td>\n",
       "      <td>0.449655</td>\n",
       "      <td>0.173582</td>\n",
       "      <td>0.152193</td>\n",
       "      <td>0.190415</td>\n",
       "      <td>0.158163</td>\n",
       "      <td>0.123656</td>\n",
       "      <td>0.695581</td>\n",
       "      <td>0.822994</td>\n",
       "      <td>0.157983</td>\n",
       "      <td>0.388861</td>\n",
       "      <td>0.643811</td>\n",
       "      <td>0.472842</td>\n",
       "      <td>0.488442</td>\n",
       "      <td>0.177004</td>\n",
       "      <td>0.980936</td>\n",
       "      <td>0.988426</td>\n",
       "      <td>1.762766e-05</td>\n",
       "      <td>0.050712</td>\n",
       "      <td>0.809310</td>\n",
       "      <td>0.889343</td>\n",
       "      <td>0.293965</td>\n",
       "      <td>0.517576</td>\n",
       "      <td>0.851223</td>\n",
       "      <td>0.738997</td>\n",
       "      <td>0.534355</td>\n",
       "      <td>0.254799</td>\n",
       "      <td>0.803128</td>\n",
       "      <td>0.766201</td>\n",
       "      <td>0.388563</td>\n",
       "      <td>0.290308</td>\n",
       "      <td>0.130693</td>\n",
       "      <td>0.113132</td>\n",
       "      <td>0.293965</td>\n",
       "      <td>0.202365</td>\n",
       "      <td>0.134726</td>\n",
       "      <td>0.756770</td>\n",
       "      <td>0.557407</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.150919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>100</td>\n",
       "      <td>5153</td>\n",
       "      <td>0.498049</td>\n",
       "      <td>0.255375</td>\n",
       "      <td>0.205944</td>\n",
       "      <td>0.346341</td>\n",
       "      <td>0.248265</td>\n",
       "      <td>0.204870</td>\n",
       "      <td>0.907639</td>\n",
       "      <td>0.946790</td>\n",
       "      <td>0.714735</td>\n",
       "      <td>0.935742</td>\n",
       "      <td>0.999952</td>\n",
       "      <td>0.998964</td>\n",
       "      <td>0.946267</td>\n",
       "      <td>0.993401</td>\n",
       "      <td>0.982195</td>\n",
       "      <td>0.990205</td>\n",
       "      <td>9.602068e-01</td>\n",
       "      <td>0.971601</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.897559</td>\n",
       "      <td>0.648575</td>\n",
       "      <td>0.346042</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.869588</td>\n",
       "      <td>0.493623</td>\n",
       "      <td>0.301690</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.236706</td>\n",
       "      <td>0.725834</td>\n",
       "      <td>0.889163</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.603780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>100</td>\n",
       "      <td>1975</td>\n",
       "      <td>0.517766</td>\n",
       "      <td>0.246333</td>\n",
       "      <td>0.155104</td>\n",
       "      <td>0.365803</td>\n",
       "      <td>0.262292</td>\n",
       "      <td>0.171215</td>\n",
       "      <td>0.847666</td>\n",
       "      <td>0.844332</td>\n",
       "      <td>0.714735</td>\n",
       "      <td>0.735052</td>\n",
       "      <td>0.998707</td>\n",
       "      <td>0.991175</td>\n",
       "      <td>0.897693</td>\n",
       "      <td>0.943254</td>\n",
       "      <td>0.977903</td>\n",
       "      <td>0.993223</td>\n",
       "      <td>7.340050e-01</td>\n",
       "      <td>0.788591</td>\n",
       "      <td>0.977303</td>\n",
       "      <td>0.987493</td>\n",
       "      <td>0.930794</td>\n",
       "      <td>0.962515</td>\n",
       "      <td>0.966581</td>\n",
       "      <td>0.874183</td>\n",
       "      <td>0.652770</td>\n",
       "      <td>0.307714</td>\n",
       "      <td>0.976264</td>\n",
       "      <td>0.967525</td>\n",
       "      <td>0.894120</td>\n",
       "      <td>0.879221</td>\n",
       "      <td>0.386746</td>\n",
       "      <td>0.281545</td>\n",
       "      <td>0.924241</td>\n",
       "      <td>0.908044</td>\n",
       "      <td>0.185603</td>\n",
       "      <td>0.757168</td>\n",
       "      <td>0.839198</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.428290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>100</td>\n",
       "      <td>705</td>\n",
       "      <td>0.372423</td>\n",
       "      <td>0.466228</td>\n",
       "      <td>0.296158</td>\n",
       "      <td>0.355532</td>\n",
       "      <td>0.485242</td>\n",
       "      <td>0.402482</td>\n",
       "      <td>0.765789</td>\n",
       "      <td>0.937770</td>\n",
       "      <td>0.694703</td>\n",
       "      <td>0.920472</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>0.995581</td>\n",
       "      <td>0.986567</td>\n",
       "      <td>0.997620</td>\n",
       "      <td>0.980992</td>\n",
       "      <td>0.987018</td>\n",
       "      <td>9.519369e-01</td>\n",
       "      <td>0.973318</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.727823</td>\n",
       "      <td>0.278443</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.497310</td>\n",
       "      <td>0.247837</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.161334</td>\n",
       "      <td>0.755283</td>\n",
       "      <td>0.694804</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.632151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>100</td>\n",
       "      <td>2465</td>\n",
       "      <td>0.400593</td>\n",
       "      <td>0.496899</td>\n",
       "      <td>0.300016</td>\n",
       "      <td>0.359965</td>\n",
       "      <td>0.486943</td>\n",
       "      <td>0.300016</td>\n",
       "      <td>0.938961</td>\n",
       "      <td>0.966689</td>\n",
       "      <td>0.920880</td>\n",
       "      <td>0.955600</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.976880</td>\n",
       "      <td>0.988303</td>\n",
       "      <td>9.550776e-01</td>\n",
       "      <td>0.981918</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.957711</td>\n",
       "      <td>0.885079</td>\n",
       "      <td>0.981948</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.949175</td>\n",
       "      <td>0.827598</td>\n",
       "      <td>0.859332</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.231866</td>\n",
       "      <td>0.744921</td>\n",
       "      <td>0.919836</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.741689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>100</td>\n",
       "      <td>4826</td>\n",
       "      <td>0.455674</td>\n",
       "      <td>0.314752</td>\n",
       "      <td>0.164622</td>\n",
       "      <td>0.285976</td>\n",
       "      <td>0.263800</td>\n",
       "      <td>0.141633</td>\n",
       "      <td>0.862357</td>\n",
       "      <td>0.829606</td>\n",
       "      <td>0.686363</td>\n",
       "      <td>0.696630</td>\n",
       "      <td>0.821795</td>\n",
       "      <td>0.697329</td>\n",
       "      <td>0.349369</td>\n",
       "      <td>0.179964</td>\n",
       "      <td>0.987204</td>\n",
       "      <td>0.988050</td>\n",
       "      <td>9.478470e-01</td>\n",
       "      <td>0.967856</td>\n",
       "      <td>0.901601</td>\n",
       "      <td>0.952641</td>\n",
       "      <td>0.800605</td>\n",
       "      <td>0.915722</td>\n",
       "      <td>0.921890</td>\n",
       "      <td>0.843335</td>\n",
       "      <td>0.630609</td>\n",
       "      <td>0.228930</td>\n",
       "      <td>0.893790</td>\n",
       "      <td>0.867906</td>\n",
       "      <td>0.824654</td>\n",
       "      <td>0.740736</td>\n",
       "      <td>0.508417</td>\n",
       "      <td>0.181875</td>\n",
       "      <td>0.800605</td>\n",
       "      <td>0.774736</td>\n",
       "      <td>0.196729</td>\n",
       "      <td>0.753039</td>\n",
       "      <td>0.926500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.307623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>100</td>\n",
       "      <td>4361</td>\n",
       "      <td>0.245022</td>\n",
       "      <td>0.156215</td>\n",
       "      <td>0.192543</td>\n",
       "      <td>0.210180</td>\n",
       "      <td>0.221758</td>\n",
       "      <td>0.182364</td>\n",
       "      <td>0.786647</td>\n",
       "      <td>0.825674</td>\n",
       "      <td>0.721867</td>\n",
       "      <td>0.800733</td>\n",
       "      <td>0.760857</td>\n",
       "      <td>0.743708</td>\n",
       "      <td>0.612054</td>\n",
       "      <td>0.321660</td>\n",
       "      <td>0.977733</td>\n",
       "      <td>0.988820</td>\n",
       "      <td>9.693904e-01</td>\n",
       "      <td>0.983416</td>\n",
       "      <td>0.858266</td>\n",
       "      <td>0.944924</td>\n",
       "      <td>0.834894</td>\n",
       "      <td>0.933571</td>\n",
       "      <td>0.803079</td>\n",
       "      <td>0.691092</td>\n",
       "      <td>0.555945</td>\n",
       "      <td>0.308838</td>\n",
       "      <td>0.858266</td>\n",
       "      <td>0.831412</td>\n",
       "      <td>0.746720</td>\n",
       "      <td>0.598453</td>\n",
       "      <td>0.370800</td>\n",
       "      <td>0.266747</td>\n",
       "      <td>0.834894</td>\n",
       "      <td>0.813473</td>\n",
       "      <td>0.234463</td>\n",
       "      <td>0.688798</td>\n",
       "      <td>0.305225</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.281980</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    from    to  Doc2Vec:Wikipedia,Size=300  Word2Vec:Wikipedia,Size=300,Mean  Word2Vec:Wikipedia,Size=300,Max  Doc2Vec Phenes:Wikipedia,Size=300  Word2Vec Phenes:Wikipedia,Size=300,Mean  Word2Vec Phenes:Wikipedia,Size=300,Max  NOBLE Coder:Precise,TFIDF  NOBLE Coder:Partial,TFIDF  NOBLE Coder Phenes:Precise,TFIDF  NOBLE Coder Phenes:Partial,TFIDF  Topic Models:NMF,Full,Topics=50  Topic Models:NMF,Full,Topics=100  Topic Models Phenes:NMF,Full,Topics=50  Topic Models Phenes:NMF,Full,Topics=100  Topic Models:LDA,Full,Topics=50  Topic Models:LDA,Full,Topics=100  Topic Models Phenes:LDA,Full,Topics=50  Topic Models Phenes:LDA,Full,Topics=100  N-Grams:Full,Words,1-grams,TFIDF  N-Grams:Full,Words,1-grams,2-grams,TFIDF  N-Grams Phenes:Full,Words,1-grams,TFIDF  N-Grams Phenes:Full,Words,1-grams,2-grams,TFIDF  N-Grams:Full,Nouns,Adjectives,1-grams  N-Grams:Linares_Pontes,Words,1-grams  N-Grams:Full,Precise_Annotations,Words,1-grams  N-Grams:Full,Partial_Annotations,Words,1-grams  \\\n",
       "0    100  1145                    0.504560                          0.503235                         0.263459                           0.414963                                 0.478481                                0.288674                   0.857573                   0.928872                          0.796288                          0.900807                         1.000000                          1.000000                                1.000000                                 0.995888                         0.980399                          0.990102                            9.668565e-01                                 0.981963                          1.000000                                  1.000000                                 1.000000                                         1.000000                               1.000000                              1.000000                                        0.836855                                        0.566964   \n",
       "1    100  4114                    0.309927                          0.260014                         0.185656                           0.276678                                 0.270105                                0.180168                   0.932399                   0.962904                          0.910822                          0.957076                         0.999785                          0.999297                                0.999941                                 0.999121                         0.983668                          0.991767                            9.684386e-01                                 0.982268                          1.000000                                  1.000000                                 1.000000                                         1.000000                               1.000000                              0.977206                                        0.797835                                        0.406689   \n",
       "2    100   231                    0.435983                          0.279231                         0.185035                           0.299665                                 0.271672                                0.188429                   0.872037                   0.922563                          0.817956                          0.916699                         0.733982                          0.715878                                0.797588                                 0.900100                         0.977441                          0.990781                            9.554953e-01                                 0.971250                          0.934402                                  0.969146                                 0.883653                                         0.928505                               0.920096                              0.880906                                        0.529131                                        0.490530   \n",
       "3    100  5244                    0.551568                          0.602756                         0.363885                           0.404959                                 0.607823                                0.362408                   1.000000                   0.958144                          1.000000                          0.945128                         1.000000                          1.000000                                0.990909                                 0.905914                         0.976078                          0.983010                            9.529703e-01                                 0.974258                          1.000000                                  1.000000                                 1.000000                                         1.000000                               1.000000                              1.000000                                        1.000000                                        0.978320   \n",
       "4    100   733                    0.508654                          0.270065                         0.181497                           0.355532                                 0.293558                                0.170425                   0.893924                   0.927862                          0.797668                          0.919038                         0.999892                          0.998867                                1.000000                                 0.999008                         0.974111                          0.988849                            9.546172e-01                                 0.971961                          1.000000                                  1.000000                                 1.000000                                         1.000000                               1.000000                              0.865899                                        0.796603                                        0.284657   \n",
       "5    100  3896                    0.518026                          0.536171                         0.298879                           0.428593                                 0.590710                                0.391840                   0.970234                   0.972461                          1.000000                          0.967205                         1.000000                          1.000000                                1.000000                                 1.000000                         0.976449                          0.988082                            9.620776e-01                                 0.961087                          1.000000                                  1.000000                                 1.000000                                         1.000000                               1.000000                              1.000000                                        0.912374                                        0.338805   \n",
       "6    100  4572                    0.498664                          0.326860                         0.179187                           0.349483                                 0.341777                                0.209361                   0.948135                   0.927444                          0.939123                          0.925689                         0.998685                          0.986242                                0.988918                                 0.640430                         0.982011                          0.990924                            9.532030e-01                                 0.978660                          1.000000                                  1.000000                                 1.000000                                         1.000000                               1.000000                              0.908057                                        0.713808                                        0.345801   \n",
       "7    100  2823                    0.542816                          0.272979                         0.187657                           0.296875                                 0.278486                                0.199103                   0.887384                   0.909117                          1.000000                          0.885990                         1.000000                          1.000000                                0.639737                                 0.740649                         0.980833                          0.990628                            2.500710e-09                                 0.788591                          1.000000                                  1.000000                                 1.000000                                         1.000000                               1.000000                              0.970817                                        0.724138                                        0.247397   \n",
       "8    100  1592                    0.453901                          0.438724                         0.198668                           0.296394                                 0.365019                                0.222920                   0.902751                   0.926640                          1.000000                          0.905401                         1.000000                          0.999490                                0.984330                                 1.000000                         0.973381                          0.991938                            9.606524e-01                                 0.971783                          1.000000                                  1.000000                                 1.000000                                         1.000000                               1.000000                              0.945727                                        0.815585                                        0.329073   \n",
       "9    100  1185                    0.437521                          0.197340                         0.151455                           0.280486                                 0.232980                                0.155569                   0.901545                   0.921714                          0.654037                          0.911570                         0.995473                          0.992384                                0.375339                                 0.979698                         0.983954                          0.992425                            9.599578e-01                                 0.970949                          0.971604                                  0.987393                                 0.880267                                         0.948704                               1.000000                              0.857459                                        0.699810                                        0.319292   \n",
       "10   100   883                    0.433015                          0.601558                         0.872109                           0.345507                                 0.597342                                0.807199                   0.840931                   0.933173                          0.797668                          0.922610                         0.999966                          0.999663                                1.000000                                 1.000000                         0.976885                          0.988305                            9.519369e-01                                 0.973318                          1.000000                                  1.000000                                 1.000000                                         1.000000                               1.000000                              1.000000                                        0.889686                                        0.281991   \n",
       "11   100  2456                    0.506571                          0.186860                         0.160455                           0.196499                                 0.194339                                0.160468                   0.885565                   0.871551                          0.635296                          0.668224                         0.768235                          0.762891                                0.685551                                 0.309989                         0.987835                          0.987893                            9.538829e-01                                 0.713962                          0.887148                                  0.937832                                 0.820744                                         0.906416                               0.892741                              0.778592                                        0.641168                                        0.268298   \n",
       "12   100  5326                    0.490244                          0.380940                         0.186081                           0.408533                                 0.426500                                0.226843                   0.896534                   0.762814                          0.820543                          0.518491                         0.918731                          0.987538                                0.866146                                 0.939288                         0.978446                          0.375235                            9.540923e-01                                 0.967144                          0.923487                                  0.969880                                 0.855463                                         0.937715                               0.911106                              0.915145                                        0.706214                                        0.257861   \n",
       "13   100  1389                    0.449655                          0.173582                         0.152193                           0.190415                                 0.158163                                0.123656                   0.695581                   0.822994                          0.157983                          0.388861                         0.643811                          0.472842                                0.488442                                 0.177004                         0.980936                          0.988426                            1.762766e-05                                 0.050712                          0.809310                                  0.889343                                 0.293965                                         0.517576                               0.851223                              0.738997                                        0.534355                                        0.254799   \n",
       "14   100  5153                    0.498049                          0.255375                         0.205944                           0.346341                                 0.248265                                0.204870                   0.907639                   0.946790                          0.714735                          0.935742                         0.999952                          0.998964                                0.946267                                 0.993401                         0.982195                          0.990205                            9.602068e-01                                 0.971601                          1.000000                                  1.000000                                 1.000000                                         1.000000                               1.000000                              0.897559                                        0.648575                                        0.346042   \n",
       "15   100  1975                    0.517766                          0.246333                         0.155104                           0.365803                                 0.262292                                0.171215                   0.847666                   0.844332                          0.714735                          0.735052                         0.998707                          0.991175                                0.897693                                 0.943254                         0.977903                          0.993223                            7.340050e-01                                 0.788591                          0.977303                                  0.987493                                 0.930794                                         0.962515                               0.966581                              0.874183                                        0.652770                                        0.307714   \n",
       "16   100   705                    0.372423                          0.466228                         0.296158                           0.355532                                 0.485242                                0.402482                   0.765789                   0.937770                          0.694703                          0.920472                         0.999997                          0.995581                                0.986567                                 0.997620                         0.980992                          0.987018                            9.519369e-01                                 0.973318                          1.000000                                  1.000000                                 1.000000                                         1.000000                               1.000000                              1.000000                                        0.727823                                        0.278443   \n",
       "17   100  2465                    0.400593                          0.496899                         0.300016                           0.359965                                 0.486943                                0.300016                   0.938961                   0.966689                          0.920880                          0.955600                         1.000000                          1.000000                                1.000000                                 1.000000                         0.976880                          0.988303                            9.550776e-01                                 0.981918                          1.000000                                  1.000000                                 1.000000                                         1.000000                               1.000000                              0.957711                                        0.885079                                        0.981948   \n",
       "18   100  4826                    0.455674                          0.314752                         0.164622                           0.285976                                 0.263800                                0.141633                   0.862357                   0.829606                          0.686363                          0.696630                         0.821795                          0.697329                                0.349369                                 0.179964                         0.987204                          0.988050                            9.478470e-01                                 0.967856                          0.901601                                  0.952641                                 0.800605                                         0.915722                               0.921890                              0.843335                                        0.630609                                        0.228930   \n",
       "19   100  4361                    0.245022                          0.156215                         0.192543                           0.210180                                 0.221758                                0.182364                   0.786647                   0.825674                          0.721867                          0.800733                         0.760857                          0.743708                                0.612054                                 0.321660                         0.977733                          0.988820                            9.693904e-01                                 0.983416                          0.858266                                  0.944924                                 0.834894                                         0.933571                               0.803079                              0.691092                                        0.555945                                        0.308838   \n",
       "\n",
       "    N-Grams:Full,Plant Overrepresented Tokens,1-grams  N-Grams:Full,Bio Ontology Tokens,1-grams  N-Grams Phenes:Full,Nouns,Adjectives,1-grams  N-Grams Phenes:Linares_Pontes,Words,1-grams  N-Grams Phenes:Full,Precise_Annotations,Words,1-grams  N-Grams Phenes:Full,Partial_Annotations,Words,1-grams  N-Grams Phenes:Full,Plant Overrepresented Tokens,1-grams  N-Grams Phenes:Full,Bio Ontology Tokens,1-grams  GO:Union  PO:Union  GO:Maximum  PO:Maximum      Mean  \n",
       "0                                            1.000000                                  1.000000                                      1.000000                                     1.000000                                           0.586272                                               0.428988                                               1.000000                                                1.000000  1.000000  0.917046    1.000000    0.646146  0.720441  \n",
       "1                                            1.000000                                  1.000000                                      1.000000                                     0.977423                                           0.741544                                               0.422529                                               1.000000                                                1.000000  1.000000  1.000000    1.000000    1.000000  0.656684  \n",
       "2                                            0.934402                                  0.915424                                      0.812598                                     0.863527                                           0.376286                                               0.415109                                               0.883653                                                0.853920  0.224368  0.700841    0.905412    0.000000  0.392922  \n",
       "3                                            1.000000                                  1.000000                                      1.000000                                     1.000000                                           1.000000                                               0.897213                                               1.000000                                                1.000000  0.355641  0.629555    0.689286    0.476599  0.775899  \n",
       "4                                            1.000000                                  1.000000                                      1.000000                                     0.850601                                           0.593352                                               0.247837                                               1.000000                                                1.000000  0.188509  0.575006    0.689286    0.000000  0.604054  \n",
       "5                                            1.000000                                  1.000000                                      1.000000                                     1.000000                                           0.841140                                               0.310185                                               1.000000                                                1.000000  1.000000  1.000000    1.000000    1.000000  0.764766  \n",
       "6                                            1.000000                                  1.000000                                      1.000000                                     0.899051                                           0.600257                                               0.263837                                               1.000000                                                1.000000  0.425165  0.556259    0.925314    0.476599  0.618412  \n",
       "7                                            1.000000                                  1.000000                                      1.000000                                     0.949335                                           0.548854                                               0.229812                                               1.000000                                                1.000000  1.000000  1.000000    1.000000    1.000000  0.580942  \n",
       "8                                            1.000000                                  1.000000                                      1.000000                                     0.889008                                           0.732580                                               0.247194                                               1.000000                                                1.000000  0.215764  0.644082    0.488195    0.000000  0.648037  \n",
       "9                                            0.971132                                  1.000000                                      1.000000                                     0.808575                                           0.420889                                               0.275842                                               0.854551                                                1.000000  0.200531  0.796364    0.898161    0.538176  0.467105  \n",
       "10                                           1.000000                                  1.000000                                      1.000000                                     1.000000                                           0.714460                                               0.247837                                               1.000000                                                1.000000  0.297119  0.765555    0.918007    0.000000  0.699790  \n",
       "11                                           0.879809                                  0.859276                                      0.718486                                     0.784513                                           0.323591                                               0.215743                                               0.817136                                                0.794983  0.143607  0.642601    0.000000    0.000000  0.289605  \n",
       "12                                           0.919181                                  0.909812                                      0.832597                                     0.838619                                           0.626924                                               0.214428                                               0.828453                                                0.812806  1.000000  0.848694    1.000000    0.000000  0.404818  \n",
       "13                                           0.803128                                  0.766201                                      0.388563                                     0.290308                                           0.130693                                               0.113132                                               0.293965                                                0.202365  0.134726  0.756770    0.557407    0.000000  0.150919  \n",
       "14                                           1.000000                                  1.000000                                      1.000000                                     0.869588                                           0.493623                                               0.301690                                               1.000000                                                1.000000  0.236706  0.725834    0.889163    0.000000  0.603780  \n",
       "15                                           0.976264                                  0.967525                                      0.894120                                     0.879221                                           0.386746                                               0.281545                                               0.924241                                                0.908044  0.185603  0.757168    0.839198    0.000000  0.428290  \n",
       "16                                           1.000000                                  1.000000                                      1.000000                                     1.000000                                           0.497310                                               0.247837                                               1.000000                                                1.000000  0.161334  0.755283    0.694804    0.000000  0.632151  \n",
       "17                                           1.000000                                  1.000000                                      1.000000                                     0.949175                                           0.827598                                               0.859332                                               1.000000                                                1.000000  0.231866  0.744921    0.919836    0.000000  0.741689  \n",
       "18                                           0.893790                                  0.867906                                      0.824654                                     0.740736                                           0.508417                                               0.181875                                               0.800605                                                0.774736  0.196729  0.753039    0.926500    0.000000  0.307623  \n",
       "19                                           0.858266                                  0.831412                                      0.746720                                     0.598453                                           0.370800                                               0.266747                                               0.834894                                                0.813473  0.234463  0.688798    0.305225    0.000000  0.281980  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"species\"></a>\n",
    "### Checking whether gene pairs are intraspecies or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>from</th>\n",
       "      <th>to</th>\n",
       "      <th>Doc2Vec:Wikipedia,Size=300</th>\n",
       "      <th>Word2Vec:Wikipedia,Size=300,Mean</th>\n",
       "      <th>Word2Vec:Wikipedia,Size=300,Max</th>\n",
       "      <th>Doc2Vec Phenes:Wikipedia,Size=300</th>\n",
       "      <th>Word2Vec Phenes:Wikipedia,Size=300,Mean</th>\n",
       "      <th>Word2Vec Phenes:Wikipedia,Size=300,Max</th>\n",
       "      <th>NOBLE Coder:Precise,TFIDF</th>\n",
       "      <th>NOBLE Coder:Partial,TFIDF</th>\n",
       "      <th>NOBLE Coder Phenes:Precise,TFIDF</th>\n",
       "      <th>NOBLE Coder Phenes:Partial,TFIDF</th>\n",
       "      <th>Topic Models:NMF,Full,Topics=50</th>\n",
       "      <th>Topic Models:NMF,Full,Topics=100</th>\n",
       "      <th>Topic Models Phenes:NMF,Full,Topics=50</th>\n",
       "      <th>Topic Models Phenes:NMF,Full,Topics=100</th>\n",
       "      <th>Topic Models:LDA,Full,Topics=50</th>\n",
       "      <th>Topic Models:LDA,Full,Topics=100</th>\n",
       "      <th>Topic Models Phenes:LDA,Full,Topics=50</th>\n",
       "      <th>Topic Models Phenes:LDA,Full,Topics=100</th>\n",
       "      <th>N-Grams:Full,Words,1-grams,TFIDF</th>\n",
       "      <th>N-Grams:Full,Words,1-grams,2-grams,TFIDF</th>\n",
       "      <th>N-Grams Phenes:Full,Words,1-grams,TFIDF</th>\n",
       "      <th>N-Grams Phenes:Full,Words,1-grams,2-grams,TFIDF</th>\n",
       "      <th>N-Grams:Full,Nouns,Adjectives,1-grams</th>\n",
       "      <th>N-Grams:Linares_Pontes,Words,1-grams</th>\n",
       "      <th>N-Grams:Full,Precise_Annotations,Words,1-grams</th>\n",
       "      <th>N-Grams:Full,Partial_Annotations,Words,1-grams</th>\n",
       "      <th>N-Grams:Full,Plant Overrepresented Tokens,1-grams</th>\n",
       "      <th>N-Grams:Full,Bio Ontology Tokens,1-grams</th>\n",
       "      <th>N-Grams Phenes:Full,Nouns,Adjectives,1-grams</th>\n",
       "      <th>N-Grams Phenes:Linares_Pontes,Words,1-grams</th>\n",
       "      <th>N-Grams Phenes:Full,Precise_Annotations,Words,1-grams</th>\n",
       "      <th>N-Grams Phenes:Full,Partial_Annotations,Words,1-grams</th>\n",
       "      <th>N-Grams Phenes:Full,Plant Overrepresented Tokens,1-grams</th>\n",
       "      <th>N-Grams Phenes:Full,Bio Ontology Tokens,1-grams</th>\n",
       "      <th>GO:Union</th>\n",
       "      <th>PO:Union</th>\n",
       "      <th>GO:Maximum</th>\n",
       "      <th>PO:Maximum</th>\n",
       "      <th>Mean</th>\n",
       "      <th>same</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>1145</td>\n",
       "      <td>0.504560</td>\n",
       "      <td>0.503235</td>\n",
       "      <td>0.263459</td>\n",
       "      <td>0.414963</td>\n",
       "      <td>0.478481</td>\n",
       "      <td>0.288674</td>\n",
       "      <td>0.857573</td>\n",
       "      <td>0.928872</td>\n",
       "      <td>0.796288</td>\n",
       "      <td>0.900807</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.995888</td>\n",
       "      <td>0.980399</td>\n",
       "      <td>0.990102</td>\n",
       "      <td>9.668565e-01</td>\n",
       "      <td>0.981963</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.836855</td>\n",
       "      <td>0.566964</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.586272</td>\n",
       "      <td>0.428988</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.917046</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.646146</td>\n",
       "      <td>0.720441</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100</td>\n",
       "      <td>4114</td>\n",
       "      <td>0.309927</td>\n",
       "      <td>0.260014</td>\n",
       "      <td>0.185656</td>\n",
       "      <td>0.276678</td>\n",
       "      <td>0.270105</td>\n",
       "      <td>0.180168</td>\n",
       "      <td>0.932399</td>\n",
       "      <td>0.962904</td>\n",
       "      <td>0.910822</td>\n",
       "      <td>0.957076</td>\n",
       "      <td>0.999785</td>\n",
       "      <td>0.999297</td>\n",
       "      <td>0.999941</td>\n",
       "      <td>0.999121</td>\n",
       "      <td>0.983668</td>\n",
       "      <td>0.991767</td>\n",
       "      <td>9.684386e-01</td>\n",
       "      <td>0.982268</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.977206</td>\n",
       "      <td>0.797835</td>\n",
       "      <td>0.406689</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.977423</td>\n",
       "      <td>0.741544</td>\n",
       "      <td>0.422529</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.656684</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>231</td>\n",
       "      <td>0.435983</td>\n",
       "      <td>0.279231</td>\n",
       "      <td>0.185035</td>\n",
       "      <td>0.299665</td>\n",
       "      <td>0.271672</td>\n",
       "      <td>0.188429</td>\n",
       "      <td>0.872037</td>\n",
       "      <td>0.922563</td>\n",
       "      <td>0.817956</td>\n",
       "      <td>0.916699</td>\n",
       "      <td>0.733982</td>\n",
       "      <td>0.715878</td>\n",
       "      <td>0.797588</td>\n",
       "      <td>0.900100</td>\n",
       "      <td>0.977441</td>\n",
       "      <td>0.990781</td>\n",
       "      <td>9.554953e-01</td>\n",
       "      <td>0.971250</td>\n",
       "      <td>0.934402</td>\n",
       "      <td>0.969146</td>\n",
       "      <td>0.883653</td>\n",
       "      <td>0.928505</td>\n",
       "      <td>0.920096</td>\n",
       "      <td>0.880906</td>\n",
       "      <td>0.529131</td>\n",
       "      <td>0.490530</td>\n",
       "      <td>0.934402</td>\n",
       "      <td>0.915424</td>\n",
       "      <td>0.812598</td>\n",
       "      <td>0.863527</td>\n",
       "      <td>0.376286</td>\n",
       "      <td>0.415109</td>\n",
       "      <td>0.883653</td>\n",
       "      <td>0.85392</td>\n",
       "      <td>0.224368</td>\n",
       "      <td>0.700841</td>\n",
       "      <td>0.905412</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.392922</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100</td>\n",
       "      <td>5244</td>\n",
       "      <td>0.551568</td>\n",
       "      <td>0.602756</td>\n",
       "      <td>0.363885</td>\n",
       "      <td>0.404959</td>\n",
       "      <td>0.607823</td>\n",
       "      <td>0.362408</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.958144</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.945128</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.990909</td>\n",
       "      <td>0.905914</td>\n",
       "      <td>0.976078</td>\n",
       "      <td>0.983010</td>\n",
       "      <td>9.529703e-01</td>\n",
       "      <td>0.974258</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.978320</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.897213</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.355641</td>\n",
       "      <td>0.629555</td>\n",
       "      <td>0.689286</td>\n",
       "      <td>0.476599</td>\n",
       "      <td>0.775899</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100</td>\n",
       "      <td>733</td>\n",
       "      <td>0.508654</td>\n",
       "      <td>0.270065</td>\n",
       "      <td>0.181497</td>\n",
       "      <td>0.355532</td>\n",
       "      <td>0.293558</td>\n",
       "      <td>0.170425</td>\n",
       "      <td>0.893924</td>\n",
       "      <td>0.927862</td>\n",
       "      <td>0.797668</td>\n",
       "      <td>0.919038</td>\n",
       "      <td>0.999892</td>\n",
       "      <td>0.998867</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999008</td>\n",
       "      <td>0.974111</td>\n",
       "      <td>0.988849</td>\n",
       "      <td>9.546172e-01</td>\n",
       "      <td>0.971961</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.865899</td>\n",
       "      <td>0.796603</td>\n",
       "      <td>0.284657</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.850601</td>\n",
       "      <td>0.593352</td>\n",
       "      <td>0.247837</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.188509</td>\n",
       "      <td>0.575006</td>\n",
       "      <td>0.689286</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.604054</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>100</td>\n",
       "      <td>3896</td>\n",
       "      <td>0.518026</td>\n",
       "      <td>0.536171</td>\n",
       "      <td>0.298879</td>\n",
       "      <td>0.428593</td>\n",
       "      <td>0.590710</td>\n",
       "      <td>0.391840</td>\n",
       "      <td>0.970234</td>\n",
       "      <td>0.972461</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.967205</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.976449</td>\n",
       "      <td>0.988082</td>\n",
       "      <td>9.620776e-01</td>\n",
       "      <td>0.961087</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.912374</td>\n",
       "      <td>0.338805</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.841140</td>\n",
       "      <td>0.310185</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.764766</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>100</td>\n",
       "      <td>4572</td>\n",
       "      <td>0.498664</td>\n",
       "      <td>0.326860</td>\n",
       "      <td>0.179187</td>\n",
       "      <td>0.349483</td>\n",
       "      <td>0.341777</td>\n",
       "      <td>0.209361</td>\n",
       "      <td>0.948135</td>\n",
       "      <td>0.927444</td>\n",
       "      <td>0.939123</td>\n",
       "      <td>0.925689</td>\n",
       "      <td>0.998685</td>\n",
       "      <td>0.986242</td>\n",
       "      <td>0.988918</td>\n",
       "      <td>0.640430</td>\n",
       "      <td>0.982011</td>\n",
       "      <td>0.990924</td>\n",
       "      <td>9.532030e-01</td>\n",
       "      <td>0.978660</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.908057</td>\n",
       "      <td>0.713808</td>\n",
       "      <td>0.345801</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.899051</td>\n",
       "      <td>0.600257</td>\n",
       "      <td>0.263837</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.425165</td>\n",
       "      <td>0.556259</td>\n",
       "      <td>0.925314</td>\n",
       "      <td>0.476599</td>\n",
       "      <td>0.618412</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>100</td>\n",
       "      <td>2823</td>\n",
       "      <td>0.542816</td>\n",
       "      <td>0.272979</td>\n",
       "      <td>0.187657</td>\n",
       "      <td>0.296875</td>\n",
       "      <td>0.278486</td>\n",
       "      <td>0.199103</td>\n",
       "      <td>0.887384</td>\n",
       "      <td>0.909117</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.885990</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.639737</td>\n",
       "      <td>0.740649</td>\n",
       "      <td>0.980833</td>\n",
       "      <td>0.990628</td>\n",
       "      <td>2.500710e-09</td>\n",
       "      <td>0.788591</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.970817</td>\n",
       "      <td>0.724138</td>\n",
       "      <td>0.247397</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.949335</td>\n",
       "      <td>0.548854</td>\n",
       "      <td>0.229812</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.580942</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>100</td>\n",
       "      <td>1592</td>\n",
       "      <td>0.453901</td>\n",
       "      <td>0.438724</td>\n",
       "      <td>0.198668</td>\n",
       "      <td>0.296394</td>\n",
       "      <td>0.365019</td>\n",
       "      <td>0.222920</td>\n",
       "      <td>0.902751</td>\n",
       "      <td>0.926640</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.905401</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999490</td>\n",
       "      <td>0.984330</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.973381</td>\n",
       "      <td>0.991938</td>\n",
       "      <td>9.606524e-01</td>\n",
       "      <td>0.971783</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.945727</td>\n",
       "      <td>0.815585</td>\n",
       "      <td>0.329073</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.889008</td>\n",
       "      <td>0.732580</td>\n",
       "      <td>0.247194</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.215764</td>\n",
       "      <td>0.644082</td>\n",
       "      <td>0.488195</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.648037</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>100</td>\n",
       "      <td>1185</td>\n",
       "      <td>0.437521</td>\n",
       "      <td>0.197340</td>\n",
       "      <td>0.151455</td>\n",
       "      <td>0.280486</td>\n",
       "      <td>0.232980</td>\n",
       "      <td>0.155569</td>\n",
       "      <td>0.901545</td>\n",
       "      <td>0.921714</td>\n",
       "      <td>0.654037</td>\n",
       "      <td>0.911570</td>\n",
       "      <td>0.995473</td>\n",
       "      <td>0.992384</td>\n",
       "      <td>0.375339</td>\n",
       "      <td>0.979698</td>\n",
       "      <td>0.983954</td>\n",
       "      <td>0.992425</td>\n",
       "      <td>9.599578e-01</td>\n",
       "      <td>0.970949</td>\n",
       "      <td>0.971604</td>\n",
       "      <td>0.987393</td>\n",
       "      <td>0.880267</td>\n",
       "      <td>0.948704</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.857459</td>\n",
       "      <td>0.699810</td>\n",
       "      <td>0.319292</td>\n",
       "      <td>0.971132</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.808575</td>\n",
       "      <td>0.420889</td>\n",
       "      <td>0.275842</td>\n",
       "      <td>0.854551</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.200531</td>\n",
       "      <td>0.796364</td>\n",
       "      <td>0.898161</td>\n",
       "      <td>0.538176</td>\n",
       "      <td>0.467105</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   from    to  Doc2Vec:Wikipedia,Size=300  Word2Vec:Wikipedia,Size=300,Mean  Word2Vec:Wikipedia,Size=300,Max  Doc2Vec Phenes:Wikipedia,Size=300  Word2Vec Phenes:Wikipedia,Size=300,Mean  Word2Vec Phenes:Wikipedia,Size=300,Max  NOBLE Coder:Precise,TFIDF  NOBLE Coder:Partial,TFIDF  NOBLE Coder Phenes:Precise,TFIDF  NOBLE Coder Phenes:Partial,TFIDF  Topic Models:NMF,Full,Topics=50  Topic Models:NMF,Full,Topics=100  Topic Models Phenes:NMF,Full,Topics=50  Topic Models Phenes:NMF,Full,Topics=100  Topic Models:LDA,Full,Topics=50  Topic Models:LDA,Full,Topics=100  Topic Models Phenes:LDA,Full,Topics=50  Topic Models Phenes:LDA,Full,Topics=100  N-Grams:Full,Words,1-grams,TFIDF  N-Grams:Full,Words,1-grams,2-grams,TFIDF  N-Grams Phenes:Full,Words,1-grams,TFIDF  N-Grams Phenes:Full,Words,1-grams,2-grams,TFIDF  N-Grams:Full,Nouns,Adjectives,1-grams  N-Grams:Linares_Pontes,Words,1-grams  N-Grams:Full,Precise_Annotations,Words,1-grams  N-Grams:Full,Partial_Annotations,Words,1-grams  \\\n",
       "0   100  1145                    0.504560                          0.503235                         0.263459                           0.414963                                 0.478481                                0.288674                   0.857573                   0.928872                          0.796288                          0.900807                         1.000000                          1.000000                                1.000000                                 0.995888                         0.980399                          0.990102                            9.668565e-01                                 0.981963                          1.000000                                  1.000000                                 1.000000                                         1.000000                               1.000000                              1.000000                                        0.836855                                        0.566964   \n",
       "1   100  4114                    0.309927                          0.260014                         0.185656                           0.276678                                 0.270105                                0.180168                   0.932399                   0.962904                          0.910822                          0.957076                         0.999785                          0.999297                                0.999941                                 0.999121                         0.983668                          0.991767                            9.684386e-01                                 0.982268                          1.000000                                  1.000000                                 1.000000                                         1.000000                               1.000000                              0.977206                                        0.797835                                        0.406689   \n",
       "2   100   231                    0.435983                          0.279231                         0.185035                           0.299665                                 0.271672                                0.188429                   0.872037                   0.922563                          0.817956                          0.916699                         0.733982                          0.715878                                0.797588                                 0.900100                         0.977441                          0.990781                            9.554953e-01                                 0.971250                          0.934402                                  0.969146                                 0.883653                                         0.928505                               0.920096                              0.880906                                        0.529131                                        0.490530   \n",
       "3   100  5244                    0.551568                          0.602756                         0.363885                           0.404959                                 0.607823                                0.362408                   1.000000                   0.958144                          1.000000                          0.945128                         1.000000                          1.000000                                0.990909                                 0.905914                         0.976078                          0.983010                            9.529703e-01                                 0.974258                          1.000000                                  1.000000                                 1.000000                                         1.000000                               1.000000                              1.000000                                        1.000000                                        0.978320   \n",
       "4   100   733                    0.508654                          0.270065                         0.181497                           0.355532                                 0.293558                                0.170425                   0.893924                   0.927862                          0.797668                          0.919038                         0.999892                          0.998867                                1.000000                                 0.999008                         0.974111                          0.988849                            9.546172e-01                                 0.971961                          1.000000                                  1.000000                                 1.000000                                         1.000000                               1.000000                              0.865899                                        0.796603                                        0.284657   \n",
       "5   100  3896                    0.518026                          0.536171                         0.298879                           0.428593                                 0.590710                                0.391840                   0.970234                   0.972461                          1.000000                          0.967205                         1.000000                          1.000000                                1.000000                                 1.000000                         0.976449                          0.988082                            9.620776e-01                                 0.961087                          1.000000                                  1.000000                                 1.000000                                         1.000000                               1.000000                              1.000000                                        0.912374                                        0.338805   \n",
       "6   100  4572                    0.498664                          0.326860                         0.179187                           0.349483                                 0.341777                                0.209361                   0.948135                   0.927444                          0.939123                          0.925689                         0.998685                          0.986242                                0.988918                                 0.640430                         0.982011                          0.990924                            9.532030e-01                                 0.978660                          1.000000                                  1.000000                                 1.000000                                         1.000000                               1.000000                              0.908057                                        0.713808                                        0.345801   \n",
       "7   100  2823                    0.542816                          0.272979                         0.187657                           0.296875                                 0.278486                                0.199103                   0.887384                   0.909117                          1.000000                          0.885990                         1.000000                          1.000000                                0.639737                                 0.740649                         0.980833                          0.990628                            2.500710e-09                                 0.788591                          1.000000                                  1.000000                                 1.000000                                         1.000000                               1.000000                              0.970817                                        0.724138                                        0.247397   \n",
       "8   100  1592                    0.453901                          0.438724                         0.198668                           0.296394                                 0.365019                                0.222920                   0.902751                   0.926640                          1.000000                          0.905401                         1.000000                          0.999490                                0.984330                                 1.000000                         0.973381                          0.991938                            9.606524e-01                                 0.971783                          1.000000                                  1.000000                                 1.000000                                         1.000000                               1.000000                              0.945727                                        0.815585                                        0.329073   \n",
       "9   100  1185                    0.437521                          0.197340                         0.151455                           0.280486                                 0.232980                                0.155569                   0.901545                   0.921714                          0.654037                          0.911570                         0.995473                          0.992384                                0.375339                                 0.979698                         0.983954                          0.992425                            9.599578e-01                                 0.970949                          0.971604                                  0.987393                                 0.880267                                         0.948704                               1.000000                              0.857459                                        0.699810                                        0.319292   \n",
       "\n",
       "   N-Grams:Full,Plant Overrepresented Tokens,1-grams  N-Grams:Full,Bio Ontology Tokens,1-grams  N-Grams Phenes:Full,Nouns,Adjectives,1-grams  N-Grams Phenes:Linares_Pontes,Words,1-grams  N-Grams Phenes:Full,Precise_Annotations,Words,1-grams  N-Grams Phenes:Full,Partial_Annotations,Words,1-grams  N-Grams Phenes:Full,Plant Overrepresented Tokens,1-grams  N-Grams Phenes:Full,Bio Ontology Tokens,1-grams  GO:Union  PO:Union  GO:Maximum  PO:Maximum      Mean   same  \n",
       "0                                           1.000000                                  1.000000                                      1.000000                                     1.000000                                           0.586272                                               0.428988                                               1.000000                                                 1.00000  1.000000  0.917046    1.000000    0.646146  0.720441  False  \n",
       "1                                           1.000000                                  1.000000                                      1.000000                                     0.977423                                           0.741544                                               0.422529                                               1.000000                                                 1.00000  1.000000  1.000000    1.000000    1.000000  0.656684   True  \n",
       "2                                           0.934402                                  0.915424                                      0.812598                                     0.863527                                           0.376286                                               0.415109                                               0.883653                                                 0.85392  0.224368  0.700841    0.905412    0.000000  0.392922   True  \n",
       "3                                           1.000000                                  1.000000                                      1.000000                                     1.000000                                           1.000000                                               0.897213                                               1.000000                                                 1.00000  0.355641  0.629555    0.689286    0.476599  0.775899   True  \n",
       "4                                           1.000000                                  1.000000                                      1.000000                                     0.850601                                           0.593352                                               0.247837                                               1.000000                                                 1.00000  0.188509  0.575006    0.689286    0.000000  0.604054   True  \n",
       "5                                           1.000000                                  1.000000                                      1.000000                                     1.000000                                           0.841140                                               0.310185                                               1.000000                                                 1.00000  1.000000  1.000000    1.000000    1.000000  0.764766  False  \n",
       "6                                           1.000000                                  1.000000                                      1.000000                                     0.899051                                           0.600257                                               0.263837                                               1.000000                                                 1.00000  0.425165  0.556259    0.925314    0.476599  0.618412   True  \n",
       "7                                           1.000000                                  1.000000                                      1.000000                                     0.949335                                           0.548854                                               0.229812                                               1.000000                                                 1.00000  1.000000  1.000000    1.000000    1.000000  0.580942  False  \n",
       "8                                           1.000000                                  1.000000                                      1.000000                                     0.889008                                           0.732580                                               0.247194                                               1.000000                                                 1.00000  0.215764  0.644082    0.488195    0.000000  0.648037   True  \n",
       "9                                           0.971132                                  1.000000                                      1.000000                                     0.808575                                           0.420889                                               0.275842                                               0.854551                                                 1.00000  0.200531  0.796364    0.898161    0.538176  0.467105   True  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "species_dict = dataset.get_species_dictionary()\n",
    "df[\"same\"] = df[[\"from\",\"to\"]].apply(lambda x: species_dict[x[\"from\"]]==species_dict[x[\"to\"]],axis=1)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"pathway_objective\"></a>\n",
    "### Using shared pathway membership (PlantCyc and KEGG) as the objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a column that indicates whether or not both genes of the pair mapped to a pathway resource.\n",
    "pathway_mapped_ids = set(kegg_mapped_ids+pmn_mapped_ids)\n",
    "df[\"from_is_valid\"] = df[\"from\"].map(lambda x: x in pathway_mapped_ids)\n",
    "df[\"to_is_valid\"] = df[\"to\"].map(lambda x: x in pathway_mapped_ids)\n",
    "df[\"pair_is_valid\"] = df[\"from_is_valid\"]*df[\"to_is_valid\"]\n",
    "\n",
    "\n",
    "# Add a column giving the actual target output value for this biological task, with -1 for the irrelevant rows.\n",
    "df[\"pathways\"] = -1\n",
    "id_to_kegg_group_ids, kegg_group_id_to_ids = kegg_groups.get_groupings_for_dataset(dataset)\n",
    "id_to_pmn_group_ids, pmn_group_id_to_ids = pmn_groups.get_groupings_for_dataset(dataset)\n",
    "id_to_group_ids = {i:flatten([id_to_kegg_group_ids[i],id_to_pmn_group_ids[i]]) for i in dataset.get_ids()}\n",
    "df.loc[(df[\"pair_is_valid\"]==True),\"pathways\"] = df[[\"from\",\"to\"]].apply(lambda x: len(set(id_to_group_ids[x[\"from\"]]).intersection(set(id_to_group_ids[x[\"to\"]])))>0, axis=1)*1\n",
    "df.drop(labels=[\"from_is_valid\",\"to_is_valid\",\"pair_is_valid\"], axis=\"columns\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a column that indicates whether or not both genes of the pair mapped to a pathway resource.\n",
    "pathway_mapped_ids = set(kegg_mapped_ids)\n",
    "df[\"from_is_valid\"] = df[\"from\"].map(lambda x: x in pathway_mapped_ids)\n",
    "df[\"to_is_valid\"] = df[\"to\"].map(lambda x: x in pathway_mapped_ids)\n",
    "df[\"pair_is_valid\"] = df[\"from_is_valid\"]*df[\"to_is_valid\"]\n",
    "\n",
    "\n",
    "# Add a column giving the actual target output value for this biological task, with -1 for the irrelevant rows.\n",
    "df[\"kegg_only\"] = -1\n",
    "id_to_kegg_group_ids, kegg_group_id_to_ids = kegg_groups.get_groupings_for_dataset(dataset)\n",
    "id_to_pmn_group_ids, pmn_group_id_to_ids = pmn_groups.get_groupings_for_dataset(dataset)\n",
    "id_to_group_ids = {i:flatten([id_to_kegg_group_ids[i],id_to_pmn_group_ids[i]]) for i in dataset.get_ids()}\n",
    "df.loc[(df[\"pair_is_valid\"]==True),\"kegg_only\"] = df[[\"from\",\"to\"]].apply(lambda x: len(set(id_to_group_ids[x[\"from\"]]).intersection(set(id_to_group_ids[x[\"to\"]])))>0, axis=1)*1\n",
    "df.drop(labels=[\"from_is_valid\",\"to_is_valid\",\"pair_is_valid\"], axis=\"columns\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>from</th>\n",
       "      <th>to</th>\n",
       "      <th>Doc2Vec:Wikipedia,Size=300</th>\n",
       "      <th>Word2Vec:Wikipedia,Size=300,Mean</th>\n",
       "      <th>Word2Vec:Wikipedia,Size=300,Max</th>\n",
       "      <th>Doc2Vec Phenes:Wikipedia,Size=300</th>\n",
       "      <th>Word2Vec Phenes:Wikipedia,Size=300,Mean</th>\n",
       "      <th>Word2Vec Phenes:Wikipedia,Size=300,Max</th>\n",
       "      <th>NOBLE Coder:Precise,TFIDF</th>\n",
       "      <th>NOBLE Coder:Partial,TFIDF</th>\n",
       "      <th>NOBLE Coder Phenes:Precise,TFIDF</th>\n",
       "      <th>NOBLE Coder Phenes:Partial,TFIDF</th>\n",
       "      <th>Topic Models:NMF,Full,Topics=50</th>\n",
       "      <th>Topic Models:NMF,Full,Topics=100</th>\n",
       "      <th>Topic Models Phenes:NMF,Full,Topics=50</th>\n",
       "      <th>Topic Models Phenes:NMF,Full,Topics=100</th>\n",
       "      <th>Topic Models:LDA,Full,Topics=50</th>\n",
       "      <th>Topic Models:LDA,Full,Topics=100</th>\n",
       "      <th>Topic Models Phenes:LDA,Full,Topics=50</th>\n",
       "      <th>Topic Models Phenes:LDA,Full,Topics=100</th>\n",
       "      <th>N-Grams:Full,Words,1-grams,TFIDF</th>\n",
       "      <th>N-Grams:Full,Words,1-grams,2-grams,TFIDF</th>\n",
       "      <th>N-Grams Phenes:Full,Words,1-grams,TFIDF</th>\n",
       "      <th>N-Grams Phenes:Full,Words,1-grams,2-grams,TFIDF</th>\n",
       "      <th>N-Grams:Full,Nouns,Adjectives,1-grams</th>\n",
       "      <th>N-Grams:Linares_Pontes,Words,1-grams</th>\n",
       "      <th>N-Grams:Full,Precise_Annotations,Words,1-grams</th>\n",
       "      <th>N-Grams:Full,Partial_Annotations,Words,1-grams</th>\n",
       "      <th>N-Grams:Full,Plant Overrepresented Tokens,1-grams</th>\n",
       "      <th>N-Grams:Full,Bio Ontology Tokens,1-grams</th>\n",
       "      <th>N-Grams Phenes:Full,Nouns,Adjectives,1-grams</th>\n",
       "      <th>N-Grams Phenes:Linares_Pontes,Words,1-grams</th>\n",
       "      <th>N-Grams Phenes:Full,Precise_Annotations,Words,1-grams</th>\n",
       "      <th>N-Grams Phenes:Full,Partial_Annotations,Words,1-grams</th>\n",
       "      <th>N-Grams Phenes:Full,Plant Overrepresented Tokens,1-grams</th>\n",
       "      <th>N-Grams Phenes:Full,Bio Ontology Tokens,1-grams</th>\n",
       "      <th>GO:Union</th>\n",
       "      <th>PO:Union</th>\n",
       "      <th>GO:Maximum</th>\n",
       "      <th>PO:Maximum</th>\n",
       "      <th>Mean</th>\n",
       "      <th>same</th>\n",
       "      <th>pathways</th>\n",
       "      <th>kegg_only</th>\n",
       "      <th>pmn_only</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>1145</td>\n",
       "      <td>0.504560</td>\n",
       "      <td>0.503235</td>\n",
       "      <td>0.263459</td>\n",
       "      <td>0.414963</td>\n",
       "      <td>0.478481</td>\n",
       "      <td>0.288674</td>\n",
       "      <td>0.857573</td>\n",
       "      <td>0.928872</td>\n",
       "      <td>0.796288</td>\n",
       "      <td>0.900807</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.995888</td>\n",
       "      <td>0.980399</td>\n",
       "      <td>0.990102</td>\n",
       "      <td>9.668565e-01</td>\n",
       "      <td>0.981963</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.836855</td>\n",
       "      <td>0.566964</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.586272</td>\n",
       "      <td>0.428988</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.917046</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.646146</td>\n",
       "      <td>0.720441</td>\n",
       "      <td>False</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100</td>\n",
       "      <td>4114</td>\n",
       "      <td>0.309927</td>\n",
       "      <td>0.260014</td>\n",
       "      <td>0.185656</td>\n",
       "      <td>0.276678</td>\n",
       "      <td>0.270105</td>\n",
       "      <td>0.180168</td>\n",
       "      <td>0.932399</td>\n",
       "      <td>0.962904</td>\n",
       "      <td>0.910822</td>\n",
       "      <td>0.957076</td>\n",
       "      <td>0.999785</td>\n",
       "      <td>0.999297</td>\n",
       "      <td>0.999941</td>\n",
       "      <td>0.999121</td>\n",
       "      <td>0.983668</td>\n",
       "      <td>0.991767</td>\n",
       "      <td>9.684386e-01</td>\n",
       "      <td>0.982268</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.977206</td>\n",
       "      <td>0.797835</td>\n",
       "      <td>0.406689</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.977423</td>\n",
       "      <td>0.741544</td>\n",
       "      <td>0.422529</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.656684</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>231</td>\n",
       "      <td>0.435983</td>\n",
       "      <td>0.279231</td>\n",
       "      <td>0.185035</td>\n",
       "      <td>0.299665</td>\n",
       "      <td>0.271672</td>\n",
       "      <td>0.188429</td>\n",
       "      <td>0.872037</td>\n",
       "      <td>0.922563</td>\n",
       "      <td>0.817956</td>\n",
       "      <td>0.916699</td>\n",
       "      <td>0.733982</td>\n",
       "      <td>0.715878</td>\n",
       "      <td>0.797588</td>\n",
       "      <td>0.900100</td>\n",
       "      <td>0.977441</td>\n",
       "      <td>0.990781</td>\n",
       "      <td>9.554953e-01</td>\n",
       "      <td>0.971250</td>\n",
       "      <td>0.934402</td>\n",
       "      <td>0.969146</td>\n",
       "      <td>0.883653</td>\n",
       "      <td>0.928505</td>\n",
       "      <td>0.920096</td>\n",
       "      <td>0.880906</td>\n",
       "      <td>0.529131</td>\n",
       "      <td>0.490530</td>\n",
       "      <td>0.934402</td>\n",
       "      <td>0.915424</td>\n",
       "      <td>0.812598</td>\n",
       "      <td>0.863527</td>\n",
       "      <td>0.376286</td>\n",
       "      <td>0.415109</td>\n",
       "      <td>0.883653</td>\n",
       "      <td>0.853920</td>\n",
       "      <td>0.224368</td>\n",
       "      <td>0.700841</td>\n",
       "      <td>0.905412</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.392922</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100</td>\n",
       "      <td>5244</td>\n",
       "      <td>0.551568</td>\n",
       "      <td>0.602756</td>\n",
       "      <td>0.363885</td>\n",
       "      <td>0.404959</td>\n",
       "      <td>0.607823</td>\n",
       "      <td>0.362408</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.958144</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.945128</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.990909</td>\n",
       "      <td>0.905914</td>\n",
       "      <td>0.976078</td>\n",
       "      <td>0.983010</td>\n",
       "      <td>9.529703e-01</td>\n",
       "      <td>0.974258</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.978320</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.897213</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.355641</td>\n",
       "      <td>0.629555</td>\n",
       "      <td>0.689286</td>\n",
       "      <td>0.476599</td>\n",
       "      <td>0.775899</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100</td>\n",
       "      <td>733</td>\n",
       "      <td>0.508654</td>\n",
       "      <td>0.270065</td>\n",
       "      <td>0.181497</td>\n",
       "      <td>0.355532</td>\n",
       "      <td>0.293558</td>\n",
       "      <td>0.170425</td>\n",
       "      <td>0.893924</td>\n",
       "      <td>0.927862</td>\n",
       "      <td>0.797668</td>\n",
       "      <td>0.919038</td>\n",
       "      <td>0.999892</td>\n",
       "      <td>0.998867</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999008</td>\n",
       "      <td>0.974111</td>\n",
       "      <td>0.988849</td>\n",
       "      <td>9.546172e-01</td>\n",
       "      <td>0.971961</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.865899</td>\n",
       "      <td>0.796603</td>\n",
       "      <td>0.284657</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.850601</td>\n",
       "      <td>0.593352</td>\n",
       "      <td>0.247837</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.188509</td>\n",
       "      <td>0.575006</td>\n",
       "      <td>0.689286</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.604054</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>100</td>\n",
       "      <td>3896</td>\n",
       "      <td>0.518026</td>\n",
       "      <td>0.536171</td>\n",
       "      <td>0.298879</td>\n",
       "      <td>0.428593</td>\n",
       "      <td>0.590710</td>\n",
       "      <td>0.391840</td>\n",
       "      <td>0.970234</td>\n",
       "      <td>0.972461</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.967205</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.976449</td>\n",
       "      <td>0.988082</td>\n",
       "      <td>9.620776e-01</td>\n",
       "      <td>0.961087</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.912374</td>\n",
       "      <td>0.338805</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.841140</td>\n",
       "      <td>0.310185</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.764766</td>\n",
       "      <td>False</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>100</td>\n",
       "      <td>4572</td>\n",
       "      <td>0.498664</td>\n",
       "      <td>0.326860</td>\n",
       "      <td>0.179187</td>\n",
       "      <td>0.349483</td>\n",
       "      <td>0.341777</td>\n",
       "      <td>0.209361</td>\n",
       "      <td>0.948135</td>\n",
       "      <td>0.927444</td>\n",
       "      <td>0.939123</td>\n",
       "      <td>0.925689</td>\n",
       "      <td>0.998685</td>\n",
       "      <td>0.986242</td>\n",
       "      <td>0.988918</td>\n",
       "      <td>0.640430</td>\n",
       "      <td>0.982011</td>\n",
       "      <td>0.990924</td>\n",
       "      <td>9.532030e-01</td>\n",
       "      <td>0.978660</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.908057</td>\n",
       "      <td>0.713808</td>\n",
       "      <td>0.345801</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.899051</td>\n",
       "      <td>0.600257</td>\n",
       "      <td>0.263837</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.425165</td>\n",
       "      <td>0.556259</td>\n",
       "      <td>0.925314</td>\n",
       "      <td>0.476599</td>\n",
       "      <td>0.618412</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>100</td>\n",
       "      <td>2823</td>\n",
       "      <td>0.542816</td>\n",
       "      <td>0.272979</td>\n",
       "      <td>0.187657</td>\n",
       "      <td>0.296875</td>\n",
       "      <td>0.278486</td>\n",
       "      <td>0.199103</td>\n",
       "      <td>0.887384</td>\n",
       "      <td>0.909117</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.885990</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.639737</td>\n",
       "      <td>0.740649</td>\n",
       "      <td>0.980833</td>\n",
       "      <td>0.990628</td>\n",
       "      <td>2.500710e-09</td>\n",
       "      <td>0.788591</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.970817</td>\n",
       "      <td>0.724138</td>\n",
       "      <td>0.247397</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.949335</td>\n",
       "      <td>0.548854</td>\n",
       "      <td>0.229812</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.580942</td>\n",
       "      <td>False</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>100</td>\n",
       "      <td>1592</td>\n",
       "      <td>0.453901</td>\n",
       "      <td>0.438724</td>\n",
       "      <td>0.198668</td>\n",
       "      <td>0.296394</td>\n",
       "      <td>0.365019</td>\n",
       "      <td>0.222920</td>\n",
       "      <td>0.902751</td>\n",
       "      <td>0.926640</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.905401</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999490</td>\n",
       "      <td>0.984330</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.973381</td>\n",
       "      <td>0.991938</td>\n",
       "      <td>9.606524e-01</td>\n",
       "      <td>0.971783</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.945727</td>\n",
       "      <td>0.815585</td>\n",
       "      <td>0.329073</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.889008</td>\n",
       "      <td>0.732580</td>\n",
       "      <td>0.247194</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.215764</td>\n",
       "      <td>0.644082</td>\n",
       "      <td>0.488195</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.648037</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>100</td>\n",
       "      <td>1185</td>\n",
       "      <td>0.437521</td>\n",
       "      <td>0.197340</td>\n",
       "      <td>0.151455</td>\n",
       "      <td>0.280486</td>\n",
       "      <td>0.232980</td>\n",
       "      <td>0.155569</td>\n",
       "      <td>0.901545</td>\n",
       "      <td>0.921714</td>\n",
       "      <td>0.654037</td>\n",
       "      <td>0.911570</td>\n",
       "      <td>0.995473</td>\n",
       "      <td>0.992384</td>\n",
       "      <td>0.375339</td>\n",
       "      <td>0.979698</td>\n",
       "      <td>0.983954</td>\n",
       "      <td>0.992425</td>\n",
       "      <td>9.599578e-01</td>\n",
       "      <td>0.970949</td>\n",
       "      <td>0.971604</td>\n",
       "      <td>0.987393</td>\n",
       "      <td>0.880267</td>\n",
       "      <td>0.948704</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.857459</td>\n",
       "      <td>0.699810</td>\n",
       "      <td>0.319292</td>\n",
       "      <td>0.971132</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.808575</td>\n",
       "      <td>0.420889</td>\n",
       "      <td>0.275842</td>\n",
       "      <td>0.854551</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.200531</td>\n",
       "      <td>0.796364</td>\n",
       "      <td>0.898161</td>\n",
       "      <td>0.538176</td>\n",
       "      <td>0.467105</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>100</td>\n",
       "      <td>883</td>\n",
       "      <td>0.433015</td>\n",
       "      <td>0.601558</td>\n",
       "      <td>0.872109</td>\n",
       "      <td>0.345507</td>\n",
       "      <td>0.597342</td>\n",
       "      <td>0.807199</td>\n",
       "      <td>0.840931</td>\n",
       "      <td>0.933173</td>\n",
       "      <td>0.797668</td>\n",
       "      <td>0.922610</td>\n",
       "      <td>0.999966</td>\n",
       "      <td>0.999663</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.976885</td>\n",
       "      <td>0.988305</td>\n",
       "      <td>9.519369e-01</td>\n",
       "      <td>0.973318</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.889686</td>\n",
       "      <td>0.281991</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.714460</td>\n",
       "      <td>0.247837</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.297119</td>\n",
       "      <td>0.765555</td>\n",
       "      <td>0.918007</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.699790</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>100</td>\n",
       "      <td>2456</td>\n",
       "      <td>0.506571</td>\n",
       "      <td>0.186860</td>\n",
       "      <td>0.160455</td>\n",
       "      <td>0.196499</td>\n",
       "      <td>0.194339</td>\n",
       "      <td>0.160468</td>\n",
       "      <td>0.885565</td>\n",
       "      <td>0.871551</td>\n",
       "      <td>0.635296</td>\n",
       "      <td>0.668224</td>\n",
       "      <td>0.768235</td>\n",
       "      <td>0.762891</td>\n",
       "      <td>0.685551</td>\n",
       "      <td>0.309989</td>\n",
       "      <td>0.987835</td>\n",
       "      <td>0.987893</td>\n",
       "      <td>9.538829e-01</td>\n",
       "      <td>0.713962</td>\n",
       "      <td>0.887148</td>\n",
       "      <td>0.937832</td>\n",
       "      <td>0.820744</td>\n",
       "      <td>0.906416</td>\n",
       "      <td>0.892741</td>\n",
       "      <td>0.778592</td>\n",
       "      <td>0.641168</td>\n",
       "      <td>0.268298</td>\n",
       "      <td>0.879809</td>\n",
       "      <td>0.859276</td>\n",
       "      <td>0.718486</td>\n",
       "      <td>0.784513</td>\n",
       "      <td>0.323591</td>\n",
       "      <td>0.215743</td>\n",
       "      <td>0.817136</td>\n",
       "      <td>0.794983</td>\n",
       "      <td>0.143607</td>\n",
       "      <td>0.642601</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.289605</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>100</td>\n",
       "      <td>5326</td>\n",
       "      <td>0.490244</td>\n",
       "      <td>0.380940</td>\n",
       "      <td>0.186081</td>\n",
       "      <td>0.408533</td>\n",
       "      <td>0.426500</td>\n",
       "      <td>0.226843</td>\n",
       "      <td>0.896534</td>\n",
       "      <td>0.762814</td>\n",
       "      <td>0.820543</td>\n",
       "      <td>0.518491</td>\n",
       "      <td>0.918731</td>\n",
       "      <td>0.987538</td>\n",
       "      <td>0.866146</td>\n",
       "      <td>0.939288</td>\n",
       "      <td>0.978446</td>\n",
       "      <td>0.375235</td>\n",
       "      <td>9.540923e-01</td>\n",
       "      <td>0.967144</td>\n",
       "      <td>0.923487</td>\n",
       "      <td>0.969880</td>\n",
       "      <td>0.855463</td>\n",
       "      <td>0.937715</td>\n",
       "      <td>0.911106</td>\n",
       "      <td>0.915145</td>\n",
       "      <td>0.706214</td>\n",
       "      <td>0.257861</td>\n",
       "      <td>0.919181</td>\n",
       "      <td>0.909812</td>\n",
       "      <td>0.832597</td>\n",
       "      <td>0.838619</td>\n",
       "      <td>0.626924</td>\n",
       "      <td>0.214428</td>\n",
       "      <td>0.828453</td>\n",
       "      <td>0.812806</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.848694</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.404818</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>100</td>\n",
       "      <td>1389</td>\n",
       "      <td>0.449655</td>\n",
       "      <td>0.173582</td>\n",
       "      <td>0.152193</td>\n",
       "      <td>0.190415</td>\n",
       "      <td>0.158163</td>\n",
       "      <td>0.123656</td>\n",
       "      <td>0.695581</td>\n",
       "      <td>0.822994</td>\n",
       "      <td>0.157983</td>\n",
       "      <td>0.388861</td>\n",
       "      <td>0.643811</td>\n",
       "      <td>0.472842</td>\n",
       "      <td>0.488442</td>\n",
       "      <td>0.177004</td>\n",
       "      <td>0.980936</td>\n",
       "      <td>0.988426</td>\n",
       "      <td>1.762766e-05</td>\n",
       "      <td>0.050712</td>\n",
       "      <td>0.809310</td>\n",
       "      <td>0.889343</td>\n",
       "      <td>0.293965</td>\n",
       "      <td>0.517576</td>\n",
       "      <td>0.851223</td>\n",
       "      <td>0.738997</td>\n",
       "      <td>0.534355</td>\n",
       "      <td>0.254799</td>\n",
       "      <td>0.803128</td>\n",
       "      <td>0.766201</td>\n",
       "      <td>0.388563</td>\n",
       "      <td>0.290308</td>\n",
       "      <td>0.130693</td>\n",
       "      <td>0.113132</td>\n",
       "      <td>0.293965</td>\n",
       "      <td>0.202365</td>\n",
       "      <td>0.134726</td>\n",
       "      <td>0.756770</td>\n",
       "      <td>0.557407</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.150919</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>100</td>\n",
       "      <td>5153</td>\n",
       "      <td>0.498049</td>\n",
       "      <td>0.255375</td>\n",
       "      <td>0.205944</td>\n",
       "      <td>0.346341</td>\n",
       "      <td>0.248265</td>\n",
       "      <td>0.204870</td>\n",
       "      <td>0.907639</td>\n",
       "      <td>0.946790</td>\n",
       "      <td>0.714735</td>\n",
       "      <td>0.935742</td>\n",
       "      <td>0.999952</td>\n",
       "      <td>0.998964</td>\n",
       "      <td>0.946267</td>\n",
       "      <td>0.993401</td>\n",
       "      <td>0.982195</td>\n",
       "      <td>0.990205</td>\n",
       "      <td>9.602068e-01</td>\n",
       "      <td>0.971601</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.897559</td>\n",
       "      <td>0.648575</td>\n",
       "      <td>0.346042</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.869588</td>\n",
       "      <td>0.493623</td>\n",
       "      <td>0.301690</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.236706</td>\n",
       "      <td>0.725834</td>\n",
       "      <td>0.889163</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.603780</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>100</td>\n",
       "      <td>1975</td>\n",
       "      <td>0.517766</td>\n",
       "      <td>0.246333</td>\n",
       "      <td>0.155104</td>\n",
       "      <td>0.365803</td>\n",
       "      <td>0.262292</td>\n",
       "      <td>0.171215</td>\n",
       "      <td>0.847666</td>\n",
       "      <td>0.844332</td>\n",
       "      <td>0.714735</td>\n",
       "      <td>0.735052</td>\n",
       "      <td>0.998707</td>\n",
       "      <td>0.991175</td>\n",
       "      <td>0.897693</td>\n",
       "      <td>0.943254</td>\n",
       "      <td>0.977903</td>\n",
       "      <td>0.993223</td>\n",
       "      <td>7.340050e-01</td>\n",
       "      <td>0.788591</td>\n",
       "      <td>0.977303</td>\n",
       "      <td>0.987493</td>\n",
       "      <td>0.930794</td>\n",
       "      <td>0.962515</td>\n",
       "      <td>0.966581</td>\n",
       "      <td>0.874183</td>\n",
       "      <td>0.652770</td>\n",
       "      <td>0.307714</td>\n",
       "      <td>0.976264</td>\n",
       "      <td>0.967525</td>\n",
       "      <td>0.894120</td>\n",
       "      <td>0.879221</td>\n",
       "      <td>0.386746</td>\n",
       "      <td>0.281545</td>\n",
       "      <td>0.924241</td>\n",
       "      <td>0.908044</td>\n",
       "      <td>0.185603</td>\n",
       "      <td>0.757168</td>\n",
       "      <td>0.839198</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.428290</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>100</td>\n",
       "      <td>705</td>\n",
       "      <td>0.372423</td>\n",
       "      <td>0.466228</td>\n",
       "      <td>0.296158</td>\n",
       "      <td>0.355532</td>\n",
       "      <td>0.485242</td>\n",
       "      <td>0.402482</td>\n",
       "      <td>0.765789</td>\n",
       "      <td>0.937770</td>\n",
       "      <td>0.694703</td>\n",
       "      <td>0.920472</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>0.995581</td>\n",
       "      <td>0.986567</td>\n",
       "      <td>0.997620</td>\n",
       "      <td>0.980992</td>\n",
       "      <td>0.987018</td>\n",
       "      <td>9.519369e-01</td>\n",
       "      <td>0.973318</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.727823</td>\n",
       "      <td>0.278443</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.497310</td>\n",
       "      <td>0.247837</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.161334</td>\n",
       "      <td>0.755283</td>\n",
       "      <td>0.694804</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.632151</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>100</td>\n",
       "      <td>2465</td>\n",
       "      <td>0.400593</td>\n",
       "      <td>0.496899</td>\n",
       "      <td>0.300016</td>\n",
       "      <td>0.359965</td>\n",
       "      <td>0.486943</td>\n",
       "      <td>0.300016</td>\n",
       "      <td>0.938961</td>\n",
       "      <td>0.966689</td>\n",
       "      <td>0.920880</td>\n",
       "      <td>0.955600</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.976880</td>\n",
       "      <td>0.988303</td>\n",
       "      <td>9.550776e-01</td>\n",
       "      <td>0.981918</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.957711</td>\n",
       "      <td>0.885079</td>\n",
       "      <td>0.981948</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.949175</td>\n",
       "      <td>0.827598</td>\n",
       "      <td>0.859332</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.231866</td>\n",
       "      <td>0.744921</td>\n",
       "      <td>0.919836</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.741689</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>100</td>\n",
       "      <td>4826</td>\n",
       "      <td>0.455674</td>\n",
       "      <td>0.314752</td>\n",
       "      <td>0.164622</td>\n",
       "      <td>0.285976</td>\n",
       "      <td>0.263800</td>\n",
       "      <td>0.141633</td>\n",
       "      <td>0.862357</td>\n",
       "      <td>0.829606</td>\n",
       "      <td>0.686363</td>\n",
       "      <td>0.696630</td>\n",
       "      <td>0.821795</td>\n",
       "      <td>0.697329</td>\n",
       "      <td>0.349369</td>\n",
       "      <td>0.179964</td>\n",
       "      <td>0.987204</td>\n",
       "      <td>0.988050</td>\n",
       "      <td>9.478470e-01</td>\n",
       "      <td>0.967856</td>\n",
       "      <td>0.901601</td>\n",
       "      <td>0.952641</td>\n",
       "      <td>0.800605</td>\n",
       "      <td>0.915722</td>\n",
       "      <td>0.921890</td>\n",
       "      <td>0.843335</td>\n",
       "      <td>0.630609</td>\n",
       "      <td>0.228930</td>\n",
       "      <td>0.893790</td>\n",
       "      <td>0.867906</td>\n",
       "      <td>0.824654</td>\n",
       "      <td>0.740736</td>\n",
       "      <td>0.508417</td>\n",
       "      <td>0.181875</td>\n",
       "      <td>0.800605</td>\n",
       "      <td>0.774736</td>\n",
       "      <td>0.196729</td>\n",
       "      <td>0.753039</td>\n",
       "      <td>0.926500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.307623</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>100</td>\n",
       "      <td>4361</td>\n",
       "      <td>0.245022</td>\n",
       "      <td>0.156215</td>\n",
       "      <td>0.192543</td>\n",
       "      <td>0.210180</td>\n",
       "      <td>0.221758</td>\n",
       "      <td>0.182364</td>\n",
       "      <td>0.786647</td>\n",
       "      <td>0.825674</td>\n",
       "      <td>0.721867</td>\n",
       "      <td>0.800733</td>\n",
       "      <td>0.760857</td>\n",
       "      <td>0.743708</td>\n",
       "      <td>0.612054</td>\n",
       "      <td>0.321660</td>\n",
       "      <td>0.977733</td>\n",
       "      <td>0.988820</td>\n",
       "      <td>9.693904e-01</td>\n",
       "      <td>0.983416</td>\n",
       "      <td>0.858266</td>\n",
       "      <td>0.944924</td>\n",
       "      <td>0.834894</td>\n",
       "      <td>0.933571</td>\n",
       "      <td>0.803079</td>\n",
       "      <td>0.691092</td>\n",
       "      <td>0.555945</td>\n",
       "      <td>0.308838</td>\n",
       "      <td>0.858266</td>\n",
       "      <td>0.831412</td>\n",
       "      <td>0.746720</td>\n",
       "      <td>0.598453</td>\n",
       "      <td>0.370800</td>\n",
       "      <td>0.266747</td>\n",
       "      <td>0.834894</td>\n",
       "      <td>0.813473</td>\n",
       "      <td>0.234463</td>\n",
       "      <td>0.688798</td>\n",
       "      <td>0.305225</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.281980</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    from    to  Doc2Vec:Wikipedia,Size=300  Word2Vec:Wikipedia,Size=300,Mean  Word2Vec:Wikipedia,Size=300,Max  Doc2Vec Phenes:Wikipedia,Size=300  Word2Vec Phenes:Wikipedia,Size=300,Mean  Word2Vec Phenes:Wikipedia,Size=300,Max  NOBLE Coder:Precise,TFIDF  NOBLE Coder:Partial,TFIDF  NOBLE Coder Phenes:Precise,TFIDF  NOBLE Coder Phenes:Partial,TFIDF  Topic Models:NMF,Full,Topics=50  Topic Models:NMF,Full,Topics=100  Topic Models Phenes:NMF,Full,Topics=50  Topic Models Phenes:NMF,Full,Topics=100  Topic Models:LDA,Full,Topics=50  Topic Models:LDA,Full,Topics=100  Topic Models Phenes:LDA,Full,Topics=50  Topic Models Phenes:LDA,Full,Topics=100  N-Grams:Full,Words,1-grams,TFIDF  N-Grams:Full,Words,1-grams,2-grams,TFIDF  N-Grams Phenes:Full,Words,1-grams,TFIDF  N-Grams Phenes:Full,Words,1-grams,2-grams,TFIDF  N-Grams:Full,Nouns,Adjectives,1-grams  N-Grams:Linares_Pontes,Words,1-grams  N-Grams:Full,Precise_Annotations,Words,1-grams  N-Grams:Full,Partial_Annotations,Words,1-grams  \\\n",
       "0    100  1145                    0.504560                          0.503235                         0.263459                           0.414963                                 0.478481                                0.288674                   0.857573                   0.928872                          0.796288                          0.900807                         1.000000                          1.000000                                1.000000                                 0.995888                         0.980399                          0.990102                            9.668565e-01                                 0.981963                          1.000000                                  1.000000                                 1.000000                                         1.000000                               1.000000                              1.000000                                        0.836855                                        0.566964   \n",
       "1    100  4114                    0.309927                          0.260014                         0.185656                           0.276678                                 0.270105                                0.180168                   0.932399                   0.962904                          0.910822                          0.957076                         0.999785                          0.999297                                0.999941                                 0.999121                         0.983668                          0.991767                            9.684386e-01                                 0.982268                          1.000000                                  1.000000                                 1.000000                                         1.000000                               1.000000                              0.977206                                        0.797835                                        0.406689   \n",
       "2    100   231                    0.435983                          0.279231                         0.185035                           0.299665                                 0.271672                                0.188429                   0.872037                   0.922563                          0.817956                          0.916699                         0.733982                          0.715878                                0.797588                                 0.900100                         0.977441                          0.990781                            9.554953e-01                                 0.971250                          0.934402                                  0.969146                                 0.883653                                         0.928505                               0.920096                              0.880906                                        0.529131                                        0.490530   \n",
       "3    100  5244                    0.551568                          0.602756                         0.363885                           0.404959                                 0.607823                                0.362408                   1.000000                   0.958144                          1.000000                          0.945128                         1.000000                          1.000000                                0.990909                                 0.905914                         0.976078                          0.983010                            9.529703e-01                                 0.974258                          1.000000                                  1.000000                                 1.000000                                         1.000000                               1.000000                              1.000000                                        1.000000                                        0.978320   \n",
       "4    100   733                    0.508654                          0.270065                         0.181497                           0.355532                                 0.293558                                0.170425                   0.893924                   0.927862                          0.797668                          0.919038                         0.999892                          0.998867                                1.000000                                 0.999008                         0.974111                          0.988849                            9.546172e-01                                 0.971961                          1.000000                                  1.000000                                 1.000000                                         1.000000                               1.000000                              0.865899                                        0.796603                                        0.284657   \n",
       "5    100  3896                    0.518026                          0.536171                         0.298879                           0.428593                                 0.590710                                0.391840                   0.970234                   0.972461                          1.000000                          0.967205                         1.000000                          1.000000                                1.000000                                 1.000000                         0.976449                          0.988082                            9.620776e-01                                 0.961087                          1.000000                                  1.000000                                 1.000000                                         1.000000                               1.000000                              1.000000                                        0.912374                                        0.338805   \n",
       "6    100  4572                    0.498664                          0.326860                         0.179187                           0.349483                                 0.341777                                0.209361                   0.948135                   0.927444                          0.939123                          0.925689                         0.998685                          0.986242                                0.988918                                 0.640430                         0.982011                          0.990924                            9.532030e-01                                 0.978660                          1.000000                                  1.000000                                 1.000000                                         1.000000                               1.000000                              0.908057                                        0.713808                                        0.345801   \n",
       "7    100  2823                    0.542816                          0.272979                         0.187657                           0.296875                                 0.278486                                0.199103                   0.887384                   0.909117                          1.000000                          0.885990                         1.000000                          1.000000                                0.639737                                 0.740649                         0.980833                          0.990628                            2.500710e-09                                 0.788591                          1.000000                                  1.000000                                 1.000000                                         1.000000                               1.000000                              0.970817                                        0.724138                                        0.247397   \n",
       "8    100  1592                    0.453901                          0.438724                         0.198668                           0.296394                                 0.365019                                0.222920                   0.902751                   0.926640                          1.000000                          0.905401                         1.000000                          0.999490                                0.984330                                 1.000000                         0.973381                          0.991938                            9.606524e-01                                 0.971783                          1.000000                                  1.000000                                 1.000000                                         1.000000                               1.000000                              0.945727                                        0.815585                                        0.329073   \n",
       "9    100  1185                    0.437521                          0.197340                         0.151455                           0.280486                                 0.232980                                0.155569                   0.901545                   0.921714                          0.654037                          0.911570                         0.995473                          0.992384                                0.375339                                 0.979698                         0.983954                          0.992425                            9.599578e-01                                 0.970949                          0.971604                                  0.987393                                 0.880267                                         0.948704                               1.000000                              0.857459                                        0.699810                                        0.319292   \n",
       "10   100   883                    0.433015                          0.601558                         0.872109                           0.345507                                 0.597342                                0.807199                   0.840931                   0.933173                          0.797668                          0.922610                         0.999966                          0.999663                                1.000000                                 1.000000                         0.976885                          0.988305                            9.519369e-01                                 0.973318                          1.000000                                  1.000000                                 1.000000                                         1.000000                               1.000000                              1.000000                                        0.889686                                        0.281991   \n",
       "11   100  2456                    0.506571                          0.186860                         0.160455                           0.196499                                 0.194339                                0.160468                   0.885565                   0.871551                          0.635296                          0.668224                         0.768235                          0.762891                                0.685551                                 0.309989                         0.987835                          0.987893                            9.538829e-01                                 0.713962                          0.887148                                  0.937832                                 0.820744                                         0.906416                               0.892741                              0.778592                                        0.641168                                        0.268298   \n",
       "12   100  5326                    0.490244                          0.380940                         0.186081                           0.408533                                 0.426500                                0.226843                   0.896534                   0.762814                          0.820543                          0.518491                         0.918731                          0.987538                                0.866146                                 0.939288                         0.978446                          0.375235                            9.540923e-01                                 0.967144                          0.923487                                  0.969880                                 0.855463                                         0.937715                               0.911106                              0.915145                                        0.706214                                        0.257861   \n",
       "13   100  1389                    0.449655                          0.173582                         0.152193                           0.190415                                 0.158163                                0.123656                   0.695581                   0.822994                          0.157983                          0.388861                         0.643811                          0.472842                                0.488442                                 0.177004                         0.980936                          0.988426                            1.762766e-05                                 0.050712                          0.809310                                  0.889343                                 0.293965                                         0.517576                               0.851223                              0.738997                                        0.534355                                        0.254799   \n",
       "14   100  5153                    0.498049                          0.255375                         0.205944                           0.346341                                 0.248265                                0.204870                   0.907639                   0.946790                          0.714735                          0.935742                         0.999952                          0.998964                                0.946267                                 0.993401                         0.982195                          0.990205                            9.602068e-01                                 0.971601                          1.000000                                  1.000000                                 1.000000                                         1.000000                               1.000000                              0.897559                                        0.648575                                        0.346042   \n",
       "15   100  1975                    0.517766                          0.246333                         0.155104                           0.365803                                 0.262292                                0.171215                   0.847666                   0.844332                          0.714735                          0.735052                         0.998707                          0.991175                                0.897693                                 0.943254                         0.977903                          0.993223                            7.340050e-01                                 0.788591                          0.977303                                  0.987493                                 0.930794                                         0.962515                               0.966581                              0.874183                                        0.652770                                        0.307714   \n",
       "16   100   705                    0.372423                          0.466228                         0.296158                           0.355532                                 0.485242                                0.402482                   0.765789                   0.937770                          0.694703                          0.920472                         0.999997                          0.995581                                0.986567                                 0.997620                         0.980992                          0.987018                            9.519369e-01                                 0.973318                          1.000000                                  1.000000                                 1.000000                                         1.000000                               1.000000                              1.000000                                        0.727823                                        0.278443   \n",
       "17   100  2465                    0.400593                          0.496899                         0.300016                           0.359965                                 0.486943                                0.300016                   0.938961                   0.966689                          0.920880                          0.955600                         1.000000                          1.000000                                1.000000                                 1.000000                         0.976880                          0.988303                            9.550776e-01                                 0.981918                          1.000000                                  1.000000                                 1.000000                                         1.000000                               1.000000                              0.957711                                        0.885079                                        0.981948   \n",
       "18   100  4826                    0.455674                          0.314752                         0.164622                           0.285976                                 0.263800                                0.141633                   0.862357                   0.829606                          0.686363                          0.696630                         0.821795                          0.697329                                0.349369                                 0.179964                         0.987204                          0.988050                            9.478470e-01                                 0.967856                          0.901601                                  0.952641                                 0.800605                                         0.915722                               0.921890                              0.843335                                        0.630609                                        0.228930   \n",
       "19   100  4361                    0.245022                          0.156215                         0.192543                           0.210180                                 0.221758                                0.182364                   0.786647                   0.825674                          0.721867                          0.800733                         0.760857                          0.743708                                0.612054                                 0.321660                         0.977733                          0.988820                            9.693904e-01                                 0.983416                          0.858266                                  0.944924                                 0.834894                                         0.933571                               0.803079                              0.691092                                        0.555945                                        0.308838   \n",
       "\n",
       "    N-Grams:Full,Plant Overrepresented Tokens,1-grams  N-Grams:Full,Bio Ontology Tokens,1-grams  N-Grams Phenes:Full,Nouns,Adjectives,1-grams  N-Grams Phenes:Linares_Pontes,Words,1-grams  N-Grams Phenes:Full,Precise_Annotations,Words,1-grams  N-Grams Phenes:Full,Partial_Annotations,Words,1-grams  N-Grams Phenes:Full,Plant Overrepresented Tokens,1-grams  N-Grams Phenes:Full,Bio Ontology Tokens,1-grams  GO:Union  PO:Union  GO:Maximum  PO:Maximum      Mean   same  pathways  kegg_only  pmn_only  \n",
       "0                                            1.000000                                  1.000000                                      1.000000                                     1.000000                                           0.586272                                               0.428988                                               1.000000                                                1.000000  1.000000  0.917046    1.000000    0.646146  0.720441  False        -1         -1        -1  \n",
       "1                                            1.000000                                  1.000000                                      1.000000                                     0.977423                                           0.741544                                               0.422529                                               1.000000                                                1.000000  1.000000  1.000000    1.000000    1.000000  0.656684   True        -1         -1        -1  \n",
       "2                                            0.934402                                  0.915424                                      0.812598                                     0.863527                                           0.376286                                               0.415109                                               0.883653                                                0.853920  0.224368  0.700841    0.905412    0.000000  0.392922   True        -1         -1        -1  \n",
       "3                                            1.000000                                  1.000000                                      1.000000                                     1.000000                                           1.000000                                               0.897213                                               1.000000                                                1.000000  0.355641  0.629555    0.689286    0.476599  0.775899   True        -1         -1        -1  \n",
       "4                                            1.000000                                  1.000000                                      1.000000                                     0.850601                                           0.593352                                               0.247837                                               1.000000                                                1.000000  0.188509  0.575006    0.689286    0.000000  0.604054   True        -1         -1        -1  \n",
       "5                                            1.000000                                  1.000000                                      1.000000                                     1.000000                                           0.841140                                               0.310185                                               1.000000                                                1.000000  1.000000  1.000000    1.000000    1.000000  0.764766  False        -1         -1        -1  \n",
       "6                                            1.000000                                  1.000000                                      1.000000                                     0.899051                                           0.600257                                               0.263837                                               1.000000                                                1.000000  0.425165  0.556259    0.925314    0.476599  0.618412   True        -1         -1        -1  \n",
       "7                                            1.000000                                  1.000000                                      1.000000                                     0.949335                                           0.548854                                               0.229812                                               1.000000                                                1.000000  1.000000  1.000000    1.000000    1.000000  0.580942  False        -1         -1        -1  \n",
       "8                                            1.000000                                  1.000000                                      1.000000                                     0.889008                                           0.732580                                               0.247194                                               1.000000                                                1.000000  0.215764  0.644082    0.488195    0.000000  0.648037   True        -1         -1        -1  \n",
       "9                                            0.971132                                  1.000000                                      1.000000                                     0.808575                                           0.420889                                               0.275842                                               0.854551                                                1.000000  0.200531  0.796364    0.898161    0.538176  0.467105   True        -1         -1        -1  \n",
       "10                                           1.000000                                  1.000000                                      1.000000                                     1.000000                                           0.714460                                               0.247837                                               1.000000                                                1.000000  0.297119  0.765555    0.918007    0.000000  0.699790   True        -1         -1        -1  \n",
       "11                                           0.879809                                  0.859276                                      0.718486                                     0.784513                                           0.323591                                               0.215743                                               0.817136                                                0.794983  0.143607  0.642601    0.000000    0.000000  0.289605   True        -1         -1        -1  \n",
       "12                                           0.919181                                  0.909812                                      0.832597                                     0.838619                                           0.626924                                               0.214428                                               0.828453                                                0.812806  1.000000  0.848694    1.000000    0.000000  0.404818   True        -1         -1        -1  \n",
       "13                                           0.803128                                  0.766201                                      0.388563                                     0.290308                                           0.130693                                               0.113132                                               0.293965                                                0.202365  0.134726  0.756770    0.557407    0.000000  0.150919   True        -1         -1        -1  \n",
       "14                                           1.000000                                  1.000000                                      1.000000                                     0.869588                                           0.493623                                               0.301690                                               1.000000                                                1.000000  0.236706  0.725834    0.889163    0.000000  0.603780   True        -1         -1        -1  \n",
       "15                                           0.976264                                  0.967525                                      0.894120                                     0.879221                                           0.386746                                               0.281545                                               0.924241                                                0.908044  0.185603  0.757168    0.839198    0.000000  0.428290   True        -1         -1        -1  \n",
       "16                                           1.000000                                  1.000000                                      1.000000                                     1.000000                                           0.497310                                               0.247837                                               1.000000                                                1.000000  0.161334  0.755283    0.694804    0.000000  0.632151   True        -1         -1        -1  \n",
       "17                                           1.000000                                  1.000000                                      1.000000                                     0.949175                                           0.827598                                               0.859332                                               1.000000                                                1.000000  0.231866  0.744921    0.919836    0.000000  0.741689   True        -1         -1        -1  \n",
       "18                                           0.893790                                  0.867906                                      0.824654                                     0.740736                                           0.508417                                               0.181875                                               0.800605                                                0.774736  0.196729  0.753039    0.926500    0.000000  0.307623   True        -1         -1        -1  \n",
       "19                                           0.858266                                  0.831412                                      0.746720                                     0.598453                                           0.370800                                               0.266747                                               0.834894                                                0.813473  0.234463  0.688798    0.305225    0.000000  0.281980   True        -1         -1        -1  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add a column that indicates whether or not both genes of the pair mapped to a pathway resource.\n",
    "pathway_mapped_ids = set(pmn_mapped_ids)\n",
    "df[\"from_is_valid\"] = df[\"from\"].map(lambda x: x in pathway_mapped_ids)\n",
    "df[\"to_is_valid\"] = df[\"to\"].map(lambda x: x in pathway_mapped_ids)\n",
    "df[\"pair_is_valid\"] = df[\"from_is_valid\"]*df[\"to_is_valid\"]\n",
    "\n",
    "\n",
    "# Add a column giving the actual target output value for this biological task, with -1 for the irrelevant rows.\n",
    "df[\"pmn_only\"] = -1\n",
    "id_to_kegg_group_ids, kegg_group_id_to_ids = kegg_groups.get_groupings_for_dataset(dataset)\n",
    "id_to_pmn_group_ids, pmn_group_id_to_ids = pmn_groups.get_groupings_for_dataset(dataset)\n",
    "id_to_group_ids = {i:flatten([id_to_kegg_group_ids[i],id_to_pmn_group_ids[i]]) for i in dataset.get_ids()}\n",
    "df.loc[(df[\"pair_is_valid\"]==True),\"pmn_only\"] = df[[\"from\",\"to\"]].apply(lambda x: len(set(id_to_group_ids[x[\"from\"]]).intersection(set(id_to_group_ids[x[\"to\"]])))>0, axis=1)*1\n",
    "df.drop(labels=[\"from_is_valid\",\"to_is_valid\",\"pair_is_valid\"], axis=\"columns\", inplace=True)\n",
    "\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"subset_objective\"></a>\n",
    "### Using shared phenotype classification (Lloyd and Meinke et al., 2012) as the objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>from</th>\n",
       "      <th>to</th>\n",
       "      <th>Doc2Vec:Wikipedia,Size=300</th>\n",
       "      <th>Word2Vec:Wikipedia,Size=300,Mean</th>\n",
       "      <th>Word2Vec:Wikipedia,Size=300,Max</th>\n",
       "      <th>Doc2Vec Phenes:Wikipedia,Size=300</th>\n",
       "      <th>Word2Vec Phenes:Wikipedia,Size=300,Mean</th>\n",
       "      <th>Word2Vec Phenes:Wikipedia,Size=300,Max</th>\n",
       "      <th>NOBLE Coder:Precise,TFIDF</th>\n",
       "      <th>NOBLE Coder:Partial,TFIDF</th>\n",
       "      <th>NOBLE Coder Phenes:Precise,TFIDF</th>\n",
       "      <th>NOBLE Coder Phenes:Partial,TFIDF</th>\n",
       "      <th>Topic Models:NMF,Full,Topics=50</th>\n",
       "      <th>Topic Models:NMF,Full,Topics=100</th>\n",
       "      <th>Topic Models Phenes:NMF,Full,Topics=50</th>\n",
       "      <th>Topic Models Phenes:NMF,Full,Topics=100</th>\n",
       "      <th>Topic Models:LDA,Full,Topics=50</th>\n",
       "      <th>Topic Models:LDA,Full,Topics=100</th>\n",
       "      <th>Topic Models Phenes:LDA,Full,Topics=50</th>\n",
       "      <th>Topic Models Phenes:LDA,Full,Topics=100</th>\n",
       "      <th>N-Grams:Full,Words,1-grams,TFIDF</th>\n",
       "      <th>N-Grams:Full,Words,1-grams,2-grams,TFIDF</th>\n",
       "      <th>N-Grams Phenes:Full,Words,1-grams,TFIDF</th>\n",
       "      <th>N-Grams Phenes:Full,Words,1-grams,2-grams,TFIDF</th>\n",
       "      <th>N-Grams:Full,Nouns,Adjectives,1-grams</th>\n",
       "      <th>N-Grams:Linares_Pontes,Words,1-grams</th>\n",
       "      <th>N-Grams:Full,Precise_Annotations,Words,1-grams</th>\n",
       "      <th>N-Grams:Full,Partial_Annotations,Words,1-grams</th>\n",
       "      <th>N-Grams:Full,Plant Overrepresented Tokens,1-grams</th>\n",
       "      <th>N-Grams:Full,Bio Ontology Tokens,1-grams</th>\n",
       "      <th>N-Grams Phenes:Full,Nouns,Adjectives,1-grams</th>\n",
       "      <th>N-Grams Phenes:Linares_Pontes,Words,1-grams</th>\n",
       "      <th>N-Grams Phenes:Full,Precise_Annotations,Words,1-grams</th>\n",
       "      <th>N-Grams Phenes:Full,Partial_Annotations,Words,1-grams</th>\n",
       "      <th>N-Grams Phenes:Full,Plant Overrepresented Tokens,1-grams</th>\n",
       "      <th>N-Grams Phenes:Full,Bio Ontology Tokens,1-grams</th>\n",
       "      <th>GO:Union</th>\n",
       "      <th>PO:Union</th>\n",
       "      <th>GO:Maximum</th>\n",
       "      <th>PO:Maximum</th>\n",
       "      <th>Mean</th>\n",
       "      <th>same</th>\n",
       "      <th>pathways</th>\n",
       "      <th>kegg_only</th>\n",
       "      <th>pmn_only</th>\n",
       "      <th>subsets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>1145</td>\n",
       "      <td>0.504560</td>\n",
       "      <td>0.503235</td>\n",
       "      <td>0.263459</td>\n",
       "      <td>0.414963</td>\n",
       "      <td>0.478481</td>\n",
       "      <td>0.288674</td>\n",
       "      <td>0.857573</td>\n",
       "      <td>0.928872</td>\n",
       "      <td>0.796288</td>\n",
       "      <td>0.900807</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.995888</td>\n",
       "      <td>0.980399</td>\n",
       "      <td>0.990102</td>\n",
       "      <td>9.668565e-01</td>\n",
       "      <td>0.981963</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.836855</td>\n",
       "      <td>0.566964</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.586272</td>\n",
       "      <td>0.428988</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.917046</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.646146</td>\n",
       "      <td>0.720441</td>\n",
       "      <td>False</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100</td>\n",
       "      <td>4114</td>\n",
       "      <td>0.309927</td>\n",
       "      <td>0.260014</td>\n",
       "      <td>0.185656</td>\n",
       "      <td>0.276678</td>\n",
       "      <td>0.270105</td>\n",
       "      <td>0.180168</td>\n",
       "      <td>0.932399</td>\n",
       "      <td>0.962904</td>\n",
       "      <td>0.910822</td>\n",
       "      <td>0.957076</td>\n",
       "      <td>0.999785</td>\n",
       "      <td>0.999297</td>\n",
       "      <td>0.999941</td>\n",
       "      <td>0.999121</td>\n",
       "      <td>0.983668</td>\n",
       "      <td>0.991767</td>\n",
       "      <td>9.684386e-01</td>\n",
       "      <td>0.982268</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.977206</td>\n",
       "      <td>0.797835</td>\n",
       "      <td>0.406689</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.977423</td>\n",
       "      <td>0.741544</td>\n",
       "      <td>0.422529</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.656684</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>231</td>\n",
       "      <td>0.435983</td>\n",
       "      <td>0.279231</td>\n",
       "      <td>0.185035</td>\n",
       "      <td>0.299665</td>\n",
       "      <td>0.271672</td>\n",
       "      <td>0.188429</td>\n",
       "      <td>0.872037</td>\n",
       "      <td>0.922563</td>\n",
       "      <td>0.817956</td>\n",
       "      <td>0.916699</td>\n",
       "      <td>0.733982</td>\n",
       "      <td>0.715878</td>\n",
       "      <td>0.797588</td>\n",
       "      <td>0.900100</td>\n",
       "      <td>0.977441</td>\n",
       "      <td>0.990781</td>\n",
       "      <td>9.554953e-01</td>\n",
       "      <td>0.971250</td>\n",
       "      <td>0.934402</td>\n",
       "      <td>0.969146</td>\n",
       "      <td>0.883653</td>\n",
       "      <td>0.928505</td>\n",
       "      <td>0.920096</td>\n",
       "      <td>0.880906</td>\n",
       "      <td>0.529131</td>\n",
       "      <td>0.490530</td>\n",
       "      <td>0.934402</td>\n",
       "      <td>0.915424</td>\n",
       "      <td>0.812598</td>\n",
       "      <td>0.863527</td>\n",
       "      <td>0.376286</td>\n",
       "      <td>0.415109</td>\n",
       "      <td>0.883653</td>\n",
       "      <td>0.853920</td>\n",
       "      <td>0.224368</td>\n",
       "      <td>0.700841</td>\n",
       "      <td>0.905412</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.392922</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100</td>\n",
       "      <td>5244</td>\n",
       "      <td>0.551568</td>\n",
       "      <td>0.602756</td>\n",
       "      <td>0.363885</td>\n",
       "      <td>0.404959</td>\n",
       "      <td>0.607823</td>\n",
       "      <td>0.362408</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.958144</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.945128</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.990909</td>\n",
       "      <td>0.905914</td>\n",
       "      <td>0.976078</td>\n",
       "      <td>0.983010</td>\n",
       "      <td>9.529703e-01</td>\n",
       "      <td>0.974258</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.978320</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.897213</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.355641</td>\n",
       "      <td>0.629555</td>\n",
       "      <td>0.689286</td>\n",
       "      <td>0.476599</td>\n",
       "      <td>0.775899</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100</td>\n",
       "      <td>733</td>\n",
       "      <td>0.508654</td>\n",
       "      <td>0.270065</td>\n",
       "      <td>0.181497</td>\n",
       "      <td>0.355532</td>\n",
       "      <td>0.293558</td>\n",
       "      <td>0.170425</td>\n",
       "      <td>0.893924</td>\n",
       "      <td>0.927862</td>\n",
       "      <td>0.797668</td>\n",
       "      <td>0.919038</td>\n",
       "      <td>0.999892</td>\n",
       "      <td>0.998867</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999008</td>\n",
       "      <td>0.974111</td>\n",
       "      <td>0.988849</td>\n",
       "      <td>9.546172e-01</td>\n",
       "      <td>0.971961</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.865899</td>\n",
       "      <td>0.796603</td>\n",
       "      <td>0.284657</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.850601</td>\n",
       "      <td>0.593352</td>\n",
       "      <td>0.247837</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.188509</td>\n",
       "      <td>0.575006</td>\n",
       "      <td>0.689286</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.604054</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>100</td>\n",
       "      <td>3896</td>\n",
       "      <td>0.518026</td>\n",
       "      <td>0.536171</td>\n",
       "      <td>0.298879</td>\n",
       "      <td>0.428593</td>\n",
       "      <td>0.590710</td>\n",
       "      <td>0.391840</td>\n",
       "      <td>0.970234</td>\n",
       "      <td>0.972461</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.967205</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.976449</td>\n",
       "      <td>0.988082</td>\n",
       "      <td>9.620776e-01</td>\n",
       "      <td>0.961087</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.912374</td>\n",
       "      <td>0.338805</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.841140</td>\n",
       "      <td>0.310185</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.764766</td>\n",
       "      <td>False</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>100</td>\n",
       "      <td>4572</td>\n",
       "      <td>0.498664</td>\n",
       "      <td>0.326860</td>\n",
       "      <td>0.179187</td>\n",
       "      <td>0.349483</td>\n",
       "      <td>0.341777</td>\n",
       "      <td>0.209361</td>\n",
       "      <td>0.948135</td>\n",
       "      <td>0.927444</td>\n",
       "      <td>0.939123</td>\n",
       "      <td>0.925689</td>\n",
       "      <td>0.998685</td>\n",
       "      <td>0.986242</td>\n",
       "      <td>0.988918</td>\n",
       "      <td>0.640430</td>\n",
       "      <td>0.982011</td>\n",
       "      <td>0.990924</td>\n",
       "      <td>9.532030e-01</td>\n",
       "      <td>0.978660</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.908057</td>\n",
       "      <td>0.713808</td>\n",
       "      <td>0.345801</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.899051</td>\n",
       "      <td>0.600257</td>\n",
       "      <td>0.263837</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.425165</td>\n",
       "      <td>0.556259</td>\n",
       "      <td>0.925314</td>\n",
       "      <td>0.476599</td>\n",
       "      <td>0.618412</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>100</td>\n",
       "      <td>2823</td>\n",
       "      <td>0.542816</td>\n",
       "      <td>0.272979</td>\n",
       "      <td>0.187657</td>\n",
       "      <td>0.296875</td>\n",
       "      <td>0.278486</td>\n",
       "      <td>0.199103</td>\n",
       "      <td>0.887384</td>\n",
       "      <td>0.909117</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.885990</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.639737</td>\n",
       "      <td>0.740649</td>\n",
       "      <td>0.980833</td>\n",
       "      <td>0.990628</td>\n",
       "      <td>2.500710e-09</td>\n",
       "      <td>0.788591</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.970817</td>\n",
       "      <td>0.724138</td>\n",
       "      <td>0.247397</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.949335</td>\n",
       "      <td>0.548854</td>\n",
       "      <td>0.229812</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.580942</td>\n",
       "      <td>False</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>100</td>\n",
       "      <td>1592</td>\n",
       "      <td>0.453901</td>\n",
       "      <td>0.438724</td>\n",
       "      <td>0.198668</td>\n",
       "      <td>0.296394</td>\n",
       "      <td>0.365019</td>\n",
       "      <td>0.222920</td>\n",
       "      <td>0.902751</td>\n",
       "      <td>0.926640</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.905401</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999490</td>\n",
       "      <td>0.984330</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.973381</td>\n",
       "      <td>0.991938</td>\n",
       "      <td>9.606524e-01</td>\n",
       "      <td>0.971783</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.945727</td>\n",
       "      <td>0.815585</td>\n",
       "      <td>0.329073</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.889008</td>\n",
       "      <td>0.732580</td>\n",
       "      <td>0.247194</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.215764</td>\n",
       "      <td>0.644082</td>\n",
       "      <td>0.488195</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.648037</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>100</td>\n",
       "      <td>1185</td>\n",
       "      <td>0.437521</td>\n",
       "      <td>0.197340</td>\n",
       "      <td>0.151455</td>\n",
       "      <td>0.280486</td>\n",
       "      <td>0.232980</td>\n",
       "      <td>0.155569</td>\n",
       "      <td>0.901545</td>\n",
       "      <td>0.921714</td>\n",
       "      <td>0.654037</td>\n",
       "      <td>0.911570</td>\n",
       "      <td>0.995473</td>\n",
       "      <td>0.992384</td>\n",
       "      <td>0.375339</td>\n",
       "      <td>0.979698</td>\n",
       "      <td>0.983954</td>\n",
       "      <td>0.992425</td>\n",
       "      <td>9.599578e-01</td>\n",
       "      <td>0.970949</td>\n",
       "      <td>0.971604</td>\n",
       "      <td>0.987393</td>\n",
       "      <td>0.880267</td>\n",
       "      <td>0.948704</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.857459</td>\n",
       "      <td>0.699810</td>\n",
       "      <td>0.319292</td>\n",
       "      <td>0.971132</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.808575</td>\n",
       "      <td>0.420889</td>\n",
       "      <td>0.275842</td>\n",
       "      <td>0.854551</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.200531</td>\n",
       "      <td>0.796364</td>\n",
       "      <td>0.898161</td>\n",
       "      <td>0.538176</td>\n",
       "      <td>0.467105</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>100</td>\n",
       "      <td>883</td>\n",
       "      <td>0.433015</td>\n",
       "      <td>0.601558</td>\n",
       "      <td>0.872109</td>\n",
       "      <td>0.345507</td>\n",
       "      <td>0.597342</td>\n",
       "      <td>0.807199</td>\n",
       "      <td>0.840931</td>\n",
       "      <td>0.933173</td>\n",
       "      <td>0.797668</td>\n",
       "      <td>0.922610</td>\n",
       "      <td>0.999966</td>\n",
       "      <td>0.999663</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.976885</td>\n",
       "      <td>0.988305</td>\n",
       "      <td>9.519369e-01</td>\n",
       "      <td>0.973318</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.889686</td>\n",
       "      <td>0.281991</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.714460</td>\n",
       "      <td>0.247837</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.297119</td>\n",
       "      <td>0.765555</td>\n",
       "      <td>0.918007</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.699790</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>100</td>\n",
       "      <td>2456</td>\n",
       "      <td>0.506571</td>\n",
       "      <td>0.186860</td>\n",
       "      <td>0.160455</td>\n",
       "      <td>0.196499</td>\n",
       "      <td>0.194339</td>\n",
       "      <td>0.160468</td>\n",
       "      <td>0.885565</td>\n",
       "      <td>0.871551</td>\n",
       "      <td>0.635296</td>\n",
       "      <td>0.668224</td>\n",
       "      <td>0.768235</td>\n",
       "      <td>0.762891</td>\n",
       "      <td>0.685551</td>\n",
       "      <td>0.309989</td>\n",
       "      <td>0.987835</td>\n",
       "      <td>0.987893</td>\n",
       "      <td>9.538829e-01</td>\n",
       "      <td>0.713962</td>\n",
       "      <td>0.887148</td>\n",
       "      <td>0.937832</td>\n",
       "      <td>0.820744</td>\n",
       "      <td>0.906416</td>\n",
       "      <td>0.892741</td>\n",
       "      <td>0.778592</td>\n",
       "      <td>0.641168</td>\n",
       "      <td>0.268298</td>\n",
       "      <td>0.879809</td>\n",
       "      <td>0.859276</td>\n",
       "      <td>0.718486</td>\n",
       "      <td>0.784513</td>\n",
       "      <td>0.323591</td>\n",
       "      <td>0.215743</td>\n",
       "      <td>0.817136</td>\n",
       "      <td>0.794983</td>\n",
       "      <td>0.143607</td>\n",
       "      <td>0.642601</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.289605</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>100</td>\n",
       "      <td>5326</td>\n",
       "      <td>0.490244</td>\n",
       "      <td>0.380940</td>\n",
       "      <td>0.186081</td>\n",
       "      <td>0.408533</td>\n",
       "      <td>0.426500</td>\n",
       "      <td>0.226843</td>\n",
       "      <td>0.896534</td>\n",
       "      <td>0.762814</td>\n",
       "      <td>0.820543</td>\n",
       "      <td>0.518491</td>\n",
       "      <td>0.918731</td>\n",
       "      <td>0.987538</td>\n",
       "      <td>0.866146</td>\n",
       "      <td>0.939288</td>\n",
       "      <td>0.978446</td>\n",
       "      <td>0.375235</td>\n",
       "      <td>9.540923e-01</td>\n",
       "      <td>0.967144</td>\n",
       "      <td>0.923487</td>\n",
       "      <td>0.969880</td>\n",
       "      <td>0.855463</td>\n",
       "      <td>0.937715</td>\n",
       "      <td>0.911106</td>\n",
       "      <td>0.915145</td>\n",
       "      <td>0.706214</td>\n",
       "      <td>0.257861</td>\n",
       "      <td>0.919181</td>\n",
       "      <td>0.909812</td>\n",
       "      <td>0.832597</td>\n",
       "      <td>0.838619</td>\n",
       "      <td>0.626924</td>\n",
       "      <td>0.214428</td>\n",
       "      <td>0.828453</td>\n",
       "      <td>0.812806</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.848694</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.404818</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>100</td>\n",
       "      <td>1389</td>\n",
       "      <td>0.449655</td>\n",
       "      <td>0.173582</td>\n",
       "      <td>0.152193</td>\n",
       "      <td>0.190415</td>\n",
       "      <td>0.158163</td>\n",
       "      <td>0.123656</td>\n",
       "      <td>0.695581</td>\n",
       "      <td>0.822994</td>\n",
       "      <td>0.157983</td>\n",
       "      <td>0.388861</td>\n",
       "      <td>0.643811</td>\n",
       "      <td>0.472842</td>\n",
       "      <td>0.488442</td>\n",
       "      <td>0.177004</td>\n",
       "      <td>0.980936</td>\n",
       "      <td>0.988426</td>\n",
       "      <td>1.762766e-05</td>\n",
       "      <td>0.050712</td>\n",
       "      <td>0.809310</td>\n",
       "      <td>0.889343</td>\n",
       "      <td>0.293965</td>\n",
       "      <td>0.517576</td>\n",
       "      <td>0.851223</td>\n",
       "      <td>0.738997</td>\n",
       "      <td>0.534355</td>\n",
       "      <td>0.254799</td>\n",
       "      <td>0.803128</td>\n",
       "      <td>0.766201</td>\n",
       "      <td>0.388563</td>\n",
       "      <td>0.290308</td>\n",
       "      <td>0.130693</td>\n",
       "      <td>0.113132</td>\n",
       "      <td>0.293965</td>\n",
       "      <td>0.202365</td>\n",
       "      <td>0.134726</td>\n",
       "      <td>0.756770</td>\n",
       "      <td>0.557407</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.150919</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>100</td>\n",
       "      <td>5153</td>\n",
       "      <td>0.498049</td>\n",
       "      <td>0.255375</td>\n",
       "      <td>0.205944</td>\n",
       "      <td>0.346341</td>\n",
       "      <td>0.248265</td>\n",
       "      <td>0.204870</td>\n",
       "      <td>0.907639</td>\n",
       "      <td>0.946790</td>\n",
       "      <td>0.714735</td>\n",
       "      <td>0.935742</td>\n",
       "      <td>0.999952</td>\n",
       "      <td>0.998964</td>\n",
       "      <td>0.946267</td>\n",
       "      <td>0.993401</td>\n",
       "      <td>0.982195</td>\n",
       "      <td>0.990205</td>\n",
       "      <td>9.602068e-01</td>\n",
       "      <td>0.971601</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.897559</td>\n",
       "      <td>0.648575</td>\n",
       "      <td>0.346042</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.869588</td>\n",
       "      <td>0.493623</td>\n",
       "      <td>0.301690</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.236706</td>\n",
       "      <td>0.725834</td>\n",
       "      <td>0.889163</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.603780</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>100</td>\n",
       "      <td>1975</td>\n",
       "      <td>0.517766</td>\n",
       "      <td>0.246333</td>\n",
       "      <td>0.155104</td>\n",
       "      <td>0.365803</td>\n",
       "      <td>0.262292</td>\n",
       "      <td>0.171215</td>\n",
       "      <td>0.847666</td>\n",
       "      <td>0.844332</td>\n",
       "      <td>0.714735</td>\n",
       "      <td>0.735052</td>\n",
       "      <td>0.998707</td>\n",
       "      <td>0.991175</td>\n",
       "      <td>0.897693</td>\n",
       "      <td>0.943254</td>\n",
       "      <td>0.977903</td>\n",
       "      <td>0.993223</td>\n",
       "      <td>7.340050e-01</td>\n",
       "      <td>0.788591</td>\n",
       "      <td>0.977303</td>\n",
       "      <td>0.987493</td>\n",
       "      <td>0.930794</td>\n",
       "      <td>0.962515</td>\n",
       "      <td>0.966581</td>\n",
       "      <td>0.874183</td>\n",
       "      <td>0.652770</td>\n",
       "      <td>0.307714</td>\n",
       "      <td>0.976264</td>\n",
       "      <td>0.967525</td>\n",
       "      <td>0.894120</td>\n",
       "      <td>0.879221</td>\n",
       "      <td>0.386746</td>\n",
       "      <td>0.281545</td>\n",
       "      <td>0.924241</td>\n",
       "      <td>0.908044</td>\n",
       "      <td>0.185603</td>\n",
       "      <td>0.757168</td>\n",
       "      <td>0.839198</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.428290</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>100</td>\n",
       "      <td>705</td>\n",
       "      <td>0.372423</td>\n",
       "      <td>0.466228</td>\n",
       "      <td>0.296158</td>\n",
       "      <td>0.355532</td>\n",
       "      <td>0.485242</td>\n",
       "      <td>0.402482</td>\n",
       "      <td>0.765789</td>\n",
       "      <td>0.937770</td>\n",
       "      <td>0.694703</td>\n",
       "      <td>0.920472</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>0.995581</td>\n",
       "      <td>0.986567</td>\n",
       "      <td>0.997620</td>\n",
       "      <td>0.980992</td>\n",
       "      <td>0.987018</td>\n",
       "      <td>9.519369e-01</td>\n",
       "      <td>0.973318</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.727823</td>\n",
       "      <td>0.278443</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.497310</td>\n",
       "      <td>0.247837</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.161334</td>\n",
       "      <td>0.755283</td>\n",
       "      <td>0.694804</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.632151</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>100</td>\n",
       "      <td>2465</td>\n",
       "      <td>0.400593</td>\n",
       "      <td>0.496899</td>\n",
       "      <td>0.300016</td>\n",
       "      <td>0.359965</td>\n",
       "      <td>0.486943</td>\n",
       "      <td>0.300016</td>\n",
       "      <td>0.938961</td>\n",
       "      <td>0.966689</td>\n",
       "      <td>0.920880</td>\n",
       "      <td>0.955600</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.976880</td>\n",
       "      <td>0.988303</td>\n",
       "      <td>9.550776e-01</td>\n",
       "      <td>0.981918</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.957711</td>\n",
       "      <td>0.885079</td>\n",
       "      <td>0.981948</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.949175</td>\n",
       "      <td>0.827598</td>\n",
       "      <td>0.859332</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.231866</td>\n",
       "      <td>0.744921</td>\n",
       "      <td>0.919836</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.741689</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>100</td>\n",
       "      <td>4826</td>\n",
       "      <td>0.455674</td>\n",
       "      <td>0.314752</td>\n",
       "      <td>0.164622</td>\n",
       "      <td>0.285976</td>\n",
       "      <td>0.263800</td>\n",
       "      <td>0.141633</td>\n",
       "      <td>0.862357</td>\n",
       "      <td>0.829606</td>\n",
       "      <td>0.686363</td>\n",
       "      <td>0.696630</td>\n",
       "      <td>0.821795</td>\n",
       "      <td>0.697329</td>\n",
       "      <td>0.349369</td>\n",
       "      <td>0.179964</td>\n",
       "      <td>0.987204</td>\n",
       "      <td>0.988050</td>\n",
       "      <td>9.478470e-01</td>\n",
       "      <td>0.967856</td>\n",
       "      <td>0.901601</td>\n",
       "      <td>0.952641</td>\n",
       "      <td>0.800605</td>\n",
       "      <td>0.915722</td>\n",
       "      <td>0.921890</td>\n",
       "      <td>0.843335</td>\n",
       "      <td>0.630609</td>\n",
       "      <td>0.228930</td>\n",
       "      <td>0.893790</td>\n",
       "      <td>0.867906</td>\n",
       "      <td>0.824654</td>\n",
       "      <td>0.740736</td>\n",
       "      <td>0.508417</td>\n",
       "      <td>0.181875</td>\n",
       "      <td>0.800605</td>\n",
       "      <td>0.774736</td>\n",
       "      <td>0.196729</td>\n",
       "      <td>0.753039</td>\n",
       "      <td>0.926500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.307623</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>100</td>\n",
       "      <td>4361</td>\n",
       "      <td>0.245022</td>\n",
       "      <td>0.156215</td>\n",
       "      <td>0.192543</td>\n",
       "      <td>0.210180</td>\n",
       "      <td>0.221758</td>\n",
       "      <td>0.182364</td>\n",
       "      <td>0.786647</td>\n",
       "      <td>0.825674</td>\n",
       "      <td>0.721867</td>\n",
       "      <td>0.800733</td>\n",
       "      <td>0.760857</td>\n",
       "      <td>0.743708</td>\n",
       "      <td>0.612054</td>\n",
       "      <td>0.321660</td>\n",
       "      <td>0.977733</td>\n",
       "      <td>0.988820</td>\n",
       "      <td>9.693904e-01</td>\n",
       "      <td>0.983416</td>\n",
       "      <td>0.858266</td>\n",
       "      <td>0.944924</td>\n",
       "      <td>0.834894</td>\n",
       "      <td>0.933571</td>\n",
       "      <td>0.803079</td>\n",
       "      <td>0.691092</td>\n",
       "      <td>0.555945</td>\n",
       "      <td>0.308838</td>\n",
       "      <td>0.858266</td>\n",
       "      <td>0.831412</td>\n",
       "      <td>0.746720</td>\n",
       "      <td>0.598453</td>\n",
       "      <td>0.370800</td>\n",
       "      <td>0.266747</td>\n",
       "      <td>0.834894</td>\n",
       "      <td>0.813473</td>\n",
       "      <td>0.234463</td>\n",
       "      <td>0.688798</td>\n",
       "      <td>0.305225</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.281980</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    from    to  Doc2Vec:Wikipedia,Size=300  Word2Vec:Wikipedia,Size=300,Mean  Word2Vec:Wikipedia,Size=300,Max  Doc2Vec Phenes:Wikipedia,Size=300  Word2Vec Phenes:Wikipedia,Size=300,Mean  Word2Vec Phenes:Wikipedia,Size=300,Max  NOBLE Coder:Precise,TFIDF  NOBLE Coder:Partial,TFIDF  NOBLE Coder Phenes:Precise,TFIDF  NOBLE Coder Phenes:Partial,TFIDF  Topic Models:NMF,Full,Topics=50  Topic Models:NMF,Full,Topics=100  Topic Models Phenes:NMF,Full,Topics=50  Topic Models Phenes:NMF,Full,Topics=100  Topic Models:LDA,Full,Topics=50  Topic Models:LDA,Full,Topics=100  Topic Models Phenes:LDA,Full,Topics=50  Topic Models Phenes:LDA,Full,Topics=100  N-Grams:Full,Words,1-grams,TFIDF  N-Grams:Full,Words,1-grams,2-grams,TFIDF  N-Grams Phenes:Full,Words,1-grams,TFIDF  N-Grams Phenes:Full,Words,1-grams,2-grams,TFIDF  N-Grams:Full,Nouns,Adjectives,1-grams  N-Grams:Linares_Pontes,Words,1-grams  N-Grams:Full,Precise_Annotations,Words,1-grams  N-Grams:Full,Partial_Annotations,Words,1-grams  \\\n",
       "0    100  1145                    0.504560                          0.503235                         0.263459                           0.414963                                 0.478481                                0.288674                   0.857573                   0.928872                          0.796288                          0.900807                         1.000000                          1.000000                                1.000000                                 0.995888                         0.980399                          0.990102                            9.668565e-01                                 0.981963                          1.000000                                  1.000000                                 1.000000                                         1.000000                               1.000000                              1.000000                                        0.836855                                        0.566964   \n",
       "1    100  4114                    0.309927                          0.260014                         0.185656                           0.276678                                 0.270105                                0.180168                   0.932399                   0.962904                          0.910822                          0.957076                         0.999785                          0.999297                                0.999941                                 0.999121                         0.983668                          0.991767                            9.684386e-01                                 0.982268                          1.000000                                  1.000000                                 1.000000                                         1.000000                               1.000000                              0.977206                                        0.797835                                        0.406689   \n",
       "2    100   231                    0.435983                          0.279231                         0.185035                           0.299665                                 0.271672                                0.188429                   0.872037                   0.922563                          0.817956                          0.916699                         0.733982                          0.715878                                0.797588                                 0.900100                         0.977441                          0.990781                            9.554953e-01                                 0.971250                          0.934402                                  0.969146                                 0.883653                                         0.928505                               0.920096                              0.880906                                        0.529131                                        0.490530   \n",
       "3    100  5244                    0.551568                          0.602756                         0.363885                           0.404959                                 0.607823                                0.362408                   1.000000                   0.958144                          1.000000                          0.945128                         1.000000                          1.000000                                0.990909                                 0.905914                         0.976078                          0.983010                            9.529703e-01                                 0.974258                          1.000000                                  1.000000                                 1.000000                                         1.000000                               1.000000                              1.000000                                        1.000000                                        0.978320   \n",
       "4    100   733                    0.508654                          0.270065                         0.181497                           0.355532                                 0.293558                                0.170425                   0.893924                   0.927862                          0.797668                          0.919038                         0.999892                          0.998867                                1.000000                                 0.999008                         0.974111                          0.988849                            9.546172e-01                                 0.971961                          1.000000                                  1.000000                                 1.000000                                         1.000000                               1.000000                              0.865899                                        0.796603                                        0.284657   \n",
       "5    100  3896                    0.518026                          0.536171                         0.298879                           0.428593                                 0.590710                                0.391840                   0.970234                   0.972461                          1.000000                          0.967205                         1.000000                          1.000000                                1.000000                                 1.000000                         0.976449                          0.988082                            9.620776e-01                                 0.961087                          1.000000                                  1.000000                                 1.000000                                         1.000000                               1.000000                              1.000000                                        0.912374                                        0.338805   \n",
       "6    100  4572                    0.498664                          0.326860                         0.179187                           0.349483                                 0.341777                                0.209361                   0.948135                   0.927444                          0.939123                          0.925689                         0.998685                          0.986242                                0.988918                                 0.640430                         0.982011                          0.990924                            9.532030e-01                                 0.978660                          1.000000                                  1.000000                                 1.000000                                         1.000000                               1.000000                              0.908057                                        0.713808                                        0.345801   \n",
       "7    100  2823                    0.542816                          0.272979                         0.187657                           0.296875                                 0.278486                                0.199103                   0.887384                   0.909117                          1.000000                          0.885990                         1.000000                          1.000000                                0.639737                                 0.740649                         0.980833                          0.990628                            2.500710e-09                                 0.788591                          1.000000                                  1.000000                                 1.000000                                         1.000000                               1.000000                              0.970817                                        0.724138                                        0.247397   \n",
       "8    100  1592                    0.453901                          0.438724                         0.198668                           0.296394                                 0.365019                                0.222920                   0.902751                   0.926640                          1.000000                          0.905401                         1.000000                          0.999490                                0.984330                                 1.000000                         0.973381                          0.991938                            9.606524e-01                                 0.971783                          1.000000                                  1.000000                                 1.000000                                         1.000000                               1.000000                              0.945727                                        0.815585                                        0.329073   \n",
       "9    100  1185                    0.437521                          0.197340                         0.151455                           0.280486                                 0.232980                                0.155569                   0.901545                   0.921714                          0.654037                          0.911570                         0.995473                          0.992384                                0.375339                                 0.979698                         0.983954                          0.992425                            9.599578e-01                                 0.970949                          0.971604                                  0.987393                                 0.880267                                         0.948704                               1.000000                              0.857459                                        0.699810                                        0.319292   \n",
       "10   100   883                    0.433015                          0.601558                         0.872109                           0.345507                                 0.597342                                0.807199                   0.840931                   0.933173                          0.797668                          0.922610                         0.999966                          0.999663                                1.000000                                 1.000000                         0.976885                          0.988305                            9.519369e-01                                 0.973318                          1.000000                                  1.000000                                 1.000000                                         1.000000                               1.000000                              1.000000                                        0.889686                                        0.281991   \n",
       "11   100  2456                    0.506571                          0.186860                         0.160455                           0.196499                                 0.194339                                0.160468                   0.885565                   0.871551                          0.635296                          0.668224                         0.768235                          0.762891                                0.685551                                 0.309989                         0.987835                          0.987893                            9.538829e-01                                 0.713962                          0.887148                                  0.937832                                 0.820744                                         0.906416                               0.892741                              0.778592                                        0.641168                                        0.268298   \n",
       "12   100  5326                    0.490244                          0.380940                         0.186081                           0.408533                                 0.426500                                0.226843                   0.896534                   0.762814                          0.820543                          0.518491                         0.918731                          0.987538                                0.866146                                 0.939288                         0.978446                          0.375235                            9.540923e-01                                 0.967144                          0.923487                                  0.969880                                 0.855463                                         0.937715                               0.911106                              0.915145                                        0.706214                                        0.257861   \n",
       "13   100  1389                    0.449655                          0.173582                         0.152193                           0.190415                                 0.158163                                0.123656                   0.695581                   0.822994                          0.157983                          0.388861                         0.643811                          0.472842                                0.488442                                 0.177004                         0.980936                          0.988426                            1.762766e-05                                 0.050712                          0.809310                                  0.889343                                 0.293965                                         0.517576                               0.851223                              0.738997                                        0.534355                                        0.254799   \n",
       "14   100  5153                    0.498049                          0.255375                         0.205944                           0.346341                                 0.248265                                0.204870                   0.907639                   0.946790                          0.714735                          0.935742                         0.999952                          0.998964                                0.946267                                 0.993401                         0.982195                          0.990205                            9.602068e-01                                 0.971601                          1.000000                                  1.000000                                 1.000000                                         1.000000                               1.000000                              0.897559                                        0.648575                                        0.346042   \n",
       "15   100  1975                    0.517766                          0.246333                         0.155104                           0.365803                                 0.262292                                0.171215                   0.847666                   0.844332                          0.714735                          0.735052                         0.998707                          0.991175                                0.897693                                 0.943254                         0.977903                          0.993223                            7.340050e-01                                 0.788591                          0.977303                                  0.987493                                 0.930794                                         0.962515                               0.966581                              0.874183                                        0.652770                                        0.307714   \n",
       "16   100   705                    0.372423                          0.466228                         0.296158                           0.355532                                 0.485242                                0.402482                   0.765789                   0.937770                          0.694703                          0.920472                         0.999997                          0.995581                                0.986567                                 0.997620                         0.980992                          0.987018                            9.519369e-01                                 0.973318                          1.000000                                  1.000000                                 1.000000                                         1.000000                               1.000000                              1.000000                                        0.727823                                        0.278443   \n",
       "17   100  2465                    0.400593                          0.496899                         0.300016                           0.359965                                 0.486943                                0.300016                   0.938961                   0.966689                          0.920880                          0.955600                         1.000000                          1.000000                                1.000000                                 1.000000                         0.976880                          0.988303                            9.550776e-01                                 0.981918                          1.000000                                  1.000000                                 1.000000                                         1.000000                               1.000000                              0.957711                                        0.885079                                        0.981948   \n",
       "18   100  4826                    0.455674                          0.314752                         0.164622                           0.285976                                 0.263800                                0.141633                   0.862357                   0.829606                          0.686363                          0.696630                         0.821795                          0.697329                                0.349369                                 0.179964                         0.987204                          0.988050                            9.478470e-01                                 0.967856                          0.901601                                  0.952641                                 0.800605                                         0.915722                               0.921890                              0.843335                                        0.630609                                        0.228930   \n",
       "19   100  4361                    0.245022                          0.156215                         0.192543                           0.210180                                 0.221758                                0.182364                   0.786647                   0.825674                          0.721867                          0.800733                         0.760857                          0.743708                                0.612054                                 0.321660                         0.977733                          0.988820                            9.693904e-01                                 0.983416                          0.858266                                  0.944924                                 0.834894                                         0.933571                               0.803079                              0.691092                                        0.555945                                        0.308838   \n",
       "\n",
       "    N-Grams:Full,Plant Overrepresented Tokens,1-grams  N-Grams:Full,Bio Ontology Tokens,1-grams  N-Grams Phenes:Full,Nouns,Adjectives,1-grams  N-Grams Phenes:Linares_Pontes,Words,1-grams  N-Grams Phenes:Full,Precise_Annotations,Words,1-grams  N-Grams Phenes:Full,Partial_Annotations,Words,1-grams  N-Grams Phenes:Full,Plant Overrepresented Tokens,1-grams  N-Grams Phenes:Full,Bio Ontology Tokens,1-grams  GO:Union  PO:Union  GO:Maximum  PO:Maximum      Mean   same  pathways  kegg_only  pmn_only  subsets  \n",
       "0                                            1.000000                                  1.000000                                      1.000000                                     1.000000                                           0.586272                                               0.428988                                               1.000000                                                1.000000  1.000000  0.917046    1.000000    0.646146  0.720441  False        -1         -1        -1       -1  \n",
       "1                                            1.000000                                  1.000000                                      1.000000                                     0.977423                                           0.741544                                               0.422529                                               1.000000                                                1.000000  1.000000  1.000000    1.000000    1.000000  0.656684   True        -1         -1        -1       -1  \n",
       "2                                            0.934402                                  0.915424                                      0.812598                                     0.863527                                           0.376286                                               0.415109                                               0.883653                                                0.853920  0.224368  0.700841    0.905412    0.000000  0.392922   True        -1         -1        -1        0  \n",
       "3                                            1.000000                                  1.000000                                      1.000000                                     1.000000                                           1.000000                                               0.897213                                               1.000000                                                1.000000  0.355641  0.629555    0.689286    0.476599  0.775899   True        -1         -1        -1       -1  \n",
       "4                                            1.000000                                  1.000000                                      1.000000                                     0.850601                                           0.593352                                               0.247837                                               1.000000                                                1.000000  0.188509  0.575006    0.689286    0.000000  0.604054   True        -1         -1        -1        0  \n",
       "5                                            1.000000                                  1.000000                                      1.000000                                     1.000000                                           0.841140                                               0.310185                                               1.000000                                                1.000000  1.000000  1.000000    1.000000    1.000000  0.764766  False        -1         -1        -1       -1  \n",
       "6                                            1.000000                                  1.000000                                      1.000000                                     0.899051                                           0.600257                                               0.263837                                               1.000000                                                1.000000  0.425165  0.556259    0.925314    0.476599  0.618412   True        -1         -1        -1       -1  \n",
       "7                                            1.000000                                  1.000000                                      1.000000                                     0.949335                                           0.548854                                               0.229812                                               1.000000                                                1.000000  1.000000  1.000000    1.000000    1.000000  0.580942  False        -1         -1        -1       -1  \n",
       "8                                            1.000000                                  1.000000                                      1.000000                                     0.889008                                           0.732580                                               0.247194                                               1.000000                                                1.000000  0.215764  0.644082    0.488195    0.000000  0.648037   True        -1         -1        -1        0  \n",
       "9                                            0.971132                                  1.000000                                      1.000000                                     0.808575                                           0.420889                                               0.275842                                               0.854551                                                1.000000  0.200531  0.796364    0.898161    0.538176  0.467105   True        -1         -1        -1        0  \n",
       "10                                           1.000000                                  1.000000                                      1.000000                                     1.000000                                           0.714460                                               0.247837                                               1.000000                                                1.000000  0.297119  0.765555    0.918007    0.000000  0.699790   True        -1         -1        -1        0  \n",
       "11                                           0.879809                                  0.859276                                      0.718486                                     0.784513                                           0.323591                                               0.215743                                               0.817136                                                0.794983  0.143607  0.642601    0.000000    0.000000  0.289605   True        -1         -1        -1        1  \n",
       "12                                           0.919181                                  0.909812                                      0.832597                                     0.838619                                           0.626924                                               0.214428                                               0.828453                                                0.812806  1.000000  0.848694    1.000000    0.000000  0.404818   True        -1         -1        -1       -1  \n",
       "13                                           0.803128                                  0.766201                                      0.388563                                     0.290308                                           0.130693                                               0.113132                                               0.293965                                                0.202365  0.134726  0.756770    0.557407    0.000000  0.150919   True        -1         -1        -1        1  \n",
       "14                                           1.000000                                  1.000000                                      1.000000                                     0.869588                                           0.493623                                               0.301690                                               1.000000                                                1.000000  0.236706  0.725834    0.889163    0.000000  0.603780   True        -1         -1        -1       -1  \n",
       "15                                           0.976264                                  0.967525                                      0.894120                                     0.879221                                           0.386746                                               0.281545                                               0.924241                                                0.908044  0.185603  0.757168    0.839198    0.000000  0.428290   True        -1         -1        -1        0  \n",
       "16                                           1.000000                                  1.000000                                      1.000000                                     1.000000                                           0.497310                                               0.247837                                               1.000000                                                1.000000  0.161334  0.755283    0.694804    0.000000  0.632151   True        -1         -1        -1        0  \n",
       "17                                           1.000000                                  1.000000                                      1.000000                                     0.949175                                           0.827598                                               0.859332                                               1.000000                                                1.000000  0.231866  0.744921    0.919836    0.000000  0.741689   True        -1         -1        -1        0  \n",
       "18                                           0.893790                                  0.867906                                      0.824654                                     0.740736                                           0.508417                                               0.181875                                               0.800605                                                0.774736  0.196729  0.753039    0.926500    0.000000  0.307623   True        -1         -1        -1       -1  \n",
       "19                                           0.858266                                  0.831412                                      0.746720                                     0.598453                                           0.370800                                               0.266747                                               0.834894                                                0.813473  0.234463  0.688798    0.305225    0.000000  0.281980   True        -1         -1        -1       -1  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add a column that indicates whether or not both genes of the pair are mapped to a phenotype classification.\n",
    "relevant_ids = set(subsets_mapped_ids)\n",
    "df[\"from_is_valid\"] = df[\"from\"].map(lambda x: x in relevant_ids)\n",
    "df[\"to_is_valid\"] = df[\"to\"].map(lambda x: x in relevant_ids)\n",
    "df[\"pair_is_valid\"] = df[\"from_is_valid\"]*df[\"to_is_valid\"]\n",
    "\n",
    "# Add a column giving the actual target output value for this biological task, with -1 for the irrelevant rows.\n",
    "df[\"subsets\"] = -1\n",
    "id_to_group_ids,_ = phe_subsets_groups.get_groupings_for_dataset(dataset)\n",
    "df.loc[(df[\"pair_is_valid\"]==True),\"subsets\"] = df[[\"from\",\"to\"]].apply(lambda x: len(set(id_to_group_ids[x[\"from\"]]).intersection(set(id_to_group_ids[x[\"to\"]])))>0, axis=1)*1\n",
    "df.drop(labels=[\"from_is_valid\",\"to_is_valid\", \"pair_is_valid\"], axis=\"columns\", inplace=True)\n",
    "\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"association_objective\"></a>\n",
    "### Using protein assocations (STRING) as the objective "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>from</th>\n",
       "      <th>to</th>\n",
       "      <th>Doc2Vec:Wikipedia,Size=300</th>\n",
       "      <th>Word2Vec:Wikipedia,Size=300,Mean</th>\n",
       "      <th>Word2Vec:Wikipedia,Size=300,Max</th>\n",
       "      <th>Doc2Vec Phenes:Wikipedia,Size=300</th>\n",
       "      <th>Word2Vec Phenes:Wikipedia,Size=300,Mean</th>\n",
       "      <th>Word2Vec Phenes:Wikipedia,Size=300,Max</th>\n",
       "      <th>NOBLE Coder:Precise,TFIDF</th>\n",
       "      <th>NOBLE Coder:Partial,TFIDF</th>\n",
       "      <th>NOBLE Coder Phenes:Precise,TFIDF</th>\n",
       "      <th>NOBLE Coder Phenes:Partial,TFIDF</th>\n",
       "      <th>Topic Models:NMF,Full,Topics=50</th>\n",
       "      <th>Topic Models:NMF,Full,Topics=100</th>\n",
       "      <th>Topic Models Phenes:NMF,Full,Topics=50</th>\n",
       "      <th>Topic Models Phenes:NMF,Full,Topics=100</th>\n",
       "      <th>Topic Models:LDA,Full,Topics=50</th>\n",
       "      <th>Topic Models:LDA,Full,Topics=100</th>\n",
       "      <th>Topic Models Phenes:LDA,Full,Topics=50</th>\n",
       "      <th>Topic Models Phenes:LDA,Full,Topics=100</th>\n",
       "      <th>N-Grams:Full,Words,1-grams,TFIDF</th>\n",
       "      <th>N-Grams:Full,Words,1-grams,2-grams,TFIDF</th>\n",
       "      <th>N-Grams Phenes:Full,Words,1-grams,TFIDF</th>\n",
       "      <th>N-Grams Phenes:Full,Words,1-grams,2-grams,TFIDF</th>\n",
       "      <th>N-Grams:Full,Nouns,Adjectives,1-grams</th>\n",
       "      <th>N-Grams:Linares_Pontes,Words,1-grams</th>\n",
       "      <th>N-Grams:Full,Precise_Annotations,Words,1-grams</th>\n",
       "      <th>N-Grams:Full,Partial_Annotations,Words,1-grams</th>\n",
       "      <th>N-Grams:Full,Plant Overrepresented Tokens,1-grams</th>\n",
       "      <th>N-Grams:Full,Bio Ontology Tokens,1-grams</th>\n",
       "      <th>N-Grams Phenes:Full,Nouns,Adjectives,1-grams</th>\n",
       "      <th>N-Grams Phenes:Linares_Pontes,Words,1-grams</th>\n",
       "      <th>N-Grams Phenes:Full,Precise_Annotations,Words,1-grams</th>\n",
       "      <th>N-Grams Phenes:Full,Partial_Annotations,Words,1-grams</th>\n",
       "      <th>N-Grams Phenes:Full,Plant Overrepresented Tokens,1-grams</th>\n",
       "      <th>N-Grams Phenes:Full,Bio Ontology Tokens,1-grams</th>\n",
       "      <th>GO:Union</th>\n",
       "      <th>PO:Union</th>\n",
       "      <th>GO:Maximum</th>\n",
       "      <th>PO:Maximum</th>\n",
       "      <th>Mean</th>\n",
       "      <th>same</th>\n",
       "      <th>pathways</th>\n",
       "      <th>kegg_only</th>\n",
       "      <th>pmn_only</th>\n",
       "      <th>subsets</th>\n",
       "      <th>known</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>1145</td>\n",
       "      <td>0.504560</td>\n",
       "      <td>0.503235</td>\n",
       "      <td>0.263459</td>\n",
       "      <td>0.414963</td>\n",
       "      <td>0.478481</td>\n",
       "      <td>0.288674</td>\n",
       "      <td>0.857573</td>\n",
       "      <td>0.928872</td>\n",
       "      <td>0.796288</td>\n",
       "      <td>0.900807</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.995888</td>\n",
       "      <td>0.980399</td>\n",
       "      <td>0.990102</td>\n",
       "      <td>9.668565e-01</td>\n",
       "      <td>0.981963</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.836855</td>\n",
       "      <td>0.566964</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.586272</td>\n",
       "      <td>0.428988</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.917046</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.646146</td>\n",
       "      <td>0.720441</td>\n",
       "      <td>False</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100</td>\n",
       "      <td>4114</td>\n",
       "      <td>0.309927</td>\n",
       "      <td>0.260014</td>\n",
       "      <td>0.185656</td>\n",
       "      <td>0.276678</td>\n",
       "      <td>0.270105</td>\n",
       "      <td>0.180168</td>\n",
       "      <td>0.932399</td>\n",
       "      <td>0.962904</td>\n",
       "      <td>0.910822</td>\n",
       "      <td>0.957076</td>\n",
       "      <td>0.999785</td>\n",
       "      <td>0.999297</td>\n",
       "      <td>0.999941</td>\n",
       "      <td>0.999121</td>\n",
       "      <td>0.983668</td>\n",
       "      <td>0.991767</td>\n",
       "      <td>9.684386e-01</td>\n",
       "      <td>0.982268</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.977206</td>\n",
       "      <td>0.797835</td>\n",
       "      <td>0.406689</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.977423</td>\n",
       "      <td>0.741544</td>\n",
       "      <td>0.422529</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.656684</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>231</td>\n",
       "      <td>0.435983</td>\n",
       "      <td>0.279231</td>\n",
       "      <td>0.185035</td>\n",
       "      <td>0.299665</td>\n",
       "      <td>0.271672</td>\n",
       "      <td>0.188429</td>\n",
       "      <td>0.872037</td>\n",
       "      <td>0.922563</td>\n",
       "      <td>0.817956</td>\n",
       "      <td>0.916699</td>\n",
       "      <td>0.733982</td>\n",
       "      <td>0.715878</td>\n",
       "      <td>0.797588</td>\n",
       "      <td>0.900100</td>\n",
       "      <td>0.977441</td>\n",
       "      <td>0.990781</td>\n",
       "      <td>9.554953e-01</td>\n",
       "      <td>0.971250</td>\n",
       "      <td>0.934402</td>\n",
       "      <td>0.969146</td>\n",
       "      <td>0.883653</td>\n",
       "      <td>0.928505</td>\n",
       "      <td>0.920096</td>\n",
       "      <td>0.880906</td>\n",
       "      <td>0.529131</td>\n",
       "      <td>0.490530</td>\n",
       "      <td>0.934402</td>\n",
       "      <td>0.915424</td>\n",
       "      <td>0.812598</td>\n",
       "      <td>0.863527</td>\n",
       "      <td>0.376286</td>\n",
       "      <td>0.415109</td>\n",
       "      <td>0.883653</td>\n",
       "      <td>0.853920</td>\n",
       "      <td>0.224368</td>\n",
       "      <td>0.700841</td>\n",
       "      <td>0.905412</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.392922</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100</td>\n",
       "      <td>5244</td>\n",
       "      <td>0.551568</td>\n",
       "      <td>0.602756</td>\n",
       "      <td>0.363885</td>\n",
       "      <td>0.404959</td>\n",
       "      <td>0.607823</td>\n",
       "      <td>0.362408</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.958144</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.945128</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.990909</td>\n",
       "      <td>0.905914</td>\n",
       "      <td>0.976078</td>\n",
       "      <td>0.983010</td>\n",
       "      <td>9.529703e-01</td>\n",
       "      <td>0.974258</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.978320</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.897213</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.355641</td>\n",
       "      <td>0.629555</td>\n",
       "      <td>0.689286</td>\n",
       "      <td>0.476599</td>\n",
       "      <td>0.775899</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100</td>\n",
       "      <td>733</td>\n",
       "      <td>0.508654</td>\n",
       "      <td>0.270065</td>\n",
       "      <td>0.181497</td>\n",
       "      <td>0.355532</td>\n",
       "      <td>0.293558</td>\n",
       "      <td>0.170425</td>\n",
       "      <td>0.893924</td>\n",
       "      <td>0.927862</td>\n",
       "      <td>0.797668</td>\n",
       "      <td>0.919038</td>\n",
       "      <td>0.999892</td>\n",
       "      <td>0.998867</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999008</td>\n",
       "      <td>0.974111</td>\n",
       "      <td>0.988849</td>\n",
       "      <td>9.546172e-01</td>\n",
       "      <td>0.971961</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.865899</td>\n",
       "      <td>0.796603</td>\n",
       "      <td>0.284657</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.850601</td>\n",
       "      <td>0.593352</td>\n",
       "      <td>0.247837</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.188509</td>\n",
       "      <td>0.575006</td>\n",
       "      <td>0.689286</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.604054</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>100</td>\n",
       "      <td>3896</td>\n",
       "      <td>0.518026</td>\n",
       "      <td>0.536171</td>\n",
       "      <td>0.298879</td>\n",
       "      <td>0.428593</td>\n",
       "      <td>0.590710</td>\n",
       "      <td>0.391840</td>\n",
       "      <td>0.970234</td>\n",
       "      <td>0.972461</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.967205</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.976449</td>\n",
       "      <td>0.988082</td>\n",
       "      <td>9.620776e-01</td>\n",
       "      <td>0.961087</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.912374</td>\n",
       "      <td>0.338805</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.841140</td>\n",
       "      <td>0.310185</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.764766</td>\n",
       "      <td>False</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>100</td>\n",
       "      <td>4572</td>\n",
       "      <td>0.498664</td>\n",
       "      <td>0.326860</td>\n",
       "      <td>0.179187</td>\n",
       "      <td>0.349483</td>\n",
       "      <td>0.341777</td>\n",
       "      <td>0.209361</td>\n",
       "      <td>0.948135</td>\n",
       "      <td>0.927444</td>\n",
       "      <td>0.939123</td>\n",
       "      <td>0.925689</td>\n",
       "      <td>0.998685</td>\n",
       "      <td>0.986242</td>\n",
       "      <td>0.988918</td>\n",
       "      <td>0.640430</td>\n",
       "      <td>0.982011</td>\n",
       "      <td>0.990924</td>\n",
       "      <td>9.532030e-01</td>\n",
       "      <td>0.978660</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.908057</td>\n",
       "      <td>0.713808</td>\n",
       "      <td>0.345801</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.899051</td>\n",
       "      <td>0.600257</td>\n",
       "      <td>0.263837</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.425165</td>\n",
       "      <td>0.556259</td>\n",
       "      <td>0.925314</td>\n",
       "      <td>0.476599</td>\n",
       "      <td>0.618412</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>100</td>\n",
       "      <td>2823</td>\n",
       "      <td>0.542816</td>\n",
       "      <td>0.272979</td>\n",
       "      <td>0.187657</td>\n",
       "      <td>0.296875</td>\n",
       "      <td>0.278486</td>\n",
       "      <td>0.199103</td>\n",
       "      <td>0.887384</td>\n",
       "      <td>0.909117</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.885990</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.639737</td>\n",
       "      <td>0.740649</td>\n",
       "      <td>0.980833</td>\n",
       "      <td>0.990628</td>\n",
       "      <td>2.500710e-09</td>\n",
       "      <td>0.788591</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.970817</td>\n",
       "      <td>0.724138</td>\n",
       "      <td>0.247397</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.949335</td>\n",
       "      <td>0.548854</td>\n",
       "      <td>0.229812</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.580942</td>\n",
       "      <td>False</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>100</td>\n",
       "      <td>1592</td>\n",
       "      <td>0.453901</td>\n",
       "      <td>0.438724</td>\n",
       "      <td>0.198668</td>\n",
       "      <td>0.296394</td>\n",
       "      <td>0.365019</td>\n",
       "      <td>0.222920</td>\n",
       "      <td>0.902751</td>\n",
       "      <td>0.926640</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.905401</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999490</td>\n",
       "      <td>0.984330</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.973381</td>\n",
       "      <td>0.991938</td>\n",
       "      <td>9.606524e-01</td>\n",
       "      <td>0.971783</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.945727</td>\n",
       "      <td>0.815585</td>\n",
       "      <td>0.329073</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.889008</td>\n",
       "      <td>0.732580</td>\n",
       "      <td>0.247194</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.215764</td>\n",
       "      <td>0.644082</td>\n",
       "      <td>0.488195</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.648037</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>100</td>\n",
       "      <td>1185</td>\n",
       "      <td>0.437521</td>\n",
       "      <td>0.197340</td>\n",
       "      <td>0.151455</td>\n",
       "      <td>0.280486</td>\n",
       "      <td>0.232980</td>\n",
       "      <td>0.155569</td>\n",
       "      <td>0.901545</td>\n",
       "      <td>0.921714</td>\n",
       "      <td>0.654037</td>\n",
       "      <td>0.911570</td>\n",
       "      <td>0.995473</td>\n",
       "      <td>0.992384</td>\n",
       "      <td>0.375339</td>\n",
       "      <td>0.979698</td>\n",
       "      <td>0.983954</td>\n",
       "      <td>0.992425</td>\n",
       "      <td>9.599578e-01</td>\n",
       "      <td>0.970949</td>\n",
       "      <td>0.971604</td>\n",
       "      <td>0.987393</td>\n",
       "      <td>0.880267</td>\n",
       "      <td>0.948704</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.857459</td>\n",
       "      <td>0.699810</td>\n",
       "      <td>0.319292</td>\n",
       "      <td>0.971132</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.808575</td>\n",
       "      <td>0.420889</td>\n",
       "      <td>0.275842</td>\n",
       "      <td>0.854551</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.200531</td>\n",
       "      <td>0.796364</td>\n",
       "      <td>0.898161</td>\n",
       "      <td>0.538176</td>\n",
       "      <td>0.467105</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>100</td>\n",
       "      <td>883</td>\n",
       "      <td>0.433015</td>\n",
       "      <td>0.601558</td>\n",
       "      <td>0.872109</td>\n",
       "      <td>0.345507</td>\n",
       "      <td>0.597342</td>\n",
       "      <td>0.807199</td>\n",
       "      <td>0.840931</td>\n",
       "      <td>0.933173</td>\n",
       "      <td>0.797668</td>\n",
       "      <td>0.922610</td>\n",
       "      <td>0.999966</td>\n",
       "      <td>0.999663</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.976885</td>\n",
       "      <td>0.988305</td>\n",
       "      <td>9.519369e-01</td>\n",
       "      <td>0.973318</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.889686</td>\n",
       "      <td>0.281991</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.714460</td>\n",
       "      <td>0.247837</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.297119</td>\n",
       "      <td>0.765555</td>\n",
       "      <td>0.918007</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.699790</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>100</td>\n",
       "      <td>2456</td>\n",
       "      <td>0.506571</td>\n",
       "      <td>0.186860</td>\n",
       "      <td>0.160455</td>\n",
       "      <td>0.196499</td>\n",
       "      <td>0.194339</td>\n",
       "      <td>0.160468</td>\n",
       "      <td>0.885565</td>\n",
       "      <td>0.871551</td>\n",
       "      <td>0.635296</td>\n",
       "      <td>0.668224</td>\n",
       "      <td>0.768235</td>\n",
       "      <td>0.762891</td>\n",
       "      <td>0.685551</td>\n",
       "      <td>0.309989</td>\n",
       "      <td>0.987835</td>\n",
       "      <td>0.987893</td>\n",
       "      <td>9.538829e-01</td>\n",
       "      <td>0.713962</td>\n",
       "      <td>0.887148</td>\n",
       "      <td>0.937832</td>\n",
       "      <td>0.820744</td>\n",
       "      <td>0.906416</td>\n",
       "      <td>0.892741</td>\n",
       "      <td>0.778592</td>\n",
       "      <td>0.641168</td>\n",
       "      <td>0.268298</td>\n",
       "      <td>0.879809</td>\n",
       "      <td>0.859276</td>\n",
       "      <td>0.718486</td>\n",
       "      <td>0.784513</td>\n",
       "      <td>0.323591</td>\n",
       "      <td>0.215743</td>\n",
       "      <td>0.817136</td>\n",
       "      <td>0.794983</td>\n",
       "      <td>0.143607</td>\n",
       "      <td>0.642601</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.289605</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>100</td>\n",
       "      <td>5326</td>\n",
       "      <td>0.490244</td>\n",
       "      <td>0.380940</td>\n",
       "      <td>0.186081</td>\n",
       "      <td>0.408533</td>\n",
       "      <td>0.426500</td>\n",
       "      <td>0.226843</td>\n",
       "      <td>0.896534</td>\n",
       "      <td>0.762814</td>\n",
       "      <td>0.820543</td>\n",
       "      <td>0.518491</td>\n",
       "      <td>0.918731</td>\n",
       "      <td>0.987538</td>\n",
       "      <td>0.866146</td>\n",
       "      <td>0.939288</td>\n",
       "      <td>0.978446</td>\n",
       "      <td>0.375235</td>\n",
       "      <td>9.540923e-01</td>\n",
       "      <td>0.967144</td>\n",
       "      <td>0.923487</td>\n",
       "      <td>0.969880</td>\n",
       "      <td>0.855463</td>\n",
       "      <td>0.937715</td>\n",
       "      <td>0.911106</td>\n",
       "      <td>0.915145</td>\n",
       "      <td>0.706214</td>\n",
       "      <td>0.257861</td>\n",
       "      <td>0.919181</td>\n",
       "      <td>0.909812</td>\n",
       "      <td>0.832597</td>\n",
       "      <td>0.838619</td>\n",
       "      <td>0.626924</td>\n",
       "      <td>0.214428</td>\n",
       "      <td>0.828453</td>\n",
       "      <td>0.812806</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.848694</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.404818</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>100</td>\n",
       "      <td>1389</td>\n",
       "      <td>0.449655</td>\n",
       "      <td>0.173582</td>\n",
       "      <td>0.152193</td>\n",
       "      <td>0.190415</td>\n",
       "      <td>0.158163</td>\n",
       "      <td>0.123656</td>\n",
       "      <td>0.695581</td>\n",
       "      <td>0.822994</td>\n",
       "      <td>0.157983</td>\n",
       "      <td>0.388861</td>\n",
       "      <td>0.643811</td>\n",
       "      <td>0.472842</td>\n",
       "      <td>0.488442</td>\n",
       "      <td>0.177004</td>\n",
       "      <td>0.980936</td>\n",
       "      <td>0.988426</td>\n",
       "      <td>1.762766e-05</td>\n",
       "      <td>0.050712</td>\n",
       "      <td>0.809310</td>\n",
       "      <td>0.889343</td>\n",
       "      <td>0.293965</td>\n",
       "      <td>0.517576</td>\n",
       "      <td>0.851223</td>\n",
       "      <td>0.738997</td>\n",
       "      <td>0.534355</td>\n",
       "      <td>0.254799</td>\n",
       "      <td>0.803128</td>\n",
       "      <td>0.766201</td>\n",
       "      <td>0.388563</td>\n",
       "      <td>0.290308</td>\n",
       "      <td>0.130693</td>\n",
       "      <td>0.113132</td>\n",
       "      <td>0.293965</td>\n",
       "      <td>0.202365</td>\n",
       "      <td>0.134726</td>\n",
       "      <td>0.756770</td>\n",
       "      <td>0.557407</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.150919</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>100</td>\n",
       "      <td>5153</td>\n",
       "      <td>0.498049</td>\n",
       "      <td>0.255375</td>\n",
       "      <td>0.205944</td>\n",
       "      <td>0.346341</td>\n",
       "      <td>0.248265</td>\n",
       "      <td>0.204870</td>\n",
       "      <td>0.907639</td>\n",
       "      <td>0.946790</td>\n",
       "      <td>0.714735</td>\n",
       "      <td>0.935742</td>\n",
       "      <td>0.999952</td>\n",
       "      <td>0.998964</td>\n",
       "      <td>0.946267</td>\n",
       "      <td>0.993401</td>\n",
       "      <td>0.982195</td>\n",
       "      <td>0.990205</td>\n",
       "      <td>9.602068e-01</td>\n",
       "      <td>0.971601</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.897559</td>\n",
       "      <td>0.648575</td>\n",
       "      <td>0.346042</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.869588</td>\n",
       "      <td>0.493623</td>\n",
       "      <td>0.301690</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.236706</td>\n",
       "      <td>0.725834</td>\n",
       "      <td>0.889163</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.603780</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>100</td>\n",
       "      <td>1975</td>\n",
       "      <td>0.517766</td>\n",
       "      <td>0.246333</td>\n",
       "      <td>0.155104</td>\n",
       "      <td>0.365803</td>\n",
       "      <td>0.262292</td>\n",
       "      <td>0.171215</td>\n",
       "      <td>0.847666</td>\n",
       "      <td>0.844332</td>\n",
       "      <td>0.714735</td>\n",
       "      <td>0.735052</td>\n",
       "      <td>0.998707</td>\n",
       "      <td>0.991175</td>\n",
       "      <td>0.897693</td>\n",
       "      <td>0.943254</td>\n",
       "      <td>0.977903</td>\n",
       "      <td>0.993223</td>\n",
       "      <td>7.340050e-01</td>\n",
       "      <td>0.788591</td>\n",
       "      <td>0.977303</td>\n",
       "      <td>0.987493</td>\n",
       "      <td>0.930794</td>\n",
       "      <td>0.962515</td>\n",
       "      <td>0.966581</td>\n",
       "      <td>0.874183</td>\n",
       "      <td>0.652770</td>\n",
       "      <td>0.307714</td>\n",
       "      <td>0.976264</td>\n",
       "      <td>0.967525</td>\n",
       "      <td>0.894120</td>\n",
       "      <td>0.879221</td>\n",
       "      <td>0.386746</td>\n",
       "      <td>0.281545</td>\n",
       "      <td>0.924241</td>\n",
       "      <td>0.908044</td>\n",
       "      <td>0.185603</td>\n",
       "      <td>0.757168</td>\n",
       "      <td>0.839198</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.428290</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>100</td>\n",
       "      <td>705</td>\n",
       "      <td>0.372423</td>\n",
       "      <td>0.466228</td>\n",
       "      <td>0.296158</td>\n",
       "      <td>0.355532</td>\n",
       "      <td>0.485242</td>\n",
       "      <td>0.402482</td>\n",
       "      <td>0.765789</td>\n",
       "      <td>0.937770</td>\n",
       "      <td>0.694703</td>\n",
       "      <td>0.920472</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>0.995581</td>\n",
       "      <td>0.986567</td>\n",
       "      <td>0.997620</td>\n",
       "      <td>0.980992</td>\n",
       "      <td>0.987018</td>\n",
       "      <td>9.519369e-01</td>\n",
       "      <td>0.973318</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.727823</td>\n",
       "      <td>0.278443</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.497310</td>\n",
       "      <td>0.247837</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.161334</td>\n",
       "      <td>0.755283</td>\n",
       "      <td>0.694804</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.632151</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>100</td>\n",
       "      <td>2465</td>\n",
       "      <td>0.400593</td>\n",
       "      <td>0.496899</td>\n",
       "      <td>0.300016</td>\n",
       "      <td>0.359965</td>\n",
       "      <td>0.486943</td>\n",
       "      <td>0.300016</td>\n",
       "      <td>0.938961</td>\n",
       "      <td>0.966689</td>\n",
       "      <td>0.920880</td>\n",
       "      <td>0.955600</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.976880</td>\n",
       "      <td>0.988303</td>\n",
       "      <td>9.550776e-01</td>\n",
       "      <td>0.981918</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.957711</td>\n",
       "      <td>0.885079</td>\n",
       "      <td>0.981948</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.949175</td>\n",
       "      <td>0.827598</td>\n",
       "      <td>0.859332</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.231866</td>\n",
       "      <td>0.744921</td>\n",
       "      <td>0.919836</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.741689</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>100</td>\n",
       "      <td>4826</td>\n",
       "      <td>0.455674</td>\n",
       "      <td>0.314752</td>\n",
       "      <td>0.164622</td>\n",
       "      <td>0.285976</td>\n",
       "      <td>0.263800</td>\n",
       "      <td>0.141633</td>\n",
       "      <td>0.862357</td>\n",
       "      <td>0.829606</td>\n",
       "      <td>0.686363</td>\n",
       "      <td>0.696630</td>\n",
       "      <td>0.821795</td>\n",
       "      <td>0.697329</td>\n",
       "      <td>0.349369</td>\n",
       "      <td>0.179964</td>\n",
       "      <td>0.987204</td>\n",
       "      <td>0.988050</td>\n",
       "      <td>9.478470e-01</td>\n",
       "      <td>0.967856</td>\n",
       "      <td>0.901601</td>\n",
       "      <td>0.952641</td>\n",
       "      <td>0.800605</td>\n",
       "      <td>0.915722</td>\n",
       "      <td>0.921890</td>\n",
       "      <td>0.843335</td>\n",
       "      <td>0.630609</td>\n",
       "      <td>0.228930</td>\n",
       "      <td>0.893790</td>\n",
       "      <td>0.867906</td>\n",
       "      <td>0.824654</td>\n",
       "      <td>0.740736</td>\n",
       "      <td>0.508417</td>\n",
       "      <td>0.181875</td>\n",
       "      <td>0.800605</td>\n",
       "      <td>0.774736</td>\n",
       "      <td>0.196729</td>\n",
       "      <td>0.753039</td>\n",
       "      <td>0.926500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.307623</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>100</td>\n",
       "      <td>4361</td>\n",
       "      <td>0.245022</td>\n",
       "      <td>0.156215</td>\n",
       "      <td>0.192543</td>\n",
       "      <td>0.210180</td>\n",
       "      <td>0.221758</td>\n",
       "      <td>0.182364</td>\n",
       "      <td>0.786647</td>\n",
       "      <td>0.825674</td>\n",
       "      <td>0.721867</td>\n",
       "      <td>0.800733</td>\n",
       "      <td>0.760857</td>\n",
       "      <td>0.743708</td>\n",
       "      <td>0.612054</td>\n",
       "      <td>0.321660</td>\n",
       "      <td>0.977733</td>\n",
       "      <td>0.988820</td>\n",
       "      <td>9.693904e-01</td>\n",
       "      <td>0.983416</td>\n",
       "      <td>0.858266</td>\n",
       "      <td>0.944924</td>\n",
       "      <td>0.834894</td>\n",
       "      <td>0.933571</td>\n",
       "      <td>0.803079</td>\n",
       "      <td>0.691092</td>\n",
       "      <td>0.555945</td>\n",
       "      <td>0.308838</td>\n",
       "      <td>0.858266</td>\n",
       "      <td>0.831412</td>\n",
       "      <td>0.746720</td>\n",
       "      <td>0.598453</td>\n",
       "      <td>0.370800</td>\n",
       "      <td>0.266747</td>\n",
       "      <td>0.834894</td>\n",
       "      <td>0.813473</td>\n",
       "      <td>0.234463</td>\n",
       "      <td>0.688798</td>\n",
       "      <td>0.305225</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.281980</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    from    to  Doc2Vec:Wikipedia,Size=300  Word2Vec:Wikipedia,Size=300,Mean  Word2Vec:Wikipedia,Size=300,Max  Doc2Vec Phenes:Wikipedia,Size=300  Word2Vec Phenes:Wikipedia,Size=300,Mean  Word2Vec Phenes:Wikipedia,Size=300,Max  NOBLE Coder:Precise,TFIDF  NOBLE Coder:Partial,TFIDF  NOBLE Coder Phenes:Precise,TFIDF  NOBLE Coder Phenes:Partial,TFIDF  Topic Models:NMF,Full,Topics=50  Topic Models:NMF,Full,Topics=100  Topic Models Phenes:NMF,Full,Topics=50  Topic Models Phenes:NMF,Full,Topics=100  Topic Models:LDA,Full,Topics=50  Topic Models:LDA,Full,Topics=100  Topic Models Phenes:LDA,Full,Topics=50  Topic Models Phenes:LDA,Full,Topics=100  N-Grams:Full,Words,1-grams,TFIDF  N-Grams:Full,Words,1-grams,2-grams,TFIDF  N-Grams Phenes:Full,Words,1-grams,TFIDF  N-Grams Phenes:Full,Words,1-grams,2-grams,TFIDF  N-Grams:Full,Nouns,Adjectives,1-grams  N-Grams:Linares_Pontes,Words,1-grams  N-Grams:Full,Precise_Annotations,Words,1-grams  N-Grams:Full,Partial_Annotations,Words,1-grams  \\\n",
       "0    100  1145                    0.504560                          0.503235                         0.263459                           0.414963                                 0.478481                                0.288674                   0.857573                   0.928872                          0.796288                          0.900807                         1.000000                          1.000000                                1.000000                                 0.995888                         0.980399                          0.990102                            9.668565e-01                                 0.981963                          1.000000                                  1.000000                                 1.000000                                         1.000000                               1.000000                              1.000000                                        0.836855                                        0.566964   \n",
       "1    100  4114                    0.309927                          0.260014                         0.185656                           0.276678                                 0.270105                                0.180168                   0.932399                   0.962904                          0.910822                          0.957076                         0.999785                          0.999297                                0.999941                                 0.999121                         0.983668                          0.991767                            9.684386e-01                                 0.982268                          1.000000                                  1.000000                                 1.000000                                         1.000000                               1.000000                              0.977206                                        0.797835                                        0.406689   \n",
       "2    100   231                    0.435983                          0.279231                         0.185035                           0.299665                                 0.271672                                0.188429                   0.872037                   0.922563                          0.817956                          0.916699                         0.733982                          0.715878                                0.797588                                 0.900100                         0.977441                          0.990781                            9.554953e-01                                 0.971250                          0.934402                                  0.969146                                 0.883653                                         0.928505                               0.920096                              0.880906                                        0.529131                                        0.490530   \n",
       "3    100  5244                    0.551568                          0.602756                         0.363885                           0.404959                                 0.607823                                0.362408                   1.000000                   0.958144                          1.000000                          0.945128                         1.000000                          1.000000                                0.990909                                 0.905914                         0.976078                          0.983010                            9.529703e-01                                 0.974258                          1.000000                                  1.000000                                 1.000000                                         1.000000                               1.000000                              1.000000                                        1.000000                                        0.978320   \n",
       "4    100   733                    0.508654                          0.270065                         0.181497                           0.355532                                 0.293558                                0.170425                   0.893924                   0.927862                          0.797668                          0.919038                         0.999892                          0.998867                                1.000000                                 0.999008                         0.974111                          0.988849                            9.546172e-01                                 0.971961                          1.000000                                  1.000000                                 1.000000                                         1.000000                               1.000000                              0.865899                                        0.796603                                        0.284657   \n",
       "5    100  3896                    0.518026                          0.536171                         0.298879                           0.428593                                 0.590710                                0.391840                   0.970234                   0.972461                          1.000000                          0.967205                         1.000000                          1.000000                                1.000000                                 1.000000                         0.976449                          0.988082                            9.620776e-01                                 0.961087                          1.000000                                  1.000000                                 1.000000                                         1.000000                               1.000000                              1.000000                                        0.912374                                        0.338805   \n",
       "6    100  4572                    0.498664                          0.326860                         0.179187                           0.349483                                 0.341777                                0.209361                   0.948135                   0.927444                          0.939123                          0.925689                         0.998685                          0.986242                                0.988918                                 0.640430                         0.982011                          0.990924                            9.532030e-01                                 0.978660                          1.000000                                  1.000000                                 1.000000                                         1.000000                               1.000000                              0.908057                                        0.713808                                        0.345801   \n",
       "7    100  2823                    0.542816                          0.272979                         0.187657                           0.296875                                 0.278486                                0.199103                   0.887384                   0.909117                          1.000000                          0.885990                         1.000000                          1.000000                                0.639737                                 0.740649                         0.980833                          0.990628                            2.500710e-09                                 0.788591                          1.000000                                  1.000000                                 1.000000                                         1.000000                               1.000000                              0.970817                                        0.724138                                        0.247397   \n",
       "8    100  1592                    0.453901                          0.438724                         0.198668                           0.296394                                 0.365019                                0.222920                   0.902751                   0.926640                          1.000000                          0.905401                         1.000000                          0.999490                                0.984330                                 1.000000                         0.973381                          0.991938                            9.606524e-01                                 0.971783                          1.000000                                  1.000000                                 1.000000                                         1.000000                               1.000000                              0.945727                                        0.815585                                        0.329073   \n",
       "9    100  1185                    0.437521                          0.197340                         0.151455                           0.280486                                 0.232980                                0.155569                   0.901545                   0.921714                          0.654037                          0.911570                         0.995473                          0.992384                                0.375339                                 0.979698                         0.983954                          0.992425                            9.599578e-01                                 0.970949                          0.971604                                  0.987393                                 0.880267                                         0.948704                               1.000000                              0.857459                                        0.699810                                        0.319292   \n",
       "10   100   883                    0.433015                          0.601558                         0.872109                           0.345507                                 0.597342                                0.807199                   0.840931                   0.933173                          0.797668                          0.922610                         0.999966                          0.999663                                1.000000                                 1.000000                         0.976885                          0.988305                            9.519369e-01                                 0.973318                          1.000000                                  1.000000                                 1.000000                                         1.000000                               1.000000                              1.000000                                        0.889686                                        0.281991   \n",
       "11   100  2456                    0.506571                          0.186860                         0.160455                           0.196499                                 0.194339                                0.160468                   0.885565                   0.871551                          0.635296                          0.668224                         0.768235                          0.762891                                0.685551                                 0.309989                         0.987835                          0.987893                            9.538829e-01                                 0.713962                          0.887148                                  0.937832                                 0.820744                                         0.906416                               0.892741                              0.778592                                        0.641168                                        0.268298   \n",
       "12   100  5326                    0.490244                          0.380940                         0.186081                           0.408533                                 0.426500                                0.226843                   0.896534                   0.762814                          0.820543                          0.518491                         0.918731                          0.987538                                0.866146                                 0.939288                         0.978446                          0.375235                            9.540923e-01                                 0.967144                          0.923487                                  0.969880                                 0.855463                                         0.937715                               0.911106                              0.915145                                        0.706214                                        0.257861   \n",
       "13   100  1389                    0.449655                          0.173582                         0.152193                           0.190415                                 0.158163                                0.123656                   0.695581                   0.822994                          0.157983                          0.388861                         0.643811                          0.472842                                0.488442                                 0.177004                         0.980936                          0.988426                            1.762766e-05                                 0.050712                          0.809310                                  0.889343                                 0.293965                                         0.517576                               0.851223                              0.738997                                        0.534355                                        0.254799   \n",
       "14   100  5153                    0.498049                          0.255375                         0.205944                           0.346341                                 0.248265                                0.204870                   0.907639                   0.946790                          0.714735                          0.935742                         0.999952                          0.998964                                0.946267                                 0.993401                         0.982195                          0.990205                            9.602068e-01                                 0.971601                          1.000000                                  1.000000                                 1.000000                                         1.000000                               1.000000                              0.897559                                        0.648575                                        0.346042   \n",
       "15   100  1975                    0.517766                          0.246333                         0.155104                           0.365803                                 0.262292                                0.171215                   0.847666                   0.844332                          0.714735                          0.735052                         0.998707                          0.991175                                0.897693                                 0.943254                         0.977903                          0.993223                            7.340050e-01                                 0.788591                          0.977303                                  0.987493                                 0.930794                                         0.962515                               0.966581                              0.874183                                        0.652770                                        0.307714   \n",
       "16   100   705                    0.372423                          0.466228                         0.296158                           0.355532                                 0.485242                                0.402482                   0.765789                   0.937770                          0.694703                          0.920472                         0.999997                          0.995581                                0.986567                                 0.997620                         0.980992                          0.987018                            9.519369e-01                                 0.973318                          1.000000                                  1.000000                                 1.000000                                         1.000000                               1.000000                              1.000000                                        0.727823                                        0.278443   \n",
       "17   100  2465                    0.400593                          0.496899                         0.300016                           0.359965                                 0.486943                                0.300016                   0.938961                   0.966689                          0.920880                          0.955600                         1.000000                          1.000000                                1.000000                                 1.000000                         0.976880                          0.988303                            9.550776e-01                                 0.981918                          1.000000                                  1.000000                                 1.000000                                         1.000000                               1.000000                              0.957711                                        0.885079                                        0.981948   \n",
       "18   100  4826                    0.455674                          0.314752                         0.164622                           0.285976                                 0.263800                                0.141633                   0.862357                   0.829606                          0.686363                          0.696630                         0.821795                          0.697329                                0.349369                                 0.179964                         0.987204                          0.988050                            9.478470e-01                                 0.967856                          0.901601                                  0.952641                                 0.800605                                         0.915722                               0.921890                              0.843335                                        0.630609                                        0.228930   \n",
       "19   100  4361                    0.245022                          0.156215                         0.192543                           0.210180                                 0.221758                                0.182364                   0.786647                   0.825674                          0.721867                          0.800733                         0.760857                          0.743708                                0.612054                                 0.321660                         0.977733                          0.988820                            9.693904e-01                                 0.983416                          0.858266                                  0.944924                                 0.834894                                         0.933571                               0.803079                              0.691092                                        0.555945                                        0.308838   \n",
       "\n",
       "    N-Grams:Full,Plant Overrepresented Tokens,1-grams  N-Grams:Full,Bio Ontology Tokens,1-grams  N-Grams Phenes:Full,Nouns,Adjectives,1-grams  N-Grams Phenes:Linares_Pontes,Words,1-grams  N-Grams Phenes:Full,Precise_Annotations,Words,1-grams  N-Grams Phenes:Full,Partial_Annotations,Words,1-grams  N-Grams Phenes:Full,Plant Overrepresented Tokens,1-grams  N-Grams Phenes:Full,Bio Ontology Tokens,1-grams  GO:Union  PO:Union  GO:Maximum  PO:Maximum      Mean   same  pathways  kegg_only  pmn_only  subsets  known  predicted  \n",
       "0                                            1.000000                                  1.000000                                      1.000000                                     1.000000                                           0.586272                                               0.428988                                               1.000000                                                1.000000  1.000000  0.917046    1.000000    0.646146  0.720441  False        -1         -1        -1       -1   -1.0       -1.0  \n",
       "1                                            1.000000                                  1.000000                                      1.000000                                     0.977423                                           0.741544                                               0.422529                                               1.000000                                                1.000000  1.000000  1.000000    1.000000    1.000000  0.656684   True        -1         -1        -1       -1    0.0        0.0  \n",
       "2                                            0.934402                                  0.915424                                      0.812598                                     0.863527                                           0.376286                                               0.415109                                               0.883653                                                0.853920  0.224368  0.700841    0.905412    0.000000  0.392922   True        -1         -1        -1        0    0.0        0.0  \n",
       "3                                            1.000000                                  1.000000                                      1.000000                                     1.000000                                           1.000000                                               0.897213                                               1.000000                                                1.000000  0.355641  0.629555    0.689286    0.476599  0.775899   True        -1         -1        -1       -1    0.0        0.0  \n",
       "4                                            1.000000                                  1.000000                                      1.000000                                     0.850601                                           0.593352                                               0.247837                                               1.000000                                                1.000000  0.188509  0.575006    0.689286    0.000000  0.604054   True        -1         -1        -1        0    0.0        0.0  \n",
       "5                                            1.000000                                  1.000000                                      1.000000                                     1.000000                                           0.841140                                               0.310185                                               1.000000                                                1.000000  1.000000  1.000000    1.000000    1.000000  0.764766  False        -1         -1        -1       -1   -1.0       -1.0  \n",
       "6                                            1.000000                                  1.000000                                      1.000000                                     0.899051                                           0.600257                                               0.263837                                               1.000000                                                1.000000  0.425165  0.556259    0.925314    0.476599  0.618412   True        -1         -1        -1       -1    0.0        0.0  \n",
       "7                                            1.000000                                  1.000000                                      1.000000                                     0.949335                                           0.548854                                               0.229812                                               1.000000                                                1.000000  1.000000  1.000000    1.000000    1.000000  0.580942  False        -1         -1        -1       -1   -1.0       -1.0  \n",
       "8                                            1.000000                                  1.000000                                      1.000000                                     0.889008                                           0.732580                                               0.247194                                               1.000000                                                1.000000  0.215764  0.644082    0.488195    0.000000  0.648037   True        -1         -1        -1        0    0.0        0.0  \n",
       "9                                            0.971132                                  1.000000                                      1.000000                                     0.808575                                           0.420889                                               0.275842                                               0.854551                                                1.000000  0.200531  0.796364    0.898161    0.538176  0.467105   True        -1         -1        -1        0    0.0        0.0  \n",
       "10                                           1.000000                                  1.000000                                      1.000000                                     1.000000                                           0.714460                                               0.247837                                               1.000000                                                1.000000  0.297119  0.765555    0.918007    0.000000  0.699790   True        -1         -1        -1        0    0.0        0.0  \n",
       "11                                           0.879809                                  0.859276                                      0.718486                                     0.784513                                           0.323591                                               0.215743                                               0.817136                                                0.794983  0.143607  0.642601    0.000000    0.000000  0.289605   True        -1         -1        -1        1    0.0        0.0  \n",
       "12                                           0.919181                                  0.909812                                      0.832597                                     0.838619                                           0.626924                                               0.214428                                               0.828453                                                0.812806  1.000000  0.848694    1.000000    0.000000  0.404818   True        -1         -1        -1       -1    0.0        0.0  \n",
       "13                                           0.803128                                  0.766201                                      0.388563                                     0.290308                                           0.130693                                               0.113132                                               0.293965                                                0.202365  0.134726  0.756770    0.557407    0.000000  0.150919   True        -1         -1        -1        1    0.0        0.0  \n",
       "14                                           1.000000                                  1.000000                                      1.000000                                     0.869588                                           0.493623                                               0.301690                                               1.000000                                                1.000000  0.236706  0.725834    0.889163    0.000000  0.603780   True        -1         -1        -1       -1    0.0        0.0  \n",
       "15                                           0.976264                                  0.967525                                      0.894120                                     0.879221                                           0.386746                                               0.281545                                               0.924241                                                0.908044  0.185603  0.757168    0.839198    0.000000  0.428290   True        -1         -1        -1        0    0.0        0.0  \n",
       "16                                           1.000000                                  1.000000                                      1.000000                                     1.000000                                           0.497310                                               0.247837                                               1.000000                                                1.000000  0.161334  0.755283    0.694804    0.000000  0.632151   True        -1         -1        -1        0    0.0        0.0  \n",
       "17                                           1.000000                                  1.000000                                      1.000000                                     0.949175                                           0.827598                                               0.859332                                               1.000000                                                1.000000  0.231866  0.744921    0.919836    0.000000  0.741689   True        -1         -1        -1        0    0.0        0.0  \n",
       "18                                           0.893790                                  0.867906                                      0.824654                                     0.740736                                           0.508417                                               0.181875                                               0.800605                                                0.774736  0.196729  0.753039    0.926500    0.000000  0.307623   True        -1         -1        -1       -1    0.0        0.0  \n",
       "19                                           0.858266                                  0.831412                                      0.746720                                     0.598453                                           0.370800                                               0.266747                                               0.834894                                                0.813473  0.234463  0.688798    0.305225    0.000000  0.281980   True        -1         -1        -1       -1    0.0        0.0  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add a column that indicates whether or not both genes of the pair are mapped to a phenotype classification.\n",
    "relevant_ids = set(string_edgelist.ids)\n",
    "df[\"from_is_valid\"] = df[\"from\"].map(lambda x: x in relevant_ids)\n",
    "df[\"to_is_valid\"] = df[\"to\"].map(lambda x: x in relevant_ids)\n",
    "df[\"pair_is_valid\"] = df[\"from_is_valid\"]*df[\"to_is_valid\"]*df[\"same\"]\n",
    "\n",
    "# Add a column giving the actual target output value for this biological task, with -1 for the irrelevant rows.\n",
    "df[\"known\"] = -1\n",
    "df[\"predicted\"] = -1\n",
    "df = df.merge(right=string_edgelist.df, how=\"left\", on=[\"from\",\"to\"])\n",
    "df[\"known_associations\"].fillna(value=0, inplace=True)\n",
    "df[\"predicted_associations\"].fillna(value=0, inplace=True)\n",
    "df.loc[(df[\"pair_is_valid\"]==True),\"known\"] = df[\"known_associations\"]\n",
    "df.loc[(df[\"pair_is_valid\"]==True),\"predicted\"] = df[\"predicted_associations\"]\n",
    "\n",
    "# Convert all the positive values from string on range 0 to arbitrary n to be equal to 1.\n",
    "df.loc[df[\"known\"] >= 1, \"known\"] = 1 \n",
    "df.loc[df[\"predicted\"] >= 1, \"predicted\"] = 1 \n",
    "df.drop(labels=[\"from_is_valid\",\"to_is_valid\",\"pair_is_valid\",\"known_associations\",\"predicted_associations\"], axis=\"columns\", inplace=True)\n",
    "\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"ortholog_objective\"></a>\n",
    "### Using orthology between genes (PANTHER) as the objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>from</th>\n",
       "      <th>to</th>\n",
       "      <th>Doc2Vec:Wikipedia,Size=300</th>\n",
       "      <th>Word2Vec:Wikipedia,Size=300,Mean</th>\n",
       "      <th>Word2Vec:Wikipedia,Size=300,Max</th>\n",
       "      <th>Doc2Vec Phenes:Wikipedia,Size=300</th>\n",
       "      <th>Word2Vec Phenes:Wikipedia,Size=300,Mean</th>\n",
       "      <th>Word2Vec Phenes:Wikipedia,Size=300,Max</th>\n",
       "      <th>NOBLE Coder:Precise,TFIDF</th>\n",
       "      <th>NOBLE Coder:Partial,TFIDF</th>\n",
       "      <th>NOBLE Coder Phenes:Precise,TFIDF</th>\n",
       "      <th>NOBLE Coder Phenes:Partial,TFIDF</th>\n",
       "      <th>Topic Models:NMF,Full,Topics=50</th>\n",
       "      <th>Topic Models:NMF,Full,Topics=100</th>\n",
       "      <th>Topic Models Phenes:NMF,Full,Topics=50</th>\n",
       "      <th>Topic Models Phenes:NMF,Full,Topics=100</th>\n",
       "      <th>Topic Models:LDA,Full,Topics=50</th>\n",
       "      <th>Topic Models:LDA,Full,Topics=100</th>\n",
       "      <th>Topic Models Phenes:LDA,Full,Topics=50</th>\n",
       "      <th>Topic Models Phenes:LDA,Full,Topics=100</th>\n",
       "      <th>N-Grams:Full,Words,1-grams,TFIDF</th>\n",
       "      <th>N-Grams:Full,Words,1-grams,2-grams,TFIDF</th>\n",
       "      <th>N-Grams Phenes:Full,Words,1-grams,TFIDF</th>\n",
       "      <th>N-Grams Phenes:Full,Words,1-grams,2-grams,TFIDF</th>\n",
       "      <th>N-Grams:Full,Nouns,Adjectives,1-grams</th>\n",
       "      <th>N-Grams:Linares_Pontes,Words,1-grams</th>\n",
       "      <th>N-Grams:Full,Precise_Annotations,Words,1-grams</th>\n",
       "      <th>N-Grams:Full,Partial_Annotations,Words,1-grams</th>\n",
       "      <th>N-Grams:Full,Plant Overrepresented Tokens,1-grams</th>\n",
       "      <th>N-Grams:Full,Bio Ontology Tokens,1-grams</th>\n",
       "      <th>N-Grams Phenes:Full,Nouns,Adjectives,1-grams</th>\n",
       "      <th>N-Grams Phenes:Linares_Pontes,Words,1-grams</th>\n",
       "      <th>N-Grams Phenes:Full,Precise_Annotations,Words,1-grams</th>\n",
       "      <th>N-Grams Phenes:Full,Partial_Annotations,Words,1-grams</th>\n",
       "      <th>N-Grams Phenes:Full,Plant Overrepresented Tokens,1-grams</th>\n",
       "      <th>N-Grams Phenes:Full,Bio Ontology Tokens,1-grams</th>\n",
       "      <th>GO:Union</th>\n",
       "      <th>PO:Union</th>\n",
       "      <th>GO:Maximum</th>\n",
       "      <th>PO:Maximum</th>\n",
       "      <th>Mean</th>\n",
       "      <th>same</th>\n",
       "      <th>pathways</th>\n",
       "      <th>kegg_only</th>\n",
       "      <th>pmn_only</th>\n",
       "      <th>subsets</th>\n",
       "      <th>known</th>\n",
       "      <th>predicted</th>\n",
       "      <th>orthologs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>1145</td>\n",
       "      <td>0.504560</td>\n",
       "      <td>0.503235</td>\n",
       "      <td>0.263459</td>\n",
       "      <td>0.414963</td>\n",
       "      <td>0.478481</td>\n",
       "      <td>0.288674</td>\n",
       "      <td>0.857573</td>\n",
       "      <td>0.928872</td>\n",
       "      <td>0.796288</td>\n",
       "      <td>0.900807</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.995888</td>\n",
       "      <td>0.980399</td>\n",
       "      <td>0.990102</td>\n",
       "      <td>9.668565e-01</td>\n",
       "      <td>0.981963</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.836855</td>\n",
       "      <td>0.566964</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.586272</td>\n",
       "      <td>0.428988</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.917046</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.646146</td>\n",
       "      <td>0.720441</td>\n",
       "      <td>False</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100</td>\n",
       "      <td>4114</td>\n",
       "      <td>0.309927</td>\n",
       "      <td>0.260014</td>\n",
       "      <td>0.185656</td>\n",
       "      <td>0.276678</td>\n",
       "      <td>0.270105</td>\n",
       "      <td>0.180168</td>\n",
       "      <td>0.932399</td>\n",
       "      <td>0.962904</td>\n",
       "      <td>0.910822</td>\n",
       "      <td>0.957076</td>\n",
       "      <td>0.999785</td>\n",
       "      <td>0.999297</td>\n",
       "      <td>0.999941</td>\n",
       "      <td>0.999121</td>\n",
       "      <td>0.983668</td>\n",
       "      <td>0.991767</td>\n",
       "      <td>9.684386e-01</td>\n",
       "      <td>0.982268</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.977206</td>\n",
       "      <td>0.797835</td>\n",
       "      <td>0.406689</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.977423</td>\n",
       "      <td>0.741544</td>\n",
       "      <td>0.422529</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.656684</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>231</td>\n",
       "      <td>0.435983</td>\n",
       "      <td>0.279231</td>\n",
       "      <td>0.185035</td>\n",
       "      <td>0.299665</td>\n",
       "      <td>0.271672</td>\n",
       "      <td>0.188429</td>\n",
       "      <td>0.872037</td>\n",
       "      <td>0.922563</td>\n",
       "      <td>0.817956</td>\n",
       "      <td>0.916699</td>\n",
       "      <td>0.733982</td>\n",
       "      <td>0.715878</td>\n",
       "      <td>0.797588</td>\n",
       "      <td>0.900100</td>\n",
       "      <td>0.977441</td>\n",
       "      <td>0.990781</td>\n",
       "      <td>9.554953e-01</td>\n",
       "      <td>0.971250</td>\n",
       "      <td>0.934402</td>\n",
       "      <td>0.969146</td>\n",
       "      <td>0.883653</td>\n",
       "      <td>0.928505</td>\n",
       "      <td>0.920096</td>\n",
       "      <td>0.880906</td>\n",
       "      <td>0.529131</td>\n",
       "      <td>0.490530</td>\n",
       "      <td>0.934402</td>\n",
       "      <td>0.915424</td>\n",
       "      <td>0.812598</td>\n",
       "      <td>0.863527</td>\n",
       "      <td>0.376286</td>\n",
       "      <td>0.415109</td>\n",
       "      <td>0.883653</td>\n",
       "      <td>0.853920</td>\n",
       "      <td>0.224368</td>\n",
       "      <td>0.700841</td>\n",
       "      <td>0.905412</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.392922</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100</td>\n",
       "      <td>5244</td>\n",
       "      <td>0.551568</td>\n",
       "      <td>0.602756</td>\n",
       "      <td>0.363885</td>\n",
       "      <td>0.404959</td>\n",
       "      <td>0.607823</td>\n",
       "      <td>0.362408</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.958144</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.945128</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.990909</td>\n",
       "      <td>0.905914</td>\n",
       "      <td>0.976078</td>\n",
       "      <td>0.983010</td>\n",
       "      <td>9.529703e-01</td>\n",
       "      <td>0.974258</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.978320</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.897213</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.355641</td>\n",
       "      <td>0.629555</td>\n",
       "      <td>0.689286</td>\n",
       "      <td>0.476599</td>\n",
       "      <td>0.775899</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100</td>\n",
       "      <td>733</td>\n",
       "      <td>0.508654</td>\n",
       "      <td>0.270065</td>\n",
       "      <td>0.181497</td>\n",
       "      <td>0.355532</td>\n",
       "      <td>0.293558</td>\n",
       "      <td>0.170425</td>\n",
       "      <td>0.893924</td>\n",
       "      <td>0.927862</td>\n",
       "      <td>0.797668</td>\n",
       "      <td>0.919038</td>\n",
       "      <td>0.999892</td>\n",
       "      <td>0.998867</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999008</td>\n",
       "      <td>0.974111</td>\n",
       "      <td>0.988849</td>\n",
       "      <td>9.546172e-01</td>\n",
       "      <td>0.971961</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.865899</td>\n",
       "      <td>0.796603</td>\n",
       "      <td>0.284657</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.850601</td>\n",
       "      <td>0.593352</td>\n",
       "      <td>0.247837</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.188509</td>\n",
       "      <td>0.575006</td>\n",
       "      <td>0.689286</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.604054</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>100</td>\n",
       "      <td>3896</td>\n",
       "      <td>0.518026</td>\n",
       "      <td>0.536171</td>\n",
       "      <td>0.298879</td>\n",
       "      <td>0.428593</td>\n",
       "      <td>0.590710</td>\n",
       "      <td>0.391840</td>\n",
       "      <td>0.970234</td>\n",
       "      <td>0.972461</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.967205</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.976449</td>\n",
       "      <td>0.988082</td>\n",
       "      <td>9.620776e-01</td>\n",
       "      <td>0.961087</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.912374</td>\n",
       "      <td>0.338805</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.841140</td>\n",
       "      <td>0.310185</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.764766</td>\n",
       "      <td>False</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>100</td>\n",
       "      <td>4572</td>\n",
       "      <td>0.498664</td>\n",
       "      <td>0.326860</td>\n",
       "      <td>0.179187</td>\n",
       "      <td>0.349483</td>\n",
       "      <td>0.341777</td>\n",
       "      <td>0.209361</td>\n",
       "      <td>0.948135</td>\n",
       "      <td>0.927444</td>\n",
       "      <td>0.939123</td>\n",
       "      <td>0.925689</td>\n",
       "      <td>0.998685</td>\n",
       "      <td>0.986242</td>\n",
       "      <td>0.988918</td>\n",
       "      <td>0.640430</td>\n",
       "      <td>0.982011</td>\n",
       "      <td>0.990924</td>\n",
       "      <td>9.532030e-01</td>\n",
       "      <td>0.978660</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.908057</td>\n",
       "      <td>0.713808</td>\n",
       "      <td>0.345801</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.899051</td>\n",
       "      <td>0.600257</td>\n",
       "      <td>0.263837</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.425165</td>\n",
       "      <td>0.556259</td>\n",
       "      <td>0.925314</td>\n",
       "      <td>0.476599</td>\n",
       "      <td>0.618412</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>100</td>\n",
       "      <td>2823</td>\n",
       "      <td>0.542816</td>\n",
       "      <td>0.272979</td>\n",
       "      <td>0.187657</td>\n",
       "      <td>0.296875</td>\n",
       "      <td>0.278486</td>\n",
       "      <td>0.199103</td>\n",
       "      <td>0.887384</td>\n",
       "      <td>0.909117</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.885990</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.639737</td>\n",
       "      <td>0.740649</td>\n",
       "      <td>0.980833</td>\n",
       "      <td>0.990628</td>\n",
       "      <td>2.500710e-09</td>\n",
       "      <td>0.788591</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.970817</td>\n",
       "      <td>0.724138</td>\n",
       "      <td>0.247397</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.949335</td>\n",
       "      <td>0.548854</td>\n",
       "      <td>0.229812</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.580942</td>\n",
       "      <td>False</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>100</td>\n",
       "      <td>1592</td>\n",
       "      <td>0.453901</td>\n",
       "      <td>0.438724</td>\n",
       "      <td>0.198668</td>\n",
       "      <td>0.296394</td>\n",
       "      <td>0.365019</td>\n",
       "      <td>0.222920</td>\n",
       "      <td>0.902751</td>\n",
       "      <td>0.926640</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.905401</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999490</td>\n",
       "      <td>0.984330</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.973381</td>\n",
       "      <td>0.991938</td>\n",
       "      <td>9.606524e-01</td>\n",
       "      <td>0.971783</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.945727</td>\n",
       "      <td>0.815585</td>\n",
       "      <td>0.329073</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.889008</td>\n",
       "      <td>0.732580</td>\n",
       "      <td>0.247194</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.215764</td>\n",
       "      <td>0.644082</td>\n",
       "      <td>0.488195</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.648037</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>100</td>\n",
       "      <td>1185</td>\n",
       "      <td>0.437521</td>\n",
       "      <td>0.197340</td>\n",
       "      <td>0.151455</td>\n",
       "      <td>0.280486</td>\n",
       "      <td>0.232980</td>\n",
       "      <td>0.155569</td>\n",
       "      <td>0.901545</td>\n",
       "      <td>0.921714</td>\n",
       "      <td>0.654037</td>\n",
       "      <td>0.911570</td>\n",
       "      <td>0.995473</td>\n",
       "      <td>0.992384</td>\n",
       "      <td>0.375339</td>\n",
       "      <td>0.979698</td>\n",
       "      <td>0.983954</td>\n",
       "      <td>0.992425</td>\n",
       "      <td>9.599578e-01</td>\n",
       "      <td>0.970949</td>\n",
       "      <td>0.971604</td>\n",
       "      <td>0.987393</td>\n",
       "      <td>0.880267</td>\n",
       "      <td>0.948704</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.857459</td>\n",
       "      <td>0.699810</td>\n",
       "      <td>0.319292</td>\n",
       "      <td>0.971132</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.808575</td>\n",
       "      <td>0.420889</td>\n",
       "      <td>0.275842</td>\n",
       "      <td>0.854551</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.200531</td>\n",
       "      <td>0.796364</td>\n",
       "      <td>0.898161</td>\n",
       "      <td>0.538176</td>\n",
       "      <td>0.467105</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>100</td>\n",
       "      <td>883</td>\n",
       "      <td>0.433015</td>\n",
       "      <td>0.601558</td>\n",
       "      <td>0.872109</td>\n",
       "      <td>0.345507</td>\n",
       "      <td>0.597342</td>\n",
       "      <td>0.807199</td>\n",
       "      <td>0.840931</td>\n",
       "      <td>0.933173</td>\n",
       "      <td>0.797668</td>\n",
       "      <td>0.922610</td>\n",
       "      <td>0.999966</td>\n",
       "      <td>0.999663</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.976885</td>\n",
       "      <td>0.988305</td>\n",
       "      <td>9.519369e-01</td>\n",
       "      <td>0.973318</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.889686</td>\n",
       "      <td>0.281991</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.714460</td>\n",
       "      <td>0.247837</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.297119</td>\n",
       "      <td>0.765555</td>\n",
       "      <td>0.918007</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.699790</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>100</td>\n",
       "      <td>2456</td>\n",
       "      <td>0.506571</td>\n",
       "      <td>0.186860</td>\n",
       "      <td>0.160455</td>\n",
       "      <td>0.196499</td>\n",
       "      <td>0.194339</td>\n",
       "      <td>0.160468</td>\n",
       "      <td>0.885565</td>\n",
       "      <td>0.871551</td>\n",
       "      <td>0.635296</td>\n",
       "      <td>0.668224</td>\n",
       "      <td>0.768235</td>\n",
       "      <td>0.762891</td>\n",
       "      <td>0.685551</td>\n",
       "      <td>0.309989</td>\n",
       "      <td>0.987835</td>\n",
       "      <td>0.987893</td>\n",
       "      <td>9.538829e-01</td>\n",
       "      <td>0.713962</td>\n",
       "      <td>0.887148</td>\n",
       "      <td>0.937832</td>\n",
       "      <td>0.820744</td>\n",
       "      <td>0.906416</td>\n",
       "      <td>0.892741</td>\n",
       "      <td>0.778592</td>\n",
       "      <td>0.641168</td>\n",
       "      <td>0.268298</td>\n",
       "      <td>0.879809</td>\n",
       "      <td>0.859276</td>\n",
       "      <td>0.718486</td>\n",
       "      <td>0.784513</td>\n",
       "      <td>0.323591</td>\n",
       "      <td>0.215743</td>\n",
       "      <td>0.817136</td>\n",
       "      <td>0.794983</td>\n",
       "      <td>0.143607</td>\n",
       "      <td>0.642601</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.289605</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>100</td>\n",
       "      <td>5326</td>\n",
       "      <td>0.490244</td>\n",
       "      <td>0.380940</td>\n",
       "      <td>0.186081</td>\n",
       "      <td>0.408533</td>\n",
       "      <td>0.426500</td>\n",
       "      <td>0.226843</td>\n",
       "      <td>0.896534</td>\n",
       "      <td>0.762814</td>\n",
       "      <td>0.820543</td>\n",
       "      <td>0.518491</td>\n",
       "      <td>0.918731</td>\n",
       "      <td>0.987538</td>\n",
       "      <td>0.866146</td>\n",
       "      <td>0.939288</td>\n",
       "      <td>0.978446</td>\n",
       "      <td>0.375235</td>\n",
       "      <td>9.540923e-01</td>\n",
       "      <td>0.967144</td>\n",
       "      <td>0.923487</td>\n",
       "      <td>0.969880</td>\n",
       "      <td>0.855463</td>\n",
       "      <td>0.937715</td>\n",
       "      <td>0.911106</td>\n",
       "      <td>0.915145</td>\n",
       "      <td>0.706214</td>\n",
       "      <td>0.257861</td>\n",
       "      <td>0.919181</td>\n",
       "      <td>0.909812</td>\n",
       "      <td>0.832597</td>\n",
       "      <td>0.838619</td>\n",
       "      <td>0.626924</td>\n",
       "      <td>0.214428</td>\n",
       "      <td>0.828453</td>\n",
       "      <td>0.812806</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.848694</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.404818</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>100</td>\n",
       "      <td>1389</td>\n",
       "      <td>0.449655</td>\n",
       "      <td>0.173582</td>\n",
       "      <td>0.152193</td>\n",
       "      <td>0.190415</td>\n",
       "      <td>0.158163</td>\n",
       "      <td>0.123656</td>\n",
       "      <td>0.695581</td>\n",
       "      <td>0.822994</td>\n",
       "      <td>0.157983</td>\n",
       "      <td>0.388861</td>\n",
       "      <td>0.643811</td>\n",
       "      <td>0.472842</td>\n",
       "      <td>0.488442</td>\n",
       "      <td>0.177004</td>\n",
       "      <td>0.980936</td>\n",
       "      <td>0.988426</td>\n",
       "      <td>1.762766e-05</td>\n",
       "      <td>0.050712</td>\n",
       "      <td>0.809310</td>\n",
       "      <td>0.889343</td>\n",
       "      <td>0.293965</td>\n",
       "      <td>0.517576</td>\n",
       "      <td>0.851223</td>\n",
       "      <td>0.738997</td>\n",
       "      <td>0.534355</td>\n",
       "      <td>0.254799</td>\n",
       "      <td>0.803128</td>\n",
       "      <td>0.766201</td>\n",
       "      <td>0.388563</td>\n",
       "      <td>0.290308</td>\n",
       "      <td>0.130693</td>\n",
       "      <td>0.113132</td>\n",
       "      <td>0.293965</td>\n",
       "      <td>0.202365</td>\n",
       "      <td>0.134726</td>\n",
       "      <td>0.756770</td>\n",
       "      <td>0.557407</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.150919</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>100</td>\n",
       "      <td>5153</td>\n",
       "      <td>0.498049</td>\n",
       "      <td>0.255375</td>\n",
       "      <td>0.205944</td>\n",
       "      <td>0.346341</td>\n",
       "      <td>0.248265</td>\n",
       "      <td>0.204870</td>\n",
       "      <td>0.907639</td>\n",
       "      <td>0.946790</td>\n",
       "      <td>0.714735</td>\n",
       "      <td>0.935742</td>\n",
       "      <td>0.999952</td>\n",
       "      <td>0.998964</td>\n",
       "      <td>0.946267</td>\n",
       "      <td>0.993401</td>\n",
       "      <td>0.982195</td>\n",
       "      <td>0.990205</td>\n",
       "      <td>9.602068e-01</td>\n",
       "      <td>0.971601</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.897559</td>\n",
       "      <td>0.648575</td>\n",
       "      <td>0.346042</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.869588</td>\n",
       "      <td>0.493623</td>\n",
       "      <td>0.301690</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.236706</td>\n",
       "      <td>0.725834</td>\n",
       "      <td>0.889163</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.603780</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>100</td>\n",
       "      <td>1975</td>\n",
       "      <td>0.517766</td>\n",
       "      <td>0.246333</td>\n",
       "      <td>0.155104</td>\n",
       "      <td>0.365803</td>\n",
       "      <td>0.262292</td>\n",
       "      <td>0.171215</td>\n",
       "      <td>0.847666</td>\n",
       "      <td>0.844332</td>\n",
       "      <td>0.714735</td>\n",
       "      <td>0.735052</td>\n",
       "      <td>0.998707</td>\n",
       "      <td>0.991175</td>\n",
       "      <td>0.897693</td>\n",
       "      <td>0.943254</td>\n",
       "      <td>0.977903</td>\n",
       "      <td>0.993223</td>\n",
       "      <td>7.340050e-01</td>\n",
       "      <td>0.788591</td>\n",
       "      <td>0.977303</td>\n",
       "      <td>0.987493</td>\n",
       "      <td>0.930794</td>\n",
       "      <td>0.962515</td>\n",
       "      <td>0.966581</td>\n",
       "      <td>0.874183</td>\n",
       "      <td>0.652770</td>\n",
       "      <td>0.307714</td>\n",
       "      <td>0.976264</td>\n",
       "      <td>0.967525</td>\n",
       "      <td>0.894120</td>\n",
       "      <td>0.879221</td>\n",
       "      <td>0.386746</td>\n",
       "      <td>0.281545</td>\n",
       "      <td>0.924241</td>\n",
       "      <td>0.908044</td>\n",
       "      <td>0.185603</td>\n",
       "      <td>0.757168</td>\n",
       "      <td>0.839198</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.428290</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>100</td>\n",
       "      <td>705</td>\n",
       "      <td>0.372423</td>\n",
       "      <td>0.466228</td>\n",
       "      <td>0.296158</td>\n",
       "      <td>0.355532</td>\n",
       "      <td>0.485242</td>\n",
       "      <td>0.402482</td>\n",
       "      <td>0.765789</td>\n",
       "      <td>0.937770</td>\n",
       "      <td>0.694703</td>\n",
       "      <td>0.920472</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>0.995581</td>\n",
       "      <td>0.986567</td>\n",
       "      <td>0.997620</td>\n",
       "      <td>0.980992</td>\n",
       "      <td>0.987018</td>\n",
       "      <td>9.519369e-01</td>\n",
       "      <td>0.973318</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.727823</td>\n",
       "      <td>0.278443</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.497310</td>\n",
       "      <td>0.247837</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.161334</td>\n",
       "      <td>0.755283</td>\n",
       "      <td>0.694804</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.632151</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>100</td>\n",
       "      <td>2465</td>\n",
       "      <td>0.400593</td>\n",
       "      <td>0.496899</td>\n",
       "      <td>0.300016</td>\n",
       "      <td>0.359965</td>\n",
       "      <td>0.486943</td>\n",
       "      <td>0.300016</td>\n",
       "      <td>0.938961</td>\n",
       "      <td>0.966689</td>\n",
       "      <td>0.920880</td>\n",
       "      <td>0.955600</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.976880</td>\n",
       "      <td>0.988303</td>\n",
       "      <td>9.550776e-01</td>\n",
       "      <td>0.981918</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.957711</td>\n",
       "      <td>0.885079</td>\n",
       "      <td>0.981948</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.949175</td>\n",
       "      <td>0.827598</td>\n",
       "      <td>0.859332</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.231866</td>\n",
       "      <td>0.744921</td>\n",
       "      <td>0.919836</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.741689</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>100</td>\n",
       "      <td>4826</td>\n",
       "      <td>0.455674</td>\n",
       "      <td>0.314752</td>\n",
       "      <td>0.164622</td>\n",
       "      <td>0.285976</td>\n",
       "      <td>0.263800</td>\n",
       "      <td>0.141633</td>\n",
       "      <td>0.862357</td>\n",
       "      <td>0.829606</td>\n",
       "      <td>0.686363</td>\n",
       "      <td>0.696630</td>\n",
       "      <td>0.821795</td>\n",
       "      <td>0.697329</td>\n",
       "      <td>0.349369</td>\n",
       "      <td>0.179964</td>\n",
       "      <td>0.987204</td>\n",
       "      <td>0.988050</td>\n",
       "      <td>9.478470e-01</td>\n",
       "      <td>0.967856</td>\n",
       "      <td>0.901601</td>\n",
       "      <td>0.952641</td>\n",
       "      <td>0.800605</td>\n",
       "      <td>0.915722</td>\n",
       "      <td>0.921890</td>\n",
       "      <td>0.843335</td>\n",
       "      <td>0.630609</td>\n",
       "      <td>0.228930</td>\n",
       "      <td>0.893790</td>\n",
       "      <td>0.867906</td>\n",
       "      <td>0.824654</td>\n",
       "      <td>0.740736</td>\n",
       "      <td>0.508417</td>\n",
       "      <td>0.181875</td>\n",
       "      <td>0.800605</td>\n",
       "      <td>0.774736</td>\n",
       "      <td>0.196729</td>\n",
       "      <td>0.753039</td>\n",
       "      <td>0.926500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.307623</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>100</td>\n",
       "      <td>4361</td>\n",
       "      <td>0.245022</td>\n",
       "      <td>0.156215</td>\n",
       "      <td>0.192543</td>\n",
       "      <td>0.210180</td>\n",
       "      <td>0.221758</td>\n",
       "      <td>0.182364</td>\n",
       "      <td>0.786647</td>\n",
       "      <td>0.825674</td>\n",
       "      <td>0.721867</td>\n",
       "      <td>0.800733</td>\n",
       "      <td>0.760857</td>\n",
       "      <td>0.743708</td>\n",
       "      <td>0.612054</td>\n",
       "      <td>0.321660</td>\n",
       "      <td>0.977733</td>\n",
       "      <td>0.988820</td>\n",
       "      <td>9.693904e-01</td>\n",
       "      <td>0.983416</td>\n",
       "      <td>0.858266</td>\n",
       "      <td>0.944924</td>\n",
       "      <td>0.834894</td>\n",
       "      <td>0.933571</td>\n",
       "      <td>0.803079</td>\n",
       "      <td>0.691092</td>\n",
       "      <td>0.555945</td>\n",
       "      <td>0.308838</td>\n",
       "      <td>0.858266</td>\n",
       "      <td>0.831412</td>\n",
       "      <td>0.746720</td>\n",
       "      <td>0.598453</td>\n",
       "      <td>0.370800</td>\n",
       "      <td>0.266747</td>\n",
       "      <td>0.834894</td>\n",
       "      <td>0.813473</td>\n",
       "      <td>0.234463</td>\n",
       "      <td>0.688798</td>\n",
       "      <td>0.305225</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.281980</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    from    to  Doc2Vec:Wikipedia,Size=300  Word2Vec:Wikipedia,Size=300,Mean  Word2Vec:Wikipedia,Size=300,Max  Doc2Vec Phenes:Wikipedia,Size=300  Word2Vec Phenes:Wikipedia,Size=300,Mean  Word2Vec Phenes:Wikipedia,Size=300,Max  NOBLE Coder:Precise,TFIDF  NOBLE Coder:Partial,TFIDF  NOBLE Coder Phenes:Precise,TFIDF  NOBLE Coder Phenes:Partial,TFIDF  Topic Models:NMF,Full,Topics=50  Topic Models:NMF,Full,Topics=100  Topic Models Phenes:NMF,Full,Topics=50  Topic Models Phenes:NMF,Full,Topics=100  Topic Models:LDA,Full,Topics=50  Topic Models:LDA,Full,Topics=100  Topic Models Phenes:LDA,Full,Topics=50  Topic Models Phenes:LDA,Full,Topics=100  N-Grams:Full,Words,1-grams,TFIDF  N-Grams:Full,Words,1-grams,2-grams,TFIDF  N-Grams Phenes:Full,Words,1-grams,TFIDF  N-Grams Phenes:Full,Words,1-grams,2-grams,TFIDF  N-Grams:Full,Nouns,Adjectives,1-grams  N-Grams:Linares_Pontes,Words,1-grams  N-Grams:Full,Precise_Annotations,Words,1-grams  N-Grams:Full,Partial_Annotations,Words,1-grams  \\\n",
       "0    100  1145                    0.504560                          0.503235                         0.263459                           0.414963                                 0.478481                                0.288674                   0.857573                   0.928872                          0.796288                          0.900807                         1.000000                          1.000000                                1.000000                                 0.995888                         0.980399                          0.990102                            9.668565e-01                                 0.981963                          1.000000                                  1.000000                                 1.000000                                         1.000000                               1.000000                              1.000000                                        0.836855                                        0.566964   \n",
       "1    100  4114                    0.309927                          0.260014                         0.185656                           0.276678                                 0.270105                                0.180168                   0.932399                   0.962904                          0.910822                          0.957076                         0.999785                          0.999297                                0.999941                                 0.999121                         0.983668                          0.991767                            9.684386e-01                                 0.982268                          1.000000                                  1.000000                                 1.000000                                         1.000000                               1.000000                              0.977206                                        0.797835                                        0.406689   \n",
       "2    100   231                    0.435983                          0.279231                         0.185035                           0.299665                                 0.271672                                0.188429                   0.872037                   0.922563                          0.817956                          0.916699                         0.733982                          0.715878                                0.797588                                 0.900100                         0.977441                          0.990781                            9.554953e-01                                 0.971250                          0.934402                                  0.969146                                 0.883653                                         0.928505                               0.920096                              0.880906                                        0.529131                                        0.490530   \n",
       "3    100  5244                    0.551568                          0.602756                         0.363885                           0.404959                                 0.607823                                0.362408                   1.000000                   0.958144                          1.000000                          0.945128                         1.000000                          1.000000                                0.990909                                 0.905914                         0.976078                          0.983010                            9.529703e-01                                 0.974258                          1.000000                                  1.000000                                 1.000000                                         1.000000                               1.000000                              1.000000                                        1.000000                                        0.978320   \n",
       "4    100   733                    0.508654                          0.270065                         0.181497                           0.355532                                 0.293558                                0.170425                   0.893924                   0.927862                          0.797668                          0.919038                         0.999892                          0.998867                                1.000000                                 0.999008                         0.974111                          0.988849                            9.546172e-01                                 0.971961                          1.000000                                  1.000000                                 1.000000                                         1.000000                               1.000000                              0.865899                                        0.796603                                        0.284657   \n",
       "5    100  3896                    0.518026                          0.536171                         0.298879                           0.428593                                 0.590710                                0.391840                   0.970234                   0.972461                          1.000000                          0.967205                         1.000000                          1.000000                                1.000000                                 1.000000                         0.976449                          0.988082                            9.620776e-01                                 0.961087                          1.000000                                  1.000000                                 1.000000                                         1.000000                               1.000000                              1.000000                                        0.912374                                        0.338805   \n",
       "6    100  4572                    0.498664                          0.326860                         0.179187                           0.349483                                 0.341777                                0.209361                   0.948135                   0.927444                          0.939123                          0.925689                         0.998685                          0.986242                                0.988918                                 0.640430                         0.982011                          0.990924                            9.532030e-01                                 0.978660                          1.000000                                  1.000000                                 1.000000                                         1.000000                               1.000000                              0.908057                                        0.713808                                        0.345801   \n",
       "7    100  2823                    0.542816                          0.272979                         0.187657                           0.296875                                 0.278486                                0.199103                   0.887384                   0.909117                          1.000000                          0.885990                         1.000000                          1.000000                                0.639737                                 0.740649                         0.980833                          0.990628                            2.500710e-09                                 0.788591                          1.000000                                  1.000000                                 1.000000                                         1.000000                               1.000000                              0.970817                                        0.724138                                        0.247397   \n",
       "8    100  1592                    0.453901                          0.438724                         0.198668                           0.296394                                 0.365019                                0.222920                   0.902751                   0.926640                          1.000000                          0.905401                         1.000000                          0.999490                                0.984330                                 1.000000                         0.973381                          0.991938                            9.606524e-01                                 0.971783                          1.000000                                  1.000000                                 1.000000                                         1.000000                               1.000000                              0.945727                                        0.815585                                        0.329073   \n",
       "9    100  1185                    0.437521                          0.197340                         0.151455                           0.280486                                 0.232980                                0.155569                   0.901545                   0.921714                          0.654037                          0.911570                         0.995473                          0.992384                                0.375339                                 0.979698                         0.983954                          0.992425                            9.599578e-01                                 0.970949                          0.971604                                  0.987393                                 0.880267                                         0.948704                               1.000000                              0.857459                                        0.699810                                        0.319292   \n",
       "10   100   883                    0.433015                          0.601558                         0.872109                           0.345507                                 0.597342                                0.807199                   0.840931                   0.933173                          0.797668                          0.922610                         0.999966                          0.999663                                1.000000                                 1.000000                         0.976885                          0.988305                            9.519369e-01                                 0.973318                          1.000000                                  1.000000                                 1.000000                                         1.000000                               1.000000                              1.000000                                        0.889686                                        0.281991   \n",
       "11   100  2456                    0.506571                          0.186860                         0.160455                           0.196499                                 0.194339                                0.160468                   0.885565                   0.871551                          0.635296                          0.668224                         0.768235                          0.762891                                0.685551                                 0.309989                         0.987835                          0.987893                            9.538829e-01                                 0.713962                          0.887148                                  0.937832                                 0.820744                                         0.906416                               0.892741                              0.778592                                        0.641168                                        0.268298   \n",
       "12   100  5326                    0.490244                          0.380940                         0.186081                           0.408533                                 0.426500                                0.226843                   0.896534                   0.762814                          0.820543                          0.518491                         0.918731                          0.987538                                0.866146                                 0.939288                         0.978446                          0.375235                            9.540923e-01                                 0.967144                          0.923487                                  0.969880                                 0.855463                                         0.937715                               0.911106                              0.915145                                        0.706214                                        0.257861   \n",
       "13   100  1389                    0.449655                          0.173582                         0.152193                           0.190415                                 0.158163                                0.123656                   0.695581                   0.822994                          0.157983                          0.388861                         0.643811                          0.472842                                0.488442                                 0.177004                         0.980936                          0.988426                            1.762766e-05                                 0.050712                          0.809310                                  0.889343                                 0.293965                                         0.517576                               0.851223                              0.738997                                        0.534355                                        0.254799   \n",
       "14   100  5153                    0.498049                          0.255375                         0.205944                           0.346341                                 0.248265                                0.204870                   0.907639                   0.946790                          0.714735                          0.935742                         0.999952                          0.998964                                0.946267                                 0.993401                         0.982195                          0.990205                            9.602068e-01                                 0.971601                          1.000000                                  1.000000                                 1.000000                                         1.000000                               1.000000                              0.897559                                        0.648575                                        0.346042   \n",
       "15   100  1975                    0.517766                          0.246333                         0.155104                           0.365803                                 0.262292                                0.171215                   0.847666                   0.844332                          0.714735                          0.735052                         0.998707                          0.991175                                0.897693                                 0.943254                         0.977903                          0.993223                            7.340050e-01                                 0.788591                          0.977303                                  0.987493                                 0.930794                                         0.962515                               0.966581                              0.874183                                        0.652770                                        0.307714   \n",
       "16   100   705                    0.372423                          0.466228                         0.296158                           0.355532                                 0.485242                                0.402482                   0.765789                   0.937770                          0.694703                          0.920472                         0.999997                          0.995581                                0.986567                                 0.997620                         0.980992                          0.987018                            9.519369e-01                                 0.973318                          1.000000                                  1.000000                                 1.000000                                         1.000000                               1.000000                              1.000000                                        0.727823                                        0.278443   \n",
       "17   100  2465                    0.400593                          0.496899                         0.300016                           0.359965                                 0.486943                                0.300016                   0.938961                   0.966689                          0.920880                          0.955600                         1.000000                          1.000000                                1.000000                                 1.000000                         0.976880                          0.988303                            9.550776e-01                                 0.981918                          1.000000                                  1.000000                                 1.000000                                         1.000000                               1.000000                              0.957711                                        0.885079                                        0.981948   \n",
       "18   100  4826                    0.455674                          0.314752                         0.164622                           0.285976                                 0.263800                                0.141633                   0.862357                   0.829606                          0.686363                          0.696630                         0.821795                          0.697329                                0.349369                                 0.179964                         0.987204                          0.988050                            9.478470e-01                                 0.967856                          0.901601                                  0.952641                                 0.800605                                         0.915722                               0.921890                              0.843335                                        0.630609                                        0.228930   \n",
       "19   100  4361                    0.245022                          0.156215                         0.192543                           0.210180                                 0.221758                                0.182364                   0.786647                   0.825674                          0.721867                          0.800733                         0.760857                          0.743708                                0.612054                                 0.321660                         0.977733                          0.988820                            9.693904e-01                                 0.983416                          0.858266                                  0.944924                                 0.834894                                         0.933571                               0.803079                              0.691092                                        0.555945                                        0.308838   \n",
       "\n",
       "    N-Grams:Full,Plant Overrepresented Tokens,1-grams  N-Grams:Full,Bio Ontology Tokens,1-grams  N-Grams Phenes:Full,Nouns,Adjectives,1-grams  N-Grams Phenes:Linares_Pontes,Words,1-grams  N-Grams Phenes:Full,Precise_Annotations,Words,1-grams  N-Grams Phenes:Full,Partial_Annotations,Words,1-grams  N-Grams Phenes:Full,Plant Overrepresented Tokens,1-grams  N-Grams Phenes:Full,Bio Ontology Tokens,1-grams  GO:Union  PO:Union  GO:Maximum  PO:Maximum      Mean   same  pathways  kegg_only  pmn_only  subsets  known  predicted  orthologs  \n",
       "0                                            1.000000                                  1.000000                                      1.000000                                     1.000000                                           0.586272                                               0.428988                                               1.000000                                                1.000000  1.000000  0.917046    1.000000    0.646146  0.720441  False        -1         -1        -1       -1   -1.0       -1.0       -1.0  \n",
       "1                                            1.000000                                  1.000000                                      1.000000                                     0.977423                                           0.741544                                               0.422529                                               1.000000                                                1.000000  1.000000  1.000000    1.000000    1.000000  0.656684   True        -1         -1        -1       -1    0.0        0.0       -1.0  \n",
       "2                                            0.934402                                  0.915424                                      0.812598                                     0.863527                                           0.376286                                               0.415109                                               0.883653                                                0.853920  0.224368  0.700841    0.905412    0.000000  0.392922   True        -1         -1        -1        0    0.0        0.0       -1.0  \n",
       "3                                            1.000000                                  1.000000                                      1.000000                                     1.000000                                           1.000000                                               0.897213                                               1.000000                                                1.000000  0.355641  0.629555    0.689286    0.476599  0.775899   True        -1         -1        -1       -1    0.0        0.0       -1.0  \n",
       "4                                            1.000000                                  1.000000                                      1.000000                                     0.850601                                           0.593352                                               0.247837                                               1.000000                                                1.000000  0.188509  0.575006    0.689286    0.000000  0.604054   True        -1         -1        -1        0    0.0        0.0       -1.0  \n",
       "5                                            1.000000                                  1.000000                                      1.000000                                     1.000000                                           0.841140                                               0.310185                                               1.000000                                                1.000000  1.000000  1.000000    1.000000    1.000000  0.764766  False        -1         -1        -1       -1   -1.0       -1.0       -1.0  \n",
       "6                                            1.000000                                  1.000000                                      1.000000                                     0.899051                                           0.600257                                               0.263837                                               1.000000                                                1.000000  0.425165  0.556259    0.925314    0.476599  0.618412   True        -1         -1        -1       -1    0.0        0.0       -1.0  \n",
       "7                                            1.000000                                  1.000000                                      1.000000                                     0.949335                                           0.548854                                               0.229812                                               1.000000                                                1.000000  1.000000  1.000000    1.000000    1.000000  0.580942  False        -1         -1        -1       -1   -1.0       -1.0       -1.0  \n",
       "8                                            1.000000                                  1.000000                                      1.000000                                     0.889008                                           0.732580                                               0.247194                                               1.000000                                                1.000000  0.215764  0.644082    0.488195    0.000000  0.648037   True        -1         -1        -1        0    0.0        0.0       -1.0  \n",
       "9                                            0.971132                                  1.000000                                      1.000000                                     0.808575                                           0.420889                                               0.275842                                               0.854551                                                1.000000  0.200531  0.796364    0.898161    0.538176  0.467105   True        -1         -1        -1        0    0.0        0.0       -1.0  \n",
       "10                                           1.000000                                  1.000000                                      1.000000                                     1.000000                                           0.714460                                               0.247837                                               1.000000                                                1.000000  0.297119  0.765555    0.918007    0.000000  0.699790   True        -1         -1        -1        0    0.0        0.0       -1.0  \n",
       "11                                           0.879809                                  0.859276                                      0.718486                                     0.784513                                           0.323591                                               0.215743                                               0.817136                                                0.794983  0.143607  0.642601    0.000000    0.000000  0.289605   True        -1         -1        -1        1    0.0        0.0       -1.0  \n",
       "12                                           0.919181                                  0.909812                                      0.832597                                     0.838619                                           0.626924                                               0.214428                                               0.828453                                                0.812806  1.000000  0.848694    1.000000    0.000000  0.404818   True        -1         -1        -1       -1    0.0        0.0       -1.0  \n",
       "13                                           0.803128                                  0.766201                                      0.388563                                     0.290308                                           0.130693                                               0.113132                                               0.293965                                                0.202365  0.134726  0.756770    0.557407    0.000000  0.150919   True        -1         -1        -1        1    0.0        0.0       -1.0  \n",
       "14                                           1.000000                                  1.000000                                      1.000000                                     0.869588                                           0.493623                                               0.301690                                               1.000000                                                1.000000  0.236706  0.725834    0.889163    0.000000  0.603780   True        -1         -1        -1       -1    0.0        0.0       -1.0  \n",
       "15                                           0.976264                                  0.967525                                      0.894120                                     0.879221                                           0.386746                                               0.281545                                               0.924241                                                0.908044  0.185603  0.757168    0.839198    0.000000  0.428290   True        -1         -1        -1        0    0.0        0.0       -1.0  \n",
       "16                                           1.000000                                  1.000000                                      1.000000                                     1.000000                                           0.497310                                               0.247837                                               1.000000                                                1.000000  0.161334  0.755283    0.694804    0.000000  0.632151   True        -1         -1        -1        0    0.0        0.0       -1.0  \n",
       "17                                           1.000000                                  1.000000                                      1.000000                                     0.949175                                           0.827598                                               0.859332                                               1.000000                                                1.000000  0.231866  0.744921    0.919836    0.000000  0.741689   True        -1         -1        -1        0    0.0        0.0       -1.0  \n",
       "18                                           0.893790                                  0.867906                                      0.824654                                     0.740736                                           0.508417                                               0.181875                                               0.800605                                                0.774736  0.196729  0.753039    0.926500    0.000000  0.307623   True        -1         -1        -1       -1    0.0        0.0       -1.0  \n",
       "19                                           0.858266                                  0.831412                                      0.746720                                     0.598453                                           0.370800                                               0.266747                                               0.834894                                                0.813473  0.234463  0.688798    0.305225    0.000000  0.281980   True        -1         -1        -1       -1    0.0        0.0       -1.0  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add a column that indicates whether or not both genes of the pair are mapped to a phenotype classification.\n",
    "relevant_ids = set(panther_edgelist.ids)\n",
    "df[\"from_is_valid\"] = df[\"from\"].map(lambda x: x in relevant_ids)\n",
    "df[\"to_is_valid\"] = df[\"to\"].map(lambda x: x in relevant_ids)\n",
    "df[\"pair_is_valid\"] = df[\"from_is_valid\"]*df[\"to_is_valid\"]*~df[\"same\"]\n",
    "\n",
    "# Add a column giving the actual target output value for this biological task, with -1 for the irrelevant rows.\n",
    "df[\"orthologs\"] = -1\n",
    "df = df.merge(right=panther_edgelist.df, how=\"left\", on=[\"from\",\"to\"])\n",
    "df[\"value\"].fillna(value=0, inplace=True)\n",
    "df.loc[(df[\"pair_is_valid\"]==True),\"orthologs\"] = df[\"value\"]\n",
    "df.drop(labels=[\"from_is_valid\",\"to_is_valid\",\"pair_is_valid\",\"value\"], axis=\"columns\", inplace=True)\n",
    "\n",
    "df.head(20)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"eq_sim\"></a>\n",
    "### Curator-derived similarity values from Oellrich, Walls et al., 2015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>from</th>\n",
       "      <th>to</th>\n",
       "      <th>Doc2Vec:Wikipedia,Size=300</th>\n",
       "      <th>Word2Vec:Wikipedia,Size=300,Mean</th>\n",
       "      <th>Word2Vec:Wikipedia,Size=300,Max</th>\n",
       "      <th>Doc2Vec Phenes:Wikipedia,Size=300</th>\n",
       "      <th>Word2Vec Phenes:Wikipedia,Size=300,Mean</th>\n",
       "      <th>Word2Vec Phenes:Wikipedia,Size=300,Max</th>\n",
       "      <th>NOBLE Coder:Precise,TFIDF</th>\n",
       "      <th>NOBLE Coder:Partial,TFIDF</th>\n",
       "      <th>NOBLE Coder Phenes:Precise,TFIDF</th>\n",
       "      <th>NOBLE Coder Phenes:Partial,TFIDF</th>\n",
       "      <th>Topic Models:NMF,Full,Topics=50</th>\n",
       "      <th>Topic Models:NMF,Full,Topics=100</th>\n",
       "      <th>Topic Models Phenes:NMF,Full,Topics=50</th>\n",
       "      <th>Topic Models Phenes:NMF,Full,Topics=100</th>\n",
       "      <th>Topic Models:LDA,Full,Topics=50</th>\n",
       "      <th>Topic Models:LDA,Full,Topics=100</th>\n",
       "      <th>Topic Models Phenes:LDA,Full,Topics=50</th>\n",
       "      <th>Topic Models Phenes:LDA,Full,Topics=100</th>\n",
       "      <th>N-Grams:Full,Words,1-grams,TFIDF</th>\n",
       "      <th>N-Grams:Full,Words,1-grams,2-grams,TFIDF</th>\n",
       "      <th>N-Grams Phenes:Full,Words,1-grams,TFIDF</th>\n",
       "      <th>N-Grams Phenes:Full,Words,1-grams,2-grams,TFIDF</th>\n",
       "      <th>N-Grams:Full,Nouns,Adjectives,1-grams</th>\n",
       "      <th>N-Grams:Linares_Pontes,Words,1-grams</th>\n",
       "      <th>N-Grams:Full,Precise_Annotations,Words,1-grams</th>\n",
       "      <th>N-Grams:Full,Partial_Annotations,Words,1-grams</th>\n",
       "      <th>N-Grams:Full,Plant Overrepresented Tokens,1-grams</th>\n",
       "      <th>N-Grams:Full,Bio Ontology Tokens,1-grams</th>\n",
       "      <th>N-Grams Phenes:Full,Nouns,Adjectives,1-grams</th>\n",
       "      <th>N-Grams Phenes:Linares_Pontes,Words,1-grams</th>\n",
       "      <th>N-Grams Phenes:Full,Precise_Annotations,Words,1-grams</th>\n",
       "      <th>N-Grams Phenes:Full,Partial_Annotations,Words,1-grams</th>\n",
       "      <th>N-Grams Phenes:Full,Plant Overrepresented Tokens,1-grams</th>\n",
       "      <th>N-Grams Phenes:Full,Bio Ontology Tokens,1-grams</th>\n",
       "      <th>GO:Union</th>\n",
       "      <th>PO:Union</th>\n",
       "      <th>GO:Maximum</th>\n",
       "      <th>PO:Maximum</th>\n",
       "      <th>Mean</th>\n",
       "      <th>same</th>\n",
       "      <th>pathways</th>\n",
       "      <th>kegg_only</th>\n",
       "      <th>pmn_only</th>\n",
       "      <th>subsets</th>\n",
       "      <th>known</th>\n",
       "      <th>predicted</th>\n",
       "      <th>orthologs</th>\n",
       "      <th>eqs_distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>1145</td>\n",
       "      <td>0.504560</td>\n",
       "      <td>0.503235</td>\n",
       "      <td>0.263459</td>\n",
       "      <td>0.414963</td>\n",
       "      <td>0.478481</td>\n",
       "      <td>0.288674</td>\n",
       "      <td>0.857573</td>\n",
       "      <td>0.928872</td>\n",
       "      <td>0.796288</td>\n",
       "      <td>0.900807</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.995888</td>\n",
       "      <td>0.980399</td>\n",
       "      <td>0.990102</td>\n",
       "      <td>9.668565e-01</td>\n",
       "      <td>0.981963</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.836855</td>\n",
       "      <td>0.566964</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.586272</td>\n",
       "      <td>0.428988</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.917046</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.646146</td>\n",
       "      <td>0.720441</td>\n",
       "      <td>False</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100</td>\n",
       "      <td>4114</td>\n",
       "      <td>0.309927</td>\n",
       "      <td>0.260014</td>\n",
       "      <td>0.185656</td>\n",
       "      <td>0.276678</td>\n",
       "      <td>0.270105</td>\n",
       "      <td>0.180168</td>\n",
       "      <td>0.932399</td>\n",
       "      <td>0.962904</td>\n",
       "      <td>0.910822</td>\n",
       "      <td>0.957076</td>\n",
       "      <td>0.999785</td>\n",
       "      <td>0.999297</td>\n",
       "      <td>0.999941</td>\n",
       "      <td>0.999121</td>\n",
       "      <td>0.983668</td>\n",
       "      <td>0.991767</td>\n",
       "      <td>9.684386e-01</td>\n",
       "      <td>0.982268</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.977206</td>\n",
       "      <td>0.797835</td>\n",
       "      <td>0.406689</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.977423</td>\n",
       "      <td>0.741544</td>\n",
       "      <td>0.422529</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.656684</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>231</td>\n",
       "      <td>0.435983</td>\n",
       "      <td>0.279231</td>\n",
       "      <td>0.185035</td>\n",
       "      <td>0.299665</td>\n",
       "      <td>0.271672</td>\n",
       "      <td>0.188429</td>\n",
       "      <td>0.872037</td>\n",
       "      <td>0.922563</td>\n",
       "      <td>0.817956</td>\n",
       "      <td>0.916699</td>\n",
       "      <td>0.733982</td>\n",
       "      <td>0.715878</td>\n",
       "      <td>0.797588</td>\n",
       "      <td>0.900100</td>\n",
       "      <td>0.977441</td>\n",
       "      <td>0.990781</td>\n",
       "      <td>9.554953e-01</td>\n",
       "      <td>0.971250</td>\n",
       "      <td>0.934402</td>\n",
       "      <td>0.969146</td>\n",
       "      <td>0.883653</td>\n",
       "      <td>0.928505</td>\n",
       "      <td>0.920096</td>\n",
       "      <td>0.880906</td>\n",
       "      <td>0.529131</td>\n",
       "      <td>0.490530</td>\n",
       "      <td>0.934402</td>\n",
       "      <td>0.915424</td>\n",
       "      <td>0.812598</td>\n",
       "      <td>0.863527</td>\n",
       "      <td>0.376286</td>\n",
       "      <td>0.415109</td>\n",
       "      <td>0.883653</td>\n",
       "      <td>0.853920</td>\n",
       "      <td>0.224368</td>\n",
       "      <td>0.700841</td>\n",
       "      <td>0.905412</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.392922</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100</td>\n",
       "      <td>5244</td>\n",
       "      <td>0.551568</td>\n",
       "      <td>0.602756</td>\n",
       "      <td>0.363885</td>\n",
       "      <td>0.404959</td>\n",
       "      <td>0.607823</td>\n",
       "      <td>0.362408</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.958144</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.945128</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.990909</td>\n",
       "      <td>0.905914</td>\n",
       "      <td>0.976078</td>\n",
       "      <td>0.983010</td>\n",
       "      <td>9.529703e-01</td>\n",
       "      <td>0.974258</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.978320</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.897213</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.355641</td>\n",
       "      <td>0.629555</td>\n",
       "      <td>0.689286</td>\n",
       "      <td>0.476599</td>\n",
       "      <td>0.775899</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100</td>\n",
       "      <td>733</td>\n",
       "      <td>0.508654</td>\n",
       "      <td>0.270065</td>\n",
       "      <td>0.181497</td>\n",
       "      <td>0.355532</td>\n",
       "      <td>0.293558</td>\n",
       "      <td>0.170425</td>\n",
       "      <td>0.893924</td>\n",
       "      <td>0.927862</td>\n",
       "      <td>0.797668</td>\n",
       "      <td>0.919038</td>\n",
       "      <td>0.999892</td>\n",
       "      <td>0.998867</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999008</td>\n",
       "      <td>0.974111</td>\n",
       "      <td>0.988849</td>\n",
       "      <td>9.546172e-01</td>\n",
       "      <td>0.971961</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.865899</td>\n",
       "      <td>0.796603</td>\n",
       "      <td>0.284657</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.850601</td>\n",
       "      <td>0.593352</td>\n",
       "      <td>0.247837</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.188509</td>\n",
       "      <td>0.575006</td>\n",
       "      <td>0.689286</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.604054</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>100</td>\n",
       "      <td>3896</td>\n",
       "      <td>0.518026</td>\n",
       "      <td>0.536171</td>\n",
       "      <td>0.298879</td>\n",
       "      <td>0.428593</td>\n",
       "      <td>0.590710</td>\n",
       "      <td>0.391840</td>\n",
       "      <td>0.970234</td>\n",
       "      <td>0.972461</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.967205</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.976449</td>\n",
       "      <td>0.988082</td>\n",
       "      <td>9.620776e-01</td>\n",
       "      <td>0.961087</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.912374</td>\n",
       "      <td>0.338805</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.841140</td>\n",
       "      <td>0.310185</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.764766</td>\n",
       "      <td>False</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>100</td>\n",
       "      <td>4572</td>\n",
       "      <td>0.498664</td>\n",
       "      <td>0.326860</td>\n",
       "      <td>0.179187</td>\n",
       "      <td>0.349483</td>\n",
       "      <td>0.341777</td>\n",
       "      <td>0.209361</td>\n",
       "      <td>0.948135</td>\n",
       "      <td>0.927444</td>\n",
       "      <td>0.939123</td>\n",
       "      <td>0.925689</td>\n",
       "      <td>0.998685</td>\n",
       "      <td>0.986242</td>\n",
       "      <td>0.988918</td>\n",
       "      <td>0.640430</td>\n",
       "      <td>0.982011</td>\n",
       "      <td>0.990924</td>\n",
       "      <td>9.532030e-01</td>\n",
       "      <td>0.978660</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.908057</td>\n",
       "      <td>0.713808</td>\n",
       "      <td>0.345801</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.899051</td>\n",
       "      <td>0.600257</td>\n",
       "      <td>0.263837</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.425165</td>\n",
       "      <td>0.556259</td>\n",
       "      <td>0.925314</td>\n",
       "      <td>0.476599</td>\n",
       "      <td>0.618412</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>100</td>\n",
       "      <td>2823</td>\n",
       "      <td>0.542816</td>\n",
       "      <td>0.272979</td>\n",
       "      <td>0.187657</td>\n",
       "      <td>0.296875</td>\n",
       "      <td>0.278486</td>\n",
       "      <td>0.199103</td>\n",
       "      <td>0.887384</td>\n",
       "      <td>0.909117</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.885990</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.639737</td>\n",
       "      <td>0.740649</td>\n",
       "      <td>0.980833</td>\n",
       "      <td>0.990628</td>\n",
       "      <td>2.500710e-09</td>\n",
       "      <td>0.788591</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.970817</td>\n",
       "      <td>0.724138</td>\n",
       "      <td>0.247397</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.949335</td>\n",
       "      <td>0.548854</td>\n",
       "      <td>0.229812</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.580942</td>\n",
       "      <td>False</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>100</td>\n",
       "      <td>1592</td>\n",
       "      <td>0.453901</td>\n",
       "      <td>0.438724</td>\n",
       "      <td>0.198668</td>\n",
       "      <td>0.296394</td>\n",
       "      <td>0.365019</td>\n",
       "      <td>0.222920</td>\n",
       "      <td>0.902751</td>\n",
       "      <td>0.926640</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.905401</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999490</td>\n",
       "      <td>0.984330</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.973381</td>\n",
       "      <td>0.991938</td>\n",
       "      <td>9.606524e-01</td>\n",
       "      <td>0.971783</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.945727</td>\n",
       "      <td>0.815585</td>\n",
       "      <td>0.329073</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.889008</td>\n",
       "      <td>0.732580</td>\n",
       "      <td>0.247194</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.215764</td>\n",
       "      <td>0.644082</td>\n",
       "      <td>0.488195</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.648037</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>100</td>\n",
       "      <td>1185</td>\n",
       "      <td>0.437521</td>\n",
       "      <td>0.197340</td>\n",
       "      <td>0.151455</td>\n",
       "      <td>0.280486</td>\n",
       "      <td>0.232980</td>\n",
       "      <td>0.155569</td>\n",
       "      <td>0.901545</td>\n",
       "      <td>0.921714</td>\n",
       "      <td>0.654037</td>\n",
       "      <td>0.911570</td>\n",
       "      <td>0.995473</td>\n",
       "      <td>0.992384</td>\n",
       "      <td>0.375339</td>\n",
       "      <td>0.979698</td>\n",
       "      <td>0.983954</td>\n",
       "      <td>0.992425</td>\n",
       "      <td>9.599578e-01</td>\n",
       "      <td>0.970949</td>\n",
       "      <td>0.971604</td>\n",
       "      <td>0.987393</td>\n",
       "      <td>0.880267</td>\n",
       "      <td>0.948704</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.857459</td>\n",
       "      <td>0.699810</td>\n",
       "      <td>0.319292</td>\n",
       "      <td>0.971132</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.808575</td>\n",
       "      <td>0.420889</td>\n",
       "      <td>0.275842</td>\n",
       "      <td>0.854551</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.200531</td>\n",
       "      <td>0.796364</td>\n",
       "      <td>0.898161</td>\n",
       "      <td>0.538176</td>\n",
       "      <td>0.467105</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>100</td>\n",
       "      <td>883</td>\n",
       "      <td>0.433015</td>\n",
       "      <td>0.601558</td>\n",
       "      <td>0.872109</td>\n",
       "      <td>0.345507</td>\n",
       "      <td>0.597342</td>\n",
       "      <td>0.807199</td>\n",
       "      <td>0.840931</td>\n",
       "      <td>0.933173</td>\n",
       "      <td>0.797668</td>\n",
       "      <td>0.922610</td>\n",
       "      <td>0.999966</td>\n",
       "      <td>0.999663</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.976885</td>\n",
       "      <td>0.988305</td>\n",
       "      <td>9.519369e-01</td>\n",
       "      <td>0.973318</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.889686</td>\n",
       "      <td>0.281991</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.714460</td>\n",
       "      <td>0.247837</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.297119</td>\n",
       "      <td>0.765555</td>\n",
       "      <td>0.918007</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.699790</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>100</td>\n",
       "      <td>2456</td>\n",
       "      <td>0.506571</td>\n",
       "      <td>0.186860</td>\n",
       "      <td>0.160455</td>\n",
       "      <td>0.196499</td>\n",
       "      <td>0.194339</td>\n",
       "      <td>0.160468</td>\n",
       "      <td>0.885565</td>\n",
       "      <td>0.871551</td>\n",
       "      <td>0.635296</td>\n",
       "      <td>0.668224</td>\n",
       "      <td>0.768235</td>\n",
       "      <td>0.762891</td>\n",
       "      <td>0.685551</td>\n",
       "      <td>0.309989</td>\n",
       "      <td>0.987835</td>\n",
       "      <td>0.987893</td>\n",
       "      <td>9.538829e-01</td>\n",
       "      <td>0.713962</td>\n",
       "      <td>0.887148</td>\n",
       "      <td>0.937832</td>\n",
       "      <td>0.820744</td>\n",
       "      <td>0.906416</td>\n",
       "      <td>0.892741</td>\n",
       "      <td>0.778592</td>\n",
       "      <td>0.641168</td>\n",
       "      <td>0.268298</td>\n",
       "      <td>0.879809</td>\n",
       "      <td>0.859276</td>\n",
       "      <td>0.718486</td>\n",
       "      <td>0.784513</td>\n",
       "      <td>0.323591</td>\n",
       "      <td>0.215743</td>\n",
       "      <td>0.817136</td>\n",
       "      <td>0.794983</td>\n",
       "      <td>0.143607</td>\n",
       "      <td>0.642601</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.289605</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>100</td>\n",
       "      <td>5326</td>\n",
       "      <td>0.490244</td>\n",
       "      <td>0.380940</td>\n",
       "      <td>0.186081</td>\n",
       "      <td>0.408533</td>\n",
       "      <td>0.426500</td>\n",
       "      <td>0.226843</td>\n",
       "      <td>0.896534</td>\n",
       "      <td>0.762814</td>\n",
       "      <td>0.820543</td>\n",
       "      <td>0.518491</td>\n",
       "      <td>0.918731</td>\n",
       "      <td>0.987538</td>\n",
       "      <td>0.866146</td>\n",
       "      <td>0.939288</td>\n",
       "      <td>0.978446</td>\n",
       "      <td>0.375235</td>\n",
       "      <td>9.540923e-01</td>\n",
       "      <td>0.967144</td>\n",
       "      <td>0.923487</td>\n",
       "      <td>0.969880</td>\n",
       "      <td>0.855463</td>\n",
       "      <td>0.937715</td>\n",
       "      <td>0.911106</td>\n",
       "      <td>0.915145</td>\n",
       "      <td>0.706214</td>\n",
       "      <td>0.257861</td>\n",
       "      <td>0.919181</td>\n",
       "      <td>0.909812</td>\n",
       "      <td>0.832597</td>\n",
       "      <td>0.838619</td>\n",
       "      <td>0.626924</td>\n",
       "      <td>0.214428</td>\n",
       "      <td>0.828453</td>\n",
       "      <td>0.812806</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.848694</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.404818</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>100</td>\n",
       "      <td>1389</td>\n",
       "      <td>0.449655</td>\n",
       "      <td>0.173582</td>\n",
       "      <td>0.152193</td>\n",
       "      <td>0.190415</td>\n",
       "      <td>0.158163</td>\n",
       "      <td>0.123656</td>\n",
       "      <td>0.695581</td>\n",
       "      <td>0.822994</td>\n",
       "      <td>0.157983</td>\n",
       "      <td>0.388861</td>\n",
       "      <td>0.643811</td>\n",
       "      <td>0.472842</td>\n",
       "      <td>0.488442</td>\n",
       "      <td>0.177004</td>\n",
       "      <td>0.980936</td>\n",
       "      <td>0.988426</td>\n",
       "      <td>1.762766e-05</td>\n",
       "      <td>0.050712</td>\n",
       "      <td>0.809310</td>\n",
       "      <td>0.889343</td>\n",
       "      <td>0.293965</td>\n",
       "      <td>0.517576</td>\n",
       "      <td>0.851223</td>\n",
       "      <td>0.738997</td>\n",
       "      <td>0.534355</td>\n",
       "      <td>0.254799</td>\n",
       "      <td>0.803128</td>\n",
       "      <td>0.766201</td>\n",
       "      <td>0.388563</td>\n",
       "      <td>0.290308</td>\n",
       "      <td>0.130693</td>\n",
       "      <td>0.113132</td>\n",
       "      <td>0.293965</td>\n",
       "      <td>0.202365</td>\n",
       "      <td>0.134726</td>\n",
       "      <td>0.756770</td>\n",
       "      <td>0.557407</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.150919</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>100</td>\n",
       "      <td>5153</td>\n",
       "      <td>0.498049</td>\n",
       "      <td>0.255375</td>\n",
       "      <td>0.205944</td>\n",
       "      <td>0.346341</td>\n",
       "      <td>0.248265</td>\n",
       "      <td>0.204870</td>\n",
       "      <td>0.907639</td>\n",
       "      <td>0.946790</td>\n",
       "      <td>0.714735</td>\n",
       "      <td>0.935742</td>\n",
       "      <td>0.999952</td>\n",
       "      <td>0.998964</td>\n",
       "      <td>0.946267</td>\n",
       "      <td>0.993401</td>\n",
       "      <td>0.982195</td>\n",
       "      <td>0.990205</td>\n",
       "      <td>9.602068e-01</td>\n",
       "      <td>0.971601</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.897559</td>\n",
       "      <td>0.648575</td>\n",
       "      <td>0.346042</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.869588</td>\n",
       "      <td>0.493623</td>\n",
       "      <td>0.301690</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.236706</td>\n",
       "      <td>0.725834</td>\n",
       "      <td>0.889163</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.603780</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>100</td>\n",
       "      <td>1975</td>\n",
       "      <td>0.517766</td>\n",
       "      <td>0.246333</td>\n",
       "      <td>0.155104</td>\n",
       "      <td>0.365803</td>\n",
       "      <td>0.262292</td>\n",
       "      <td>0.171215</td>\n",
       "      <td>0.847666</td>\n",
       "      <td>0.844332</td>\n",
       "      <td>0.714735</td>\n",
       "      <td>0.735052</td>\n",
       "      <td>0.998707</td>\n",
       "      <td>0.991175</td>\n",
       "      <td>0.897693</td>\n",
       "      <td>0.943254</td>\n",
       "      <td>0.977903</td>\n",
       "      <td>0.993223</td>\n",
       "      <td>7.340050e-01</td>\n",
       "      <td>0.788591</td>\n",
       "      <td>0.977303</td>\n",
       "      <td>0.987493</td>\n",
       "      <td>0.930794</td>\n",
       "      <td>0.962515</td>\n",
       "      <td>0.966581</td>\n",
       "      <td>0.874183</td>\n",
       "      <td>0.652770</td>\n",
       "      <td>0.307714</td>\n",
       "      <td>0.976264</td>\n",
       "      <td>0.967525</td>\n",
       "      <td>0.894120</td>\n",
       "      <td>0.879221</td>\n",
       "      <td>0.386746</td>\n",
       "      <td>0.281545</td>\n",
       "      <td>0.924241</td>\n",
       "      <td>0.908044</td>\n",
       "      <td>0.185603</td>\n",
       "      <td>0.757168</td>\n",
       "      <td>0.839198</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.428290</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>100</td>\n",
       "      <td>705</td>\n",
       "      <td>0.372423</td>\n",
       "      <td>0.466228</td>\n",
       "      <td>0.296158</td>\n",
       "      <td>0.355532</td>\n",
       "      <td>0.485242</td>\n",
       "      <td>0.402482</td>\n",
       "      <td>0.765789</td>\n",
       "      <td>0.937770</td>\n",
       "      <td>0.694703</td>\n",
       "      <td>0.920472</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>0.995581</td>\n",
       "      <td>0.986567</td>\n",
       "      <td>0.997620</td>\n",
       "      <td>0.980992</td>\n",
       "      <td>0.987018</td>\n",
       "      <td>9.519369e-01</td>\n",
       "      <td>0.973318</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.727823</td>\n",
       "      <td>0.278443</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.497310</td>\n",
       "      <td>0.247837</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.161334</td>\n",
       "      <td>0.755283</td>\n",
       "      <td>0.694804</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.632151</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>100</td>\n",
       "      <td>2465</td>\n",
       "      <td>0.400593</td>\n",
       "      <td>0.496899</td>\n",
       "      <td>0.300016</td>\n",
       "      <td>0.359965</td>\n",
       "      <td>0.486943</td>\n",
       "      <td>0.300016</td>\n",
       "      <td>0.938961</td>\n",
       "      <td>0.966689</td>\n",
       "      <td>0.920880</td>\n",
       "      <td>0.955600</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.976880</td>\n",
       "      <td>0.988303</td>\n",
       "      <td>9.550776e-01</td>\n",
       "      <td>0.981918</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.957711</td>\n",
       "      <td>0.885079</td>\n",
       "      <td>0.981948</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.949175</td>\n",
       "      <td>0.827598</td>\n",
       "      <td>0.859332</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.231866</td>\n",
       "      <td>0.744921</td>\n",
       "      <td>0.919836</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.741689</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>100</td>\n",
       "      <td>4826</td>\n",
       "      <td>0.455674</td>\n",
       "      <td>0.314752</td>\n",
       "      <td>0.164622</td>\n",
       "      <td>0.285976</td>\n",
       "      <td>0.263800</td>\n",
       "      <td>0.141633</td>\n",
       "      <td>0.862357</td>\n",
       "      <td>0.829606</td>\n",
       "      <td>0.686363</td>\n",
       "      <td>0.696630</td>\n",
       "      <td>0.821795</td>\n",
       "      <td>0.697329</td>\n",
       "      <td>0.349369</td>\n",
       "      <td>0.179964</td>\n",
       "      <td>0.987204</td>\n",
       "      <td>0.988050</td>\n",
       "      <td>9.478470e-01</td>\n",
       "      <td>0.967856</td>\n",
       "      <td>0.901601</td>\n",
       "      <td>0.952641</td>\n",
       "      <td>0.800605</td>\n",
       "      <td>0.915722</td>\n",
       "      <td>0.921890</td>\n",
       "      <td>0.843335</td>\n",
       "      <td>0.630609</td>\n",
       "      <td>0.228930</td>\n",
       "      <td>0.893790</td>\n",
       "      <td>0.867906</td>\n",
       "      <td>0.824654</td>\n",
       "      <td>0.740736</td>\n",
       "      <td>0.508417</td>\n",
       "      <td>0.181875</td>\n",
       "      <td>0.800605</td>\n",
       "      <td>0.774736</td>\n",
       "      <td>0.196729</td>\n",
       "      <td>0.753039</td>\n",
       "      <td>0.926500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.307623</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>100</td>\n",
       "      <td>4361</td>\n",
       "      <td>0.245022</td>\n",
       "      <td>0.156215</td>\n",
       "      <td>0.192543</td>\n",
       "      <td>0.210180</td>\n",
       "      <td>0.221758</td>\n",
       "      <td>0.182364</td>\n",
       "      <td>0.786647</td>\n",
       "      <td>0.825674</td>\n",
       "      <td>0.721867</td>\n",
       "      <td>0.800733</td>\n",
       "      <td>0.760857</td>\n",
       "      <td>0.743708</td>\n",
       "      <td>0.612054</td>\n",
       "      <td>0.321660</td>\n",
       "      <td>0.977733</td>\n",
       "      <td>0.988820</td>\n",
       "      <td>9.693904e-01</td>\n",
       "      <td>0.983416</td>\n",
       "      <td>0.858266</td>\n",
       "      <td>0.944924</td>\n",
       "      <td>0.834894</td>\n",
       "      <td>0.933571</td>\n",
       "      <td>0.803079</td>\n",
       "      <td>0.691092</td>\n",
       "      <td>0.555945</td>\n",
       "      <td>0.308838</td>\n",
       "      <td>0.858266</td>\n",
       "      <td>0.831412</td>\n",
       "      <td>0.746720</td>\n",
       "      <td>0.598453</td>\n",
       "      <td>0.370800</td>\n",
       "      <td>0.266747</td>\n",
       "      <td>0.834894</td>\n",
       "      <td>0.813473</td>\n",
       "      <td>0.234463</td>\n",
       "      <td>0.688798</td>\n",
       "      <td>0.305225</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.281980</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    from    to  Doc2Vec:Wikipedia,Size=300  Word2Vec:Wikipedia,Size=300,Mean  Word2Vec:Wikipedia,Size=300,Max  Doc2Vec Phenes:Wikipedia,Size=300  Word2Vec Phenes:Wikipedia,Size=300,Mean  Word2Vec Phenes:Wikipedia,Size=300,Max  NOBLE Coder:Precise,TFIDF  NOBLE Coder:Partial,TFIDF  NOBLE Coder Phenes:Precise,TFIDF  NOBLE Coder Phenes:Partial,TFIDF  Topic Models:NMF,Full,Topics=50  Topic Models:NMF,Full,Topics=100  Topic Models Phenes:NMF,Full,Topics=50  Topic Models Phenes:NMF,Full,Topics=100  Topic Models:LDA,Full,Topics=50  Topic Models:LDA,Full,Topics=100  Topic Models Phenes:LDA,Full,Topics=50  Topic Models Phenes:LDA,Full,Topics=100  N-Grams:Full,Words,1-grams,TFIDF  N-Grams:Full,Words,1-grams,2-grams,TFIDF  N-Grams Phenes:Full,Words,1-grams,TFIDF  N-Grams Phenes:Full,Words,1-grams,2-grams,TFIDF  N-Grams:Full,Nouns,Adjectives,1-grams  N-Grams:Linares_Pontes,Words,1-grams  N-Grams:Full,Precise_Annotations,Words,1-grams  N-Grams:Full,Partial_Annotations,Words,1-grams  \\\n",
       "0    100  1145                    0.504560                          0.503235                         0.263459                           0.414963                                 0.478481                                0.288674                   0.857573                   0.928872                          0.796288                          0.900807                         1.000000                          1.000000                                1.000000                                 0.995888                         0.980399                          0.990102                            9.668565e-01                                 0.981963                          1.000000                                  1.000000                                 1.000000                                         1.000000                               1.000000                              1.000000                                        0.836855                                        0.566964   \n",
       "1    100  4114                    0.309927                          0.260014                         0.185656                           0.276678                                 0.270105                                0.180168                   0.932399                   0.962904                          0.910822                          0.957076                         0.999785                          0.999297                                0.999941                                 0.999121                         0.983668                          0.991767                            9.684386e-01                                 0.982268                          1.000000                                  1.000000                                 1.000000                                         1.000000                               1.000000                              0.977206                                        0.797835                                        0.406689   \n",
       "2    100   231                    0.435983                          0.279231                         0.185035                           0.299665                                 0.271672                                0.188429                   0.872037                   0.922563                          0.817956                          0.916699                         0.733982                          0.715878                                0.797588                                 0.900100                         0.977441                          0.990781                            9.554953e-01                                 0.971250                          0.934402                                  0.969146                                 0.883653                                         0.928505                               0.920096                              0.880906                                        0.529131                                        0.490530   \n",
       "3    100  5244                    0.551568                          0.602756                         0.363885                           0.404959                                 0.607823                                0.362408                   1.000000                   0.958144                          1.000000                          0.945128                         1.000000                          1.000000                                0.990909                                 0.905914                         0.976078                          0.983010                            9.529703e-01                                 0.974258                          1.000000                                  1.000000                                 1.000000                                         1.000000                               1.000000                              1.000000                                        1.000000                                        0.978320   \n",
       "4    100   733                    0.508654                          0.270065                         0.181497                           0.355532                                 0.293558                                0.170425                   0.893924                   0.927862                          0.797668                          0.919038                         0.999892                          0.998867                                1.000000                                 0.999008                         0.974111                          0.988849                            9.546172e-01                                 0.971961                          1.000000                                  1.000000                                 1.000000                                         1.000000                               1.000000                              0.865899                                        0.796603                                        0.284657   \n",
       "5    100  3896                    0.518026                          0.536171                         0.298879                           0.428593                                 0.590710                                0.391840                   0.970234                   0.972461                          1.000000                          0.967205                         1.000000                          1.000000                                1.000000                                 1.000000                         0.976449                          0.988082                            9.620776e-01                                 0.961087                          1.000000                                  1.000000                                 1.000000                                         1.000000                               1.000000                              1.000000                                        0.912374                                        0.338805   \n",
       "6    100  4572                    0.498664                          0.326860                         0.179187                           0.349483                                 0.341777                                0.209361                   0.948135                   0.927444                          0.939123                          0.925689                         0.998685                          0.986242                                0.988918                                 0.640430                         0.982011                          0.990924                            9.532030e-01                                 0.978660                          1.000000                                  1.000000                                 1.000000                                         1.000000                               1.000000                              0.908057                                        0.713808                                        0.345801   \n",
       "7    100  2823                    0.542816                          0.272979                         0.187657                           0.296875                                 0.278486                                0.199103                   0.887384                   0.909117                          1.000000                          0.885990                         1.000000                          1.000000                                0.639737                                 0.740649                         0.980833                          0.990628                            2.500710e-09                                 0.788591                          1.000000                                  1.000000                                 1.000000                                         1.000000                               1.000000                              0.970817                                        0.724138                                        0.247397   \n",
       "8    100  1592                    0.453901                          0.438724                         0.198668                           0.296394                                 0.365019                                0.222920                   0.902751                   0.926640                          1.000000                          0.905401                         1.000000                          0.999490                                0.984330                                 1.000000                         0.973381                          0.991938                            9.606524e-01                                 0.971783                          1.000000                                  1.000000                                 1.000000                                         1.000000                               1.000000                              0.945727                                        0.815585                                        0.329073   \n",
       "9    100  1185                    0.437521                          0.197340                         0.151455                           0.280486                                 0.232980                                0.155569                   0.901545                   0.921714                          0.654037                          0.911570                         0.995473                          0.992384                                0.375339                                 0.979698                         0.983954                          0.992425                            9.599578e-01                                 0.970949                          0.971604                                  0.987393                                 0.880267                                         0.948704                               1.000000                              0.857459                                        0.699810                                        0.319292   \n",
       "10   100   883                    0.433015                          0.601558                         0.872109                           0.345507                                 0.597342                                0.807199                   0.840931                   0.933173                          0.797668                          0.922610                         0.999966                          0.999663                                1.000000                                 1.000000                         0.976885                          0.988305                            9.519369e-01                                 0.973318                          1.000000                                  1.000000                                 1.000000                                         1.000000                               1.000000                              1.000000                                        0.889686                                        0.281991   \n",
       "11   100  2456                    0.506571                          0.186860                         0.160455                           0.196499                                 0.194339                                0.160468                   0.885565                   0.871551                          0.635296                          0.668224                         0.768235                          0.762891                                0.685551                                 0.309989                         0.987835                          0.987893                            9.538829e-01                                 0.713962                          0.887148                                  0.937832                                 0.820744                                         0.906416                               0.892741                              0.778592                                        0.641168                                        0.268298   \n",
       "12   100  5326                    0.490244                          0.380940                         0.186081                           0.408533                                 0.426500                                0.226843                   0.896534                   0.762814                          0.820543                          0.518491                         0.918731                          0.987538                                0.866146                                 0.939288                         0.978446                          0.375235                            9.540923e-01                                 0.967144                          0.923487                                  0.969880                                 0.855463                                         0.937715                               0.911106                              0.915145                                        0.706214                                        0.257861   \n",
       "13   100  1389                    0.449655                          0.173582                         0.152193                           0.190415                                 0.158163                                0.123656                   0.695581                   0.822994                          0.157983                          0.388861                         0.643811                          0.472842                                0.488442                                 0.177004                         0.980936                          0.988426                            1.762766e-05                                 0.050712                          0.809310                                  0.889343                                 0.293965                                         0.517576                               0.851223                              0.738997                                        0.534355                                        0.254799   \n",
       "14   100  5153                    0.498049                          0.255375                         0.205944                           0.346341                                 0.248265                                0.204870                   0.907639                   0.946790                          0.714735                          0.935742                         0.999952                          0.998964                                0.946267                                 0.993401                         0.982195                          0.990205                            9.602068e-01                                 0.971601                          1.000000                                  1.000000                                 1.000000                                         1.000000                               1.000000                              0.897559                                        0.648575                                        0.346042   \n",
       "15   100  1975                    0.517766                          0.246333                         0.155104                           0.365803                                 0.262292                                0.171215                   0.847666                   0.844332                          0.714735                          0.735052                         0.998707                          0.991175                                0.897693                                 0.943254                         0.977903                          0.993223                            7.340050e-01                                 0.788591                          0.977303                                  0.987493                                 0.930794                                         0.962515                               0.966581                              0.874183                                        0.652770                                        0.307714   \n",
       "16   100   705                    0.372423                          0.466228                         0.296158                           0.355532                                 0.485242                                0.402482                   0.765789                   0.937770                          0.694703                          0.920472                         0.999997                          0.995581                                0.986567                                 0.997620                         0.980992                          0.987018                            9.519369e-01                                 0.973318                          1.000000                                  1.000000                                 1.000000                                         1.000000                               1.000000                              1.000000                                        0.727823                                        0.278443   \n",
       "17   100  2465                    0.400593                          0.496899                         0.300016                           0.359965                                 0.486943                                0.300016                   0.938961                   0.966689                          0.920880                          0.955600                         1.000000                          1.000000                                1.000000                                 1.000000                         0.976880                          0.988303                            9.550776e-01                                 0.981918                          1.000000                                  1.000000                                 1.000000                                         1.000000                               1.000000                              0.957711                                        0.885079                                        0.981948   \n",
       "18   100  4826                    0.455674                          0.314752                         0.164622                           0.285976                                 0.263800                                0.141633                   0.862357                   0.829606                          0.686363                          0.696630                         0.821795                          0.697329                                0.349369                                 0.179964                         0.987204                          0.988050                            9.478470e-01                                 0.967856                          0.901601                                  0.952641                                 0.800605                                         0.915722                               0.921890                              0.843335                                        0.630609                                        0.228930   \n",
       "19   100  4361                    0.245022                          0.156215                         0.192543                           0.210180                                 0.221758                                0.182364                   0.786647                   0.825674                          0.721867                          0.800733                         0.760857                          0.743708                                0.612054                                 0.321660                         0.977733                          0.988820                            9.693904e-01                                 0.983416                          0.858266                                  0.944924                                 0.834894                                         0.933571                               0.803079                              0.691092                                        0.555945                                        0.308838   \n",
       "\n",
       "    N-Grams:Full,Plant Overrepresented Tokens,1-grams  N-Grams:Full,Bio Ontology Tokens,1-grams  N-Grams Phenes:Full,Nouns,Adjectives,1-grams  N-Grams Phenes:Linares_Pontes,Words,1-grams  N-Grams Phenes:Full,Precise_Annotations,Words,1-grams  N-Grams Phenes:Full,Partial_Annotations,Words,1-grams  N-Grams Phenes:Full,Plant Overrepresented Tokens,1-grams  N-Grams Phenes:Full,Bio Ontology Tokens,1-grams  GO:Union  PO:Union  GO:Maximum  PO:Maximum      Mean   same  pathways  kegg_only  pmn_only  subsets  known  predicted  orthologs  eqs_distance  \n",
       "0                                            1.000000                                  1.000000                                      1.000000                                     1.000000                                           0.586272                                               0.428988                                               1.000000                                                1.000000  1.000000  0.917046    1.000000    0.646146  0.720441  False        -1         -1        -1       -1   -1.0       -1.0       -1.0           1.0  \n",
       "1                                            1.000000                                  1.000000                                      1.000000                                     0.977423                                           0.741544                                               0.422529                                               1.000000                                                1.000000  1.000000  1.000000    1.000000    1.000000  0.656684   True        -1         -1        -1       -1    0.0        0.0       -1.0          -1.0  \n",
       "2                                            0.934402                                  0.915424                                      0.812598                                     0.863527                                           0.376286                                               0.415109                                               0.883653                                                0.853920  0.224368  0.700841    0.905412    0.000000  0.392922   True        -1         -1        -1        0    0.0        0.0       -1.0           1.0  \n",
       "3                                            1.000000                                  1.000000                                      1.000000                                     1.000000                                           1.000000                                               0.897213                                               1.000000                                                1.000000  0.355641  0.629555    0.689286    0.476599  0.775899   True        -1         -1        -1       -1    0.0        0.0       -1.0          -1.0  \n",
       "4                                            1.000000                                  1.000000                                      1.000000                                     0.850601                                           0.593352                                               0.247837                                               1.000000                                                1.000000  0.188509  0.575006    0.689286    0.000000  0.604054   True        -1         -1        -1        0    0.0        0.0       -1.0           1.0  \n",
       "5                                            1.000000                                  1.000000                                      1.000000                                     1.000000                                           0.841140                                               0.310185                                               1.000000                                                1.000000  1.000000  1.000000    1.000000    1.000000  0.764766  False        -1         -1        -1       -1   -1.0       -1.0       -1.0          -1.0  \n",
       "6                                            1.000000                                  1.000000                                      1.000000                                     0.899051                                           0.600257                                               0.263837                                               1.000000                                                1.000000  0.425165  0.556259    0.925314    0.476599  0.618412   True        -1         -1        -1       -1    0.0        0.0       -1.0          -1.0  \n",
       "7                                            1.000000                                  1.000000                                      1.000000                                     0.949335                                           0.548854                                               0.229812                                               1.000000                                                1.000000  1.000000  1.000000    1.000000    1.000000  0.580942  False        -1         -1        -1       -1   -1.0       -1.0       -1.0          -1.0  \n",
       "8                                            1.000000                                  1.000000                                      1.000000                                     0.889008                                           0.732580                                               0.247194                                               1.000000                                                1.000000  0.215764  0.644082    0.488195    0.000000  0.648037   True        -1         -1        -1        0    0.0        0.0       -1.0           1.0  \n",
       "9                                            0.971132                                  1.000000                                      1.000000                                     0.808575                                           0.420889                                               0.275842                                               0.854551                                                1.000000  0.200531  0.796364    0.898161    0.538176  0.467105   True        -1         -1        -1        0    0.0        0.0       -1.0           1.0  \n",
       "10                                           1.000000                                  1.000000                                      1.000000                                     1.000000                                           0.714460                                               0.247837                                               1.000000                                                1.000000  0.297119  0.765555    0.918007    0.000000  0.699790   True        -1         -1        -1        0    0.0        0.0       -1.0           1.0  \n",
       "11                                           0.879809                                  0.859276                                      0.718486                                     0.784513                                           0.323591                                               0.215743                                               0.817136                                                0.794983  0.143607  0.642601    0.000000    0.000000  0.289605   True        -1         -1        -1        1    0.0        0.0       -1.0           1.0  \n",
       "12                                           0.919181                                  0.909812                                      0.832597                                     0.838619                                           0.626924                                               0.214428                                               0.828453                                                0.812806  1.000000  0.848694    1.000000    0.000000  0.404818   True        -1         -1        -1       -1    0.0        0.0       -1.0          -1.0  \n",
       "13                                           0.803128                                  0.766201                                      0.388563                                     0.290308                                           0.130693                                               0.113132                                               0.293965                                                0.202365  0.134726  0.756770    0.557407    0.000000  0.150919   True        -1         -1        -1        1    0.0        0.0       -1.0           1.0  \n",
       "14                                           1.000000                                  1.000000                                      1.000000                                     0.869588                                           0.493623                                               0.301690                                               1.000000                                                1.000000  0.236706  0.725834    0.889163    0.000000  0.603780   True        -1         -1        -1       -1    0.0        0.0       -1.0          -1.0  \n",
       "15                                           0.976264                                  0.967525                                      0.894120                                     0.879221                                           0.386746                                               0.281545                                               0.924241                                                0.908044  0.185603  0.757168    0.839198    0.000000  0.428290   True        -1         -1        -1        0    0.0        0.0       -1.0           1.0  \n",
       "16                                           1.000000                                  1.000000                                      1.000000                                     1.000000                                           0.497310                                               0.247837                                               1.000000                                                1.000000  0.161334  0.755283    0.694804    0.000000  0.632151   True        -1         -1        -1        0    0.0        0.0       -1.0           1.0  \n",
       "17                                           1.000000                                  1.000000                                      1.000000                                     0.949175                                           0.827598                                               0.859332                                               1.000000                                                1.000000  0.231866  0.744921    0.919836    0.000000  0.741689   True        -1         -1        -1        0    0.0        0.0       -1.0           1.0  \n",
       "18                                           0.893790                                  0.867906                                      0.824654                                     0.740736                                           0.508417                                               0.181875                                               0.800605                                                0.774736  0.196729  0.753039    0.926500    0.000000  0.307623   True        -1         -1        -1       -1    0.0        0.0       -1.0          -1.0  \n",
       "19                                           0.858266                                  0.831412                                      0.746720                                     0.598453                                           0.370800                                               0.266747                                               0.834894                                                0.813473  0.234463  0.688798    0.305225    0.000000  0.281980   True        -1         -1        -1       -1    0.0        0.0       -1.0          -1.0  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add a column that indicates whether or not both genes of the pair are mapped to all the curation types.\n",
    "relevant_ids = set(ow_edgelist.ids)\n",
    "df[\"from_is_valid\"] = df[\"from\"].map(lambda x: x in relevant_ids)\n",
    "df[\"to_is_valid\"] = df[\"to\"].map(lambda x: x in relevant_ids)\n",
    "df[\"pair_is_valid\"] = df[\"from_is_valid\"]*df[\"to_is_valid\"]\n",
    "\n",
    "# Add a column giving the actual target output value for this biological task, with -1 for the irrelevant rows.\n",
    "df[\"eqs_distance\"] = -1\n",
    "df = df.merge(right=ow_edgelist.df, how=\"left\", on=[\"from\",\"to\"])\n",
    "df[\"value\"].fillna(value=0, inplace=True)\n",
    "df.loc[(df[\"pair_is_valid\"]==True),\"eqs_distance\"] = 1-df[\"value\"]\n",
    "df.drop(labels=[\"from_is_valid\",\"to_is_valid\",\"pair_is_valid\",\"value\"], axis=\"columns\", inplace=True)\n",
    "\n",
    "# Also, add the curated EQ approach to the list of column names that reference approaches to be evaluated.\n",
    "names.append(\"eqs_distance\")\n",
    "\n",
    "df.head(20)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"curated\"></a>\n",
    "### Checking whether gene pairs are considered curated or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>from</th>\n",
       "      <th>to</th>\n",
       "      <th>Doc2Vec:Wikipedia,Size=300</th>\n",
       "      <th>Word2Vec:Wikipedia,Size=300,Mean</th>\n",
       "      <th>Word2Vec:Wikipedia,Size=300,Max</th>\n",
       "      <th>Doc2Vec Phenes:Wikipedia,Size=300</th>\n",
       "      <th>Word2Vec Phenes:Wikipedia,Size=300,Mean</th>\n",
       "      <th>Word2Vec Phenes:Wikipedia,Size=300,Max</th>\n",
       "      <th>NOBLE Coder:Precise,TFIDF</th>\n",
       "      <th>NOBLE Coder:Partial,TFIDF</th>\n",
       "      <th>NOBLE Coder Phenes:Precise,TFIDF</th>\n",
       "      <th>NOBLE Coder Phenes:Partial,TFIDF</th>\n",
       "      <th>Topic Models:NMF,Full,Topics=50</th>\n",
       "      <th>Topic Models:NMF,Full,Topics=100</th>\n",
       "      <th>Topic Models Phenes:NMF,Full,Topics=50</th>\n",
       "      <th>Topic Models Phenes:NMF,Full,Topics=100</th>\n",
       "      <th>Topic Models:LDA,Full,Topics=50</th>\n",
       "      <th>Topic Models:LDA,Full,Topics=100</th>\n",
       "      <th>Topic Models Phenes:LDA,Full,Topics=50</th>\n",
       "      <th>Topic Models Phenes:LDA,Full,Topics=100</th>\n",
       "      <th>N-Grams:Full,Words,1-grams,TFIDF</th>\n",
       "      <th>N-Grams:Full,Words,1-grams,2-grams,TFIDF</th>\n",
       "      <th>N-Grams Phenes:Full,Words,1-grams,TFIDF</th>\n",
       "      <th>N-Grams Phenes:Full,Words,1-grams,2-grams,TFIDF</th>\n",
       "      <th>N-Grams:Full,Nouns,Adjectives,1-grams</th>\n",
       "      <th>N-Grams:Linares_Pontes,Words,1-grams</th>\n",
       "      <th>N-Grams:Full,Precise_Annotations,Words,1-grams</th>\n",
       "      <th>N-Grams:Full,Partial_Annotations,Words,1-grams</th>\n",
       "      <th>N-Grams:Full,Plant Overrepresented Tokens,1-grams</th>\n",
       "      <th>N-Grams:Full,Bio Ontology Tokens,1-grams</th>\n",
       "      <th>N-Grams Phenes:Full,Nouns,Adjectives,1-grams</th>\n",
       "      <th>N-Grams Phenes:Linares_Pontes,Words,1-grams</th>\n",
       "      <th>N-Grams Phenes:Full,Precise_Annotations,Words,1-grams</th>\n",
       "      <th>N-Grams Phenes:Full,Partial_Annotations,Words,1-grams</th>\n",
       "      <th>N-Grams Phenes:Full,Plant Overrepresented Tokens,1-grams</th>\n",
       "      <th>N-Grams Phenes:Full,Bio Ontology Tokens,1-grams</th>\n",
       "      <th>GO:Union</th>\n",
       "      <th>PO:Union</th>\n",
       "      <th>GO:Maximum</th>\n",
       "      <th>PO:Maximum</th>\n",
       "      <th>Mean</th>\n",
       "      <th>same</th>\n",
       "      <th>pathways</th>\n",
       "      <th>kegg_only</th>\n",
       "      <th>pmn_only</th>\n",
       "      <th>subsets</th>\n",
       "      <th>known</th>\n",
       "      <th>predicted</th>\n",
       "      <th>orthologs</th>\n",
       "      <th>eqs_distance</th>\n",
       "      <th>curated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>1145</td>\n",
       "      <td>0.504560</td>\n",
       "      <td>0.503235</td>\n",
       "      <td>0.263459</td>\n",
       "      <td>0.414963</td>\n",
       "      <td>0.478481</td>\n",
       "      <td>0.288674</td>\n",
       "      <td>0.857573</td>\n",
       "      <td>0.928872</td>\n",
       "      <td>0.796288</td>\n",
       "      <td>0.900807</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.995888</td>\n",
       "      <td>0.980399</td>\n",
       "      <td>0.990102</td>\n",
       "      <td>9.668565e-01</td>\n",
       "      <td>0.981963</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.836855</td>\n",
       "      <td>0.566964</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.586272</td>\n",
       "      <td>0.428988</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.917046</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.646146</td>\n",
       "      <td>0.720441</td>\n",
       "      <td>False</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100</td>\n",
       "      <td>4114</td>\n",
       "      <td>0.309927</td>\n",
       "      <td>0.260014</td>\n",
       "      <td>0.185656</td>\n",
       "      <td>0.276678</td>\n",
       "      <td>0.270105</td>\n",
       "      <td>0.180168</td>\n",
       "      <td>0.932399</td>\n",
       "      <td>0.962904</td>\n",
       "      <td>0.910822</td>\n",
       "      <td>0.957076</td>\n",
       "      <td>0.999785</td>\n",
       "      <td>0.999297</td>\n",
       "      <td>0.999941</td>\n",
       "      <td>0.999121</td>\n",
       "      <td>0.983668</td>\n",
       "      <td>0.991767</td>\n",
       "      <td>9.684386e-01</td>\n",
       "      <td>0.982268</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.977206</td>\n",
       "      <td>0.797835</td>\n",
       "      <td>0.406689</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.977423</td>\n",
       "      <td>0.741544</td>\n",
       "      <td>0.422529</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.656684</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>231</td>\n",
       "      <td>0.435983</td>\n",
       "      <td>0.279231</td>\n",
       "      <td>0.185035</td>\n",
       "      <td>0.299665</td>\n",
       "      <td>0.271672</td>\n",
       "      <td>0.188429</td>\n",
       "      <td>0.872037</td>\n",
       "      <td>0.922563</td>\n",
       "      <td>0.817956</td>\n",
       "      <td>0.916699</td>\n",
       "      <td>0.733982</td>\n",
       "      <td>0.715878</td>\n",
       "      <td>0.797588</td>\n",
       "      <td>0.900100</td>\n",
       "      <td>0.977441</td>\n",
       "      <td>0.990781</td>\n",
       "      <td>9.554953e-01</td>\n",
       "      <td>0.971250</td>\n",
       "      <td>0.934402</td>\n",
       "      <td>0.969146</td>\n",
       "      <td>0.883653</td>\n",
       "      <td>0.928505</td>\n",
       "      <td>0.920096</td>\n",
       "      <td>0.880906</td>\n",
       "      <td>0.529131</td>\n",
       "      <td>0.490530</td>\n",
       "      <td>0.934402</td>\n",
       "      <td>0.915424</td>\n",
       "      <td>0.812598</td>\n",
       "      <td>0.863527</td>\n",
       "      <td>0.376286</td>\n",
       "      <td>0.415109</td>\n",
       "      <td>0.883653</td>\n",
       "      <td>0.85392</td>\n",
       "      <td>0.224368</td>\n",
       "      <td>0.700841</td>\n",
       "      <td>0.905412</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.392922</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100</td>\n",
       "      <td>5244</td>\n",
       "      <td>0.551568</td>\n",
       "      <td>0.602756</td>\n",
       "      <td>0.363885</td>\n",
       "      <td>0.404959</td>\n",
       "      <td>0.607823</td>\n",
       "      <td>0.362408</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.958144</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.945128</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.990909</td>\n",
       "      <td>0.905914</td>\n",
       "      <td>0.976078</td>\n",
       "      <td>0.983010</td>\n",
       "      <td>9.529703e-01</td>\n",
       "      <td>0.974258</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.978320</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.897213</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.355641</td>\n",
       "      <td>0.629555</td>\n",
       "      <td>0.689286</td>\n",
       "      <td>0.476599</td>\n",
       "      <td>0.775899</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100</td>\n",
       "      <td>733</td>\n",
       "      <td>0.508654</td>\n",
       "      <td>0.270065</td>\n",
       "      <td>0.181497</td>\n",
       "      <td>0.355532</td>\n",
       "      <td>0.293558</td>\n",
       "      <td>0.170425</td>\n",
       "      <td>0.893924</td>\n",
       "      <td>0.927862</td>\n",
       "      <td>0.797668</td>\n",
       "      <td>0.919038</td>\n",
       "      <td>0.999892</td>\n",
       "      <td>0.998867</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999008</td>\n",
       "      <td>0.974111</td>\n",
       "      <td>0.988849</td>\n",
       "      <td>9.546172e-01</td>\n",
       "      <td>0.971961</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.865899</td>\n",
       "      <td>0.796603</td>\n",
       "      <td>0.284657</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.850601</td>\n",
       "      <td>0.593352</td>\n",
       "      <td>0.247837</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.188509</td>\n",
       "      <td>0.575006</td>\n",
       "      <td>0.689286</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.604054</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>100</td>\n",
       "      <td>3896</td>\n",
       "      <td>0.518026</td>\n",
       "      <td>0.536171</td>\n",
       "      <td>0.298879</td>\n",
       "      <td>0.428593</td>\n",
       "      <td>0.590710</td>\n",
       "      <td>0.391840</td>\n",
       "      <td>0.970234</td>\n",
       "      <td>0.972461</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.967205</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.976449</td>\n",
       "      <td>0.988082</td>\n",
       "      <td>9.620776e-01</td>\n",
       "      <td>0.961087</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.912374</td>\n",
       "      <td>0.338805</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.841140</td>\n",
       "      <td>0.310185</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.764766</td>\n",
       "      <td>False</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>100</td>\n",
       "      <td>4572</td>\n",
       "      <td>0.498664</td>\n",
       "      <td>0.326860</td>\n",
       "      <td>0.179187</td>\n",
       "      <td>0.349483</td>\n",
       "      <td>0.341777</td>\n",
       "      <td>0.209361</td>\n",
       "      <td>0.948135</td>\n",
       "      <td>0.927444</td>\n",
       "      <td>0.939123</td>\n",
       "      <td>0.925689</td>\n",
       "      <td>0.998685</td>\n",
       "      <td>0.986242</td>\n",
       "      <td>0.988918</td>\n",
       "      <td>0.640430</td>\n",
       "      <td>0.982011</td>\n",
       "      <td>0.990924</td>\n",
       "      <td>9.532030e-01</td>\n",
       "      <td>0.978660</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.908057</td>\n",
       "      <td>0.713808</td>\n",
       "      <td>0.345801</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.899051</td>\n",
       "      <td>0.600257</td>\n",
       "      <td>0.263837</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.425165</td>\n",
       "      <td>0.556259</td>\n",
       "      <td>0.925314</td>\n",
       "      <td>0.476599</td>\n",
       "      <td>0.618412</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>100</td>\n",
       "      <td>2823</td>\n",
       "      <td>0.542816</td>\n",
       "      <td>0.272979</td>\n",
       "      <td>0.187657</td>\n",
       "      <td>0.296875</td>\n",
       "      <td>0.278486</td>\n",
       "      <td>0.199103</td>\n",
       "      <td>0.887384</td>\n",
       "      <td>0.909117</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.885990</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.639737</td>\n",
       "      <td>0.740649</td>\n",
       "      <td>0.980833</td>\n",
       "      <td>0.990628</td>\n",
       "      <td>2.500710e-09</td>\n",
       "      <td>0.788591</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.970817</td>\n",
       "      <td>0.724138</td>\n",
       "      <td>0.247397</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.949335</td>\n",
       "      <td>0.548854</td>\n",
       "      <td>0.229812</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.580942</td>\n",
       "      <td>False</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>100</td>\n",
       "      <td>1592</td>\n",
       "      <td>0.453901</td>\n",
       "      <td>0.438724</td>\n",
       "      <td>0.198668</td>\n",
       "      <td>0.296394</td>\n",
       "      <td>0.365019</td>\n",
       "      <td>0.222920</td>\n",
       "      <td>0.902751</td>\n",
       "      <td>0.926640</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.905401</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999490</td>\n",
       "      <td>0.984330</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.973381</td>\n",
       "      <td>0.991938</td>\n",
       "      <td>9.606524e-01</td>\n",
       "      <td>0.971783</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.945727</td>\n",
       "      <td>0.815585</td>\n",
       "      <td>0.329073</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.889008</td>\n",
       "      <td>0.732580</td>\n",
       "      <td>0.247194</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.215764</td>\n",
       "      <td>0.644082</td>\n",
       "      <td>0.488195</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.648037</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>100</td>\n",
       "      <td>1185</td>\n",
       "      <td>0.437521</td>\n",
       "      <td>0.197340</td>\n",
       "      <td>0.151455</td>\n",
       "      <td>0.280486</td>\n",
       "      <td>0.232980</td>\n",
       "      <td>0.155569</td>\n",
       "      <td>0.901545</td>\n",
       "      <td>0.921714</td>\n",
       "      <td>0.654037</td>\n",
       "      <td>0.911570</td>\n",
       "      <td>0.995473</td>\n",
       "      <td>0.992384</td>\n",
       "      <td>0.375339</td>\n",
       "      <td>0.979698</td>\n",
       "      <td>0.983954</td>\n",
       "      <td>0.992425</td>\n",
       "      <td>9.599578e-01</td>\n",
       "      <td>0.970949</td>\n",
       "      <td>0.971604</td>\n",
       "      <td>0.987393</td>\n",
       "      <td>0.880267</td>\n",
       "      <td>0.948704</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.857459</td>\n",
       "      <td>0.699810</td>\n",
       "      <td>0.319292</td>\n",
       "      <td>0.971132</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.808575</td>\n",
       "      <td>0.420889</td>\n",
       "      <td>0.275842</td>\n",
       "      <td>0.854551</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.200531</td>\n",
       "      <td>0.796364</td>\n",
       "      <td>0.898161</td>\n",
       "      <td>0.538176</td>\n",
       "      <td>0.467105</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   from    to  Doc2Vec:Wikipedia,Size=300  Word2Vec:Wikipedia,Size=300,Mean  Word2Vec:Wikipedia,Size=300,Max  Doc2Vec Phenes:Wikipedia,Size=300  Word2Vec Phenes:Wikipedia,Size=300,Mean  Word2Vec Phenes:Wikipedia,Size=300,Max  NOBLE Coder:Precise,TFIDF  NOBLE Coder:Partial,TFIDF  NOBLE Coder Phenes:Precise,TFIDF  NOBLE Coder Phenes:Partial,TFIDF  Topic Models:NMF,Full,Topics=50  Topic Models:NMF,Full,Topics=100  Topic Models Phenes:NMF,Full,Topics=50  Topic Models Phenes:NMF,Full,Topics=100  Topic Models:LDA,Full,Topics=50  Topic Models:LDA,Full,Topics=100  Topic Models Phenes:LDA,Full,Topics=50  Topic Models Phenes:LDA,Full,Topics=100  N-Grams:Full,Words,1-grams,TFIDF  N-Grams:Full,Words,1-grams,2-grams,TFIDF  N-Grams Phenes:Full,Words,1-grams,TFIDF  N-Grams Phenes:Full,Words,1-grams,2-grams,TFIDF  N-Grams:Full,Nouns,Adjectives,1-grams  N-Grams:Linares_Pontes,Words,1-grams  N-Grams:Full,Precise_Annotations,Words,1-grams  N-Grams:Full,Partial_Annotations,Words,1-grams  \\\n",
       "0   100  1145                    0.504560                          0.503235                         0.263459                           0.414963                                 0.478481                                0.288674                   0.857573                   0.928872                          0.796288                          0.900807                         1.000000                          1.000000                                1.000000                                 0.995888                         0.980399                          0.990102                            9.668565e-01                                 0.981963                          1.000000                                  1.000000                                 1.000000                                         1.000000                               1.000000                              1.000000                                        0.836855                                        0.566964   \n",
       "1   100  4114                    0.309927                          0.260014                         0.185656                           0.276678                                 0.270105                                0.180168                   0.932399                   0.962904                          0.910822                          0.957076                         0.999785                          0.999297                                0.999941                                 0.999121                         0.983668                          0.991767                            9.684386e-01                                 0.982268                          1.000000                                  1.000000                                 1.000000                                         1.000000                               1.000000                              0.977206                                        0.797835                                        0.406689   \n",
       "2   100   231                    0.435983                          0.279231                         0.185035                           0.299665                                 0.271672                                0.188429                   0.872037                   0.922563                          0.817956                          0.916699                         0.733982                          0.715878                                0.797588                                 0.900100                         0.977441                          0.990781                            9.554953e-01                                 0.971250                          0.934402                                  0.969146                                 0.883653                                         0.928505                               0.920096                              0.880906                                        0.529131                                        0.490530   \n",
       "3   100  5244                    0.551568                          0.602756                         0.363885                           0.404959                                 0.607823                                0.362408                   1.000000                   0.958144                          1.000000                          0.945128                         1.000000                          1.000000                                0.990909                                 0.905914                         0.976078                          0.983010                            9.529703e-01                                 0.974258                          1.000000                                  1.000000                                 1.000000                                         1.000000                               1.000000                              1.000000                                        1.000000                                        0.978320   \n",
       "4   100   733                    0.508654                          0.270065                         0.181497                           0.355532                                 0.293558                                0.170425                   0.893924                   0.927862                          0.797668                          0.919038                         0.999892                          0.998867                                1.000000                                 0.999008                         0.974111                          0.988849                            9.546172e-01                                 0.971961                          1.000000                                  1.000000                                 1.000000                                         1.000000                               1.000000                              0.865899                                        0.796603                                        0.284657   \n",
       "5   100  3896                    0.518026                          0.536171                         0.298879                           0.428593                                 0.590710                                0.391840                   0.970234                   0.972461                          1.000000                          0.967205                         1.000000                          1.000000                                1.000000                                 1.000000                         0.976449                          0.988082                            9.620776e-01                                 0.961087                          1.000000                                  1.000000                                 1.000000                                         1.000000                               1.000000                              1.000000                                        0.912374                                        0.338805   \n",
       "6   100  4572                    0.498664                          0.326860                         0.179187                           0.349483                                 0.341777                                0.209361                   0.948135                   0.927444                          0.939123                          0.925689                         0.998685                          0.986242                                0.988918                                 0.640430                         0.982011                          0.990924                            9.532030e-01                                 0.978660                          1.000000                                  1.000000                                 1.000000                                         1.000000                               1.000000                              0.908057                                        0.713808                                        0.345801   \n",
       "7   100  2823                    0.542816                          0.272979                         0.187657                           0.296875                                 0.278486                                0.199103                   0.887384                   0.909117                          1.000000                          0.885990                         1.000000                          1.000000                                0.639737                                 0.740649                         0.980833                          0.990628                            2.500710e-09                                 0.788591                          1.000000                                  1.000000                                 1.000000                                         1.000000                               1.000000                              0.970817                                        0.724138                                        0.247397   \n",
       "8   100  1592                    0.453901                          0.438724                         0.198668                           0.296394                                 0.365019                                0.222920                   0.902751                   0.926640                          1.000000                          0.905401                         1.000000                          0.999490                                0.984330                                 1.000000                         0.973381                          0.991938                            9.606524e-01                                 0.971783                          1.000000                                  1.000000                                 1.000000                                         1.000000                               1.000000                              0.945727                                        0.815585                                        0.329073   \n",
       "9   100  1185                    0.437521                          0.197340                         0.151455                           0.280486                                 0.232980                                0.155569                   0.901545                   0.921714                          0.654037                          0.911570                         0.995473                          0.992384                                0.375339                                 0.979698                         0.983954                          0.992425                            9.599578e-01                                 0.970949                          0.971604                                  0.987393                                 0.880267                                         0.948704                               1.000000                              0.857459                                        0.699810                                        0.319292   \n",
       "\n",
       "   N-Grams:Full,Plant Overrepresented Tokens,1-grams  N-Grams:Full,Bio Ontology Tokens,1-grams  N-Grams Phenes:Full,Nouns,Adjectives,1-grams  N-Grams Phenes:Linares_Pontes,Words,1-grams  N-Grams Phenes:Full,Precise_Annotations,Words,1-grams  N-Grams Phenes:Full,Partial_Annotations,Words,1-grams  N-Grams Phenes:Full,Plant Overrepresented Tokens,1-grams  N-Grams Phenes:Full,Bio Ontology Tokens,1-grams  GO:Union  PO:Union  GO:Maximum  PO:Maximum      Mean   same  pathways  kegg_only  pmn_only  subsets  known  predicted  orthologs  eqs_distance  curated  \n",
       "0                                           1.000000                                  1.000000                                      1.000000                                     1.000000                                           0.586272                                               0.428988                                               1.000000                                                 1.00000  1.000000  0.917046    1.000000    0.646146  0.720441  False        -1         -1        -1       -1   -1.0       -1.0       -1.0           1.0     True  \n",
       "1                                           1.000000                                  1.000000                                      1.000000                                     0.977423                                           0.741544                                               0.422529                                               1.000000                                                 1.00000  1.000000  1.000000    1.000000    1.000000  0.656684   True        -1         -1        -1       -1    0.0        0.0       -1.0          -1.0    False  \n",
       "2                                           0.934402                                  0.915424                                      0.812598                                     0.863527                                           0.376286                                               0.415109                                               0.883653                                                 0.85392  0.224368  0.700841    0.905412    0.000000  0.392922   True        -1         -1        -1        0    0.0        0.0       -1.0           1.0     True  \n",
       "3                                           1.000000                                  1.000000                                      1.000000                                     1.000000                                           1.000000                                               0.897213                                               1.000000                                                 1.00000  0.355641  0.629555    0.689286    0.476599  0.775899   True        -1         -1        -1       -1    0.0        0.0       -1.0          -1.0    False  \n",
       "4                                           1.000000                                  1.000000                                      1.000000                                     0.850601                                           0.593352                                               0.247837                                               1.000000                                                 1.00000  0.188509  0.575006    0.689286    0.000000  0.604054   True        -1         -1        -1        0    0.0        0.0       -1.0           1.0     True  \n",
       "5                                           1.000000                                  1.000000                                      1.000000                                     1.000000                                           0.841140                                               0.310185                                               1.000000                                                 1.00000  1.000000  1.000000    1.000000    1.000000  0.764766  False        -1         -1        -1       -1   -1.0       -1.0       -1.0          -1.0    False  \n",
       "6                                           1.000000                                  1.000000                                      1.000000                                     0.899051                                           0.600257                                               0.263837                                               1.000000                                                 1.00000  0.425165  0.556259    0.925314    0.476599  0.618412   True        -1         -1        -1       -1    0.0        0.0       -1.0          -1.0    False  \n",
       "7                                           1.000000                                  1.000000                                      1.000000                                     0.949335                                           0.548854                                               0.229812                                               1.000000                                                 1.00000  1.000000  1.000000    1.000000    1.000000  0.580942  False        -1         -1        -1       -1   -1.0       -1.0       -1.0          -1.0    False  \n",
       "8                                           1.000000                                  1.000000                                      1.000000                                     0.889008                                           0.732580                                               0.247194                                               1.000000                                                 1.00000  0.215764  0.644082    0.488195    0.000000  0.648037   True        -1         -1        -1        0    0.0        0.0       -1.0           1.0     True  \n",
       "9                                           0.971132                                  1.000000                                      1.000000                                     0.808575                                           0.420889                                               0.275842                                               0.854551                                                 1.00000  0.200531  0.796364    0.898161    0.538176  0.467105   True        -1         -1        -1        0    0.0        0.0       -1.0           1.0     True  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add a column that indicates whether or not both genes of the pair are mapped to all the curation types.\n",
    "relevant_ids = set(ids_with_all_annotations)\n",
    "df[\"from_is_valid\"] = df[\"from\"].map(lambda x: x in relevant_ids)\n",
    "df[\"to_is_valid\"] = df[\"to\"].map(lambda x: x in relevant_ids)\n",
    "df[\"curated\"] = df[\"from_is_valid\"]*df[\"to_is_valid\"]\n",
    "df.drop(labels=[\"from_is_valid\",\"to_is_valid\"], axis=\"columns\", inplace=True)\n",
    "df.head(10)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking to make sure that the number of genes and pairs matches what is expected at this point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a nested dictionary with shape dict[curated][question][species][approach][metric] --> value.\n",
    "curated = [True,False]\n",
    "species = [\"intra\",\"inter\",\"both\"]\n",
    "question = [\"subsets\", \"known\", \"predicted\", \"pathways\", \"orthologs\"]\n",
    "tables = defaultdict(dict)\n",
    "for c,q in itertools.product(curated,question): \n",
    "    tables[c][q] = defaultdict(dict)\n",
    "for c,q,s in itertools.product(curated,question,species): \n",
    "    tables[c][q][s] = defaultdict(dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"n_values\"></a>\n",
    "### What are the value of *n* for each type of iteration through a subset of the dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>curated</th>\n",
       "      <th>species</th>\n",
       "      <th>num_genes</th>\n",
       "      <th>positive</th>\n",
       "      <th>negative</th>\n",
       "      <th>num_pairs</th>\n",
       "      <th>positive_fraction</th>\n",
       "      <th>negative_fraction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>subsets</td>\n",
       "      <td>true</td>\n",
       "      <td>intra</td>\n",
       "      <td>149</td>\n",
       "      <td>1129</td>\n",
       "      <td>9912</td>\n",
       "      <td>11041</td>\n",
       "      <td>0.102255</td>\n",
       "      <td>0.897745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>subsets</td>\n",
       "      <td>true</td>\n",
       "      <td>inter</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>subsets</td>\n",
       "      <td>true</td>\n",
       "      <td>both</td>\n",
       "      <td>149</td>\n",
       "      <td>1129</td>\n",
       "      <td>9912</td>\n",
       "      <td>11041</td>\n",
       "      <td>0.102255</td>\n",
       "      <td>0.897745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>known</td>\n",
       "      <td>true</td>\n",
       "      <td>intra</td>\n",
       "      <td>161</td>\n",
       "      <td>193</td>\n",
       "      <td>10726</td>\n",
       "      <td>10919</td>\n",
       "      <td>0.017676</td>\n",
       "      <td>0.982324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>known</td>\n",
       "      <td>true</td>\n",
       "      <td>inter</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>known</td>\n",
       "      <td>true</td>\n",
       "      <td>both</td>\n",
       "      <td>161</td>\n",
       "      <td>193</td>\n",
       "      <td>10726</td>\n",
       "      <td>10919</td>\n",
       "      <td>0.017676</td>\n",
       "      <td>0.982324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>predicted</td>\n",
       "      <td>true</td>\n",
       "      <td>intra</td>\n",
       "      <td>161</td>\n",
       "      <td>147</td>\n",
       "      <td>10772</td>\n",
       "      <td>10919</td>\n",
       "      <td>0.013463</td>\n",
       "      <td>0.986537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>predicted</td>\n",
       "      <td>true</td>\n",
       "      <td>inter</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>predicted</td>\n",
       "      <td>true</td>\n",
       "      <td>both</td>\n",
       "      <td>161</td>\n",
       "      <td>147</td>\n",
       "      <td>10772</td>\n",
       "      <td>10919</td>\n",
       "      <td>0.013463</td>\n",
       "      <td>0.986537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>pathways</td>\n",
       "      <td>true</td>\n",
       "      <td>intra</td>\n",
       "      <td>67</td>\n",
       "      <td>64</td>\n",
       "      <td>2154</td>\n",
       "      <td>2218</td>\n",
       "      <td>0.028855</td>\n",
       "      <td>0.971145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>pathways</td>\n",
       "      <td>true</td>\n",
       "      <td>inter</td>\n",
       "      <td>69</td>\n",
       "      <td>6</td>\n",
       "      <td>129</td>\n",
       "      <td>135</td>\n",
       "      <td>0.044444</td>\n",
       "      <td>0.955556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>pathways</td>\n",
       "      <td>true</td>\n",
       "      <td>both</td>\n",
       "      <td>69</td>\n",
       "      <td>70</td>\n",
       "      <td>2283</td>\n",
       "      <td>2353</td>\n",
       "      <td>0.029749</td>\n",
       "      <td>0.970251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>orthologs</td>\n",
       "      <td>true</td>\n",
       "      <td>intra</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>orthologs</td>\n",
       "      <td>true</td>\n",
       "      <td>inter</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>174</td>\n",
       "      <td>174</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>orthologs</td>\n",
       "      <td>true</td>\n",
       "      <td>both</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>174</td>\n",
       "      <td>174</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>subsets</td>\n",
       "      <td>false</td>\n",
       "      <td>intra</td>\n",
       "      <td>150</td>\n",
       "      <td>1141</td>\n",
       "      <td>10049</td>\n",
       "      <td>11190</td>\n",
       "      <td>0.101966</td>\n",
       "      <td>0.898034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>subsets</td>\n",
       "      <td>false</td>\n",
       "      <td>inter</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>subsets</td>\n",
       "      <td>false</td>\n",
       "      <td>both</td>\n",
       "      <td>150</td>\n",
       "      <td>1141</td>\n",
       "      <td>10049</td>\n",
       "      <td>11190</td>\n",
       "      <td>0.101966</td>\n",
       "      <td>0.898034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>known</td>\n",
       "      <td>false</td>\n",
       "      <td>intra</td>\n",
       "      <td>279</td>\n",
       "      <td>437</td>\n",
       "      <td>32332</td>\n",
       "      <td>32769</td>\n",
       "      <td>0.013336</td>\n",
       "      <td>0.986664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>known</td>\n",
       "      <td>false</td>\n",
       "      <td>inter</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>known</td>\n",
       "      <td>false</td>\n",
       "      <td>both</td>\n",
       "      <td>279</td>\n",
       "      <td>437</td>\n",
       "      <td>32332</td>\n",
       "      <td>32769</td>\n",
       "      <td>0.013336</td>\n",
       "      <td>0.986664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>predicted</td>\n",
       "      <td>false</td>\n",
       "      <td>intra</td>\n",
       "      <td>279</td>\n",
       "      <td>294</td>\n",
       "      <td>32475</td>\n",
       "      <td>32769</td>\n",
       "      <td>0.008972</td>\n",
       "      <td>0.991028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>predicted</td>\n",
       "      <td>false</td>\n",
       "      <td>inter</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>predicted</td>\n",
       "      <td>false</td>\n",
       "      <td>both</td>\n",
       "      <td>279</td>\n",
       "      <td>294</td>\n",
       "      <td>32475</td>\n",
       "      <td>32769</td>\n",
       "      <td>0.008972</td>\n",
       "      <td>0.991028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>pathways</td>\n",
       "      <td>false</td>\n",
       "      <td>intra</td>\n",
       "      <td>109</td>\n",
       "      <td>132</td>\n",
       "      <td>4683</td>\n",
       "      <td>4815</td>\n",
       "      <td>0.027414</td>\n",
       "      <td>0.972586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>pathways</td>\n",
       "      <td>false</td>\n",
       "      <td>inter</td>\n",
       "      <td>110</td>\n",
       "      <td>41</td>\n",
       "      <td>1146</td>\n",
       "      <td>1187</td>\n",
       "      <td>0.034541</td>\n",
       "      <td>0.965459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>pathways</td>\n",
       "      <td>false</td>\n",
       "      <td>both</td>\n",
       "      <td>110</td>\n",
       "      <td>173</td>\n",
       "      <td>5829</td>\n",
       "      <td>6002</td>\n",
       "      <td>0.028824</td>\n",
       "      <td>0.971176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>orthologs</td>\n",
       "      <td>false</td>\n",
       "      <td>intra</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>orthologs</td>\n",
       "      <td>false</td>\n",
       "      <td>inter</td>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>954</td>\n",
       "      <td>955</td>\n",
       "      <td>0.001047</td>\n",
       "      <td>0.998953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>orthologs</td>\n",
       "      <td>false</td>\n",
       "      <td>both</td>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>954</td>\n",
       "      <td>955</td>\n",
       "      <td>0.001047</td>\n",
       "      <td>0.998953</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     question curated species  num_genes  positive  negative  num_pairs  positive_fraction  negative_fraction\n",
       "0     subsets    true   intra        149      1129      9912      11041           0.102255           0.897745\n",
       "1     subsets    true   inter          0         0         0          0                NaN                NaN\n",
       "2     subsets    true    both        149      1129      9912      11041           0.102255           0.897745\n",
       "3       known    true   intra        161       193     10726      10919           0.017676           0.982324\n",
       "4       known    true   inter          0         0         0          0                NaN                NaN\n",
       "5       known    true    both        161       193     10726      10919           0.017676           0.982324\n",
       "6   predicted    true   intra        161       147     10772      10919           0.013463           0.986537\n",
       "7   predicted    true   inter          0         0         0          0                NaN                NaN\n",
       "8   predicted    true    both        161       147     10772      10919           0.013463           0.986537\n",
       "9    pathways    true   intra         67        64      2154       2218           0.028855           0.971145\n",
       "10   pathways    true   inter         69         6       129        135           0.044444           0.955556\n",
       "11   pathways    true    both         69        70      2283       2353           0.029749           0.970251\n",
       "12  orthologs    true   intra          0         0         0          0                NaN                NaN\n",
       "13  orthologs    true   inter         23         0       174        174           0.000000           1.000000\n",
       "14  orthologs    true    both         23         0       174        174           0.000000           1.000000\n",
       "15    subsets   false   intra        150      1141     10049      11190           0.101966           0.898034\n",
       "16    subsets   false   inter          0         0         0          0                NaN                NaN\n",
       "17    subsets   false    both        150      1141     10049      11190           0.101966           0.898034\n",
       "18      known   false   intra        279       437     32332      32769           0.013336           0.986664\n",
       "19      known   false   inter          0         0         0          0                NaN                NaN\n",
       "20      known   false    both        279       437     32332      32769           0.013336           0.986664\n",
       "21  predicted   false   intra        279       294     32475      32769           0.008972           0.991028\n",
       "22  predicted   false   inter          0         0         0          0                NaN                NaN\n",
       "23  predicted   false    both        279       294     32475      32769           0.008972           0.991028\n",
       "24   pathways   false   intra        109       132      4683       4815           0.027414           0.972586\n",
       "25   pathways   false   inter        110        41      1146       1187           0.034541           0.965459\n",
       "26   pathways   false    both        110       173      5829       6002           0.028824           0.971176\n",
       "27  orthologs   false   intra          0         0         0          0                NaN                NaN\n",
       "28  orthologs   false   inter         56         1       954        955           0.001047           0.998953\n",
       "29  orthologs   false    both         56         1       954        955           0.001047           0.998953"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset_idx_lists = []\n",
    "subset_properties = []\n",
    "table_lists = defaultdict(list)\n",
    "for c,q,s in itertools.product(curated,question,species):\n",
    "    \n",
    "    # Remembering what the properties for this particular subset are.\n",
    "    subset_properties.append((c,q,s))\n",
    "    \n",
    "    # Subsetting the dataframe to the rows (gene pairs) that are relevant for this particular biological question.\n",
    "    subset = df[df[q] != -1]\n",
    "    if c:\n",
    "        subset = subset[subset[\"curated\"] == True]\n",
    "        \n",
    "        \n",
    "    # Subsetting the dataframe to the rows (gene pairs) where both genes are from the same or different species.\n",
    "    if s == \"intra\":\n",
    "        subset = subset[subset[\"same\"] == True]\n",
    "    elif s == \"inter\":\n",
    "        subset = subset[subset[\"same\"] == False]\n",
    "        \n",
    "    subset_idx_lists.append(subset.index.to_list())\n",
    "    \n",
    "    # Adding values to the table that are specific to this biological question.\n",
    "    counts = Counter(subset[q].values)\n",
    "    \n",
    "    table_lists[\"question\"].append(q.lower())\n",
    "    table_lists[\"curated\"].append(str(c).lower())\n",
    "    table_lists[\"species\"].append(s.lower())\n",
    "    table_lists[\"num_genes\"].append(len(set(subset[\"to\"].values).union(set(subset[\"from\"].values))))\n",
    "    table_lists[\"positive\"].append(counts[1])\n",
    "    table_lists[\"negative\"].append(counts[0])\n",
    "    #table_lists[\"class_ratio\"].append(\"{:0.4f}\".format(counts[1]/counts[0]))\n",
    "\n",
    "pairs_table = pd.DataFrame(table_lists)  \n",
    "pairs_table[\"num_pairs\"] = pairs_table[\"positive\"]+pairs_table[\"negative\"]\n",
    "pairs_table[\"positive_fraction\"] = pairs_table[\"positive\"] / pairs_table[\"num_pairs\"]\n",
    "pairs_table[\"negative_fraction\"] = pairs_table[\"negative\"] / pairs_table[\"num_pairs\"]\n",
    "pairs_table.to_csv(os.path.join(OUTPUT_DIR,\"part_5_biological_question_n_values.csv\"), index=False)\n",
    "pairs_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"objective_similarities\"></a>\n",
    "### How similar are the different biological objectives to each other?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_1</th>\n",
       "      <th>question_2</th>\n",
       "      <th>num_pairs_1</th>\n",
       "      <th>num_pairs_2</th>\n",
       "      <th>num_overlap</th>\n",
       "      <th>sim_overlap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>subsets</td>\n",
       "      <td>orthologs</td>\n",
       "      <td>11190</td>\n",
       "      <td>955</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>known</td>\n",
       "      <td>orthologs</td>\n",
       "      <td>32769</td>\n",
       "      <td>955</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>predicted</td>\n",
       "      <td>orthologs</td>\n",
       "      <td>32769</td>\n",
       "      <td>955</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pathways</td>\n",
       "      <td>orthologs</td>\n",
       "      <td>6002</td>\n",
       "      <td>955</td>\n",
       "      <td>50</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>known</td>\n",
       "      <td>pathways</td>\n",
       "      <td>32769</td>\n",
       "      <td>6002</td>\n",
       "      <td>4678</td>\n",
       "      <td>0.158654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>known</td>\n",
       "      <td>predicted</td>\n",
       "      <td>32769</td>\n",
       "      <td>32769</td>\n",
       "      <td>32769</td>\n",
       "      <td>0.091045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>predicted</td>\n",
       "      <td>pathways</td>\n",
       "      <td>32769</td>\n",
       "      <td>6002</td>\n",
       "      <td>4678</td>\n",
       "      <td>0.070175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>subsets</td>\n",
       "      <td>pathways</td>\n",
       "      <td>11190</td>\n",
       "      <td>6002</td>\n",
       "      <td>2218</td>\n",
       "      <td>0.046512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>subsets</td>\n",
       "      <td>known</td>\n",
       "      <td>11190</td>\n",
       "      <td>32769</td>\n",
       "      <td>11041</td>\n",
       "      <td>0.024845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>subsets</td>\n",
       "      <td>predicted</td>\n",
       "      <td>11190</td>\n",
       "      <td>32769</td>\n",
       "      <td>11041</td>\n",
       "      <td>0.023237</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  question_1 question_2  num_pairs_1  num_pairs_2  num_overlap  sim_overlap\n",
       "0    subsets  orthologs        11190          955            0     1.000000\n",
       "1      known  orthologs        32769          955            0     1.000000\n",
       "2  predicted  orthologs        32769          955            0     1.000000\n",
       "3   pathways  orthologs         6002          955           50     0.500000\n",
       "4      known   pathways        32769         6002         4678     0.158654\n",
       "5      known  predicted        32769        32769        32769     0.091045\n",
       "6  predicted   pathways        32769         6002         4678     0.070175\n",
       "7    subsets   pathways        11190         6002         2218     0.046512\n",
       "8    subsets      known        11190        32769        11041     0.024845\n",
       "9    subsets  predicted        11190        32769        11041     0.023237"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Looking more at the distributions of target values for each of the biological questions.\n",
    "from scipy.spatial.distance import jaccard\n",
    "row_tuples = []\n",
    "for q1,q2 in itertools.combinations(question, 2):\n",
    "    q1_subset = df[df[q1] != -1]\n",
    "    q2_subset = df[df[q2] != -1]\n",
    "    overlap_subset  = q1_subset[q1_subset[q2] != -1]\n",
    "    q1_num_pairs = q1_subset.shape[0]\n",
    "    q2_num_pairs = q2_subset.shape[0]\n",
    "    overlap_size = overlap_subset.shape[0]\n",
    "    overlap_sim = 1-jaccard(overlap_subset[q1].values, overlap_subset[q2].values)\n",
    "    row_tuples.append((q1, q2, q1_num_pairs, q2_num_pairs, overlap_size, overlap_sim))\n",
    "question_overlaps_table = pd.DataFrame(row_tuples)\n",
    "question_overlaps_table.columns = [\"question_1\", \"question_2\", \"num_pairs_1\", \"num_pairs_2\", \"num_overlap\", \"sim_overlap\"]\n",
    "question_overlaps_table.sort_values(by=\"sim_overlap\", ascending=False, inplace=True)\n",
    "question_overlaps_table.reset_index(inplace=True, drop=True)\n",
    "question_overlaps_table.to_csv(os.path.join(OUTPUT_DIR,\"part_5_biological_question_overlaps.csv\"), index=False)\n",
    "question_overlaps_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"part_6\"></a>\n",
    "# Part 6. Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"ks\"></a>\n",
    "### Do the edges joining genes that share a group, pathway, or interaction come from a different distribution?\n",
    "The purpose of this section is to visualize kernel estimates for the distributions of distance or similarity scores generated by each of the methods tested for measuring semantic similarity or generating vector representations of the phenotype descriptions. Ideally, better methods should show better separation betwene the distributions for distance values between two genes involved in a common specified group or two genes that are not. Additionally, a statistical test is used to check whether these two distributions are significantly different from each other or not, although this is a less informative measure than the other tests used in subsequent sections, because it does not address how useful these differences in the distributions actually are for making predictions about group membership."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done with all kolmogorovsmirnov tests\n"
     ]
    }
   ],
   "source": [
    "for properties,idxs in zip(subset_properties, subset_idx_lists):\n",
    "    \n",
    "    # Remember the properties for this subset being looked at, and subset the dataframe accordingly.\n",
    "    c,q,s = properties\n",
    "    \n",
    "    # Don't look at the inter-species and intra-species edges except for pathways, otherwise irrelevant.\n",
    "    if (s != \"both\") and (q != \"pathways\"):\n",
    "        continue\n",
    "    \n",
    "    # Only look at gene pairs where both are relevant to the given biological question.\n",
    "    subset = df.loc[idxs]\n",
    "        \n",
    "    # Check that this subsetting leaves a valid dataset with both positive and negatives samples.\n",
    "    class_values = pd.unique(subset[q].values)\n",
    "    if not (len(class_values)==2 and 0 in class_values and 1 in class_values):\n",
    "        continue\n",
    "    \n",
    "    # Use Kolmogorov-Smirnov test to see if edges between genes that share a group come from a distinct distribution.\n",
    "    ppi_pos_dict = {name:(subset[subset[q] > 0.00][name].values) for name in names}\n",
    "    ppi_neg_dict = {name:(subset[subset[q] == 0.00][name].values) for name in names}\n",
    "    for name in names:\n",
    "        stat,p = ks_2samp(ppi_pos_dict[name],ppi_neg_dict[name])\n",
    "        pos_mean = np.average(ppi_pos_dict[name])\n",
    "        neg_mean = np.average(ppi_neg_dict[name])\n",
    "        pos_n = len(ppi_pos_dict[name])\n",
    "        neg_n = len(ppi_neg_dict[name])\n",
    "        \n",
    "        tables[c][q][s][name].update({\"mean_1\":pos_mean, \"mean_0\":neg_mean, \"n_1\":pos_n, \"n_0\":neg_n})\n",
    "        tables[c][q][s][name].update({\"ks\":stat, \"ks_pval\":p})\n",
    "\n",
    "    # Show the kernel estimates for each distribution of weights for each method.\n",
    "    #num_plots, plots_per_row, row_width, row_height = (len(names), 4, 14, 3)\n",
    "    #fig,axs = plt.subplots(math.ceil(num_plots/plots_per_row), plots_per_row, squeeze=False)\n",
    "    #for name,ax in zip(names,axs.flatten()):\n",
    "    #    ax.set_title(name)\n",
    "    #    ax.set_xlabel(\"value\")\n",
    "    #    ax.set_ylabel(\"density\")\n",
    "    #    sns.kdeplot(ppi_pos_dict[name], color=\"black\", shade=False, alpha=1.0, ax=ax)\n",
    "    #    sns.kdeplot(ppi_neg_dict[name], color=\"black\", shade=True, alpha=0.1, ax=ax) \n",
    "    #fig.set_size_inches(row_width, row_height*math.ceil(num_plots/plots_per_row))\n",
    "    #fig.tight_layout()\n",
    "    #fig.savefig(os.path.join(OUTPUT_DIR,\"part_6_kernel_density.png\"),dpi=400)\n",
    "    #plt.close()\n",
    "    \n",
    "print(\"done with all kolmogorovsmirnov tests\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"within\"></a>\n",
    "### Looking at within-group or within-pathway distances in each graph\n",
    "The purpose of this section is to determine which methods generated graphs which tightly group genes which share common pathways or group membership with one another. In order to compare across different methods where the distance value distributions are different, the mean distance values for each group for each method are convereted to percentile scores. Lower percentile scores indicate that the average distance value between any two genes that belong to that group is lower than most of the distance values in the entire distribution for that method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done generating mean within-group distance values\n"
     ]
    }
   ],
   "source": [
    "# What are the different groupings we are interested in for these mean within-group distance tables?\n",
    "grouping_objects = [kegg_groups, pmn_groups, phe_subsets_groups]\n",
    "grouping_names = [\"kegg_only\",\"pmn_only\",\"subsets\"]\n",
    "for (groups,q) in zip(grouping_objects,grouping_names):\n",
    "\n",
    "    # Only look at gene pairs where both are relevant to the given biological question.\n",
    "    subset = df[df[q] != -1]\n",
    "    \n",
    "    # The grouping dictionaries for this particular biological question.    \n",
    "    id_to_group_ids, group_id_to_ids = groups.get_groupings_for_dataset(dataset)\n",
    "\n",
    "    # Get all the average within-group distance values for each approach.\n",
    "    group_ids = list(group_id_to_ids.keys())\n",
    "    graph = IndexedGraph(subset)\n",
    "    within_percentiles_dict = defaultdict(lambda: defaultdict(list))\n",
    "    all_weights_dict = {}\n",
    "    for name in names:\n",
    "        for group in group_ids:\n",
    "            within_ids = group_id_to_ids[group]\n",
    "            within_pairs = [(i,j) for i,j in itertools.permutations(within_ids,2)]\n",
    "            mean_weight = np.mean((graph.get_values(within_pairs, kind=name)))\n",
    "            within_percentiles_dict[name][group] = stats.percentileofscore(subset[name].values, mean_weight, kind=\"rank\")\n",
    "\n",
    "    # Generating a dataframe of percentiles of the mean in-group distance scores.\n",
    "    within_dist_data = pd.DataFrame(within_percentiles_dict)\n",
    "    within_dist_data = within_dist_data.dropna(axis=0, inplace=False)\n",
    "    within_dist_data = within_dist_data.round(4)\n",
    "\n",
    "    # Adding relevant information to this dataframe and saving.\n",
    "    # Defining mean_group_rank: the average of the individual rank given to this pathway by each approach.\n",
    "    # Defining mean_avg_pair_percentile: the average across all approaches of the average distance percentile for each gene pair.\n",
    "    within_dist_data[\"mean_group_rank\"] = within_dist_data.rank().mean(axis=1)\n",
    "    within_dist_data[\"mean_avg_pair_percentile\"] = within_dist_data.mean(axis=1)\n",
    "    within_dist_data.sort_values(by=\"mean_avg_pair_percentile\", inplace=True)\n",
    "    within_dist_data.reset_index(inplace=True)\n",
    "    within_dist_data[\"group_id\"] = within_dist_data[\"index\"]\n",
    "    within_dist_data[\"full_name\"] = within_dist_data[\"group_id\"].apply(lambda x: groups.get_long_name(x))\n",
    "    within_dist_data[\"n\"] = within_dist_data[\"group_id\"].apply(lambda x: len(group_id_to_ids[x]))\n",
    "    within_dist_data = within_dist_data[flatten([\"group_id\",\"full_name\",\"n\",\"mean_avg_pair_percentile\",\"mean_group_rank\",names])]\n",
    "    within_dist_data.to_csv(os.path.join(OUTPUT_DIR,\"part_5_{}_within_distances.csv\".format(q)), index=False)\n",
    "    within_dist_data.head(5)\n",
    "\n",
    "print(\"done generating mean within-group distance values\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"auc\"></a>\n",
    "### Predicting whether two genes belong to the same group, pathway, or share an interaction\n",
    "The purpose of this section is to see if whether or not two genes share atleast one common pathway can be predicted from the distance scores assigned using analysis of text similarity. The evaluation of predictability is done by reporting a precision and recall curve for each method, as well as remembering the area under the curve, and ratio between the area under the curve and the baseline (expected area when guessing randomly) for each method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap(fraction, num_iterations, y_true, y_prob):\n",
    "    # Run the desired number of bootstrap iterations over the full population of predictions and return st devs.\n",
    "    scores = pd.DataFrame([bootstrap_iteration(fraction, y_true, y_prob) for i in range(num_iterations)])\n",
    "    standard_deviations = {\n",
    "        \"f_1_max_std\": np.std(scores[\"f_1_max\"].values),\n",
    "        \"f_2_max_std\": np.std(scores[\"f_2_max\"].values),\n",
    "        \"f_point5_max_std\": np.std(scores[\"f_point5_max\"].values)}\n",
    "    return(standard_deviations)\n",
    "\n",
    "\n",
    "def bootstrap_iteration(fraction, y_true, y_prob):\n",
    "    assert len(y_true) == len(y_prob)\n",
    "    # Subset the total population of predictions using the provided fraction.\n",
    "    num_predictions = len(y_true)\n",
    "    bootstrapping_fraction = fraction\n",
    "    num_to_retain = int(np.ceil(num_predictions*bootstrapping_fraction))\n",
    "    idx = np.random.choice(np.arange(num_predictions), num_to_retain, replace=False)\n",
    "    y_true_sample = y_true[idx]\n",
    "    y_prob_sample = y_prob[idx]\n",
    "    \n",
    "    # Calculate any desired metrics using just that subset.\n",
    "    n_pos, n_neg = Counter(y_true_sample)[1], Counter(y_true_sample)[0]\n",
    "    precision, recall, thresholds = precision_recall_curve(y_true_sample, y_prob_sample)\n",
    "    baseline = Counter(y_true_sample)[1]/len(y_true_sample) \n",
    "    area = auc(recall, precision)\n",
    "    auc_to_baseline_auc_ratio = area/baseline\n",
    "    \n",
    "    # Find the maximum F score for different values of .  \n",
    "    f_beta = lambda pr,re,beta: [((1+beta**2)*p*r)/((((beta**2)*p)+r)) for p,r in zip(pr,re)]\n",
    "    f_1_scores = f_beta(precision,recall,beta=1)\n",
    "    f_2_scores = f_beta(precision,recall,beta=2)\n",
    "    f_point5_scores = f_beta(precision,recall,beta=0.5)\n",
    "    \n",
    "    # Create a dictionary of those metric values to return.\n",
    "    scores={\"f_1_max\":np.nanmax(f_1_scores),\"f_2_max\":np.nanmax(f_2_scores),\"f_point5_max\":np.nanmax(f_point5_scores)}\n",
    "    return(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done with finding precision and recall values for each approach\n"
     ]
    }
   ],
   "source": [
    "for properties,idxs in zip(subset_properties, subset_idx_lists):\n",
    "    \n",
    "    # Remember the properties for this subset being looked at, and subset the dataframe accordingly.\n",
    "    c,q,s = properties\n",
    "    \n",
    "    # Don't look at the inter-species and intra-species edges except for pathways, otherwise irrelevant.\n",
    "    if (s != \"both\") and (q != \"pathways\"):\n",
    "        continue\n",
    "    \n",
    "    # Create a subset of the dataframe that contains only the gene pairs for this question.\n",
    "    subset = df.loc[idxs]\n",
    "\n",
    "    # Check that this subsetting leaves a valid dataset with both positive and negatives samples.\n",
    "    class_values = pd.unique(subset[q].values)\n",
    "    if not (len(class_values)==2 and 0 in class_values and 1 in class_values):\n",
    "        continue\n",
    "\n",
    "\n",
    "\n",
    "    y_true_dict = {name:subset[q].values for name in names}       #just added .values here...\n",
    "    y_prob_dict = {name:(1 - subset[name].values) for name in names}\n",
    "    num_plots, plots_per_row, row_width, row_height = (len(names), 4, 14, 3)\n",
    "    fig,axs = plt.subplots(math.ceil(num_plots/plots_per_row), plots_per_row, squeeze=False)\n",
    "    for name,ax in zip(names, axs.flatten()):\n",
    "\n",
    "        # Obtaining the values and metrics.\n",
    "        y_true, y_prob = y_true_dict[name], y_prob_dict[name]\n",
    "        n_pos, n_neg = Counter(y_true)[1], Counter(y_true)[0]\n",
    "        precision, recall, thresholds = precision_recall_curve(y_true, y_prob)\n",
    "        baseline_auc = Counter(y_true)[1]/len(y_true) \n",
    "        area = auc(recall, precision)\n",
    "        auc_to_baseline_auc_ratio = area/baseline_auc\n",
    "        # The baseline F1 max has a precision of the ratio of positives to all samples and a recall of 1.\n",
    "        # This is because a random classifier achieves that precision at all recall values, so recall is maximized to\n",
    "        # find the maximum F1 value that can be expected due to random chance.\n",
    "        baseline_f1_max = (2*baseline_auc*1)/(baseline_auc+1)\n",
    "\n",
    "        #TABLE[name].update({\"auc\":area,\"ratio\":auc_to_baseline_auc_ratio, \"baseline\":baseline_f1_max, })\n",
    "        tables[c][q][s][name].update({\"auc\":area,\"ratio\":auc_to_baseline_auc_ratio, \"baseline\":baseline_f1_max, })\n",
    "\n",
    "\n",
    "        # Find the maximum F score for different values of .  \n",
    "        f_beta = lambda pr,re,beta: [((1+beta**2)*p*r)/((((beta**2)*p)+r)) for p,r in zip(pr,re)]\n",
    "        f_1_scores = f_beta(precision,recall,beta=1)\n",
    "        f_2_scores = f_beta(precision,recall,beta=2)\n",
    "        f_point5_scores = f_beta(precision,recall,beta=0.5)\n",
    "        f_1_max, f_1_std = np.nanmax(f_1_scores), np.std(f_1_scores)\n",
    "        f_2_max, f_2_std = np.nanmax(f_2_scores), np.std(f_2_scores)\n",
    "        f_point5_max, f_point5_std = np.nanmax(f_point5_scores), np.std(f_point5_scores)\n",
    "\n",
    "        # Find the standard deviation of each metric when subsampling the dataset of predictions for each method.\n",
    "        bootstrap_fraction = 0.5\n",
    "        bootstrap_iterations = 2\n",
    "        bootstrapped_std_dict = bootstrap(bootstrap_fraction, bootstrap_iterations, y_true, y_prob)\n",
    "\n",
    "        tables[c][q][s][name].update({\"f1_max\":f_1_max, \"f5_max\":f_point5_max, \"f2_max\":f_2_max})\n",
    "        #TABLE[name].update({\"f1_std\":f_1_std, \"f5_std\":f_point5_std, \"f2_std\":f_2_std})\n",
    "        tables[c][q][s][name].update({\"f1_std\":bootstrapped_std_dict[\"f_1_max_std\"], \n",
    "                            \"f5_std\":bootstrapped_std_dict[\"f_point5_max_std\"], \n",
    "                            \"f2_std\":bootstrapped_std_dict[\"f_2_max_std\"]}) \n",
    "\n",
    "        # Producing the precision recall curve.\n",
    "        #step_kwargs = ({'step': 'post'} if 'step' in signature(plt.fill_between).parameters else {})\n",
    "        #ax.step(recall, precision, color='black', alpha=0.2, where='post')\n",
    "        #ax.fill_between(recall, precision, alpha=0.7, color='black', **step_kwargs)\n",
    "        #ax.axhline(baseline_auc, linestyle=\"--\", color=\"lightgray\")\n",
    "        #ax.set_xlabel('Recall')\n",
    "        #ax.set_ylabel('Precision')\n",
    "        #ax.set_ylim([0.0, 1.05])\n",
    "        #ax.set_xlim([0.0, 1.0])\n",
    "        #ax.set_title(\"PR {0} (Baseline={1:0.3f})\".format(name, baseline_auc))\n",
    "\n",
    "    #fig.set_size_inches(row_width, row_height*math.ceil(num_plots/plots_per_row))\n",
    "    #fig.tight_layout()\n",
    "    #fig.savefig(os.path.join(OUTPUT_DIR,\"part_5_prcurve_shared.png\"),dpi=400)\n",
    "    plt.close()\n",
    "\n",
    "print(\"done with finding precision and recall values for each approach\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"y\"></a>\n",
    "### Are genes in the same group or pathway ranked higher with respect to individual nodes?\n",
    "This is a way of statistically seeing if for some value k, the graph ranks more edges from some particular gene to any other gene that it has a true protein-protein interaction with higher or equal to rank k, than we would expect due to random chance. This way of looking at the problem helps to be less ambiguous than the previous methods, because it gets at the core of how this would actually be used. In other words, we don't really care how much true information we're missing as long as we're still able to pick up some new useful information by building these networks, so even though we could be missing a lot, what's going on at the very top of the results? These results should be comparable to very strictly thresholding the network and saying that the remaining edges are our guesses at interactions. This is comparable to just looking at the far left-hand side of the precision recall curves, but just quantifies it slightly differently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if NOTEBOOK:\n",
    "    \n",
    "    # When the edgelist is generated above, only the lower triangle of the pairwise matrix is retained for edges in the \n",
    "    # graph. This means that in terms of the indices of each node, only the (i,j) node is listed in the edge list where\n",
    "    # i is less than j. This makes sense because the graph that's specified is assumed to already be undirected. However\n",
    "    # in order to be able to easily subset the edgelist by a single column to obtain rows that correspond to all edges\n",
    "    # connected to a particular node, this method will double the number of rows to include both (i,j) and (j,i) edges.\n",
    "    df = make_undirected(df)\n",
    "\n",
    "    # What's the number of functional partners ranked k or higher in terms of phenotypic description similarity for \n",
    "    # each gene? Also figure out the maximum possible number of functional partners that could be theoretically\n",
    "    # recovered in this dataset if recovered means being ranked as k or higher here.\n",
    "    k = 10      # The threshold of interest for gene ranks.\n",
    "    n = 100     # Number of Monte Carlo simulation iterations to complete.\n",
    "    df[list(names)] = df.groupby(\"from\")[list(names)].rank()\n",
    "    ys = df[df[\"shared\"]==1][list(names)].apply(lambda s: len([x for x in s if x<=k]))\n",
    "    ymax = sum(df.groupby(\"from\")[\"shared\"].apply(lambda s: min(len([x for x in s if x==1]),k)))\n",
    "\n",
    "    # Monte Carlo simulation to see what the probability is of achieving each y-value by just randomly pulling k \n",
    "    # edges for each gene rather than taking the top k ones that the similarity methods specifies when ranking.\n",
    "    ysims = [sum(df.groupby(\"from\")[\"shared\"].apply(lambda s: len([x for x in s.sample(k) if x>0.00]))) for i in range(n)]\n",
    "    for name in names:\n",
    "        pvalue = len([ysim for ysim in ysims if ysim>=ys[name]])/float(n)\n",
    "        TABLE[name].update({\"y\":ys[name], \"y_max\":ymax, \"y_ratio\":ys[name]/ymax, \"y_pval\":pvalue})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"mean\"></a>\n",
    "### Predicting biochemical pathway or group membership based on mean vectors\n",
    "This section looks at how well the biochemical pathways that a particular gene is a member of can be predicted based on the similarity between the vector representation of the phenotype descriptions for that gene and the average vector for all the vector representations of phenotypes asociated with genes that belong to that particular pathway. In calculating the average vector for a given biochemical pathway, the vector corresponding to the gene that is currently being classified is not accounted for, to avoid overestimating the performance by including information about the ground truth during classification. This leads to missing information in the case of biochemical pathways that have only one member. This can be accounted for by only limiting the overall dataset to only include genes that belong to pathways that have atleast two genes mapped to them, and only including those pathways, or by removing the missing values before calculating the performance metrics below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get the list of methods to look at, and a mapping between each method and the correct similarity metric to apply.\n",
    "# vector_dicts = {k:v.vector_dictionary for k,v in graphs.items()}\n",
    "# names = list(vector_dicts.keys())\n",
    "# group_id_to_ids = groups.get_group_id_to_ids_dict(dataset.get_gene_dictionary())\n",
    "# valid_group_ids = [group for group,id_list in group_id_to_ids.items() if len(id_list)>1]\n",
    "# valid_ids = [i for i in dataset.get_ids() if len(set(valid_group_ids).intersection(set(id_to_group_ids[i])))>0]\n",
    "# pred_dict = defaultdict(lambda: defaultdict(dict))\n",
    "# true_dict = defaultdict(lambda: defaultdict(dict))\n",
    "# for name in names:\n",
    "#     for group in valid_group_ids:\n",
    "#         ids = group_id_to_ids[group]\n",
    "#         for identifier in valid_ids:\n",
    "#             # What's the mean vector of this group, without this particular one that we're trying to classify.\n",
    "#             vectors = np.array([vector_dicts[name][some_id] for some_id in ids if not some_id==identifier])\n",
    "#             mean_vector = vectors.mean(axis=0)\n",
    "#             this_vector = vector_dicts[name][identifier]\n",
    "#             pred_dict[name][identifier][group] = 1-metric_dict[name](mean_vector, this_vector)\n",
    "#             true_dict[name][identifier][group] = (identifier in group_id_to_ids[group])*1                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# num_plots, plots_per_row, row_width, row_height = (len(names), 4, 14, 3)\n",
    "# fig,axs = plt.subplots(math.ceil(num_plots/plots_per_row), plots_per_row, squeeze=False)\n",
    "# for name,ax in zip(names, axs.flatten()):\n",
    "#     \n",
    "#     # Obtaining the values and metrics.\n",
    "#     y_true = pd.DataFrame(true_dict[name]).as_matrix().flatten()\n",
    "#     y_prob = pd.DataFrame(pred_dict[name]).as_matrix().flatten()\n",
    "#     n_pos, n_neg = Counter(y_true)[1], Counter(y_true)[0]\n",
    "#     precision, recall, thresholds = precision_recall_curve(y_true, y_prob)\n",
    "#     baseline = Counter(y_true)[1]/len(y_true) \n",
    "#     area = auc(recall, precision)\n",
    "#     auc_to_baseline_auc_ratio = area/baseline\n",
    "#     TABLE[name].update({\"mean_auc\":area, \"mean_baseline\":baseline, \"mean_ratio\":auc_to_baseline_auc_ratio})\n",
    "# \n",
    "#     # Producing the precision recall curve.\n",
    "#     step_kwargs = ({'step': 'post'} if 'step' in signature(plt.fill_between).parameters else {})\n",
    "#     ax.step(recall, precision, color='black', alpha=0.2, where='post')\n",
    "#     ax.fill_between(recall, precision, alpha=0.7, color='black', **step_kwargs)\n",
    "#     ax.axhline(baseline, linestyle=\"--\", color=\"lightgray\")\n",
    "#     ax.set_xlabel('Recall')\n",
    "#     ax.set_ylabel('Precision')\n",
    "#     ax.set_ylim([0.0, 1.05])\n",
    "#     ax.set_xlim([0.0, 1.0])\n",
    "#     ax.set_title(\"PR {0} (Baseline={1:0.3f})\".format(name[:10], baseline))\n",
    "#     \n",
    "# fig.set_size_inches(row_width, row_height*math.ceil(num_plots/plots_per_row))\n",
    "# fig.tight_layout()\n",
    "# fig.savefig(os.path.join(OUTPUT_DIR,\"part_6_prcurve_mean_classifier.png\"),dpi=400)\n",
    "# plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting biochemical pathway membership based on mean similarity values\n",
    "This section looks at how well the biochemical pathways that a particular gene is a member of can be predicted based on the average similarity between the vector representationt of the phenotype descriptions for that gene and each of the vector representations for other phenotypes associated with genes that belong to that particular pathway. In calculating the average similarity to other genes from a given biochemical pathway, the gene that is currently being classified is not accounted for, to avoid overestimating the performance by including information about the ground truth during classification. This leads to missing information in the case of biochemical pathways that have only one member. This can be accounted for by only limiting the overall dataset to only include genes that belong to pathways that have atleast two genes mapped to them, and only including those pathways, or by removing the missing values before calculating the performance metrics below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting biochemical pathway or group membership with KNN classifier\n",
    "This section looks at how well the group(s) or biochemical pathway(s) that a particular gene belongs to can be predicted based on a KNN classifier generated using every other gene. For this section, only the groups or pathways which contain more than one gene, and the genes mapped to those groups or pathways, are of interest. This is because for other genes, if we consider them then it will be true that that gene belongs to that group in the target vector, but the KNN classifier could never predict this because when that gene is held out, nothing could provide a vote for that group, because there are zero genes available to be members of the K nearest neighbors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"output\"></a>\n",
    "### Summarizing the results for this notebook\n",
    "Write a large table of results to an output file. Columns are generally metrics and rows are generally methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Method</th>\n",
       "      <th>Species</th>\n",
       "      <th>Objective</th>\n",
       "      <th>Curated</th>\n",
       "      <th>Hyperparameters</th>\n",
       "      <th>Group</th>\n",
       "      <th>Order</th>\n",
       "      <th>mean_1</th>\n",
       "      <th>mean_0</th>\n",
       "      <th>n_1</th>\n",
       "      <th>n_0</th>\n",
       "      <th>ks</th>\n",
       "      <th>ks_pval</th>\n",
       "      <th>auc</th>\n",
       "      <th>ratio</th>\n",
       "      <th>baseline</th>\n",
       "      <th>f1_max</th>\n",
       "      <th>f5_max</th>\n",
       "      <th>f2_max</th>\n",
       "      <th>f1_std</th>\n",
       "      <th>f5_std</th>\n",
       "      <th>f2_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Doc2Vec</td>\n",
       "      <td>intra</td>\n",
       "      <td>pathways</td>\n",
       "      <td>true</td>\n",
       "      <td>Wikipedia,Size=300</td>\n",
       "      <td>nlp</td>\n",
       "      <td>0</td>\n",
       "      <td>0.424649</td>\n",
       "      <td>0.439679</td>\n",
       "      <td>64.0</td>\n",
       "      <td>2154.0</td>\n",
       "      <td>0.071771</td>\n",
       "      <td>0.882421</td>\n",
       "      <td>0.055921</td>\n",
       "      <td>1.938022</td>\n",
       "      <td>0.056091</td>\n",
       "      <td>0.092105</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.131510</td>\n",
       "      <td>0.008929</td>\n",
       "      <td>0.043883</td>\n",
       "      <td>0.009820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Word2Vec</td>\n",
       "      <td>intra</td>\n",
       "      <td>pathways</td>\n",
       "      <td>true</td>\n",
       "      <td>Wikipedia,Size=300,Mean</td>\n",
       "      <td>nlp</td>\n",
       "      <td>1</td>\n",
       "      <td>0.247770</td>\n",
       "      <td>0.298723</td>\n",
       "      <td>64.0</td>\n",
       "      <td>2154.0</td>\n",
       "      <td>0.142613</td>\n",
       "      <td>0.144346</td>\n",
       "      <td>0.066334</td>\n",
       "      <td>2.298902</td>\n",
       "      <td>0.056091</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.192308</td>\n",
       "      <td>0.158924</td>\n",
       "      <td>0.017074</td>\n",
       "      <td>0.017650</td>\n",
       "      <td>0.011801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Word2Vec</td>\n",
       "      <td>intra</td>\n",
       "      <td>pathways</td>\n",
       "      <td>true</td>\n",
       "      <td>Wikipedia,Size=300,Max</td>\n",
       "      <td>nlp</td>\n",
       "      <td>2</td>\n",
       "      <td>0.151898</td>\n",
       "      <td>0.228215</td>\n",
       "      <td>64.0</td>\n",
       "      <td>2154.0</td>\n",
       "      <td>0.169467</td>\n",
       "      <td>0.049635</td>\n",
       "      <td>0.069115</td>\n",
       "      <td>2.395278</td>\n",
       "      <td>0.056091</td>\n",
       "      <td>0.132450</td>\n",
       "      <td>0.172414</td>\n",
       "      <td>0.161830</td>\n",
       "      <td>0.033052</td>\n",
       "      <td>0.063016</td>\n",
       "      <td>0.041684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Doc2Vec Phenes</td>\n",
       "      <td>intra</td>\n",
       "      <td>pathways</td>\n",
       "      <td>true</td>\n",
       "      <td>Wikipedia,Size=300</td>\n",
       "      <td>nlp</td>\n",
       "      <td>3</td>\n",
       "      <td>0.257328</td>\n",
       "      <td>0.272577</td>\n",
       "      <td>64.0</td>\n",
       "      <td>2154.0</td>\n",
       "      <td>0.178404</td>\n",
       "      <td>0.033390</td>\n",
       "      <td>0.072475</td>\n",
       "      <td>2.511700</td>\n",
       "      <td>0.056091</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.056452</td>\n",
       "      <td>0.160312</td>\n",
       "      <td>0.008749</td>\n",
       "      <td>0.002293</td>\n",
       "      <td>0.025748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Word2Vec Phenes</td>\n",
       "      <td>intra</td>\n",
       "      <td>pathways</td>\n",
       "      <td>true</td>\n",
       "      <td>Wikipedia,Size=300,Mean</td>\n",
       "      <td>nlp</td>\n",
       "      <td>4</td>\n",
       "      <td>0.250332</td>\n",
       "      <td>0.292738</td>\n",
       "      <td>64.0</td>\n",
       "      <td>2154.0</td>\n",
       "      <td>0.144136</td>\n",
       "      <td>0.136552</td>\n",
       "      <td>0.088904</td>\n",
       "      <td>3.081085</td>\n",
       "      <td>0.056091</td>\n",
       "      <td>0.080863</td>\n",
       "      <td>0.059524</td>\n",
       "      <td>0.148862</td>\n",
       "      <td>0.012784</td>\n",
       "      <td>0.011489</td>\n",
       "      <td>0.003803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Word2Vec Phenes</td>\n",
       "      <td>intra</td>\n",
       "      <td>pathways</td>\n",
       "      <td>true</td>\n",
       "      <td>Wikipedia,Size=300,Max</td>\n",
       "      <td>nlp</td>\n",
       "      <td>5</td>\n",
       "      <td>0.164301</td>\n",
       "      <td>0.230151</td>\n",
       "      <td>64.0</td>\n",
       "      <td>2154.0</td>\n",
       "      <td>0.143614</td>\n",
       "      <td>0.139206</td>\n",
       "      <td>0.090216</td>\n",
       "      <td>3.126532</td>\n",
       "      <td>0.056091</td>\n",
       "      <td>0.087649</td>\n",
       "      <td>0.067734</td>\n",
       "      <td>0.151812</td>\n",
       "      <td>0.006143</td>\n",
       "      <td>0.003618</td>\n",
       "      <td>0.005601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NOBLE Coder</td>\n",
       "      <td>intra</td>\n",
       "      <td>pathways</td>\n",
       "      <td>true</td>\n",
       "      <td>Precise,TFIDF</td>\n",
       "      <td>nlp</td>\n",
       "      <td>6</td>\n",
       "      <td>0.767885</td>\n",
       "      <td>0.831182</td>\n",
       "      <td>64.0</td>\n",
       "      <td>2154.0</td>\n",
       "      <td>0.206070</td>\n",
       "      <td>0.008585</td>\n",
       "      <td>0.052990</td>\n",
       "      <td>1.836432</td>\n",
       "      <td>0.056091</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.148810</td>\n",
       "      <td>0.164547</td>\n",
       "      <td>0.002252</td>\n",
       "      <td>0.011905</td>\n",
       "      <td>0.008422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NOBLE Coder</td>\n",
       "      <td>intra</td>\n",
       "      <td>pathways</td>\n",
       "      <td>true</td>\n",
       "      <td>Partial,TFIDF</td>\n",
       "      <td>nlp</td>\n",
       "      <td>7</td>\n",
       "      <td>0.809939</td>\n",
       "      <td>0.871002</td>\n",
       "      <td>64.0</td>\n",
       "      <td>2154.0</td>\n",
       "      <td>0.181958</td>\n",
       "      <td>0.028357</td>\n",
       "      <td>0.055498</td>\n",
       "      <td>1.923348</td>\n",
       "      <td>0.056091</td>\n",
       "      <td>0.121212</td>\n",
       "      <td>0.144231</td>\n",
       "      <td>0.160881</td>\n",
       "      <td>0.016393</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NOBLE Coder Phenes</td>\n",
       "      <td>intra</td>\n",
       "      <td>pathways</td>\n",
       "      <td>true</td>\n",
       "      <td>Precise,TFIDF</td>\n",
       "      <td>nlp</td>\n",
       "      <td>8</td>\n",
       "      <td>0.609412</td>\n",
       "      <td>0.617485</td>\n",
       "      <td>64.0</td>\n",
       "      <td>2154.0</td>\n",
       "      <td>0.150171</td>\n",
       "      <td>0.108916</td>\n",
       "      <td>0.098653</td>\n",
       "      <td>3.418950</td>\n",
       "      <td>0.056091</td>\n",
       "      <td>0.074561</td>\n",
       "      <td>0.052083</td>\n",
       "      <td>0.131173</td>\n",
       "      <td>0.005836</td>\n",
       "      <td>0.006385</td>\n",
       "      <td>0.016258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NOBLE Coder Phenes</td>\n",
       "      <td>intra</td>\n",
       "      <td>pathways</td>\n",
       "      <td>true</td>\n",
       "      <td>Partial,TFIDF</td>\n",
       "      <td>nlp</td>\n",
       "      <td>9</td>\n",
       "      <td>0.599161</td>\n",
       "      <td>0.679207</td>\n",
       "      <td>64.0</td>\n",
       "      <td>2154.0</td>\n",
       "      <td>0.128293</td>\n",
       "      <td>0.236402</td>\n",
       "      <td>0.113260</td>\n",
       "      <td>3.925179</td>\n",
       "      <td>0.056091</td>\n",
       "      <td>0.097015</td>\n",
       "      <td>0.075301</td>\n",
       "      <td>0.147059</td>\n",
       "      <td>0.005969</td>\n",
       "      <td>0.001421</td>\n",
       "      <td>0.002405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Topic Models</td>\n",
       "      <td>intra</td>\n",
       "      <td>pathways</td>\n",
       "      <td>true</td>\n",
       "      <td>NMF,Full,Topics=50</td>\n",
       "      <td>nlp</td>\n",
       "      <td>10</td>\n",
       "      <td>0.809160</td>\n",
       "      <td>0.916140</td>\n",
       "      <td>64.0</td>\n",
       "      <td>2154.0</td>\n",
       "      <td>0.222087</td>\n",
       "      <td>0.003565</td>\n",
       "      <td>0.074917</td>\n",
       "      <td>2.596342</td>\n",
       "      <td>0.056091</td>\n",
       "      <td>0.138889</td>\n",
       "      <td>0.172414</td>\n",
       "      <td>0.187166</td>\n",
       "      <td>0.034635</td>\n",
       "      <td>0.075397</td>\n",
       "      <td>0.017415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Topic Models</td>\n",
       "      <td>intra</td>\n",
       "      <td>pathways</td>\n",
       "      <td>true</td>\n",
       "      <td>NMF,Full,Topics=100</td>\n",
       "      <td>nlp</td>\n",
       "      <td>11</td>\n",
       "      <td>0.878424</td>\n",
       "      <td>0.937362</td>\n",
       "      <td>64.0</td>\n",
       "      <td>2154.0</td>\n",
       "      <td>0.203879</td>\n",
       "      <td>0.009631</td>\n",
       "      <td>0.066794</td>\n",
       "      <td>2.314833</td>\n",
       "      <td>0.056091</td>\n",
       "      <td>0.108108</td>\n",
       "      <td>0.192308</td>\n",
       "      <td>0.161716</td>\n",
       "      <td>0.006466</td>\n",
       "      <td>0.058050</td>\n",
       "      <td>0.000569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Topic Models Phenes</td>\n",
       "      <td>intra</td>\n",
       "      <td>pathways</td>\n",
       "      <td>true</td>\n",
       "      <td>NMF,Full,Topics=50</td>\n",
       "      <td>nlp</td>\n",
       "      <td>12</td>\n",
       "      <td>0.474942</td>\n",
       "      <td>0.530409</td>\n",
       "      <td>64.0</td>\n",
       "      <td>2154.0</td>\n",
       "      <td>0.120894</td>\n",
       "      <td>0.298565</td>\n",
       "      <td>0.079622</td>\n",
       "      <td>2.759387</td>\n",
       "      <td>0.056091</td>\n",
       "      <td>0.077419</td>\n",
       "      <td>0.060160</td>\n",
       "      <td>0.144597</td>\n",
       "      <td>0.006647</td>\n",
       "      <td>0.006312</td>\n",
       "      <td>0.005290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Topic Models Phenes</td>\n",
       "      <td>intra</td>\n",
       "      <td>pathways</td>\n",
       "      <td>true</td>\n",
       "      <td>NMF,Full,Topics=100</td>\n",
       "      <td>nlp</td>\n",
       "      <td>13</td>\n",
       "      <td>0.506443</td>\n",
       "      <td>0.607690</td>\n",
       "      <td>64.0</td>\n",
       "      <td>2154.0</td>\n",
       "      <td>0.173282</td>\n",
       "      <td>0.042017</td>\n",
       "      <td>0.073884</td>\n",
       "      <td>2.560534</td>\n",
       "      <td>0.056091</td>\n",
       "      <td>0.075472</td>\n",
       "      <td>0.055066</td>\n",
       "      <td>0.157604</td>\n",
       "      <td>0.020546</td>\n",
       "      <td>0.017496</td>\n",
       "      <td>0.012055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Topic Models</td>\n",
       "      <td>intra</td>\n",
       "      <td>pathways</td>\n",
       "      <td>true</td>\n",
       "      <td>LDA,Full,Topics=50</td>\n",
       "      <td>nlp</td>\n",
       "      <td>14</td>\n",
       "      <td>0.760699</td>\n",
       "      <td>0.818264</td>\n",
       "      <td>64.0</td>\n",
       "      <td>2154.0</td>\n",
       "      <td>0.111566</td>\n",
       "      <td>0.391993</td>\n",
       "      <td>0.050570</td>\n",
       "      <td>1.752571</td>\n",
       "      <td>0.056091</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.119048</td>\n",
       "      <td>0.142379</td>\n",
       "      <td>0.015873</td>\n",
       "      <td>0.027233</td>\n",
       "      <td>0.013558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Topic Models</td>\n",
       "      <td>intra</td>\n",
       "      <td>pathways</td>\n",
       "      <td>true</td>\n",
       "      <td>LDA,Full,Topics=100</td>\n",
       "      <td>nlp</td>\n",
       "      <td>15</td>\n",
       "      <td>0.828877</td>\n",
       "      <td>0.879316</td>\n",
       "      <td>64.0</td>\n",
       "      <td>2154.0</td>\n",
       "      <td>0.179187</td>\n",
       "      <td>0.032216</td>\n",
       "      <td>0.074762</td>\n",
       "      <td>2.590965</td>\n",
       "      <td>0.056091</td>\n",
       "      <td>0.114286</td>\n",
       "      <td>0.227273</td>\n",
       "      <td>0.161588</td>\n",
       "      <td>0.024390</td>\n",
       "      <td>0.041509</td>\n",
       "      <td>0.006720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Topic Models Phenes</td>\n",
       "      <td>intra</td>\n",
       "      <td>pathways</td>\n",
       "      <td>true</td>\n",
       "      <td>LDA,Full,Topics=50</td>\n",
       "      <td>nlp</td>\n",
       "      <td>16</td>\n",
       "      <td>0.310155</td>\n",
       "      <td>0.447954</td>\n",
       "      <td>64.0</td>\n",
       "      <td>2154.0</td>\n",
       "      <td>0.193535</td>\n",
       "      <td>0.016284</td>\n",
       "      <td>0.075377</td>\n",
       "      <td>2.612268</td>\n",
       "      <td>0.056091</td>\n",
       "      <td>0.083707</td>\n",
       "      <td>0.057398</td>\n",
       "      <td>0.163785</td>\n",
       "      <td>0.015269</td>\n",
       "      <td>0.009608</td>\n",
       "      <td>0.029148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Topic Models Phenes</td>\n",
       "      <td>intra</td>\n",
       "      <td>pathways</td>\n",
       "      <td>true</td>\n",
       "      <td>LDA,Full,Topics=100</td>\n",
       "      <td>nlp</td>\n",
       "      <td>17</td>\n",
       "      <td>0.530114</td>\n",
       "      <td>0.578009</td>\n",
       "      <td>64.0</td>\n",
       "      <td>2154.0</td>\n",
       "      <td>0.128047</td>\n",
       "      <td>0.238255</td>\n",
       "      <td>0.071259</td>\n",
       "      <td>2.469586</td>\n",
       "      <td>0.056091</td>\n",
       "      <td>0.078067</td>\n",
       "      <td>0.053571</td>\n",
       "      <td>0.145943</td>\n",
       "      <td>0.008996</td>\n",
       "      <td>0.007205</td>\n",
       "      <td>0.006483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>N-Grams</td>\n",
       "      <td>intra</td>\n",
       "      <td>pathways</td>\n",
       "      <td>true</td>\n",
       "      <td>Full,Words,1-grams,TFIDF</td>\n",
       "      <td>nlp</td>\n",
       "      <td>18</td>\n",
       "      <td>0.874096</td>\n",
       "      <td>0.930578</td>\n",
       "      <td>64.0</td>\n",
       "      <td>2154.0</td>\n",
       "      <td>0.144571</td>\n",
       "      <td>0.134406</td>\n",
       "      <td>0.070610</td>\n",
       "      <td>2.447061</td>\n",
       "      <td>0.056091</td>\n",
       "      <td>0.103093</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.154131</td>\n",
       "      <td>0.008593</td>\n",
       "      <td>0.002643</td>\n",
       "      <td>0.012483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>N-Grams</td>\n",
       "      <td>intra</td>\n",
       "      <td>pathways</td>\n",
       "      <td>true</td>\n",
       "      <td>Full,Words,1-grams,2-grams,TFIDF</td>\n",
       "      <td>nlp</td>\n",
       "      <td>19</td>\n",
       "      <td>0.890279</td>\n",
       "      <td>0.946576</td>\n",
       "      <td>64.0</td>\n",
       "      <td>2154.0</td>\n",
       "      <td>0.143323</td>\n",
       "      <td>0.140697</td>\n",
       "      <td>0.074372</td>\n",
       "      <td>2.577439</td>\n",
       "      <td>0.056091</td>\n",
       "      <td>0.108108</td>\n",
       "      <td>0.192308</td>\n",
       "      <td>0.152888</td>\n",
       "      <td>0.020579</td>\n",
       "      <td>0.049487</td>\n",
       "      <td>0.002879</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Method Species Objective Curated                   Hyperparameters Group  Order    mean_1    mean_0   n_1     n_0        ks   ks_pval       auc     ratio  baseline    f1_max    f5_max    f2_max    f1_std    f5_std    f2_std\n",
       "0               Doc2Vec   intra  pathways    true                Wikipedia,Size=300   nlp      0  0.424649  0.439679  64.0  2154.0  0.071771  0.882421  0.055921  1.938022  0.056091  0.092105  0.187500  0.131510  0.008929  0.043883  0.009820\n",
       "1              Word2Vec   intra  pathways    true           Wikipedia,Size=300,Mean   nlp      1  0.247770  0.298723  64.0  2154.0  0.142613  0.144346  0.066334  2.298902  0.056091  0.133333  0.192308  0.158924  0.017074  0.017650  0.011801\n",
       "2              Word2Vec   intra  pathways    true            Wikipedia,Size=300,Max   nlp      2  0.151898  0.228215  64.0  2154.0  0.169467  0.049635  0.069115  2.395278  0.056091  0.132450  0.172414  0.161830  0.033052  0.063016  0.041684\n",
       "3        Doc2Vec Phenes   intra  pathways    true                Wikipedia,Size=300   nlp      3  0.257328  0.272577  64.0  2154.0  0.178404  0.033390  0.072475  2.511700  0.056091  0.076923  0.056452  0.160312  0.008749  0.002293  0.025748\n",
       "4       Word2Vec Phenes   intra  pathways    true           Wikipedia,Size=300,Mean   nlp      4  0.250332  0.292738  64.0  2154.0  0.144136  0.136552  0.088904  3.081085  0.056091  0.080863  0.059524  0.148862  0.012784  0.011489  0.003803\n",
       "5       Word2Vec Phenes   intra  pathways    true            Wikipedia,Size=300,Max   nlp      5  0.164301  0.230151  64.0  2154.0  0.143614  0.139206  0.090216  3.126532  0.056091  0.087649  0.067734  0.151812  0.006143  0.003618  0.005601\n",
       "6           NOBLE Coder   intra  pathways    true                     Precise,TFIDF   nlp      6  0.767885  0.831182  64.0  2154.0  0.206070  0.008585  0.052990  1.836432  0.056091  0.111111  0.148810  0.164547  0.002252  0.011905  0.008422\n",
       "7           NOBLE Coder   intra  pathways    true                     Partial,TFIDF   nlp      7  0.809939  0.871002  64.0  2154.0  0.181958  0.028357  0.055498  1.923348  0.056091  0.121212  0.144231  0.160881  0.016393  0.000000  0.001111\n",
       "8    NOBLE Coder Phenes   intra  pathways    true                     Precise,TFIDF   nlp      8  0.609412  0.617485  64.0  2154.0  0.150171  0.108916  0.098653  3.418950  0.056091  0.074561  0.052083  0.131173  0.005836  0.006385  0.016258\n",
       "9    NOBLE Coder Phenes   intra  pathways    true                     Partial,TFIDF   nlp      9  0.599161  0.679207  64.0  2154.0  0.128293  0.236402  0.113260  3.925179  0.056091  0.097015  0.075301  0.147059  0.005969  0.001421  0.002405\n",
       "10         Topic Models   intra  pathways    true                NMF,Full,Topics=50   nlp     10  0.809160  0.916140  64.0  2154.0  0.222087  0.003565  0.074917  2.596342  0.056091  0.138889  0.172414  0.187166  0.034635  0.075397  0.017415\n",
       "11         Topic Models   intra  pathways    true               NMF,Full,Topics=100   nlp     11  0.878424  0.937362  64.0  2154.0  0.203879  0.009631  0.066794  2.314833  0.056091  0.108108  0.192308  0.161716  0.006466  0.058050  0.000569\n",
       "12  Topic Models Phenes   intra  pathways    true                NMF,Full,Topics=50   nlp     12  0.474942  0.530409  64.0  2154.0  0.120894  0.298565  0.079622  2.759387  0.056091  0.077419  0.060160  0.144597  0.006647  0.006312  0.005290\n",
       "13  Topic Models Phenes   intra  pathways    true               NMF,Full,Topics=100   nlp     13  0.506443  0.607690  64.0  2154.0  0.173282  0.042017  0.073884  2.560534  0.056091  0.075472  0.055066  0.157604  0.020546  0.017496  0.012055\n",
       "14         Topic Models   intra  pathways    true                LDA,Full,Topics=50   nlp     14  0.760699  0.818264  64.0  2154.0  0.111566  0.391993  0.050570  1.752571  0.056091  0.111111  0.119048  0.142379  0.015873  0.027233  0.013558\n",
       "15         Topic Models   intra  pathways    true               LDA,Full,Topics=100   nlp     15  0.828877  0.879316  64.0  2154.0  0.179187  0.032216  0.074762  2.590965  0.056091  0.114286  0.227273  0.161588  0.024390  0.041509  0.006720\n",
       "16  Topic Models Phenes   intra  pathways    true                LDA,Full,Topics=50   nlp     16  0.310155  0.447954  64.0  2154.0  0.193535  0.016284  0.075377  2.612268  0.056091  0.083707  0.057398  0.163785  0.015269  0.009608  0.029148\n",
       "17  Topic Models Phenes   intra  pathways    true               LDA,Full,Topics=100   nlp     17  0.530114  0.578009  64.0  2154.0  0.128047  0.238255  0.071259  2.469586  0.056091  0.078067  0.053571  0.145943  0.008996  0.007205  0.006483\n",
       "18              N-Grams   intra  pathways    true          Full,Words,1-grams,TFIDF   nlp     18  0.874096  0.930578  64.0  2154.0  0.144571  0.134406  0.070610  2.447061  0.056091  0.103093  0.187500  0.154131  0.008593  0.002643  0.012483\n",
       "19              N-Grams   intra  pathways    true  Full,Words,1-grams,2-grams,TFIDF   nlp     19  0.890279  0.946576  64.0  2154.0  0.143323  0.140697  0.074372  2.577439  0.056091  0.108108  0.192308  0.152888  0.020579  0.049487  0.002879"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_dfs = []\n",
    "for s,c,q in itertools.product(species,curated,question):\n",
    "    if (s != \"both\") and (q != \"pathways\"):\n",
    "        continue\n",
    "    TABLE = tables[c][q][s]\n",
    "    results = pd.DataFrame(TABLE).transpose()\n",
    "    columns = flatten([\"Species\", \"Objective\",\"Curated\",\"Hyperparameters\",\"Group\",\"Order\",results.columns])\n",
    "    results[\"Hyperparameters\"] = \"\"\n",
    "    results[\"Group\"] = \"nlp\"\n",
    "    results[\"Order\"] = np.arange(results.shape[0])\n",
    "    results[\"Species\"] = s.lower()\n",
    "    results[\"Objective\"] = q.lower()\n",
    "    results[\"Curated\"] = str(c).lower()\n",
    "    results = results[columns]\n",
    "    results.reset_index(inplace=True)\n",
    "    results = results.rename({\"index\":\"Method\"}, axis=\"columns\")\n",
    "    hyperparam_sep = \":\"\n",
    "    results[\"Hyperparameters\"] = results[\"Method\"].map(lambda x: x.split(hyperparam_sep)[1] if hyperparam_sep in x else \"None\")\n",
    "    results[\"Method\"] = results[\"Method\"].map(lambda x: x.split(hyperparam_sep)[0])\n",
    "    result_dfs.append(results)\n",
    "\n",
    "results = pd.concat(result_dfs)\n",
    "results.reset_index(inplace=True, drop=True)\n",
    "results.to_csv(os.path.join(OUTPUT_DIR,\"part_5_full_table.csv\"), index=False)\n",
    "results.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Method</th>\n",
       "      <th>Hyperparameters</th>\n",
       "      <th>Order</th>\n",
       "      <th>both_curated_subsets</th>\n",
       "      <th>both_curated_known</th>\n",
       "      <th>both_curated_predicted</th>\n",
       "      <th>intra_curated_pathways</th>\n",
       "      <th>inter_curated_pathways</th>\n",
       "      <th>both_curated_pathways</th>\n",
       "      <th>both_curated_orthologs</th>\n",
       "      <th>both_all_subsets</th>\n",
       "      <th>both_all_known</th>\n",
       "      <th>both_all_predicted</th>\n",
       "      <th>intra_all_pathways</th>\n",
       "      <th>inter_all_pathways</th>\n",
       "      <th>both_all_pathways</th>\n",
       "      <th>both_all_orthologs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Doc2Vec</td>\n",
       "      <td>Wikipedia,Size=300</td>\n",
       "      <td>0</td>\n",
       "      <td>0.382001</td>\n",
       "      <td>0.035651</td>\n",
       "      <td>0.051780</td>\n",
       "      <td>0.092105</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.088608</td>\n",
       "      <td>None</td>\n",
       "      <td>0.378917</td>\n",
       "      <td>0.027904</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.091667</td>\n",
       "      <td>0.068734</td>\n",
       "      <td>0.078014</td>\n",
       "      <td>0.010471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Word2Vec</td>\n",
       "      <td>Wikipedia,Size=300,Mean</td>\n",
       "      <td>1</td>\n",
       "      <td>0.311823</td>\n",
       "      <td>0.067606</td>\n",
       "      <td>0.051948</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.172414</td>\n",
       "      <td>0.121212</td>\n",
       "      <td>None</td>\n",
       "      <td>0.311858</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.038806</td>\n",
       "      <td>0.167488</td>\n",
       "      <td>0.087649</td>\n",
       "      <td>0.136000</td>\n",
       "      <td>0.002183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Word2Vec</td>\n",
       "      <td>Wikipedia,Size=300,Max</td>\n",
       "      <td>2</td>\n",
       "      <td>0.235386</td>\n",
       "      <td>0.065574</td>\n",
       "      <td>0.042381</td>\n",
       "      <td>0.132450</td>\n",
       "      <td>0.185185</td>\n",
       "      <td>0.123457</td>\n",
       "      <td>None</td>\n",
       "      <td>0.234928</td>\n",
       "      <td>0.042810</td>\n",
       "      <td>0.035629</td>\n",
       "      <td>0.124542</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.106250</td>\n",
       "      <td>0.002353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Doc2Vec Phenes</td>\n",
       "      <td>Wikipedia,Size=300</td>\n",
       "      <td>3</td>\n",
       "      <td>0.544685</td>\n",
       "      <td>0.047538</td>\n",
       "      <td>0.047337</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.092593</td>\n",
       "      <td>0.076555</td>\n",
       "      <td>None</td>\n",
       "      <td>0.541374</td>\n",
       "      <td>0.038023</td>\n",
       "      <td>0.034835</td>\n",
       "      <td>0.092920</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.098485</td>\n",
       "      <td>0.002581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Word2Vec Phenes</td>\n",
       "      <td>Wikipedia,Size=300,Mean</td>\n",
       "      <td>4</td>\n",
       "      <td>0.532683</td>\n",
       "      <td>0.048565</td>\n",
       "      <td>0.040517</td>\n",
       "      <td>0.080863</td>\n",
       "      <td>0.129870</td>\n",
       "      <td>0.080460</td>\n",
       "      <td>None</td>\n",
       "      <td>0.529326</td>\n",
       "      <td>0.041525</td>\n",
       "      <td>0.029486</td>\n",
       "      <td>0.093233</td>\n",
       "      <td>0.115385</td>\n",
       "      <td>0.093085</td>\n",
       "      <td>0.002169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Word2Vec Phenes</td>\n",
       "      <td>Wikipedia,Size=300,Max</td>\n",
       "      <td>5</td>\n",
       "      <td>0.525858</td>\n",
       "      <td>0.052161</td>\n",
       "      <td>0.043379</td>\n",
       "      <td>0.087649</td>\n",
       "      <td>0.128205</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>None</td>\n",
       "      <td>0.522574</td>\n",
       "      <td>0.040876</td>\n",
       "      <td>0.030525</td>\n",
       "      <td>0.105516</td>\n",
       "      <td>0.112324</td>\n",
       "      <td>0.098765</td>\n",
       "      <td>0.002260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NOBLE Coder</td>\n",
       "      <td>Precise,TFIDF</td>\n",
       "      <td>6</td>\n",
       "      <td>0.393617</td>\n",
       "      <td>0.046823</td>\n",
       "      <td>0.049091</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.151515</td>\n",
       "      <td>0.104167</td>\n",
       "      <td>None</td>\n",
       "      <td>0.390756</td>\n",
       "      <td>0.034584</td>\n",
       "      <td>0.036849</td>\n",
       "      <td>0.113537</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.096280</td>\n",
       "      <td>0.004963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NOBLE Coder</td>\n",
       "      <td>Partial,TFIDF</td>\n",
       "      <td>7</td>\n",
       "      <td>0.402108</td>\n",
       "      <td>0.053518</td>\n",
       "      <td>0.046961</td>\n",
       "      <td>0.121212</td>\n",
       "      <td>0.140351</td>\n",
       "      <td>0.115108</td>\n",
       "      <td>None</td>\n",
       "      <td>0.400161</td>\n",
       "      <td>0.036890</td>\n",
       "      <td>0.036212</td>\n",
       "      <td>0.139706</td>\n",
       "      <td>0.093220</td>\n",
       "      <td>0.123752</td>\n",
       "      <td>0.035714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NOBLE Coder Phenes</td>\n",
       "      <td>Precise,TFIDF</td>\n",
       "      <td>8</td>\n",
       "      <td>0.416776</td>\n",
       "      <td>0.037929</td>\n",
       "      <td>0.038201</td>\n",
       "      <td>0.074561</td>\n",
       "      <td>0.085106</td>\n",
       "      <td>0.070393</td>\n",
       "      <td>None</td>\n",
       "      <td>0.414602</td>\n",
       "      <td>0.031002</td>\n",
       "      <td>0.030416</td>\n",
       "      <td>0.079343</td>\n",
       "      <td>0.078712</td>\n",
       "      <td>0.073227</td>\n",
       "      <td>0.003854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NOBLE Coder Phenes</td>\n",
       "      <td>Partial,TFIDF</td>\n",
       "      <td>9</td>\n",
       "      <td>0.529176</td>\n",
       "      <td>0.044527</td>\n",
       "      <td>0.053040</td>\n",
       "      <td>0.097015</td>\n",
       "      <td>0.097561</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>None</td>\n",
       "      <td>0.525431</td>\n",
       "      <td>0.036298</td>\n",
       "      <td>0.034218</td>\n",
       "      <td>0.091304</td>\n",
       "      <td>0.107692</td>\n",
       "      <td>0.090634</td>\n",
       "      <td>0.010204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Topic Models</td>\n",
       "      <td>NMF,Full,Topics=50</td>\n",
       "      <td>10</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.057971</td>\n",
       "      <td>0.051429</td>\n",
       "      <td>0.138889</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.129032</td>\n",
       "      <td>None</td>\n",
       "      <td>0.439727</td>\n",
       "      <td>0.035209</td>\n",
       "      <td>0.033654</td>\n",
       "      <td>0.167331</td>\n",
       "      <td>0.107527</td>\n",
       "      <td>0.145946</td>\n",
       "      <td>0.002092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Topic Models</td>\n",
       "      <td>NMF,Full,Topics=100</td>\n",
       "      <td>11</td>\n",
       "      <td>0.442098</td>\n",
       "      <td>0.056769</td>\n",
       "      <td>0.040491</td>\n",
       "      <td>0.108108</td>\n",
       "      <td>0.092593</td>\n",
       "      <td>0.100629</td>\n",
       "      <td>None</td>\n",
       "      <td>0.440503</td>\n",
       "      <td>0.038554</td>\n",
       "      <td>0.027160</td>\n",
       "      <td>0.119601</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.111421</td>\n",
       "      <td>0.002092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Topic Models Phenes</td>\n",
       "      <td>NMF,Full,Topics=50</td>\n",
       "      <td>12</td>\n",
       "      <td>0.530144</td>\n",
       "      <td>0.042553</td>\n",
       "      <td>0.041582</td>\n",
       "      <td>0.077419</td>\n",
       "      <td>0.087719</td>\n",
       "      <td>0.076046</td>\n",
       "      <td>None</td>\n",
       "      <td>0.526472</td>\n",
       "      <td>0.033666</td>\n",
       "      <td>0.028911</td>\n",
       "      <td>0.084095</td>\n",
       "      <td>0.116959</td>\n",
       "      <td>0.083947</td>\n",
       "      <td>0.002092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Topic Models Phenes</td>\n",
       "      <td>NMF,Full,Topics=100</td>\n",
       "      <td>13</td>\n",
       "      <td>0.520136</td>\n",
       "      <td>0.041013</td>\n",
       "      <td>0.048113</td>\n",
       "      <td>0.075472</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.073567</td>\n",
       "      <td>None</td>\n",
       "      <td>0.516876</td>\n",
       "      <td>0.033784</td>\n",
       "      <td>0.032325</td>\n",
       "      <td>0.088561</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.086687</td>\n",
       "      <td>0.002646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Topic Models</td>\n",
       "      <td>LDA,Full,Topics=50</td>\n",
       "      <td>14</td>\n",
       "      <td>0.294160</td>\n",
       "      <td>0.038986</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.228571</td>\n",
       "      <td>0.103704</td>\n",
       "      <td>None</td>\n",
       "      <td>0.292389</td>\n",
       "      <td>0.032465</td>\n",
       "      <td>0.031048</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.107692</td>\n",
       "      <td>0.111732</td>\n",
       "      <td>0.007220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Topic Models</td>\n",
       "      <td>LDA,Full,Topics=100</td>\n",
       "      <td>15</td>\n",
       "      <td>0.352979</td>\n",
       "      <td>0.047313</td>\n",
       "      <td>0.052326</td>\n",
       "      <td>0.114286</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>None</td>\n",
       "      <td>0.351264</td>\n",
       "      <td>0.039829</td>\n",
       "      <td>0.035230</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.072595</td>\n",
       "      <td>0.078201</td>\n",
       "      <td>0.009434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Topic Models Phenes</td>\n",
       "      <td>LDA,Full,Topics=50</td>\n",
       "      <td>16</td>\n",
       "      <td>0.470986</td>\n",
       "      <td>0.044037</td>\n",
       "      <td>0.040691</td>\n",
       "      <td>0.083707</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.085906</td>\n",
       "      <td>None</td>\n",
       "      <td>0.467823</td>\n",
       "      <td>0.036493</td>\n",
       "      <td>0.031266</td>\n",
       "      <td>0.095023</td>\n",
       "      <td>0.103896</td>\n",
       "      <td>0.091097</td>\n",
       "      <td>0.002275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Topic Models Phenes</td>\n",
       "      <td>LDA,Full,Topics=100</td>\n",
       "      <td>17</td>\n",
       "      <td>0.484182</td>\n",
       "      <td>0.041590</td>\n",
       "      <td>0.042356</td>\n",
       "      <td>0.078067</td>\n",
       "      <td>0.093458</td>\n",
       "      <td>0.074450</td>\n",
       "      <td>None</td>\n",
       "      <td>0.480655</td>\n",
       "      <td>0.036406</td>\n",
       "      <td>0.029213</td>\n",
       "      <td>0.080560</td>\n",
       "      <td>0.073260</td>\n",
       "      <td>0.073814</td>\n",
       "      <td>0.021739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>N-Grams</td>\n",
       "      <td>Full,Words,1-grams,TFIDF</td>\n",
       "      <td>18</td>\n",
       "      <td>0.484970</td>\n",
       "      <td>0.047761</td>\n",
       "      <td>0.055710</td>\n",
       "      <td>0.103093</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.097087</td>\n",
       "      <td>None</td>\n",
       "      <td>0.483665</td>\n",
       "      <td>0.038159</td>\n",
       "      <td>0.040921</td>\n",
       "      <td>0.140187</td>\n",
       "      <td>0.126582</td>\n",
       "      <td>0.119601</td>\n",
       "      <td>0.002092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>N-Grams</td>\n",
       "      <td>Full,Words,1-grams,2-grams,TFIDF</td>\n",
       "      <td>19</td>\n",
       "      <td>0.499619</td>\n",
       "      <td>0.056738</td>\n",
       "      <td>0.054054</td>\n",
       "      <td>0.108108</td>\n",
       "      <td>0.146341</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>None</td>\n",
       "      <td>0.497485</td>\n",
       "      <td>0.038284</td>\n",
       "      <td>0.039735</td>\n",
       "      <td>0.140845</td>\n",
       "      <td>0.141176</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.002092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>N-Grams Phenes</td>\n",
       "      <td>Full,Words,1-grams,TFIDF</td>\n",
       "      <td>20</td>\n",
       "      <td>0.536101</td>\n",
       "      <td>0.040684</td>\n",
       "      <td>0.049204</td>\n",
       "      <td>0.080214</td>\n",
       "      <td>0.093750</td>\n",
       "      <td>0.079602</td>\n",
       "      <td>None</td>\n",
       "      <td>0.533214</td>\n",
       "      <td>0.035218</td>\n",
       "      <td>0.035848</td>\n",
       "      <td>0.090551</td>\n",
       "      <td>0.123457</td>\n",
       "      <td>0.093458</td>\n",
       "      <td>0.002092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>N-Grams Phenes</td>\n",
       "      <td>Full,Words,1-grams,2-grams,TFIDF</td>\n",
       "      <td>21</td>\n",
       "      <td>0.519632</td>\n",
       "      <td>0.041310</td>\n",
       "      <td>0.052187</td>\n",
       "      <td>0.076246</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.076087</td>\n",
       "      <td>None</td>\n",
       "      <td>0.517442</td>\n",
       "      <td>0.034390</td>\n",
       "      <td>0.035419</td>\n",
       "      <td>0.093694</td>\n",
       "      <td>0.112676</td>\n",
       "      <td>0.093750</td>\n",
       "      <td>0.002092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>N-Grams</td>\n",
       "      <td>Full,Nouns,Adjectives,1-grams</td>\n",
       "      <td>22</td>\n",
       "      <td>0.419576</td>\n",
       "      <td>0.063492</td>\n",
       "      <td>0.046809</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.109890</td>\n",
       "      <td>None</td>\n",
       "      <td>0.417971</td>\n",
       "      <td>0.038386</td>\n",
       "      <td>0.038946</td>\n",
       "      <td>0.130031</td>\n",
       "      <td>0.084211</td>\n",
       "      <td>0.113208</td>\n",
       "      <td>0.002092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>N-Grams</td>\n",
       "      <td>Linares_Pontes,Words,1-grams</td>\n",
       "      <td>23</td>\n",
       "      <td>0.405609</td>\n",
       "      <td>0.051429</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>0.108696</td>\n",
       "      <td>0.156250</td>\n",
       "      <td>0.102190</td>\n",
       "      <td>None</td>\n",
       "      <td>0.403390</td>\n",
       "      <td>0.043228</td>\n",
       "      <td>0.044653</td>\n",
       "      <td>0.162162</td>\n",
       "      <td>0.116129</td>\n",
       "      <td>0.135484</td>\n",
       "      <td>0.002092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>N-Grams</td>\n",
       "      <td>Full,Precise_Annotations,Words,1-grams</td>\n",
       "      <td>24</td>\n",
       "      <td>0.335518</td>\n",
       "      <td>0.044926</td>\n",
       "      <td>0.054217</td>\n",
       "      <td>0.092308</td>\n",
       "      <td>0.206897</td>\n",
       "      <td>0.089552</td>\n",
       "      <td>None</td>\n",
       "      <td>0.333910</td>\n",
       "      <td>0.028822</td>\n",
       "      <td>0.030769</td>\n",
       "      <td>0.098876</td>\n",
       "      <td>0.067944</td>\n",
       "      <td>0.092742</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>N-Grams</td>\n",
       "      <td>Full,Partial_Annotations,Words,1-grams</td>\n",
       "      <td>25</td>\n",
       "      <td>0.299949</td>\n",
       "      <td>0.060606</td>\n",
       "      <td>0.046512</td>\n",
       "      <td>0.089286</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.104089</td>\n",
       "      <td>None</td>\n",
       "      <td>0.298130</td>\n",
       "      <td>0.037764</td>\n",
       "      <td>0.037196</td>\n",
       "      <td>0.080586</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.079906</td>\n",
       "      <td>0.037037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>N-Grams</td>\n",
       "      <td>Full,Plant Overrepresented Tokens,1-grams</td>\n",
       "      <td>26</td>\n",
       "      <td>0.485207</td>\n",
       "      <td>0.048454</td>\n",
       "      <td>0.051680</td>\n",
       "      <td>0.094340</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.093750</td>\n",
       "      <td>None</td>\n",
       "      <td>0.483922</td>\n",
       "      <td>0.039735</td>\n",
       "      <td>0.042521</td>\n",
       "      <td>0.131004</td>\n",
       "      <td>0.139535</td>\n",
       "      <td>0.115385</td>\n",
       "      <td>0.002092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>N-Grams</td>\n",
       "      <td>Full,Bio Ontology Tokens,1-grams</td>\n",
       "      <td>27</td>\n",
       "      <td>0.484653</td>\n",
       "      <td>0.050633</td>\n",
       "      <td>0.052381</td>\n",
       "      <td>0.106383</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>None</td>\n",
       "      <td>0.483949</td>\n",
       "      <td>0.039651</td>\n",
       "      <td>0.042403</td>\n",
       "      <td>0.130769</td>\n",
       "      <td>0.140351</td>\n",
       "      <td>0.120482</td>\n",
       "      <td>0.002092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>N-Grams Phenes</td>\n",
       "      <td>Full,Nouns,Adjectives,1-grams</td>\n",
       "      <td>28</td>\n",
       "      <td>0.481724</td>\n",
       "      <td>0.046225</td>\n",
       "      <td>0.047598</td>\n",
       "      <td>0.085409</td>\n",
       "      <td>0.087912</td>\n",
       "      <td>0.084416</td>\n",
       "      <td>None</td>\n",
       "      <td>0.479031</td>\n",
       "      <td>0.036607</td>\n",
       "      <td>0.032587</td>\n",
       "      <td>0.083682</td>\n",
       "      <td>0.087719</td>\n",
       "      <td>0.084112</td>\n",
       "      <td>0.002092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>N-Grams Phenes</td>\n",
       "      <td>Linares_Pontes,Words,1-grams</td>\n",
       "      <td>29</td>\n",
       "      <td>0.514610</td>\n",
       "      <td>0.044595</td>\n",
       "      <td>0.052260</td>\n",
       "      <td>0.081633</td>\n",
       "      <td>0.120482</td>\n",
       "      <td>0.080189</td>\n",
       "      <td>None</td>\n",
       "      <td>0.511931</td>\n",
       "      <td>0.039062</td>\n",
       "      <td>0.038046</td>\n",
       "      <td>0.092000</td>\n",
       "      <td>0.132353</td>\n",
       "      <td>0.096220</td>\n",
       "      <td>0.002092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>N-Grams Phenes</td>\n",
       "      <td>Full,Precise_Annotations,Words,1-grams</td>\n",
       "      <td>30</td>\n",
       "      <td>0.510021</td>\n",
       "      <td>0.043802</td>\n",
       "      <td>0.040312</td>\n",
       "      <td>0.075472</td>\n",
       "      <td>0.140845</td>\n",
       "      <td>0.076628</td>\n",
       "      <td>None</td>\n",
       "      <td>0.507829</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.033070</td>\n",
       "      <td>0.091483</td>\n",
       "      <td>0.115942</td>\n",
       "      <td>0.092141</td>\n",
       "      <td>0.006969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>N-Grams Phenes</td>\n",
       "      <td>Full,Partial_Annotations,Words,1-grams</td>\n",
       "      <td>31</td>\n",
       "      <td>0.525253</td>\n",
       "      <td>0.049120</td>\n",
       "      <td>0.054222</td>\n",
       "      <td>0.079310</td>\n",
       "      <td>0.121212</td>\n",
       "      <td>0.080997</td>\n",
       "      <td>None</td>\n",
       "      <td>0.521739</td>\n",
       "      <td>0.039357</td>\n",
       "      <td>0.037441</td>\n",
       "      <td>0.077121</td>\n",
       "      <td>0.088889</td>\n",
       "      <td>0.078431</td>\n",
       "      <td>0.005698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>N-Grams Phenes</td>\n",
       "      <td>Full,Plant Overrepresented Tokens,1-grams</td>\n",
       "      <td>32</td>\n",
       "      <td>0.538422</td>\n",
       "      <td>0.040704</td>\n",
       "      <td>0.044352</td>\n",
       "      <td>0.077922</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.076190</td>\n",
       "      <td>None</td>\n",
       "      <td>0.535154</td>\n",
       "      <td>0.034267</td>\n",
       "      <td>0.033728</td>\n",
       "      <td>0.089552</td>\n",
       "      <td>0.116279</td>\n",
       "      <td>0.092081</td>\n",
       "      <td>0.002092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>N-Grams Phenes</td>\n",
       "      <td>Full,Bio Ontology Tokens,1-grams</td>\n",
       "      <td>33</td>\n",
       "      <td>0.547112</td>\n",
       "      <td>0.042981</td>\n",
       "      <td>0.059272</td>\n",
       "      <td>0.073620</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.074286</td>\n",
       "      <td>None</td>\n",
       "      <td>0.543807</td>\n",
       "      <td>0.036702</td>\n",
       "      <td>0.039336</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.089600</td>\n",
       "      <td>0.002092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>GO</td>\n",
       "      <td>Union</td>\n",
       "      <td>34</td>\n",
       "      <td>0.189641</td>\n",
       "      <td>0.107226</td>\n",
       "      <td>0.113475</td>\n",
       "      <td>0.218487</td>\n",
       "      <td>0.085106</td>\n",
       "      <td>0.206349</td>\n",
       "      <td>None</td>\n",
       "      <td>0.189170</td>\n",
       "      <td>0.058458</td>\n",
       "      <td>0.047414</td>\n",
       "      <td>0.167331</td>\n",
       "      <td>0.066775</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.010204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>PO</td>\n",
       "      <td>Union</td>\n",
       "      <td>35</td>\n",
       "      <td>0.194707</td>\n",
       "      <td>0.036359</td>\n",
       "      <td>0.058156</td>\n",
       "      <td>0.067172</td>\n",
       "      <td>0.086331</td>\n",
       "      <td>0.066738</td>\n",
       "      <td>None</td>\n",
       "      <td>0.193677</td>\n",
       "      <td>0.032154</td>\n",
       "      <td>0.046485</td>\n",
       "      <td>0.061966</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.060453</td>\n",
       "      <td>0.002092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>GO</td>\n",
       "      <td>Maximum</td>\n",
       "      <td>36</td>\n",
       "      <td>0.205491</td>\n",
       "      <td>0.072129</td>\n",
       "      <td>0.058351</td>\n",
       "      <td>0.130699</td>\n",
       "      <td>0.085106</td>\n",
       "      <td>0.129129</td>\n",
       "      <td>None</td>\n",
       "      <td>0.204172</td>\n",
       "      <td>0.052410</td>\n",
       "      <td>0.042764</td>\n",
       "      <td>0.136488</td>\n",
       "      <td>0.070588</td>\n",
       "      <td>0.131757</td>\n",
       "      <td>0.012739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>PO</td>\n",
       "      <td>Maximum</td>\n",
       "      <td>37</td>\n",
       "      <td>0.188701</td>\n",
       "      <td>0.035104</td>\n",
       "      <td>0.027278</td>\n",
       "      <td>0.056288</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.058333</td>\n",
       "      <td>None</td>\n",
       "      <td>0.188189</td>\n",
       "      <td>0.027424</td>\n",
       "      <td>0.018401</td>\n",
       "      <td>0.054470</td>\n",
       "      <td>0.081818</td>\n",
       "      <td>0.056032</td>\n",
       "      <td>0.002092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Mean</td>\n",
       "      <td>None</td>\n",
       "      <td>38</td>\n",
       "      <td>0.507056</td>\n",
       "      <td>0.048346</td>\n",
       "      <td>0.048729</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.097561</td>\n",
       "      <td>None</td>\n",
       "      <td>0.504909</td>\n",
       "      <td>0.040185</td>\n",
       "      <td>0.040490</td>\n",
       "      <td>0.137931</td>\n",
       "      <td>0.113208</td>\n",
       "      <td>0.119171</td>\n",
       "      <td>0.003883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>eqs_distance</td>\n",
       "      <td>None</td>\n",
       "      <td>39</td>\n",
       "      <td>0.475188</td>\n",
       "      <td>0.055659</td>\n",
       "      <td>0.051796</td>\n",
       "      <td>0.078947</td>\n",
       "      <td>0.085106</td>\n",
       "      <td>0.075949</td>\n",
       "      <td>None</td>\n",
       "      <td>0.456576</td>\n",
       "      <td>0.026321</td>\n",
       "      <td>0.017784</td>\n",
       "      <td>0.053366</td>\n",
       "      <td>0.066775</td>\n",
       "      <td>0.056032</td>\n",
       "      <td>0.002558</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Method                            Hyperparameters  Order  both_curated_subsets  both_curated_known  both_curated_predicted  intra_curated_pathways  inter_curated_pathways  both_curated_pathways both_curated_orthologs  both_all_subsets  both_all_known  both_all_predicted  intra_all_pathways  inter_all_pathways  both_all_pathways  both_all_orthologs\n",
       "0               Doc2Vec                         Wikipedia,Size=300      0              0.382001            0.035651                0.051780                0.092105                0.181818               0.088608                   None          0.378917        0.027904            0.038462            0.091667            0.068734           0.078014            0.010471\n",
       "1              Word2Vec                    Wikipedia,Size=300,Mean      1              0.311823            0.067606                0.051948                0.133333                0.172414               0.121212                   None          0.311858        0.050000            0.038806            0.167488            0.087649           0.136000            0.002183\n",
       "2              Word2Vec                     Wikipedia,Size=300,Max      2              0.235386            0.065574                0.042381                0.132450                0.185185               0.123457                   None          0.234928        0.042810            0.035629            0.124542            0.105263           0.106250            0.002353\n",
       "3        Doc2Vec Phenes                         Wikipedia,Size=300      3              0.544685            0.047538                0.047337                0.076923                0.092593               0.076555                   None          0.541374        0.038023            0.034835            0.092920            0.133333           0.098485            0.002581\n",
       "4       Word2Vec Phenes                    Wikipedia,Size=300,Mean      4              0.532683            0.048565                0.040517                0.080863                0.129870               0.080460                   None          0.529326        0.041525            0.029486            0.093233            0.115385           0.093085            0.002169\n",
       "5       Word2Vec Phenes                     Wikipedia,Size=300,Max      5              0.525858            0.052161                0.043379                0.087649                0.128205               0.086957                   None          0.522574        0.040876            0.030525            0.105516            0.112324           0.098765            0.002260\n",
       "6           NOBLE Coder                              Precise,TFIDF      6              0.393617            0.046823                0.049091                0.111111                0.151515               0.104167                   None          0.390756        0.034584            0.036849            0.113537            0.105263           0.096280            0.004963\n",
       "7           NOBLE Coder                              Partial,TFIDF      7              0.402108            0.053518                0.046961                0.121212                0.140351               0.115108                   None          0.400161        0.036890            0.036212            0.139706            0.093220           0.123752            0.035714\n",
       "8    NOBLE Coder Phenes                              Precise,TFIDF      8              0.416776            0.037929                0.038201                0.074561                0.085106               0.070393                   None          0.414602        0.031002            0.030416            0.079343            0.078712           0.073227            0.003854\n",
       "9    NOBLE Coder Phenes                              Partial,TFIDF      9              0.529176            0.044527                0.053040                0.097015                0.097561               0.095238                   None          0.525431        0.036298            0.034218            0.091304            0.107692           0.090634            0.010204\n",
       "10         Topic Models                         NMF,Full,Topics=50     10              0.444444            0.057971                0.051429                0.138889                0.100000               0.129032                   None          0.439727        0.035209            0.033654            0.167331            0.107527           0.145946            0.002092\n",
       "11         Topic Models                        NMF,Full,Topics=100     11              0.442098            0.056769                0.040491                0.108108                0.092593               0.100629                   None          0.440503        0.038554            0.027160            0.119601            0.090909           0.111421            0.002092\n",
       "12  Topic Models Phenes                         NMF,Full,Topics=50     12              0.530144            0.042553                0.041582                0.077419                0.087719               0.076046                   None          0.526472        0.033666            0.028911            0.084095            0.116959           0.083947            0.002092\n",
       "13  Topic Models Phenes                        NMF,Full,Topics=100     13              0.520136            0.041013                0.048113                0.075472                0.090909               0.073567                   None          0.516876        0.033784            0.032325            0.088561            0.111111           0.086687            0.002646\n",
       "14         Topic Models                         LDA,Full,Topics=50     14              0.294160            0.038986                0.045455                0.111111                0.228571               0.103704                   None          0.292389        0.032465            0.031048            0.133333            0.107692           0.111732            0.007220\n",
       "15         Topic Models                        LDA,Full,Topics=100     15              0.352979            0.047313                0.052326                0.114286                0.142857               0.105263                   None          0.351264        0.039829            0.035230            0.095238            0.072595           0.078201            0.009434\n",
       "16  Topic Models Phenes                         LDA,Full,Topics=50     16              0.470986            0.044037                0.040691                0.083707                0.153846               0.085906                   None          0.467823        0.036493            0.031266            0.095023            0.103896           0.091097            0.002275\n",
       "17  Topic Models Phenes                        LDA,Full,Topics=100     17              0.484182            0.041590                0.042356                0.078067                0.093458               0.074450                   None          0.480655        0.036406            0.029213            0.080560            0.073260           0.073814            0.021739\n",
       "18              N-Grams                   Full,Words,1-grams,TFIDF     18              0.484970            0.047761                0.055710                0.103093                0.157895               0.097087                   None          0.483665        0.038159            0.040921            0.140187            0.126582           0.119601            0.002092\n",
       "19              N-Grams           Full,Words,1-grams,2-grams,TFIDF     19              0.499619            0.056738                0.054054                0.108108                0.146341               0.100000                   None          0.497485        0.038284            0.039735            0.140845            0.141176           0.117647            0.002092\n",
       "20       N-Grams Phenes                   Full,Words,1-grams,TFIDF     20              0.536101            0.040684                0.049204                0.080214                0.093750               0.079602                   None          0.533214        0.035218            0.035848            0.090551            0.123457           0.093458            0.002092\n",
       "21       N-Grams Phenes           Full,Words,1-grams,2-grams,TFIDF     21              0.519632            0.041310                0.052187                0.076246                0.095238               0.076087                   None          0.517442        0.034390            0.035419            0.093694            0.112676           0.093750            0.002092\n",
       "22              N-Grams              Full,Nouns,Adjectives,1-grams     22              0.419576            0.063492                0.046809                0.117647                0.200000               0.109890                   None          0.417971        0.038386            0.038946            0.130031            0.084211           0.113208            0.002092\n",
       "23              N-Grams               Linares_Pontes,Words,1-grams     23              0.405609            0.051429                0.060000                0.108696                0.156250               0.102190                   None          0.403390        0.043228            0.044653            0.162162            0.116129           0.135484            0.002092\n",
       "24              N-Grams     Full,Precise_Annotations,Words,1-grams     24              0.335518            0.044926                0.054217                0.092308                0.206897               0.089552                   None          0.333910        0.028822            0.030769            0.098876            0.067944           0.092742            0.500000\n",
       "25              N-Grams     Full,Partial_Annotations,Words,1-grams     25              0.299949            0.060606                0.046512                0.089286                0.272727               0.104089                   None          0.298130        0.037764            0.037196            0.080586            0.095238           0.079906            0.037037\n",
       "26              N-Grams  Full,Plant Overrepresented Tokens,1-grams     26              0.485207            0.048454                0.051680                0.094340                0.181818               0.093750                   None          0.483922        0.039735            0.042521            0.131004            0.139535           0.115385            0.002092\n",
       "27              N-Grams           Full,Bio Ontology Tokens,1-grams     27              0.484653            0.050633                0.052381                0.106383                0.200000               0.100000                   None          0.483949        0.039651            0.042403            0.130769            0.140351           0.120482            0.002092\n",
       "28       N-Grams Phenes              Full,Nouns,Adjectives,1-grams     28              0.481724            0.046225                0.047598                0.085409                0.087912               0.084416                   None          0.479031        0.036607            0.032587            0.083682            0.087719           0.084112            0.002092\n",
       "29       N-Grams Phenes               Linares_Pontes,Words,1-grams     29              0.514610            0.044595                0.052260                0.081633                0.120482               0.080189                   None          0.511931        0.039062            0.038046            0.092000            0.132353           0.096220            0.002092\n",
       "30       N-Grams Phenes     Full,Precise_Annotations,Words,1-grams     30              0.510021            0.043802                0.040312                0.075472                0.140845               0.076628                   None          0.507829        0.035714            0.033070            0.091483            0.115942           0.092141            0.006969\n",
       "31       N-Grams Phenes     Full,Partial_Annotations,Words,1-grams     31              0.525253            0.049120                0.054222                0.079310                0.121212               0.080997                   None          0.521739        0.039357            0.037441            0.077121            0.088889           0.078431            0.005698\n",
       "32       N-Grams Phenes  Full,Plant Overrepresented Tokens,1-grams     32              0.538422            0.040704                0.044352                0.077922                0.100000               0.076190                   None          0.535154        0.034267            0.033728            0.089552            0.116279           0.092081            0.002092\n",
       "33       N-Grams Phenes           Full,Bio Ontology Tokens,1-grams     33              0.547112            0.042981                0.059272                0.073620                0.090909               0.074286                   None          0.543807        0.036702            0.039336            0.090909            0.117647           0.089600            0.002092\n",
       "34                   GO                                      Union     34              0.189641            0.107226                0.113475                0.218487                0.085106               0.206349                   None          0.189170        0.058458            0.047414            0.167331            0.066775           0.142857            0.010204\n",
       "35                   PO                                      Union     35              0.194707            0.036359                0.058156                0.067172                0.086331               0.066738                   None          0.193677        0.032154            0.046485            0.061966            0.076923           0.060453            0.002092\n",
       "36                   GO                                    Maximum     36              0.205491            0.072129                0.058351                0.130699                0.085106               0.129129                   None          0.204172        0.052410            0.042764            0.136488            0.070588           0.131757            0.012739\n",
       "37                   PO                                    Maximum     37              0.188701            0.035104                0.027278                0.056288                0.095238               0.058333                   None          0.188189        0.027424            0.018401            0.054470            0.081818           0.056032            0.002092\n",
       "38                 Mean                                       None     38              0.507056            0.048346                0.048729                0.105263                0.133333               0.097561                   None          0.504909        0.040185            0.040490            0.137931            0.113208           0.119171            0.003883\n",
       "39         eqs_distance                                       None     39              0.475188            0.055659                0.051796                0.078947                0.085106               0.075949                   None          0.456576        0.026321            0.017784            0.053366            0.066775           0.056032            0.002558"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make another version of the table that is more useful for looking at one particular metric or value.\n",
    "metric_of_interest = \"f1_max\"\n",
    "reshaped_results = results[[\"Method\",\"Hyperparameters\",\"Order\"]].drop_duplicates()\n",
    "for c,q,s in itertools.product(curated,question,species):\n",
    "    if (s != \"both\") and (q != \"pathways\"):\n",
    "        continue\n",
    "    c_label = {True:\"curated\",False:\"all\"}[c]\n",
    "    col_name = \"{}_{}_{}\".format(s,c_label,q)\n",
    "    reshaped_results[col_name] = reshaped_results[\"Order\"].map(lambda x: results.loc[(results[\"Order\"]==x) & (results[\"Curated\"]==str(c).lower()) & (results[\"Objective\"]==q.lower()) & (results[\"Species\"]==s.lower()), metric_of_interest])\n",
    "    reshaped_results[col_name] = reshaped_results[col_name].map(lambda x: None if len(x)==0 else x.values[0])\n",
    "reshaped_results.to_csv(os.path.join(OUTPUT_DIR,\"part_5_partial_table_reshaped.csv\"), index=False)\n",
    "reshaped_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"part_7\"></a>\n",
    "# Part 7. Clustering Analysis\n",
    "The purpose of this section is to look at different ways that the embeddings obtained for the dataset of phenotype descriptions can be used to cluster or organize the genes to which those phenotypes are mapped into subgroups or representations. These approaches include generating topic models from the data, and doing agglomerative clustering to find clusters to which each gene belongs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Objects initially created in previous sections that are used by this section.\n",
    "groups = phe_subsets_groups\n",
    "id_to_group_ids, group_id_to_ids = groups.get_groupings_for_dataset(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"topic_modeling\"></a>\n",
    "### Approach 1: Topic modeling based on n-grams with a reduced vocabulary\n",
    "Topic modelling learns a set of word probability distributions from the dataset of text descriptions, which represent distinct topics which are present in the dataset. Each text description can then be represented as a discrete probability distribution over the learned topics based on the probability that a given piece of text belongs to each particular topics. This is a form of data reduction because a high dimensionsal bag-of-words can be represented as a vector of *k* probabilities where *k* is the number of topics. The main advantages of topic modelling over clustering is that topic modelling provides soft classifications that can be additionally interpreted, rather than hard classifications into a single cluster. Topic models are also explainable, because the word probability distributions for that topic can be used to determine which words are most representative of any given topic. One problem with topic modelling is that is uses the n-grams embeddings to semantic similarity between different words is not accounted for. To help alleviate this, this section uses implementations of some existing algorithms to compress the vocabulary as a preprocessing step based on word distance matrices generated using word embeddings.\n",
    "\n",
    "Topic models define topics present in a dataset of texts as word or n-gram probability distributions. These models represent each instance of text then as being composed of or generated as as mixture of these topics. The vector for each text that indicates which fraction of that text is generated by a each topic is of length *n* where *n* is the number of topics, and can be used as a reduced dimensionality of the text, with a much smaller vector length than the n-grams embedding itself. Therefore we can build a topic model of the data with 100 topics for example in order to then represent each description in the dataset as a a vector of length 100. This section constructs topic models from the n-gram representations of the dataset and selects different values for the number of topics in order to find a value that works well during the grid search over the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-96-3e136aed853d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# The processed text dictionaries are references unique text instances from the dataset, so the gene IDs from the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# datasets have to first be converted to the IDs that reference those other IDs for unique text instances.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mtexts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mgene_id_to_unique_ids_mappings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"whole_texts\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msubsets_mapped_ids\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mtexts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mgene_id_to_unique_ids_mappings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"whole_texts\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msubsets_mapped_ids\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-96-3e136aed853d>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# The processed text dictionaries are references unique text instances from the dataset, so the gene IDs from the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# datasets have to first be converted to the IDs that reference those other IDs for unique text instances.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mtexts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mgene_id_to_unique_ids_mappings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"whole_texts\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msubsets_mapped_ids\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mtexts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mgene_id_to_unique_ids_mappings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"whole_texts\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msubsets_mapped_ids\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 2"
     ]
    }
   ],
   "source": [
    "# JUST ADDED THIS IN, NEEDS TO BE RESET BECAUSE USED AS SOMETHING ELSE ABOVE?\n",
    "descriptions = dataset.get_description_dictionary()\n",
    "\n",
    "# What to use as the list of texts from which to actually generate the topic model, one of the processed ones above.\n",
    "# The processed text dictionaries are references unique text instances from the dataset, so the gene IDs from the \n",
    "# datasets have to first be converted to the IDs that reference those other IDs for unique text instances.\n",
    "texts = [gene_id_to_unique_ids_mappings[\"whole_texts\"][i] for i in subsets_mapped_ids]\n",
    "texts = [gene_id_to_unique_ids_mappings[\"whole_texts\"][i] for i in subsets_mapped_ids]\n",
    "\n",
    "# TODO make a version of this section that produces results for each combination of these parameters.\n",
    "algorithms = [\"lda\",\"nmf\"]\n",
    "preprocessing = [\"simple\",\"full\"]\n",
    "datatype = [\"phenotypes\",\"phenes\"]\n",
    "\n",
    "# Basic parameters for this problem that are currently used.\n",
    "number_of_topics = 42\n",
    "seed = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating and fitting the topic model, either NFM or LDA or something like that.\n",
    "vectorizer = TfidfVectorizer(max_features=10000, stop_words=\"english\", max_df=0.95, min_df=2, lowercase=True)\n",
    "features = vectorizer.fit_transform(texts)\n",
    "cls = NMF(n_components=number_of_topics, random_state=seed)\n",
    "cls.fit(features)\n",
    "\n",
    "# Function for retrieving the topic vectors for a list of text descriptions.\n",
    "def get_topic_embeddings(texts, model, vectorizer):\n",
    "    ngrams_vectors = vectorizer.transform(texts).toarray()\n",
    "    topic_vectors = model.transform(ngrams_vectors)\n",
    "    return(topic_vectors)\n",
    "\n",
    "# Create the dataframe containing the average score assigned to each topic for the genes from each subset.\n",
    "group_to_topic_vector = {}\n",
    "for group_id,ids in group_id_to_ids.items():\n",
    "    texts = [descriptions[i] for i in ids]\n",
    "    topic_vectors = get_topic_embeddings(texts, cls, vectorizer)\n",
    "    mean_topic_vector = np.mean(topic_vectors, axis=0)\n",
    "    group_to_topic_vector[group_id] = mean_topic_vector\n",
    "    \n",
    "# Turning that matrix of weights into a dataframe so it can be worked with.\n",
    "tm_df = pd.DataFrame(group_to_topic_vector)\n",
    "\n",
    "# Changing the order of the Lloyd, Meinke phenotype subsets to match other figures and tables for consistency.\n",
    "lmtm_df = pd.read_csv(lloyd_function_hierarchy_path)    \n",
    "columns_in_order = [col for col in lmtm_df[\"Subset Symbol\"].values if col in tm_df.columns]\n",
    "columns_in_order.reverse()\n",
    "assert len(columns_in_order) == number_of_topics\n",
    "tm_df = tm_df[columns_in_order]\n",
    "    \n",
    "# Reordering so consistency with the curated subsets can be checked by looking at the diagonal.\n",
    "tm_df[\"idxmax\"] = tm_df.idxmax(axis = 1)\n",
    "tm_df[\"idxmax\"] = tm_df[\"idxmax\"].apply(lambda x: tm_df.columns.get_loc(x))\n",
    "tm_df = tm_df.sort_values(by=\"idxmax\")\n",
    "tm_df.drop(columns=[\"idxmax\"], inplace=True)\n",
    "\n",
    "# Saving a version of this dataframe this is indexed by topic integers and subset strings, before makings topics a column instead.\n",
    "topic_subset_similarity_df = tm_df\n",
    "tm_df = tm_df.reset_index(drop=False).rename({\"index\":\"topic\"},axis=1).reset_index(drop=False).rename({\"index\":\"order\"},axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_subset_similarity_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tm_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describing what the most representative tokens for each topic in the model are.\n",
    "num_top_words = 5\n",
    "map_top_words = {}\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "for i,topic_vec in enumerate(cls.components_):\n",
    "    top_words = []\n",
    "    print(i,end=\": \")\n",
    "    for fid in topic_vec.argsort()[-1:-num_top_words-1:-1]:\n",
    "        word = feature_names[fid]\n",
    "        # The next line is applicable if words in the topic model are actually a function of the words in the texts.\n",
    "        #word = \" \".join(unreduce[word])\n",
    "        top_words.append(word)\n",
    "        print(word, end=\" \")  \n",
    "    map_top_words[i] = top_words\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a column that specifies what the top tokens for each topic are.\n",
    "tm_df[\"tokens\"] = tm_df[\"topic\"].map(lambda x: \"|\".join(map_top_words[x]))\n",
    "\n",
    "# Move that column to the left for readability before writing to the file.\n",
    "tokens_col = tm_df.pop(\"tokens\")\n",
    "tm_df.insert(2, \"tokens\", tokens_col)\n",
    "\n",
    "# Renaming the topics to be in order, to be more helpful when preparing figures that are more intuitive.\n",
    "tm_df[\"topic_renumbered\"] = tm_df[\"order\"].values[::-1]+1\n",
    "topic_renumbered_col = tm_df.pop(\"topic_renumbered\")\n",
    "tm_df.insert(2, \"topic_renumbered\", topic_renumbered_col)\n",
    "\n",
    "# Remembering a mapping between the topics, their order, and what the renumbered names are.\n",
    "topic_order_map = {t:i for t,i in zip(tm_df[\"topic\"].values, tm_df[\"order\"].values)}\n",
    "topic_renumbered_map = {t:i for t,i in zip(tm_df[\"topic\"].values, tm_df[\"topic_renumbered\"].values)}\n",
    "\n",
    "# Saving this version of the subset and topic similarity data to a file.\n",
    "tm_df.to_csv(os.path.join(OUTPUT_DIR,\"part_6_topic_modeling_matrix.csv\"), index=False)\n",
    "tm_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Producing a version of the previous table that is useful for producing line drawings representing these results.\n",
    "tm_lines_dict = defaultdict(list)\n",
    "\n",
    "\n",
    "# Remembering the order of the Lloyd, Meinke phenotype subsets to match other figures for consistency.\n",
    "lmtm_df = pd.read_csv(lloyd_function_hierarchy_path)   \n",
    "subset_to_class_map = {s:c for s,c in zip(lmtm_df[\"Subset Symbol\"].values, lmtm_df[\"Class Name\"].values)}\n",
    "subset_to_desc_map = {s:c for s,c in zip(lmtm_df[\"Subset Symbol\"].values, lmtm_df[\"Subset Name and Description \"].values)}\n",
    "subset_abbrevs_in_order = [col for col in lmtm_df[\"Subset Symbol\"].values if col in tm_df.columns]\n",
    "subset_abbrevs_in_order.reverse()\n",
    "subset_order_map = {subset_abbrev:i for i,subset_abbrev in enumerate(subset_abbrevs_in_order)}\n",
    "\n",
    "\n",
    "\n",
    "# Producing the line entries that represent connections between the subsets and topics.\n",
    "line_number = 0\n",
    "topic_int_list = list(topic_subset_similarity_df.columns)\n",
    "subset_str_list = list(topic_subset_similarity_df.index)\n",
    "for subset_abbrev, topic_int in itertools.product(topic_int_list,subset_str_list):\n",
    "    \n",
    "    # The weight of the line, extracted from the similarity matrix between subsets and topics built previously.\n",
    "    weight = topic_subset_similarity_df.loc[topic_int,subset_abbrev]\n",
    "    \n",
    "    # The strings that should be used to represent classes, subsets, and topics in a figure or plot.\n",
    "    subset_str = \"{} ({})\".format(subset_abbrev, subset_to_desc_map[subset_abbrev].lower())\n",
    "    tm_lines_dict[\"subset_str\"].extend([subset_str,subset_str])\n",
    "    tm_lines_dict[\"class_str\"].extend([subset_to_class_map[subset_abbrev],subset_to_class_map[subset_abbrev]])\n",
    "    topic_str = \"Topic {}: ({})\".format(topic_renumbered_map[topic_int], \"|\".join(map_top_words[topic_int]))\n",
    "    tm_lines_dict[\"topic_str\"].extend([topic_str,topic_str])\n",
    "    \n",
    "    # Which line is this, they all have individual numbers so that each line can be its own group in a ggplot object.\n",
    "    tm_lines_dict[\"line_number\"].extend([line_number,line_number])\n",
    "    tm_lines_dict[\"weight\"].extend([weight,weight])\n",
    "    \n",
    "    # Where should the line start and stop? The horizontal values are arbitrary and just have to match.\n",
    "    # The vertical values are determined by which subset and topic are being connected to each other.\n",
    "    tm_lines_dict[\"x\"].extend([0,10])\n",
    "    tm_lines_dict[\"y\"].extend([subset_order_map[subset_abbrev],topic_order_map[topic_int]])\n",
    "    \n",
    "    line_number = line_number+1\n",
    "    \n",
    "tm_lines_df = pd.DataFrame(tm_lines_dict)\n",
    "tm_lines_df.to_csv(os.path.join(OUTPUT_DIR,\"part_6_topic_modeling_lines.csv\"), index=False)\n",
    "tm_lines_df.head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"clustering\"></a>\n",
    "### Approach 2: Agglomerative clustering and comparison to predefined groups\n",
    "This clustering approach uses agglomerative clustering to cluster the genes into a fixed number of clusters based off the distances between their embedding representations using all of the above methods. Clustering into a fixed number of clusters allows for clustering into a similar number of groups as a present in some existing grouping of the data, such as phenotype categories or biochemical pathways, and then determining if the clusters obtained are at all similar to the groupings that already exist. Agglomerative clustering is used here in order to use an arbitrary predefined distance matrix, in this case the matrix being used is the mean distance percentiles from each of the different approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Generate the numpy array where values are mean distance percentiles between all the methods.\n",
    "mean_pct_array = name_to_array[\"Mean\"]\n",
    "to_id = array_index_to_id\n",
    "\n",
    "# Do agglomerative clustering based on that distance matrix.\n",
    "number_of_clusters = 42\n",
    "ac = AgglomerativeClustering(n_clusters=number_of_clusters, linkage=\"complete\", affinity=\"precomputed\")\n",
    "clustering = ac.fit(mean_pct_array)\n",
    "id_to_cluster = {}\n",
    "cluster_to_ids = defaultdict(list)\n",
    "for idx,c in enumerate(clustering.labels_):\n",
    "    id_to_cluster[to_id[idx]] = c\n",
    "    cluster_to_ids[c].append(to_id[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Create the dataframe containing the average score assigned to each topic for the genes from each subset.\n",
    "group_to_cluster_vector = {}\n",
    "for group_id,ids in group_id_to_ids.items():\n",
    "    \n",
    "    mean_cluster_vector = np.zeros(number_of_clusters)\n",
    "    for i in ids:\n",
    "        cluster = id_to_cluster[i]\n",
    "        mean_cluster_vector[cluster] = mean_cluster_vector[cluster]+1\n",
    "    mean_cluster_vector = mean_cluster_vector/mean_cluster_vector.sum(axis=0,keepdims=1)\n",
    "    group_to_cluster_vector[group_id] = mean_cluster_vector\n",
    "    \n",
    "ac_df = pd.DataFrame(group_to_cluster_vector)\n",
    "\n",
    "# Changing the order of the Lloyd, Meinke phenotype subsets to match other figures for consistency.\n",
    "filename = \"../data/group_related_files/lloyd/lloyd_function_hierarchy_irb_cleaned.csv\"\n",
    "lmtm_df = pd.read_csv(filename)    \n",
    "columns_in_order = [col for col in lmtm_df[\"Subset Symbol\"].values if col in ac_df.columns]\n",
    "ac_df = ac_df[columns_in_order]\n",
    "\n",
    "# Reordering so consistency with the curated subsets can be checked by looking at the diagonal.\n",
    "ac_df[\"idxmax\"] = ac_df.idxmax(axis = 1)\n",
    "ac_df[\"idxmax\"] = ac_df[\"idxmax\"].apply(lambda x: ac_df.columns.get_loc(x))\n",
    "ac_df = ac_df.sort_values(by=\"idxmax\")\n",
    "ac_df.drop(columns=[\"idxmax\"], inplace=True)\n",
    "ac_df = ac_df.reset_index(drop=False).rename({\"index\":\"cluster\"},axis=1).reset_index(drop=False).rename({\"index\":\"order\"},axis=1)\n",
    "ac_df.to_csv(os.path.join(OUTPUT_DIR,\"part_6_agglomerative_clustering.csv\"), index=False)\n",
    "ac_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approach 3: Agglomerative clustering and sillhouette scores for each NLP method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if NOTEBOOK:\n",
    "    from sklearn.metrics.cluster import silhouette_score\n",
    "    # Note that homogeneity scores don't fit for evaluating how close the clustering is to pathway membership, etc.\n",
    "    # This is because genes can be assigned to more than one pathway, metric would have to be changed to account for this.\n",
    "    # So all this section does is determines which values of n_clusters provide good clustering results for each matrix.\n",
    "    n_clusters_silhouette_scores = defaultdict(dict)\n",
    "    min_n_clusters = 20\n",
    "    max_n_clusters = 80\n",
    "    step_size = 4\n",
    "    number_of_clusters = np.arange(min_n_clusters, max_n_clusters, step_size)\n",
    "    for n in number_of_clusters:\n",
    "        for name in names:\n",
    "            distance_matrix = name_to_array[name]\n",
    "            ac = AgglomerativeClustering(n_clusters=n, linkage=\"complete\", affinity=\"precomputed\")\n",
    "            clustering = ac.fit(distance_matrix)\n",
    "            sil_score = silhouette_score(distance_matrix, clustering.labels_, metric=\"precomputed\")\n",
    "            n_clusters_silhouette_scores[name][n] = sil_score\n",
    "    sil_df = pd.DataFrame(n_clusters_silhouette_scores).reset_index(drop=False).rename({\"index\":\"n\"},axis=\"columns\")\n",
    "    sil_df.to_csv(os.path.join(OUTPUT_DIR,\"part_6_silhouette_scores_by_n.csv\"), index=False)\n",
    "    sil_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"phenologs\"></a>\n",
    "### Approach 4: Looking for phenolog relationships between clusters and OMIM disease phenotypes\n",
    "This section produces a table of values that provides a score for the a particular pair of a cluster found for this dataset of plant genes and a disease phenotype. Currently the value indicates the fraction of the plant genes in that cluster that have orthologs associated with that disease phenotype. This should be replaced or supplemented with a p-value for evaluating the significance of this value given the distribution of genes and their mappings to all of the disease phenotypes. All the rows from the input dataframe containing the PantherDB and OMIM information where the ID from this dataset is not known or the mapping to a phenotype was unsuccessful are removed at this step, fix this if the metric for evaluating cluster to phenotype phenolog mappings need this information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Read in the dataframe mapping plant genes --> human orthologs --> disease phenotypes.\n",
    "omim_df = pd.read_csv(panther_to_omim_filename)\n",
    "# Add a column that indicates which ID in the dataset those plant genes refer to, for mapping to phenotypes.\n",
    "name_to_id = dataset.get_name_to_id_dictionary()\n",
    "omim_df[\"id\"] = omim_df[\"gene_identifier\"].map(lambda x: name_to_id.get(x,None))\n",
    "omim_df = omim_df.dropna(subset=[\"id\",\"phenotype_mim_name\"], inplace=False)\n",
    "omim_df[\"phenotype_mim_name\"] = omim_df[\"phenotype_mim_name\"].astype(str)\n",
    "omim_df[\"compressed_phenotype_mim_name\"] = omim_df[\"phenotype_mim_name\"].map(lambda x: x.split(\",\")[0])\n",
    "omim_df[\"id\"] = omim_df[\"id\"].astype(\"int64\")\n",
    "omim_df[\"phenotype_mim_number\"] = omim_df[\"phenotype_mim_number\"].astype(\"int64\")\n",
    "# Generate mappings between the IDs in this dataset and disease phenotypes or orthologous genes.\n",
    "id_to_mim_phenotype_names = defaultdict(list)\n",
    "for i,p in zip(omim_df[\"id\"].values,omim_df[\"compressed_phenotype_mim_name\"].values):\n",
    "    id_to_mim_phenotype_names[i].append(p)\n",
    "id_to_human_gene_symbols = defaultdict(list)\n",
    "for i,s in zip(omim_df[\"id\"].values,omim_df[\"human_ortholog_gene_symbol\"].values):\n",
    "    id_to_human_gene_symbols[i].append(s)\n",
    "omim_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many genes in our dataset map to orthologs that map to the same OMIM phenotype?\n",
    "omim_df.groupby(\"compressed_phenotype_mim_name\").size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "phenolog_x_dict = defaultdict(dict)\n",
    "phenolog_p_dict = defaultdict(dict)\n",
    "candidate_genes_dict = defaultdict(dict)\n",
    "phenotypes = pd.unique(omim_df[\"compressed_phenotype_mim_name\"].values)\n",
    "clusters = list(cluster_to_ids.keys())\n",
    "for cluster,phenotype in itertools.product(clusters,phenotypes):\n",
    "    \n",
    "    # What are the candidate genes predicted if this phenolog pairing is real?\n",
    "    ids = cluster_to_ids[cluster]\n",
    "    candidate_genes_dict[cluster][phenotype] = list(set(flatten([id_to_human_gene_symbols[i] for i in ids if phenotype not in id_to_mim_phenotype_names.get(i,[])])))\n",
    "\n",
    "    # What is the p-value for this phenolog pairing?\n",
    "    # The size of the population (genes in the dataset).\n",
    "    M = len(id_to_cluster.keys())\n",
    "    # The number of elements we draw without replacement (genes in the cluster).\n",
    "    N = len(cluster_to_ids[cluster])     \n",
    "    # The number of available successes in the population (genes that map to orthologs that map to this phenotype).\n",
    "    n = len([i for i in id_to_cluster.keys() if phenotype in id_to_mim_phenotype_names.get(i,[])])\n",
    "    # The number of successes drawn (genes in this cluster that map to orthologs that map to this phenotype).\n",
    "    x = list(set(flatten([id_to_mim_phenotype_names.get(i,[]) for i in ids]))).count(phenotype)\n",
    "    prob = 1-hypergeom.cdf(x-1, M, n, N) # Equivalent to prob = 1-sum([hypergeom.pmf(x_i, M, n, N) for x_i in range(0,x)])\n",
    "    phenolog_x_dict[cluster][phenotype] = x\n",
    "    phenolog_p_dict[cluster][phenotype] = prob\n",
    "    \n",
    "\n",
    "# Convert the dictionary to a table of values with cluster and phenotype as the rows and columns.\n",
    "phenolog_matrix = pd.DataFrame(phenolog_x_dict)        \n",
    "phenolog_matrix.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Produce a melted version of the phenolog matrix sorted by value and including predicted candidate genes.\n",
    "phenolog_matrix_reset = phenolog_matrix.reset_index(drop=False).rename({\"index\":\"omim_phenotype_name\"}, axis=\"columns\")\n",
    "phenolog_df = pd.melt(phenolog_matrix_reset, id_vars=[\"omim_phenotype_name\"], value_vars=phenolog_matrix.columns[1:], var_name=\"cluster\", value_name=\"x\")\n",
    "# What other information should be present in this melted phenologs matrix?\n",
    "phenolog_df[\"size\"] = phenolog_df[\"cluster\"].map(lambda x: len(cluster_to_ids[x]))\n",
    "phenolog_df[\"candidate_gene_symbols\"] = np.vectorize(lambda x,y: concatenate_with_bar_delim(*candidate_genes_dict[x][y]))(phenolog_df[\"cluster\"], phenolog_df[\"omim_phenotype_name\"])\n",
    "phenolog_df[\"p_value\"] = np.vectorize(lambda x,y: phenolog_p_dict[x][y])(phenolog_df[\"cluster\"], phenolog_df[\"omim_phenotype_name\"])\n",
    "phenolog_df[\"p_adjusted\"] = multipletests(phenolog_df[\"p_value\"].values, method='bonferroni')[1]\n",
    "phenolog_df.sort_values(by=[\"p_value\"], inplace=True, ascending=True)\n",
    "phenolog_df = phenolog_df[[\"omim_phenotype_name\", \"cluster\", \"size\", \"x\", \"p_value\", \"p_adjusted\", \"candidate_gene_symbols\"]]\n",
    "phenolog_df.to_csv(os.path.join(OUTPUT_DIR,\"part_6_phenologs.csv\"), index=False)\n",
    "phenolog_df.head(30)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
