{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "\n",
    "- [Introduction](#introduction)\n",
    "\n",
    "- [Links of Interest](#links)\n",
    "\n",
    "- [Part 1. Loading and Filtering Data](#part_1)\n",
    "    - [Reading in arguments](#args)\n",
    "    - [Setting input and output paths](#paths)\n",
    "    - [Reading in genes, annotations, and phenotype descriptions](#read_text_data)\n",
    "    - [Relating genes in this dataset to other biological datasets](#relating)\n",
    "    - [KEGG](#kegg)\n",
    "    - [PlantCyc](#plantcyc)\n",
    "    - [Lloyd and Meinke (2012) phenotype subsets](#subsets)\n",
    "    - [Lloyd and Meinke (2012) phenotype classes](#classes)\n",
    "    - [Oellrich, Walls et al., (2015) EQ statements](#eqs)\n",
    "    - [Protein associations from STRING](#string)\n",
    "    - [Ortholog relationships from PANTHER](#panther)\n",
    "    - [Filtering the dataset to include relevant genes](#filtering)\n",
    "     \n",
    "- [Part 2. NLP Models](#part_2)\n",
    "    - [Word2Vec and Doc2Vec](#word2vec_doc2vec)\n",
    "    - [BERT and BioBERT](#bert_biobert)\n",
    "    - [Loading models](#load_models)\n",
    "\n",
    "- [Part 3. NLP Choices](#part_3)\n",
    "    - [Preprocessing descriptions](#preprocessing)\n",
    "    - [POS Tagging](#pos_tagging)\n",
    "    - [Reducing vocabulary size](#vocab)\n",
    "    - [Annotating with biological ontologies](#annotation)\n",
    "    - [Splitting into phene descriptions](#phenes)\n",
    "        \n",
    "- [Part 4. Generating Vectors and Distance Matrices](#part_4)\n",
    "    - [Defining methods to use](#methods)\n",
    "    - [Running all methods](#running)\n",
    "    - [Merging distances into an edgelist](#merging)\n",
    "      \n",
    "- [Part 5. Biological Questions](#part_5)\n",
    "    - [Using pathways as the objective](#pathway_objective)\n",
    "    - [Using phenotype subsets as the objective](#subset_objective)\n",
    "    - [Using protein associations as the objective](#association_objective)\n",
    "    - [Using orthology as the objective](#ortholog_objective)\n",
    "    - [Adding EQ similarity values](#eq_sim)\n",
    "    - [Noting whether gene pairs have curated data](#curated)\n",
    "    - [Noting whether gene pairs refer to the same species](#species)\n",
    "    - [Determining the number of genes and pairs involved in each question](#n_values)\n",
    "    - [Determining how similar the biological questions are to one another](#objective_similarities)\n",
    "    \n",
    "- [Part 6. Results](#part_6)\n",
    "    - [Distributions of distance values](#ks)\n",
    "    - [Within-group distance values](#within)\n",
    "    - [Predictions and AUC for shared pathways or interactions](#auc)\n",
    "    - [Tests for querying to recover related genes](#y)\n",
    "    - [Producing output summary table](#output)\n",
    "\n",
    "- [Part 7. Clustering Analysis](#part_7)\n",
    "    - [Topic modeling](#topic_modeling)\n",
    "    - [Agglomerative clustering](#clustering)\n",
    "    - [Phenologs for OMIM disease phenotypes](#phenologs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"introduction\"></a>\n",
    "### Introduction: Text Mining Analysis of Phenotype Descriptions in Plants\n",
    "The purpose of this notebook is to evaluate what can be learned from a natural language processing approach to analyzing free-text descriptions of phenotype descriptions of plants. The approach is to generate pairwise distances matrices between a set of plant phenotype descriptions across different species, sourced from academic papers and online model organism databases. These pairwise distance matrices can be constructed using any vectorization method that can be applied to natural language. In this notebook, we specifically evaluate the use of n-gram and bag-of-words techniques, word and document embedding using Word2Vec and Doc2Vec, context-dependent word-embeddings using BERT and BioBERT, and ontology term annotations with automated annotation tools such as NOBLE Coder.\n",
    "\n",
    "Loading, manipulation, and filtering of the dataset of phenotype descriptions associated with genes across different plant species is largely handled through a Python package created for this purpose called OATS (Ontology Annotation and Text Similarity) which is available [here](https://github.com/irbraun/oats). Preprocessing of the descriptions, mapping the dataset to additional resources such as protein-protein interaction databases and biochemical pathway databases are handled in this notebook using that package as well. In the evaluation of each of these natural language processing approaches to analyzing this dataset of descriptions, we compare performance against a dataset generated through manual annotation of a similar dataset in Oellrich Walls et al. (2015) and against manual annotations with experimentally determined terms from the Gene Ontology (PO) and the Plant Ontology (PO).\n",
    "\n",
    "<a id=\"links\"></a>\n",
    "### Relevant links of interest:\n",
    "- Paper describing comparison of NLP and ontology annotation approaches to curation: [Braun, Lawrence-Dill (2019)](https://doi.org/10.3389/fpls.2019.01629)\n",
    "- Paper describing results of manual phenotype description curation: [Oellrich, Walls et al. (2015](https://plantmethods.biomedcentral.com/articles/10.1186/s13007-015-0053-y)\n",
    "- Plant databases with phenotype description text data available: [TAIR](https://www.arabidopsis.org/), [SGN](https://solgenomics.net/), [MaizeGDB](https://www.maizegdb.org/)\n",
    "- Python package for working with phenotype descriptions: [OATS](https://github.com/irbraun/oats)\n",
    "- Python package used for general NLP functions: [NLTK](https://www.nltk.org/), [Gensim](https://radimrehurek.com/gensim/auto_examples/index.html)\n",
    "- Python package used for working with biological ontologies: [Pronto](https://pronto.readthedocs.io/en/latest/)\n",
    "- Python package for loading pretrained BERT models: [PyTorch Pretrained BERT](https://pypi.org/project/pytorch-pretrained-bert/)\n",
    "- For BERT Models pretrained on PubMed and PMC: [BioBERT Paper](https://arxiv.org/abs/1901.08746), [BioBERT Models](https://github.com/naver/biobert-pretrained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warming up PyWSD (takes ~10 secs)... took 4.111119985580444 secs.\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import math\n",
    "import sys\n",
    "import gensim\n",
    "import os\n",
    "import warnings\n",
    "import torch\n",
    "import itertools\n",
    "import argparse\n",
    "import shlex\n",
    "import random\n",
    "import multiprocessing as mp\n",
    "from collections import Counter, defaultdict\n",
    "from inspect import signature\n",
    "from scipy.stats import ks_2samp, hypergeom, pearsonr, spearmanr\n",
    "from sklearn.metrics import precision_recall_curve, f1_score, auc\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from scipy import spatial, stats\n",
    "from statsmodels.sandbox.stats.multicomp import multipletests\n",
    "from pytorch_pretrained_bert import BertTokenizer, BertModel, BertForMaskedLM\n",
    "from gensim.parsing.preprocessing import strip_non_alphanum, stem_text, preprocess_string, remove_stopwords\n",
    "from gensim.utils import simple_preprocess\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.decomposition import LatentDirichletAllocation as LDA\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "from nltk.corpus import brown, stopwords\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "nltk.download('stopwords', quiet=True)\n",
    "nltk.download('wordnet', quiet=True)\n",
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('brown', quiet=True)\n",
    "nltk.download('averaged_perceptron_tagger', quiet=True)\n",
    "\n",
    "sys.path.append(\"../../oats\")\n",
    "from oats.utils.utils import save_to_pickle, load_from_pickle, merge_list_dicts, flatten, to_hms\n",
    "from oats.utils.utils import function_wrapper_with_duration, remove_duplicates_retain_order\n",
    "from oats.biology.dataset import Dataset\n",
    "from oats.biology.groupings import Groupings\n",
    "from oats.biology.relationships import ProteinInteractions, AnyInteractions\n",
    "from oats.annotation.ontology import Ontology\n",
    "from oats.annotation.annotation import annotate_using_noble_coder\n",
    "from oats.distances import pairwise as pw\n",
    "from oats.distances.edgelists import merge_edgelists, make_undirected, remove_self_loops, subset_with_ids\n",
    "from oats.nlp.vocabulary import get_overrepresented_tokens, get_vocab_from_tokens\n",
    "from oats.nlp.vocabulary import reduce_vocab_connected_components, reduce_vocab_linares_pontes\n",
    "from oats.nlp.preprocess import concatenate_with_bar_delim\n",
    "\n",
    "from _utils import Method\n",
    "from _utils import IndexedGraph\n",
    "\n",
    "mpl.rcParams[\"figure.dpi\"] = 400\n",
    "warnings.simplefilter('ignore')\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"part_1\"></a>\n",
    "# Part 1. Loading and Filtering Data\n",
    "This section defines some constants which are used for creating a uniquely named directory to contain all the outputs from running this instance of this notebook. The naming scheme is based on the time that the notebook is run. All the input and output file paths for loading datasets or models are also contained within this cell, so that if anything is moved the directories and file names should only have to be changed at this point and nowhere else further into the notebook. If additional files are added to the notebook cells they should be put here as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"args\"></a>\n",
    "### Reading in arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NOTEBOOK = True\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--learning\", dest=\"learning\", required=False, action='store_true', help=\"use the approaches that involve neural networks\")\n",
    "parser.add_argument(\"--noblecoder\", dest=\"noblecoder\", required=False, action='store_true', help=\"use the approaches that involve computational annotation\")\n",
    "parser.add_argument(\"--lda\", dest=\"lda\", required=False, action='store_true', help=\"use the approaches that involve topic modeling\")\n",
    "parser.add_argument(\"--nmf\", dest=\"nmf\", required=False, action='store_true', help=\"use the approaches that involve topic modeling\")\n",
    "parser.add_argument(\"--vanilla\", dest=\"vanilla\", required=False, action='store_true', help=\"use the n-grams (bag-of-words) approach\")\n",
    "parser.add_argument(\"--vocab\", dest=\"vocab\", required=False, action='store_true', help=\"using the n-grams approach but with modified vocabularies\")\n",
    "parser.add_argument(\"--annotations\", dest=\"annotations\", required=False, action='store_true', help=\"use the curated annotations\")\n",
    "\n",
    "if NOTEBOOK:\n",
    "    arg_string = \"--learning --noblecoder --lda --nmf --vanilla --vocab --annotations\"\n",
    "    args = parser.parse_args(shlex.split(arg_string))\n",
    "else:\n",
    "    args = parser.parse_args()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"paths\"></a>\n",
    "### Defining the input file paths and creating output directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and name an output directory according to when the notebooks or script was run.\n",
    "OUTPUT_DIR = os.path.join(\"../outputs\",\"{}_r{}\".format(datetime.datetime.now().strftime('%m_%d_%Y_h%Hm%Ms%S'),random.randrange(1000,9999)))\n",
    "os.mkdir(OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset_filename = \"../data/pickles/gene_phenotype_dataset_all_text_and_annotations.pickle\"          # The full dataset pickle.\n",
    "kegg_pathways_filename = \"../data/pickles/groupings_from_kegg_pathways.pickle\"                       # The pathway groupings from KEGG.\n",
    "pmn_pathways_filename = \"../data/pickles/groupings_from_pmn_pathways.pickle\"                         # The pahway groupings from Plant Metabolic Network.\n",
    "lloyd_subsets_filename = \"../data/pickles/groupings_from_lloyd_subsets.pickle\"                       # The functional subsets defined by Lloyd and Meinke (2012).\n",
    "lloyd_classes_filename = \"../data/pickles/groupings_from_lloyd_classes.pickle\"                       # The functional classes defined by Lloyd and Meinke (2012).\n",
    "background_corpus_filename = \"../data/corpus_related_files/untagged_text_corpora/background.txt\"     # Text file with background content.\n",
    "phenotypes_corpus_filename = \"../data/corpus_related_files/untagged_text_corpora/phenotypes_all.txt\" # Text file with specific content.\n",
    "doc2vec_pubmed_filename = \"../gensim/pubmed_dbow/doc2vec_2.bin\"                                      # File holding saved Doc2Vec model trained on PubMed.\n",
    "doc2vec_wikipedia_filename = \"../gensim/enwiki_dbow/doc2vec.bin\"                                     # File holding saved Doc2Vec model trained on Wikipedia.\n",
    "word2vec_model_filename = \"../gensim/wiki_sg/word2vec.bin\"                                           # File holding saved Word2Vec model trained on Wikipedia.\n",
    "go_filename = \"../ontologies/go.obo\"                                                                 # Gene Ontology file in OBO format.\n",
    "po_filename = \"../ontologies/po.obo\"                                                                 # Plant Ontology file in OBO format.\n",
    "pato_filename = \"../ontologies/pato.obo\"                                                             # Phenotype and Trait Ontology file in OBO format.\n",
    "noblecoder_jarfile_path = \"../lib/NobleCoder-1.0.jar\"                                                # Jar for NOBLE Coder annotation tool.\n",
    "biobert_pmc_path = \"../gensim/biobert_v1.0_pmc/pytorch_model\"                                        # Path for PyTorch BioBERT model.\n",
    "biobert_pubmed_path = \"../gensim/biobert_v1.0_pubmed/pytorch_model\"                                  # Path for PyTorch BioBERT model.\n",
    "biobert_pubmed_pmc_path = \"../gensim/biobert_v1.0_pubmed_pmc/pytorch_model\"                          # Path for PyTorch BioBERT model.\n",
    "panther_to_omim_filename = \"../data/orthology_related_files/ath_to_hsa/pantherdb_omim_df.csv\"        # File with mappings to human orthologs and disease phenotypes.\n",
    "pppn_edgelist_path = \"../data/supplemental_files_oellrich_walls/13007_2015_53_MOESM9_ESM.txt\"\n",
    "ortholog_file_path = \"../data/orthology_related_files/pantherdb/PlantGenomeOrthologs_IRB_Modified.txt\"\n",
    "paired_phenotypes_path = \"../data/corpus_related_files/phenotype_pairs/scored.csv\"\n",
    "lloyd_function_hierarchy_path = \"../data/group_related_files/lloyd/lloyd_function_hierarchy_irb_cleaned.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"read_text_data\"></a>\n",
    "### Reading in the dataset of genes and their associated phenotype descriptions and annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>species</th>\n",
       "      <th>num_genes</th>\n",
       "      <th>unique_descriptions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ath</td>\n",
       "      <td>5851</td>\n",
       "      <td>3527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gmx</td>\n",
       "      <td>30</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mtr</td>\n",
       "      <td>37</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>osa</td>\n",
       "      <td>92</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sly</td>\n",
       "      <td>70</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>zma</td>\n",
       "      <td>1405</td>\n",
       "      <td>811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>total</td>\n",
       "      <td>7485</td>\n",
       "      <td>4553</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  species  num_genes  unique_descriptions\n",
       "0     ath       5851                 3527\n",
       "1     gmx         30                   24\n",
       "2     mtr         37                   36\n",
       "3     osa         92                   85\n",
       "4     sly         70                   70\n",
       "5     zma       1405                  811\n",
       "6   total       7485                 4553"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_from_pickle(dataset_filename)\n",
    "dataset.filter_has_description()\n",
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"relating\"></a>\n",
    "### Relating the dataset of genes to the dataset of groupings or categories\n",
    "This section generates tables that indicate how the genes present in the dataset were mapped to the defined pathways or groups. This includes a summary table that indicates how many genes by species were succcessfully mapped to atleast one pathway or group, as well as a more detailed table describing how many genes from each species were mapped to each particular pathway or group. Additionally, a pairwise group similarity matrix is also generated, where the similarity is given as the Jaccard similarity between two groups based on whether genes are shared by those groups or not. The function defined in this section returns a groupings object that can be re-used, as well as the IDs of the genes in the full dataset that were found to be relevant to those particular groupings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_in_groupings_object_and_write_summary_tables(dataset, groupings_filename, name):\n",
    "\n",
    "    # Load the groupings object.\n",
    "    groups = load_from_pickle(groupings_filename)\n",
    "    id_to_group_ids = groups.get_id_to_group_ids_dict(dataset.get_gene_dictionary())\n",
    "    group_id_to_ids = groups.get_group_id_to_ids_dict(dataset.get_gene_dictionary())\n",
    "    group_mapped_ids = [k for (k,v) in id_to_group_ids.items() if len(v)>0]\n",
    "    groups.to_csv(os.path.join(OUTPUT_DIR,\"part_1_{}_groupings.csv\".format(name)))\n",
    "\n",
    "    # Generate a table describing how many of the genes input from each species map to atleast one group.\n",
    "    summary = defaultdict(dict)\n",
    "    species_dict = dataset.get_species_dictionary()\n",
    "    for species in dataset.get_species():\n",
    "        summary[species][\"input\"] = len([x for x in dataset.get_ids() if species_dict[x]==species])\n",
    "        summary[species][\"mapped\"] = len([x for x in group_mapped_ids if species_dict[x]==species])\n",
    "    table = pd.DataFrame(summary).transpose()\n",
    "    table.loc[\"total\"]= table.sum()\n",
    "    table[\"fraction\"] = table.apply(lambda row: \"{:0.4f}\".format(row[\"mapped\"]/row[\"input\"]), axis=1)\n",
    "    table = table.reset_index(inplace=False)\n",
    "    table = table.rename({\"index\":\"species\"}, axis=\"columns\")\n",
    "    table.to_csv(os.path.join(OUTPUT_DIR,\"part_1_{}_mappings_summary.csv\".format(name)), index=False)\n",
    "\n",
    "    \n",
    "    # Generate a table describing how many genes from each species map to which particular group.\n",
    "    summary = defaultdict(dict)\n",
    "    for group_id,ids in group_id_to_ids.items():\n",
    "        summary[group_id].update({species:len([x for x in ids if species_dict[x]==species]) for species in dataset.get_species()})\n",
    "        summary[group_id][\"total\"] = len([x for x in ids])\n",
    "    table = pd.DataFrame(summary).transpose()\n",
    "    table = table.sort_values(by=\"total\", ascending=False)\n",
    "    table = table.reset_index(inplace=False)\n",
    "    table = table.rename({\"index\":\"pathway_id\"}, axis=\"columns\")\n",
    "    table[\"pathway_name\"] = table[\"pathway_id\"].map(groups.get_long_name)\n",
    "    table.loc[\"total\"] = table.sum()\n",
    "    table.loc[\"total\",\"pathway_id\"] = \"total\"\n",
    "    table.loc[\"total\",\"pathway_name\"] = \"total\"\n",
    "    table = table[table.columns.tolist()[-1:] + table.columns.tolist()[:-1]]\n",
    "    table.to_csv(os.path.join(OUTPUT_DIR,\"part_1_{}_mappings_by_group.csv\".format(name)), index=False)\n",
    "    \n",
    "    \n",
    "    # What are the similarites between the groups for the genes present in this dataset?\n",
    "    group_sims = defaultdict(dict)\n",
    "    for group_id_1,ids_1 in group_id_to_ids.items():\n",
    "        for group_id_2,ids_2 in group_id_to_ids.items():\n",
    "            jaccard_sim = len(set(ids_1).intersection(set(ids_2)))/len(set(ids_1).union(set(ids_2)))\n",
    "            group_sims[group_id_1][group_id_2] = jaccard_sim\n",
    "    table = pd.DataFrame(group_sims)\n",
    "    \n",
    "    \n",
    "    # Changing the order of the Lloyd, Meinke phenotype subsets to match other figures for consistency, special case.\n",
    "    if name == \"subsets\":\n",
    "        filename = \"../data/group_related_files/lloyd/lloyd_function_hierarchy_irb_cleaned.csv\"\n",
    "        lmtm_df = pd.read_csv(filename)    \n",
    "        subsets_in_order = [col for col in lmtm_df[\"Subset Symbol\"].values if col in table.columns]\n",
    "        table = table[subsets_in_order]\n",
    "        table = table.reindex(subsets_in_order)\n",
    "        \n",
    "        \n",
    "    # Formatting the column names for this table correctly and outputting to a file.\n",
    "    table = table.reset_index(drop=False).rename({\"index\":\"group\"},axis=1).reset_index(drop=False).rename({\"index\":\"order\"},axis=1)\n",
    "    table.to_csv(os.path.join(OUTPUT_DIR,\"part_1_{}_similarity_matrix.csv\".format(name)), index=False)\n",
    "    \n",
    "\n",
    "    # Returning the groupings object and the list of IDs for genes that were mapped to one or more groups.\n",
    "    return(groups, group_mapped_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"kegg\"></a>\n",
    "### Reading in and relating the pathways from KEGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>species</th>\n",
       "      <th>pathway_id</th>\n",
       "      <th>pathway_name</th>\n",
       "      <th>gene_names</th>\n",
       "      <th>ncbi_id</th>\n",
       "      <th>uniprot_id</th>\n",
       "      <th>ko_number</th>\n",
       "      <th>ec_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ath</td>\n",
       "      <td>ko00010</td>\n",
       "      <td>path:ath00010\\tGlycolysis / Gluconeogenesis - ...</td>\n",
       "      <td>hkl3|hexokinase-like 3</td>\n",
       "      <td>at4g37840</td>\n",
       "      <td></td>\n",
       "      <td>KO:K00844</td>\n",
       "      <td>EC:2.7.1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ath</td>\n",
       "      <td>ko00010</td>\n",
       "      <td>path:ath00010\\tGlycolysis / Gluconeogenesis - ...</td>\n",
       "      <td>hxk3|hexokinase 3</td>\n",
       "      <td>at1g47840</td>\n",
       "      <td></td>\n",
       "      <td>KO:K00844</td>\n",
       "      <td>EC:2.7.1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ath</td>\n",
       "      <td>ko00010</td>\n",
       "      <td>path:ath00010\\tGlycolysis / Gluconeogenesis - ...</td>\n",
       "      <td>hxk2|hexokinase 2</td>\n",
       "      <td>at2g19860</td>\n",
       "      <td></td>\n",
       "      <td>KO:K00844</td>\n",
       "      <td>EC:2.7.1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ath</td>\n",
       "      <td>ko00010</td>\n",
       "      <td>path:ath00010\\tGlycolysis / Gluconeogenesis - ...</td>\n",
       "      <td>hxk1|hexokinase 1</td>\n",
       "      <td>at4g29130</td>\n",
       "      <td></td>\n",
       "      <td>KO:K00844</td>\n",
       "      <td>EC:2.7.1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ath</td>\n",
       "      <td>ko00010</td>\n",
       "      <td>path:ath00010\\tGlycolysis / Gluconeogenesis - ...</td>\n",
       "      <td>hkl1|hexokinase-like 1</td>\n",
       "      <td>at1g50460</td>\n",
       "      <td></td>\n",
       "      <td>KO:K00844</td>\n",
       "      <td>EC:2.7.1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ath</td>\n",
       "      <td>ko00010</td>\n",
       "      <td>path:ath00010\\tGlycolysis / Gluconeogenesis - ...</td>\n",
       "      <td>athxk4|hexokinase</td>\n",
       "      <td>at3g20040</td>\n",
       "      <td></td>\n",
       "      <td>KO:K00844</td>\n",
       "      <td>EC:2.7.1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ath</td>\n",
       "      <td>ko00010</td>\n",
       "      <td>path:ath00010\\tGlycolysis / Gluconeogenesis - ...</td>\n",
       "      <td>pgi1|phosphoglucose isomerase 1</td>\n",
       "      <td>at4g24620</td>\n",
       "      <td></td>\n",
       "      <td>KO:K01810</td>\n",
       "      <td>EC:5.3.1.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ath</td>\n",
       "      <td>ko00010</td>\n",
       "      <td>path:ath00010\\tGlycolysis / Gluconeogenesis - ...</td>\n",
       "      <td>sugar isomerase (sis) family protein</td>\n",
       "      <td>at5g42740</td>\n",
       "      <td></td>\n",
       "      <td>KO:K01810</td>\n",
       "      <td>EC:5.3.1.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ath</td>\n",
       "      <td>ko00010</td>\n",
       "      <td>path:ath00010\\tGlycolysis / Gluconeogenesis - ...</td>\n",
       "      <td>pfk6|phosphofructokinase 6</td>\n",
       "      <td>at4g32840</td>\n",
       "      <td></td>\n",
       "      <td>KO:K00850</td>\n",
       "      <td>EC:2.7.1.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ath</td>\n",
       "      <td>ko00010</td>\n",
       "      <td>path:ath00010\\tGlycolysis / Gluconeogenesis - ...</td>\n",
       "      <td>pfk7|phosphofructokinase 7</td>\n",
       "      <td>at5g56630</td>\n",
       "      <td></td>\n",
       "      <td>KO:K00850</td>\n",
       "      <td>EC:2.7.1.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ath</td>\n",
       "      <td>ko00010</td>\n",
       "      <td>path:ath00010\\tGlycolysis / Gluconeogenesis - ...</td>\n",
       "      <td>pfk4|phosphofructokinase 4</td>\n",
       "      <td>at5g61580</td>\n",
       "      <td></td>\n",
       "      <td>KO:K00850</td>\n",
       "      <td>EC:2.7.1.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ath</td>\n",
       "      <td>ko00010</td>\n",
       "      <td>path:ath00010\\tGlycolysis / Gluconeogenesis - ...</td>\n",
       "      <td>pfk1|phosphofructokinase 1</td>\n",
       "      <td>at4g29220</td>\n",
       "      <td></td>\n",
       "      <td>KO:K00850</td>\n",
       "      <td>EC:2.7.1.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ath</td>\n",
       "      <td>ko00010</td>\n",
       "      <td>path:ath00010\\tGlycolysis / Gluconeogenesis - ...</td>\n",
       "      <td>pfk5|phosphofructokinase 5</td>\n",
       "      <td>at2g22480</td>\n",
       "      <td></td>\n",
       "      <td>KO:K00850</td>\n",
       "      <td>EC:2.7.1.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ath</td>\n",
       "      <td>ko00010</td>\n",
       "      <td>path:ath00010\\tGlycolysis / Gluconeogenesis - ...</td>\n",
       "      <td>pfk3|phosphofructokinase 3</td>\n",
       "      <td>at4g26270</td>\n",
       "      <td></td>\n",
       "      <td>KO:K00850</td>\n",
       "      <td>EC:2.7.1.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ath</td>\n",
       "      <td>ko00010</td>\n",
       "      <td>path:ath00010\\tGlycolysis / Gluconeogenesis - ...</td>\n",
       "      <td>pfk2|phosphofructokinase 2</td>\n",
       "      <td>at5g47810</td>\n",
       "      <td></td>\n",
       "      <td>KO:K00850</td>\n",
       "      <td>EC:2.7.1.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ath</td>\n",
       "      <td>ko00010</td>\n",
       "      <td>path:ath00010\\tGlycolysis / Gluconeogenesis - ...</td>\n",
       "      <td>phosphofructokinase family protein</td>\n",
       "      <td>at1g76550</td>\n",
       "      <td></td>\n",
       "      <td>KO:K00895</td>\n",
       "      <td>EC:2.7.1.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ath</td>\n",
       "      <td>ko00010</td>\n",
       "      <td>path:ath00010\\tGlycolysis / Gluconeogenesis - ...</td>\n",
       "      <td>mee51|phosphofructokinase family protein</td>\n",
       "      <td>at4g04040</td>\n",
       "      <td></td>\n",
       "      <td>KO:K00895</td>\n",
       "      <td>EC:2.7.1.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ath</td>\n",
       "      <td>ko00010</td>\n",
       "      <td>path:ath00010\\tGlycolysis / Gluconeogenesis - ...</td>\n",
       "      <td>phosphofructokinase family protein</td>\n",
       "      <td>at1g12000</td>\n",
       "      <td></td>\n",
       "      <td>KO:K00895</td>\n",
       "      <td>EC:2.7.1.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ath</td>\n",
       "      <td>ko00010</td>\n",
       "      <td>path:ath00010\\tGlycolysis / Gluconeogenesis - ...</td>\n",
       "      <td>phosphofructokinase family protein</td>\n",
       "      <td>at1g20950</td>\n",
       "      <td></td>\n",
       "      <td>KO:K00895</td>\n",
       "      <td>EC:2.7.1.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ath</td>\n",
       "      <td>ko00010</td>\n",
       "      <td>path:ath00010\\tGlycolysis / Gluconeogenesis - ...</td>\n",
       "      <td>fbp|inositol monophosphatase family protein</td>\n",
       "      <td>at1g43670</td>\n",
       "      <td></td>\n",
       "      <td>KO:K03841</td>\n",
       "      <td>EC:3.1.3.11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   species pathway_id                                       pathway_name                                   gene_names    ncbi_id uniprot_id  ko_number    ec_number\n",
       "0      ath    ko00010  path:ath00010\\tGlycolysis / Gluconeogenesis - ...                       hkl3|hexokinase-like 3  at4g37840             KO:K00844   EC:2.7.1.1\n",
       "1      ath    ko00010  path:ath00010\\tGlycolysis / Gluconeogenesis - ...                            hxk3|hexokinase 3  at1g47840             KO:K00844   EC:2.7.1.1\n",
       "2      ath    ko00010  path:ath00010\\tGlycolysis / Gluconeogenesis - ...                            hxk2|hexokinase 2  at2g19860             KO:K00844   EC:2.7.1.1\n",
       "3      ath    ko00010  path:ath00010\\tGlycolysis / Gluconeogenesis - ...                            hxk1|hexokinase 1  at4g29130             KO:K00844   EC:2.7.1.1\n",
       "4      ath    ko00010  path:ath00010\\tGlycolysis / Gluconeogenesis - ...                       hkl1|hexokinase-like 1  at1g50460             KO:K00844   EC:2.7.1.1\n",
       "5      ath    ko00010  path:ath00010\\tGlycolysis / Gluconeogenesis - ...                            athxk4|hexokinase  at3g20040             KO:K00844   EC:2.7.1.1\n",
       "6      ath    ko00010  path:ath00010\\tGlycolysis / Gluconeogenesis - ...              pgi1|phosphoglucose isomerase 1  at4g24620             KO:K01810   EC:5.3.1.9\n",
       "7      ath    ko00010  path:ath00010\\tGlycolysis / Gluconeogenesis - ...         sugar isomerase (sis) family protein  at5g42740             KO:K01810   EC:5.3.1.9\n",
       "8      ath    ko00010  path:ath00010\\tGlycolysis / Gluconeogenesis - ...                   pfk6|phosphofructokinase 6  at4g32840             KO:K00850  EC:2.7.1.11\n",
       "9      ath    ko00010  path:ath00010\\tGlycolysis / Gluconeogenesis - ...                   pfk7|phosphofructokinase 7  at5g56630             KO:K00850  EC:2.7.1.11\n",
       "10     ath    ko00010  path:ath00010\\tGlycolysis / Gluconeogenesis - ...                   pfk4|phosphofructokinase 4  at5g61580             KO:K00850  EC:2.7.1.11\n",
       "11     ath    ko00010  path:ath00010\\tGlycolysis / Gluconeogenesis - ...                   pfk1|phosphofructokinase 1  at4g29220             KO:K00850  EC:2.7.1.11\n",
       "12     ath    ko00010  path:ath00010\\tGlycolysis / Gluconeogenesis - ...                   pfk5|phosphofructokinase 5  at2g22480             KO:K00850  EC:2.7.1.11\n",
       "13     ath    ko00010  path:ath00010\\tGlycolysis / Gluconeogenesis - ...                   pfk3|phosphofructokinase 3  at4g26270             KO:K00850  EC:2.7.1.11\n",
       "14     ath    ko00010  path:ath00010\\tGlycolysis / Gluconeogenesis - ...                   pfk2|phosphofructokinase 2  at5g47810             KO:K00850  EC:2.7.1.11\n",
       "15     ath    ko00010  path:ath00010\\tGlycolysis / Gluconeogenesis - ...           phosphofructokinase family protein  at1g76550             KO:K00895  EC:2.7.1.90\n",
       "16     ath    ko00010  path:ath00010\\tGlycolysis / Gluconeogenesis - ...     mee51|phosphofructokinase family protein  at4g04040             KO:K00895  EC:2.7.1.90\n",
       "17     ath    ko00010  path:ath00010\\tGlycolysis / Gluconeogenesis - ...           phosphofructokinase family protein  at1g12000             KO:K00895  EC:2.7.1.90\n",
       "18     ath    ko00010  path:ath00010\\tGlycolysis / Gluconeogenesis - ...           phosphofructokinase family protein  at1g20950             KO:K00895  EC:2.7.1.90\n",
       "19     ath    ko00010  path:ath00010\\tGlycolysis / Gluconeogenesis - ...  fbp|inositol monophosphatase family protein  at1g43670             KO:K03841  EC:3.1.3.11"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Readin in the dataset of groupings for pathways in KEGG.\n",
    "kegg_groups, kegg_mapped_ids = read_in_groupings_object_and_write_summary_tables(dataset, kegg_pathways_filename, \"kegg\")\n",
    "kegg_groups.to_pandas().head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"plantcyc\"></a>\n",
    "### Reading in and relating the pathways from PlantCyc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>species</th>\n",
       "      <th>pathway_id</th>\n",
       "      <th>pathway_name</th>\n",
       "      <th>gene_names</th>\n",
       "      <th>ec_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ath</td>\n",
       "      <td>PWY-5272</td>\n",
       "      <td>abscisic acid degradation by glucosylation</td>\n",
       "      <td>at1g52400-monomer|abscisic acid glucose ester ...</td>\n",
       "      <td>EC-3.2.1.175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ath</td>\n",
       "      <td>PWY-5272</td>\n",
       "      <td>abscisic acid degradation by glucosylation</td>\n",
       "      <td>at4g15550-monomer|abscisate &amp;beta;-glucosyltra...</td>\n",
       "      <td>EC-2.4.1.263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ath</td>\n",
       "      <td>PWY-5272</td>\n",
       "      <td>abscisic acid degradation by glucosylation</td>\n",
       "      <td>at4g15260-monomer|abscisate &amp;beta;-glucosyltra...</td>\n",
       "      <td>EC-2.4.1.263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ath</td>\n",
       "      <td>PWY-5272</td>\n",
       "      <td>abscisic acid degradation by glucosylation</td>\n",
       "      <td>at3g21790-monomer|abscisate &amp;beta;-glucosyltra...</td>\n",
       "      <td>EC-2.4.1.263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ath</td>\n",
       "      <td>PWY-5272</td>\n",
       "      <td>abscisic acid degradation by glucosylation</td>\n",
       "      <td>at3g21760-monomer|abscisate &amp;beta;-glucosyltra...</td>\n",
       "      <td>EC-2.4.1.263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ath</td>\n",
       "      <td>PWY-5272</td>\n",
       "      <td>abscisic acid degradation by glucosylation</td>\n",
       "      <td>at2g23210-monomer|abscisate &amp;beta;-glucosyltra...</td>\n",
       "      <td>EC-2.4.1.263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ath</td>\n",
       "      <td>PWY-5272</td>\n",
       "      <td>abscisic acid degradation by glucosylation</td>\n",
       "      <td>at1g05530-monomer|abscisic acid glucosyltransf...</td>\n",
       "      <td>EC-2.4.1.263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ath</td>\n",
       "      <td>PWY-5272</td>\n",
       "      <td>abscisic acid degradation by glucosylation</td>\n",
       "      <td>at1g05560-monomer|abscisic acid glucosyltransf...</td>\n",
       "      <td>EC-2.4.1.263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ath</td>\n",
       "      <td>PWY-5272</td>\n",
       "      <td>abscisic acid degradation by glucosylation</td>\n",
       "      <td>at4g34138-monomer|abscisic acid glucosyltransf...</td>\n",
       "      <td>EC-2.4.1.263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ath</td>\n",
       "      <td>PWY-5272</td>\n",
       "      <td>abscisic acid degradation by glucosylation</td>\n",
       "      <td>at2g23250-monomer|abscisic acid glucosyltransf...</td>\n",
       "      <td>EC-2.4.1.263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ath</td>\n",
       "      <td>PWY-5272</td>\n",
       "      <td>abscisic acid degradation by glucosylation</td>\n",
       "      <td>at2g23260-monomer|abscisic acid glucosyltransf...</td>\n",
       "      <td>EC-2.4.1.263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ath</td>\n",
       "      <td>PWY-5272</td>\n",
       "      <td>abscisic acid degradation by glucosylation</td>\n",
       "      <td>at3g21780-monomer|abscisic acid glycosyltransf...</td>\n",
       "      <td>EC-2.4.1.263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ath</td>\n",
       "      <td>OXIDATIVEPENT-PWY</td>\n",
       "      <td>pentose phosphate pathway (oxidative branch) I</td>\n",
       "      <td>at1g09420-monomer|glucose-6-phosphate dehydrog...</td>\n",
       "      <td>EC-1.1.1.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ath</td>\n",
       "      <td>OXIDATIVEPENT-PWY</td>\n",
       "      <td>pentose phosphate pathway (oxidative branch) I</td>\n",
       "      <td>at5g35790-monomer|glucose-6-phosphate 1-dehydr...</td>\n",
       "      <td>EC-1.1.1.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ath</td>\n",
       "      <td>OXIDATIVEPENT-PWY</td>\n",
       "      <td>pentose phosphate pathway (oxidative branch) I</td>\n",
       "      <td>at5g13110-monomer|glucose-6-phosphate 1-dehydr...</td>\n",
       "      <td>EC-1.1.1.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ath</td>\n",
       "      <td>OXIDATIVEPENT-PWY</td>\n",
       "      <td>pentose phosphate pathway (oxidative branch) I</td>\n",
       "      <td>at5g40760-monomer|glucose-6-phosphate 1-dehydr...</td>\n",
       "      <td>EC-1.1.1.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ath</td>\n",
       "      <td>OXIDATIVEPENT-PWY</td>\n",
       "      <td>pentose phosphate pathway (oxidative branch) I</td>\n",
       "      <td>at3g27300-monomer|glucose-6-phosphate 1-dehydr...</td>\n",
       "      <td>EC-1.1.1.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ath</td>\n",
       "      <td>OXIDATIVEPENT-PWY</td>\n",
       "      <td>pentose phosphate pathway (oxidative branch) I</td>\n",
       "      <td>at1g24280-monomer|glucose-6-phosphate 1-dehydr...</td>\n",
       "      <td>EC-1.1.1.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ath</td>\n",
       "      <td>OXIDATIVEPENT-PWY</td>\n",
       "      <td>pentose phosphate pathway (oxidative branch) I</td>\n",
       "      <td>at5g41670-monomer|phosphogluconate dehydrogena...</td>\n",
       "      <td>EC-1.1.1.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ath</td>\n",
       "      <td>OXIDATIVEPENT-PWY</td>\n",
       "      <td>pentose phosphate pathway (oxidative branch) I</td>\n",
       "      <td>at1g64190-monomer|phosphogluconate dehydrogena...</td>\n",
       "      <td>EC-1.1.1.44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   species         pathway_id                                    pathway_name                                         gene_names     ec_number\n",
       "0      ath           PWY-5272      abscisic acid degradation by glucosylation  at1g52400-monomer|abscisic acid glucose ester ...  EC-3.2.1.175\n",
       "1      ath           PWY-5272      abscisic acid degradation by glucosylation  at4g15550-monomer|abscisate &beta;-glucosyltra...  EC-2.4.1.263\n",
       "2      ath           PWY-5272      abscisic acid degradation by glucosylation  at4g15260-monomer|abscisate &beta;-glucosyltra...  EC-2.4.1.263\n",
       "3      ath           PWY-5272      abscisic acid degradation by glucosylation  at3g21790-monomer|abscisate &beta;-glucosyltra...  EC-2.4.1.263\n",
       "4      ath           PWY-5272      abscisic acid degradation by glucosylation  at3g21760-monomer|abscisate &beta;-glucosyltra...  EC-2.4.1.263\n",
       "5      ath           PWY-5272      abscisic acid degradation by glucosylation  at2g23210-monomer|abscisate &beta;-glucosyltra...  EC-2.4.1.263\n",
       "6      ath           PWY-5272      abscisic acid degradation by glucosylation  at1g05530-monomer|abscisic acid glucosyltransf...  EC-2.4.1.263\n",
       "7      ath           PWY-5272      abscisic acid degradation by glucosylation  at1g05560-monomer|abscisic acid glucosyltransf...  EC-2.4.1.263\n",
       "8      ath           PWY-5272      abscisic acid degradation by glucosylation  at4g34138-monomer|abscisic acid glucosyltransf...  EC-2.4.1.263\n",
       "9      ath           PWY-5272      abscisic acid degradation by glucosylation  at2g23250-monomer|abscisic acid glucosyltransf...  EC-2.4.1.263\n",
       "10     ath           PWY-5272      abscisic acid degradation by glucosylation  at2g23260-monomer|abscisic acid glucosyltransf...  EC-2.4.1.263\n",
       "11     ath           PWY-5272      abscisic acid degradation by glucosylation  at3g21780-monomer|abscisic acid glycosyltransf...  EC-2.4.1.263\n",
       "12     ath  OXIDATIVEPENT-PWY  pentose phosphate pathway (oxidative branch) I  at1g09420-monomer|glucose-6-phosphate dehydrog...   EC-1.1.1.49\n",
       "13     ath  OXIDATIVEPENT-PWY  pentose phosphate pathway (oxidative branch) I  at5g35790-monomer|glucose-6-phosphate 1-dehydr...   EC-1.1.1.49\n",
       "14     ath  OXIDATIVEPENT-PWY  pentose phosphate pathway (oxidative branch) I  at5g13110-monomer|glucose-6-phosphate 1-dehydr...   EC-1.1.1.49\n",
       "15     ath  OXIDATIVEPENT-PWY  pentose phosphate pathway (oxidative branch) I  at5g40760-monomer|glucose-6-phosphate 1-dehydr...   EC-1.1.1.49\n",
       "16     ath  OXIDATIVEPENT-PWY  pentose phosphate pathway (oxidative branch) I  at3g27300-monomer|glucose-6-phosphate 1-dehydr...   EC-1.1.1.49\n",
       "17     ath  OXIDATIVEPENT-PWY  pentose phosphate pathway (oxidative branch) I  at1g24280-monomer|glucose-6-phosphate 1-dehydr...   EC-1.1.1.49\n",
       "18     ath  OXIDATIVEPENT-PWY  pentose phosphate pathway (oxidative branch) I  at5g41670-monomer|phosphogluconate dehydrogena...   EC-1.1.1.44\n",
       "19     ath  OXIDATIVEPENT-PWY  pentose phosphate pathway (oxidative branch) I  at1g64190-monomer|phosphogluconate dehydrogena...   EC-1.1.1.44"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading in the dataset of groupings for pathways in PlantCyc.\n",
    "pmn_groups, pmn_mapped_ids = read_in_groupings_object_and_write_summary_tables(dataset, pmn_pathways_filename, \"pmn\")\n",
    "pmn_groups.to_pandas().head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"subsets\"></a>\n",
    "###  Reading in and relating the phenotype subsets from Lloyd and Meinke (2012)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>species</th>\n",
       "      <th>group_id</th>\n",
       "      <th>gene_names</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ath</td>\n",
       "      <td>FSM</td>\n",
       "      <td>at1g01030|nga3|top1|ngatha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ath</td>\n",
       "      <td>EMB|FSM|OVP|SRF</td>\n",
       "      <td>at1g01040|sus1|dcl1|sin1|caf|abnormal suspensor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ath</td>\n",
       "      <td>CDR|LIT</td>\n",
       "      <td>at1g01060|lhy|late elongated hypocotyl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ath</td>\n",
       "      <td>IST|WAT</td>\n",
       "      <td>at1g01120|kcs1|3-ketoacyl-coa synthase defective</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ath</td>\n",
       "      <td>OVP|SRF</td>\n",
       "      <td>at1g01280|cyp703a2|cytochrome p450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ath</td>\n",
       "      <td>EMB</td>\n",
       "      <td>at1g01370|cenh3|centromere-specific histone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ath</td>\n",
       "      <td>CHS</td>\n",
       "      <td>at1g01460|pipk11|phosphatidylinositol phosphat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ath</td>\n",
       "      <td>NLS|GRS|IST</td>\n",
       "      <td>at1g01480|acs2|aminocyclopropane carboxylate s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ath</td>\n",
       "      <td>LEF|FSM</td>\n",
       "      <td>at1g01510|an|angustifolia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ath</td>\n",
       "      <td>SRL|ROT|LEF|MSL|STT|RTH|TCM|TMP</td>\n",
       "      <td>at1g01550|bps1|bypass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ath</td>\n",
       "      <td>SRF</td>\n",
       "      <td>at1g01690|prd3|putative recombination initiati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ath</td>\n",
       "      <td>TMP</td>\n",
       "      <td>at1g01860|pfc1|paleface</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ath</td>\n",
       "      <td>ROT</td>\n",
       "      <td>at1g01950|ark2|armadillo repeat kinesin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ath</td>\n",
       "      <td>OVP</td>\n",
       "      <td>at1g02050|lap6|pksa|less adhesive pollen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ath</td>\n",
       "      <td>SRF</td>\n",
       "      <td>at1g02065|spl8|squamosa promoter binding prote...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ath</td>\n",
       "      <td>PIG|LIT</td>\n",
       "      <td>at1g02090|fus5|cop15|fusca</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ath</td>\n",
       "      <td>MSL|PTH</td>\n",
       "      <td>at1g02120|vad1|vascular-associated death</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ath</td>\n",
       "      <td>GAM</td>\n",
       "      <td>at1g02140|hap1|mago|mee63|hapless</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ath</td>\n",
       "      <td>IST|FSM|WAT</td>\n",
       "      <td>at1g02205|cer1|eceriferum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ath</td>\n",
       "      <td>PIG</td>\n",
       "      <td>at1g02280|ppi1|toc33|plastid protein import</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   species                         group_id                                         gene_names\n",
       "0      ath                              FSM                         at1g01030|nga3|top1|ngatha\n",
       "1      ath                  EMB|FSM|OVP|SRF    at1g01040|sus1|dcl1|sin1|caf|abnormal suspensor\n",
       "2      ath                          CDR|LIT             at1g01060|lhy|late elongated hypocotyl\n",
       "3      ath                          IST|WAT   at1g01120|kcs1|3-ketoacyl-coa synthase defective\n",
       "4      ath                          OVP|SRF                 at1g01280|cyp703a2|cytochrome p450\n",
       "5      ath                              EMB        at1g01370|cenh3|centromere-specific histone\n",
       "6      ath                              CHS  at1g01460|pipk11|phosphatidylinositol phosphat...\n",
       "7      ath                      NLS|GRS|IST  at1g01480|acs2|aminocyclopropane carboxylate s...\n",
       "8      ath                          LEF|FSM                          at1g01510|an|angustifolia\n",
       "9      ath  SRL|ROT|LEF|MSL|STT|RTH|TCM|TMP                              at1g01550|bps1|bypass\n",
       "10     ath                              SRF  at1g01690|prd3|putative recombination initiati...\n",
       "11     ath                              TMP                            at1g01860|pfc1|paleface\n",
       "12     ath                              ROT            at1g01950|ark2|armadillo repeat kinesin\n",
       "13     ath                              OVP           at1g02050|lap6|pksa|less adhesive pollen\n",
       "14     ath                              SRF  at1g02065|spl8|squamosa promoter binding prote...\n",
       "15     ath                          PIG|LIT                         at1g02090|fus5|cop15|fusca\n",
       "16     ath                          MSL|PTH           at1g02120|vad1|vascular-associated death\n",
       "17     ath                              GAM                  at1g02140|hap1|mago|mee63|hapless\n",
       "18     ath                      IST|FSM|WAT                          at1g02205|cer1|eceriferum\n",
       "19     ath                              PIG        at1g02280|ppi1|toc33|plastid protein import"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading in the datasets of phenotype subset classifications from the Lloyd, Meinke 2012 paper.\n",
    "phe_subsets_groups, subsets_mapped_ids = read_in_groupings_object_and_write_summary_tables(dataset, lloyd_subsets_filename, \"subsets\")\n",
    "phe_subsets_groups.to_pandas().head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"classes\"></a>\n",
    "### Reading in and relating the phenotype subsets from Lloyd and Meinke (2012)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>species</th>\n",
       "      <th>group_id</th>\n",
       "      <th>gene_names</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ath</td>\n",
       "      <td>R</td>\n",
       "      <td>at1g01030|nga3|top1|ngatha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ath</td>\n",
       "      <td>S</td>\n",
       "      <td>at1g01040|sus1|dcl1|sin1|caf|abnormal suspensor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ath</td>\n",
       "      <td>T</td>\n",
       "      <td>at1g01060|lhy|late elongated hypocotyl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ath</td>\n",
       "      <td>V</td>\n",
       "      <td>at1g01120|kcs1|3-ketoacyl-coa synthase defective</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ath</td>\n",
       "      <td>R</td>\n",
       "      <td>at1g01280|cyp703a2|cytochrome p450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ath</td>\n",
       "      <td>S</td>\n",
       "      <td>at1g01370|cenh3|centromere-specific histone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ath</td>\n",
       "      <td>H</td>\n",
       "      <td>at1g01460|pipk11|phosphatidylinositol phosphat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ath</td>\n",
       "      <td>V</td>\n",
       "      <td>at1g01480|acs2|aminocyclopropane carboxylate s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ath</td>\n",
       "      <td>V</td>\n",
       "      <td>at1g01510|an|angustifolia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ath</td>\n",
       "      <td>L</td>\n",
       "      <td>at1g01550|bps1|bypass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ath</td>\n",
       "      <td>R</td>\n",
       "      <td>at1g01690|prd3|putative recombination initiati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ath</td>\n",
       "      <td>P</td>\n",
       "      <td>at1g01860|pfc1|paleface</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ath</td>\n",
       "      <td>V</td>\n",
       "      <td>at1g01950|ark2|armadillo repeat kinesin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ath</td>\n",
       "      <td>R</td>\n",
       "      <td>at1g02050|lap6|pksa|less adhesive pollen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ath</td>\n",
       "      <td>R</td>\n",
       "      <td>at1g02065|spl8|squamosa promoter binding prote...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ath</td>\n",
       "      <td>V</td>\n",
       "      <td>at1g02090|fus5|cop15|fusca</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ath</td>\n",
       "      <td>V</td>\n",
       "      <td>at1g02120|vad1|vascular-associated death</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ath</td>\n",
       "      <td>G</td>\n",
       "      <td>at1g02140|hap1|mago|mee63|hapless</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ath</td>\n",
       "      <td>V</td>\n",
       "      <td>at1g02205|cer1|eceriferum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ath</td>\n",
       "      <td>V</td>\n",
       "      <td>at1g02280|ppi1|toc33|plastid protein import</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   species group_id                                         gene_names\n",
       "0      ath        R                         at1g01030|nga3|top1|ngatha\n",
       "1      ath        S    at1g01040|sus1|dcl1|sin1|caf|abnormal suspensor\n",
       "2      ath        T             at1g01060|lhy|late elongated hypocotyl\n",
       "3      ath        V   at1g01120|kcs1|3-ketoacyl-coa synthase defective\n",
       "4      ath        R                 at1g01280|cyp703a2|cytochrome p450\n",
       "5      ath        S        at1g01370|cenh3|centromere-specific histone\n",
       "6      ath        H  at1g01460|pipk11|phosphatidylinositol phosphat...\n",
       "7      ath        V  at1g01480|acs2|aminocyclopropane carboxylate s...\n",
       "8      ath        V                          at1g01510|an|angustifolia\n",
       "9      ath        L                              at1g01550|bps1|bypass\n",
       "10     ath        R  at1g01690|prd3|putative recombination initiati...\n",
       "11     ath        P                            at1g01860|pfc1|paleface\n",
       "12     ath        V            at1g01950|ark2|armadillo repeat kinesin\n",
       "13     ath        R           at1g02050|lap6|pksa|less adhesive pollen\n",
       "14     ath        R  at1g02065|spl8|squamosa promoter binding prote...\n",
       "15     ath        V                         at1g02090|fus5|cop15|fusca\n",
       "16     ath        V           at1g02120|vad1|vascular-associated death\n",
       "17     ath        G                  at1g02140|hap1|mago|mee63|hapless\n",
       "18     ath        V                          at1g02205|cer1|eceriferum\n",
       "19     ath        V        at1g02280|ppi1|toc33|plastid protein import"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading in the datasets of phenotype class classifications from the Lloyd, Meinke 2012 paper.\n",
    "phe_classes_groups, classes_mapped_ids = read_in_groupings_object_and_write_summary_tables(dataset, lloyd_classes_filename, \"classes\")\n",
    "phe_classes_groups.to_pandas().head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relating pairs of genes to information about network edges from other sources\n",
    "This is done to only include genes (and the corresponding phenotype descriptions and annotations) which are useful for the current analysis. In this case we want to only retain genes that are mentioned atleast one time in the STRING database for a given species. If a gene is not mentioned at all in STRING, there is no information available for whether or not it interacts with any other proteins in the dataset so choose to not include it in the analysis. Only genes that have atleast one true positive are included because these are the only ones for which the missing information (negatives) is meaningful. This should be run instead of the subsequent cell, or the other way around, based on whether or not protein-protein interactions is the prediction goal for the current analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"eqs\"></a>\n",
    "### EQ-based similarities from Oellrich, Walls et al., (2015)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>from</th>\n",
       "      <th>to</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1812</td>\n",
       "      <td>1777</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1812</td>\n",
       "      <td>1818</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1812</td>\n",
       "      <td>440</td>\n",
       "      <td>0.926471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1812</td>\n",
       "      <td>1745</td>\n",
       "      <td>0.516393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1812</td>\n",
       "      <td>1816</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1812</td>\n",
       "      <td>2011</td>\n",
       "      <td>0.954545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1812</td>\n",
       "      <td>2035</td>\n",
       "      <td>0.417219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1812</td>\n",
       "      <td>1773</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1812</td>\n",
       "      <td>1872</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1812</td>\n",
       "      <td>502</td>\n",
       "      <td>0.900000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   from    to     value\n",
       "0  1812  1777  1.000000\n",
       "1  1812  1818  1.000000\n",
       "2  1812   440  0.926471\n",
       "3  1812  1745  0.516393\n",
       "4  1812  1816  1.000000\n",
       "5  1812  2011  0.954545\n",
       "6  1812  2035  0.417219\n",
       "7  1812  1773  1.000000\n",
       "8  1812  1872  1.000000\n",
       "9  1812   502  0.900000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ow_edgelist = AnyInteractions(dataset.get_name_to_id_dictionary(), pppn_edgelist_path)\n",
    "ow_edgelist.df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"string\"></a>\n",
    "### Protein associations from STRING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>from</th>\n",
       "      <th>to</th>\n",
       "      <th>known_associations</th>\n",
       "      <th>predicted_associations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>73.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>161</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>73.0</td>\n",
       "      <td>937.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>73.0</td>\n",
       "      <td>4705.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>73.0</td>\n",
       "      <td>4364.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>73.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>73.0</td>\n",
       "      <td>4185.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>73.0</td>\n",
       "      <td>470.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>73.0</td>\n",
       "      <td>5132.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>73.0</td>\n",
       "      <td>5415.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>73.0</td>\n",
       "      <td>4410.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     from      to  known_associations  predicted_associations\n",
       "346  73.0    49.0                 161                       0\n",
       "348  73.0   937.0                   0                       0\n",
       "351  73.0  4705.0                   0                       0\n",
       "352  73.0  4364.0                   0                       0\n",
       "353  73.0   131.0                   0                       0\n",
       "355  73.0  4185.0                   0                       0\n",
       "357  73.0   470.0                   0                       0\n",
       "358  73.0  5132.0                   0                       0\n",
       "359  73.0  5415.0                   0                       0\n",
       "360  73.0  4410.0                   0                       0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naming_file = \"../data/group_related_files/string/all_organisms.name_2_string.tsv\"\n",
    "interaction_files = [\n",
    "    \"../data/group_related_files/string/3702.protein.links.detailed.v11.0.txt\", # Arabidopsis\n",
    "    \"../data/group_related_files/string/4577.protein.links.detailed.v11.0.txt\", # Maize\n",
    "    \"../data/group_related_files/string/4530.protein.links.detailed.v11.0.txt\", # Tomato \n",
    "    \"../data/group_related_files/string/4081.protein.links.detailed.v11.0.txt\", # Medicago\n",
    "    \"../data/group_related_files/string/3880.protein.links.detailed.v11.0.txt\", # Rice \n",
    "    \"../data/group_related_files/string/3847.protein.links.detailed.v11.0.txt\", # Soybean\n",
    "]\n",
    "genes = dataset.get_gene_dictionary()\n",
    "string_edgelist = ProteinInteractions(genes, naming_file, *interaction_files)\n",
    "string_edgelist.df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"panther\"></a>\n",
    "### Orthologous genes from PANTHER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>from</th>\n",
       "      <th>to</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>692</th>\n",
       "      <td>565.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788</th>\n",
       "      <td>1075.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179180</th>\n",
       "      <td>1876.0</td>\n",
       "      <td>1876.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190004</th>\n",
       "      <td>3006.0</td>\n",
       "      <td>2382.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192404</th>\n",
       "      <td>1665.0</td>\n",
       "      <td>1845.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198820</th>\n",
       "      <td>3832.0</td>\n",
       "      <td>4542.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413820</th>\n",
       "      <td>3847.0</td>\n",
       "      <td>425.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415020</th>\n",
       "      <td>2532.0</td>\n",
       "      <td>1142.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431292</th>\n",
       "      <td>3620.0</td>\n",
       "      <td>2199.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470160</th>\n",
       "      <td>2520.0</td>\n",
       "      <td>571.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          from      to  value\n",
       "692      565.0    23.0    1.0\n",
       "788     1075.0    23.0    1.0\n",
       "179180  1876.0  1876.0    1.0\n",
       "190004  3006.0  2382.0    1.0\n",
       "192404  1665.0  1845.0    1.0\n",
       "198820  3832.0  4542.0    1.0\n",
       "413820  3847.0   425.0    1.0\n",
       "415020  2532.0  1142.0    1.0\n",
       "431292  3620.0  2199.0    1.0\n",
       "470160  2520.0   571.0    1.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "panther_edgelist = AnyInteractions(dataset.get_name_to_id_dictionary(), ortholog_file_path)\n",
    "panther_edgelist.df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"filtering\"></a>\n",
    "### Subsetting the dataset to include only genes with relevance to any of the biological questions\n",
    "This is done to only include genes (and the corresponding phenotype descriptions and annotations) which are useful for the current analysis. In this case we want to only retain genes that are mapped to atleast one pathway in whatever the source of pathway membership we are using is (KEGG, Plant Metabolic Network, etc). This is because for these genes, it will be impossible to correctly predict their pathway membership, and we have no evidence that they belong or do not belong in certain pathways so they can not be identified as being true or false negatives in any case. This should not actually be necessary if the dataset used to start the notebook analysis has already be subset for just the genes that either have pathway information of phenotype classification information, this should just be used to double check that the numbers make sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the list of all the IDs in this dataset that have any relevant mapping at all to the biological questions.\n",
    "ids_with_any_mapping = list(set(flatten([\n",
    "    kegg_mapped_ids,\n",
    "    pmn_mapped_ids,\n",
    "    subsets_mapped_ids,\n",
    "    classes_mapped_ids,\n",
    "    string_edgelist.ids,\n",
    "    panther_edgelist.ids\n",
    "])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the list of all the IDs in this dataset that have all of types of curated values we want to look at. \n",
    "annots = dataset.get_annotations_dictionary()\n",
    "go_mapped_ids = [i for i in dataset.get_ids() if \"GO\" in annots[i]]\n",
    "po_mapped_ids = [i for i in dataset.get_ids() if \"PO\" in annots[i]]\n",
    "ids_with_all_annotations = list(set(flatten([\n",
    "    go_mapped_ids,\n",
    "    po_mapped_ids,\n",
    "    ow_edgelist.ids\n",
    "])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>species</th>\n",
       "      <th>num_genes</th>\n",
       "      <th>unique_descriptions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ath</td>\n",
       "      <td>422</td>\n",
       "      <td>378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mtr</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>osa</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sly</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>zma</td>\n",
       "      <td>59</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>total</td>\n",
       "      <td>500</td>\n",
       "      <td>451</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  species  num_genes  unique_descriptions\n",
       "0     ath        422                  378\n",
       "1     mtr          3                    3\n",
       "2     osa         13                   12\n",
       "3     sly          3                    3\n",
       "4     zma         59                   55\n",
       "5   total        500                  451"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.filter_with_ids(ids_with_any_mapping)\n",
    "#dataset.filter_random_k(500)\n",
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"part_2\"></a>\n",
    "# Part 2. NLP Models\n",
    "\n",
    "\n",
    "<a id=\"word2vec_doc2vec\"></a>\n",
    "### Word2Vec and Doc2Vec\n",
    "Word2Vec is a word embedding technique using a neural network trained on a so-called *false task*, namely either predicting a missing word from within a sequence of context words drawn from a sentence or phrase, or predicting which contexts words surround some given input word drawn from a sentence or phrase. Each of these tasks are supervised (the correct answer is fixed and known), but can be generated from unlabelled text data such as a collection of books or wikipedia articles, meaning that even though the task itself is supervised the training data can be generated automatically, enabling the creation of enormous training sets. The internal representation for particular words learned during the training process contain semantically informative features related to that given word, and can therefore be used as embeddings used downstream for tasks such as finding similarity between words or as input into additional models. Doc2Vec is an extension of this technique that determines vector embeddings for entire documents (strings containing multiple words, could be sentences, paragraphs, or documents).\n",
    "\n",
    "\n",
    "<a id=\"bert_biobert\"></a>\n",
    "### BERT and BioBERT\n",
    "BERT ('Bidirectional Encoder Representations from Transformers') is another neueral network-based model trained on two different false tasks, namely predicting the subsequent sentence given some input sentence, or predicting the identity of a set of words masked from an input sentence. Like Word2Vec, this architecture can be used to generate vector embeddings for a particular input word by extracting values from a subset of the encoder layers that correspond to that input word. Practically, a major difference is that because the input word is input in the context of its surrounding sentence, the embedding reflects the meaning of a particular word in a particular context (such as the difference in the meaning of *root* in the phrases *plant root* and *root of the problem*. BioBERT refers to a set of BERT models which have been finetuned on the PubMed and PMC corpora. See the list of relevant links for the publications and pages associated with these models.\n",
    "\n",
    "<a id=\"load_models\"></a>\n",
    "### Loading trained and saved models\n",
    "Versions of the architectures discussed above which have been saved as trained models are loaded here. Some of these models are loaded as pretrained models from the work of other groups, and some were trained on data specific to this notebook and loaded here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Files and models related to the machine learning text embedding methods used here.\n",
    "doc2vec_wiki_model = gensim.models.Doc2Vec.load(doc2vec_wikipedia_filename)\n",
    "doc2vec_pubmed_model = gensim.models.Doc2Vec.load(doc2vec_pubmed_filename)\n",
    "word2vec_model = gensim.models.Word2Vec.load(word2vec_model_filename)\n",
    "bert_tokenizer_base = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "bert_tokenizer_pmc = BertTokenizer.from_pretrained(biobert_pmc_path)\n",
    "bert_tokenizer_pubmed = BertTokenizer.from_pretrained(biobert_pubmed_path)\n",
    "bert_tokenizer_pubmed_pmc = BertTokenizer.from_pretrained(biobert_pubmed_pmc_path)\n",
    "bert_model_base = BertModel.from_pretrained('bert-base-uncased')\n",
    "bert_model_pmc = BertModel.from_pretrained(biobert_pmc_path)\n",
    "bert_model_pubmed = BertModel.from_pretrained(biobert_pubmed_path)\n",
    "bert_model_pubmed_pmc = BertModel.from_pretrained(biobert_pubmed_pmc_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading in the descriptions from hand-picked dataset of phenotype pairs\n",
    "See the other notebook for the creation of this dataset. This is included in this notebook instead of a separated notebook because we want the treatment of the individual phenotype text instances to be the same as is done for the descriptions from the real dataset of plant phenotypes. The list of computational approaches being evaluated for this task is the same in both cases so all of the cells between the point where the descriptions are read in and when the distance matrices are found using all those methods are the same for this task as any of the biological questions that this notebook is focused on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the table of similarity scored phenotype pairs that was prepared from random selection.\n",
    "num_pairs = 50\n",
    "mupdata = pd.read_csv(paired_phenotypes_path)\n",
    "assert num_pairs == mupdata.shape[0]\n",
    "paired_descriptions = mupdata[\"Phenotype 1\"].values.tolist()\n",
    "paired_descriptions.extend(mupdata[\"Phenotype 2\"].values.tolist())\n",
    "first_paired_id = 0\n",
    "paired_descriptions = {i:description for i,description in enumerate(paired_descriptions, first_paired_id)}\n",
    "pair_to_score = {(i,i+num_pairs):s for i,s in enumerate(mupdata[\"Score\"].values, first_paired_id)}\n",
    "paired_ids = list(paired_descriptions.keys())\n",
    "\n",
    "# Set the descriptions to be used to be these from the paired phenotypes dataset.\n",
    "# This will only matter if running this in the context of the notebook and skipping the other steps.\n",
    "# Otherwise the descriptions dictionary will be reset to be the descriptions from the full dataset.\n",
    "descriptions = paired_descriptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"part_3\"></a>\n",
    "# Part 3. NLP Choices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain a mapping between IDs and the raw text descriptions associated with that ID from the dataset.\n",
    "descriptions = dataset.get_description_dictionary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_id_to_unique_ids_mappings = defaultdict(lambda: defaultdict(list))\n",
    "unique_id_to_gene_ids_mappings = defaultdict(lambda: defaultdict(list))\n",
    "\n",
    "# NOTE THAT FOR THE UNTOKENIZED (WHOLE DOC) ONES, THERE SHOULD ONLY BE ONE ENTRY IN THE LIST\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# THESE NEED TO BE POPULATED. THESE ARE USED WAY BELOW AFTER THE DISTANCE MATRICES ARE GENERATED AND THROUGHOUT.\n",
    "#gene_id_to_whole_unique_id = {}\n",
    "#gene_id_to_tokenized_unique_id_list = defaultdict(list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mapping to unique text strings for whole genes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a mapping between a new unique identifier and unique description strings that are not sentence tokenized.\n",
    "unique_id_to_unique_text = {i:text for i,text in enumerate(list(set(descriptions.values())))}\n",
    "_reverse_of_that_mapping = {text:i for i,text in unique_id_to_unique_text.items()}\n",
    "\n",
    "# Get a mapping between the original gene IDs from this dataset and the corresponding ID for unique text strings.\n",
    "gene_id_to_unique_ids_mappings[\"whole_texts\"] = {i:[_reverse_of_that_mapping[text]] for i,text in descriptions.items()}\n",
    "whole_unique_ids = list(unique_id_to_unique_text.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mapping to unique text strings that have been tokenized by sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_tokenized_descriptions = {i:sent_tokenize(d) for i,d in descriptions.items()}\n",
    "unique_sents = list(set(flatten(sent_tokenized_descriptions.values())))\n",
    "largest_whole_unique_id = max(whole_unique_ids)\n",
    "unique_id_to_unique_sent = {i:text for i,text in enumerate(unique_sents,largest_whole_unique_id+1)}\n",
    "_reverse_of_that_mapping = {text:i for i,text in unique_id_to_unique_sent.items()}\n",
    "\n",
    "for i, sent_list in sent_tokenized_descriptions.items():\n",
    "    for sent in sent_list:\n",
    "        gene_id_to_unique_ids_mappings[\"sent_tokens\"][i].append(_reverse_of_that_mapping[sent])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Establishing which dictionaries will be used for preprocessing text next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What should 'descriptions' be for the sake of doing batch pre-processing?\n",
    "descriptions = {}\n",
    "descriptions.update(unique_id_to_unique_text)\n",
    "descriptions.update(unique_id_to_unique_sent)\n",
    "assert len(descriptions) == len(unique_id_to_unique_text) + len(unique_id_to_unique_sent)\n",
    "\n",
    "# Which of the IDs that were created for unique text strings are for whole descriptions, and which are for sentences?\n",
    "unique_whole_ids = list(unique_id_to_unique_text.keys())\n",
    "unique_tokenized_ids = list(unique_id_to_unique_sent.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"preprocessing\"></a>\n",
    "### Preprocessing text descriptions\n",
    "The preprocessing methods applied to the phenotype descriptions are a choice which impacts the subsequent vectorization and similarity methods which construct the pairwise distance matrix from each of these descriptions. The preprocessing methods that make sense are also highly dependent on the vectorization method or embedding method that is to be applied. For example, stemming (which is part of the full proprocessing done below using the Gensim preprocessing function) is useful for the n-grams and bag-of-words methods but not for the document embeddings methods which need each token to be in the vocabulary that was constructed and used when the model was trained. For this reason, embedding methods with pretrained models where the vocabulary is fixed should have a lighter degree of preprocessing not involving stemming or lemmatization but should involve things like removal of non-alphanumerics and normalizing case. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Applying canned prepreprocessing approaches to the descriptions.\n",
    "processed = defaultdict(dict)\n",
    "processed[\"simple\"] = {i:\" \".join(simple_preprocess(d)) for i,d in descriptions.items()}\n",
    "processed[\"simple_no_stops\"] = {i:remove_stopwords(\" \".join(simple_preprocess(d))) for i,d in descriptions.items()}\n",
    "processed[\"full\"] = {i:\" \".join(preprocess_string(d)) for i,d in descriptions.items()}\n",
    "\n",
    "# Set of stopwords, used later for checking it tokens in a list are stopwords or not.\n",
    "stop_words = set(stopwords.words('english')) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"pos_tagging\"></a>\n",
    "### POS tagging the phenotype descriptions for nouns and adjectives\n",
    "Note that preprocessing of the descriptions should be done after part-of-speech tagging, because tokens that are removed during preprocessing before n-gram analysis contain information that the parser needs to accurately call parts-of-speech. This step should be done on the raw descriptions and then the resulting bags of words can be subset using additional preprocesssing steps before input in one of the vectorization methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_pos_tokens = lambda text,pos: \" \".join([t[0] for t in nltk.pos_tag(word_tokenize(text)) if t[1].lower()==pos.lower()])\n",
    "processed[\"nouns\"] =  {i:get_pos_tokens(d,\"NN\") for i,d in descriptions.items()}\n",
    "processed[\"nouns_full\"] = {i:\" \".join(preprocess_string(d)) for i,d in processed[\"nouns\"].items()}\n",
    "processed[\"nouns_simple\"] = {i:\" \".join(simple_preprocess(d)) for i,d in processed[\"nouns\"].items()}\n",
    "processed[\"adjectives\"] =  {i:get_pos_tokens(d,\"JJ\") for i,d in descriptions.items()}\n",
    "processed[\"adjectives_full\"] = {i:\" \".join(preprocess_string(d)) for i,d in processed[\"adjectives\"].items()}\n",
    "processed[\"adjectives_simple\"] = {i:\" \".join(simple_preprocess(d)) for i,d in processed[\"adjectives\"].items()}\n",
    "processed[\"nouns_adjectives\"] = {i:\"{} {}\".format(processed[\"nouns\"][i],processed[\"adjectives\"][i]) for i in descriptions.keys()}\n",
    "processed[\"nouns_adjectives_full\"] = {i:\"{} {}\".format(processed[\"nouns_full\"][i],processed[\"adjectives_full\"][i]) for i in descriptions.keys()}\n",
    "processed[\"nouns_adjectives_simple\"] = {i:\"{} {}\".format(processed[\"nouns_simple\"][i],processed[\"adjectives_simple\"][i]) for i in descriptions.keys()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reducing vocabulary size based on identifying important words\n",
    "These approcahes for reducing the vocabulary size of the dataset work by identifying which words in the descriptions are likely to be the most important for identifying differences between the phenotypes and meaning of the descriptions. One approach is to determine which words occur at a higher rate in text of interest such as articles about plant phenotypes as compared to their rates in more general texts such as a corpus of news articles. These approaches do not create modified versions of the descriptions but rather provide vocabulary objects that can be passed to the sklearn vectorizer or constructors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create ontology objects for all the biological ontologies being used.\n",
    "pato = Ontology(pato_filename)\n",
    "po = Ontology(po_filename)\n",
    "go = Ontology(go_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting sets of tokens that are part of bio ontology term labels or synonyms.\n",
    "bio_ontology_tokens = list(set(po.tokens()).union(set(go.tokens())))\n",
    "bio_ontology_tokens = [t for t in bio_ontology_tokens if t not in stop_words]\n",
    "bio_ontology_tokens_simple = flatten([simple_preprocess(t) for t in bio_ontology_tokens])\n",
    "bio_ontology_tokens_full = flatten([preprocess_string(t) for t in bio_ontology_tokens])\n",
    "with open(os.path.join(OUTPUT_DIR,\"part_3_bio_ontology_vocab_size_{}.txt\".format(len(bio_ontology_tokens))),\"w\") as f:\n",
    "    f.write(\" \".join(bio_ontology_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting sets of tokens that are overprepresented in plant phenotype papers as compared to some background corpus.\n",
    "maximum_number_of_tokens = 10000\n",
    "background_corpus = open(background_corpus_filename,\"r\").read()\n",
    "phenotypes_corpus = open(phenotypes_corpus_filename,\"r\").read()\n",
    "ppp_overrepresented_tokens = get_overrepresented_tokens(phenotypes_corpus, background_corpus, max_features=maximum_number_of_tokens)\n",
    "ppp_overrepresented_tokens = [t for t in ppp_overrepresented_tokens if t not in stop_words]\n",
    "ppp_overrepresented_tokens_simple = flatten([simple_preprocess(t) for t in ppp_overrepresented_tokens])\n",
    "ppp_overrepresented_tokens_full = flatten([preprocess_string(t) for t in ppp_overrepresented_tokens])\n",
    "with open(os.path.join(OUTPUT_DIR,\"part_3_plant_phenotype_vocab_size_{}.txt\".format(len(ppp_overrepresented_tokens))), \"w\") as f:\n",
    "    f.write(\" \".join(ppp_overrepresented_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating processed description entries by subsetting tokens to only include ones from these vocabularies.\n",
    "ppp_overrepresented_tokens_full_set = set(ppp_overrepresented_tokens_full)\n",
    "bio_ontology_tokens_full_set = set(bio_ontology_tokens_full)\n",
    "processed[\"plant_overrepresented_tokens\"] = {i:\" \".join([token for token in word_tokenize(text) if token in ppp_overrepresented_tokens_full_set]) for i,text in processed[\"full\"].items()}\n",
    "processed[\"bio_ontology_tokens\"] = {i:\" \".join([token for token in word_tokenize(text) if token in bio_ontology_tokens_full_set]) for i,text in processed[\"full\"].items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"vocab\"></a>\n",
    "### Reducing the vocabulary size using a word distance matrix\n",
    "These approaches for reducing the vocabulary size of the dataset work by replacing multiple words that occur throughout the dataset of descriptions with an identical word that is representative of this larger group of words. The total number of unique words across all descriptions is therefore reduced, and when observing n-gram overlaps between vector representations of these descriptions, overlaps will now occur between descriptions that included different but similar words. These methods work by actually generating versions of these descriptions that have the word replacements present. The returned objects for these methods are the revised description dictionary, a dictionary mapping tokens in the full vocabulary to tokens in the reduced vocabulary, and a dictionary mapping tokens in the reduced vocabulary to a list of tokens in the full vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Generate a pairwise distance matrix object using the oats subpackage, and create an appropriately shaped matrix,\n",
    "# making sure that the tokens list is in the same order as the indices representing each word in the distance matrix.\n",
    "# This is currently triviala because the IDs that are used are ordered integers 0 to n, but this might not always be\n",
    "# the case so it's not directly assumed here.\n",
    "tokens = list(set([w for w in flatten(d.split() for d in processed[\"simple\"].values())]))\n",
    "tokens_dict = {i:w for i,w in enumerate(tokens)}\n",
    "graph = pw.pairwise_square_word2vec(word2vec_model, tokens_dict, \"cosine\")\n",
    "distance_matrix = graph.array\n",
    "tokens = [tokens_dict[graph.index_to_id[index]] for index in np.arange(distance_matrix.shape[0])]\n",
    "\n",
    "# The other argument that the Linares Pontes algorithm needs is a value for n, see paper or description above.\n",
    "n = 3\n",
    "processed[\"linares_pontes\"], reduce_lp, unreduce_lp = reduce_vocab_linares_pontes(processed[\"simple\"], tokens, distance_matrix, n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"annotation\"></a>\n",
    "### Annotating descriptions with ontology terms\n",
    "This section generates dictionaries that map gene IDs from the dataset to lists of strings, where those strings are ontology term IDs. How the term IDs are found for each gene entry with its corresponding phenotype description depends on the cell below. Firstly, the terms are found by using the NOBLE Coder annotation tool through these wrapper functions to identify the terms by looking for instances of the term's label or synonyms in the actual text of the phenotype descriptions. Secondly, the next cell just draws the terms directly from the dataset itself. In this case, these are high-confidence annotations done by curators for a comparison against what can be accomplished through computational analysis of the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the NOBLE Coder annotator over the raw input text descriptions, which handles things like case normalization.\n",
    "direct_annots_nc_go_precise = annotate_using_noble_coder(descriptions, noblecoder_jarfile_path, \"go\", precise=1)\n",
    "direct_annots_nc_go_partial = annotate_using_noble_coder(descriptions, noblecoder_jarfile_path, \"go\", precise=0)\n",
    "direct_annots_nc_po_precise = annotate_using_noble_coder(descriptions, noblecoder_jarfile_path, \"po\", precise=1)\n",
    "direct_annots_nc_po_partial = annotate_using_noble_coder(descriptions, noblecoder_jarfile_path, \"po\", precise=0)\n",
    "direct_annots_nc_pato_precise = annotate_using_noble_coder(descriptions, noblecoder_jarfile_path, \"pato\", precise=1)\n",
    "direct_annots_nc_pato_partial = annotate_using_noble_coder(descriptions, noblecoder_jarfile_path, \"pato\", precise=0)\n",
    "\n",
    "# Use the ontology hierarchies to add terms that are inherited by the terms that were annotated to the text.\n",
    "inherited_annots_nc_go_precise = {i:go.inherited(term_id_list) for i,term_id_list in direct_annots_nc_go_precise.items()}\n",
    "inherited_annots_nc_go_partial = {i:go.inherited(term_id_list) for i,term_id_list in direct_annots_nc_go_partial.items()}\n",
    "inherited_annots_nc_po_precise = {i:po.inherited(term_id_list) for i,term_id_list in direct_annots_nc_po_precise.items()}\n",
    "inherited_annots_nc_po_partial = {i:po.inherited(term_id_list) for i,term_id_list in direct_annots_nc_po_partial.items()}\n",
    "inherited_annots_nc_pato_precise = {i:pato.inherited(term_id_list) for i,term_id_list in direct_annots_nc_pato_precise.items()}\n",
    "inherited_annots_nc_pato_partial = {i:pato.inherited(term_id_list) for i,term_id_list in direct_annots_nc_pato_partial.items()}\n",
    "\n",
    "# Merge the ontology term annotations for each descritpion into a single dictionary for the precise and partial levels.\n",
    "all_precise_annotations = {i:flatten([inherited_annots_nc_go_precise[i],inherited_annots_nc_po_precise[i],inherited_annots_nc_pato_precise[i]]) for i in descriptions.keys()}\n",
    "all_partial_annotations = {i:flatten([inherited_annots_nc_go_partial[i],inherited_annots_nc_po_partial[i],inherited_annots_nc_pato_partial[i]]) for i in descriptions.keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treating these sets of inherited ontology terms as tokens so that they can be used as n-grams.\n",
    "processed[\"precise_annotations\"] = {i:\" \".join(annots) for i,annots in all_precise_annotations.items()}\n",
    "processed[\"partial_annotations\"] = {i:\" \".join(annots) for i,annots in all_partial_annotations.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create description strings with all ontology term anntotations concatenated to the end of the descriptions.\n",
    "processed[\"simple_plus_precise_annotations\"] = {i:\" \".join(flatten([text,all_precise_annotations[i]])) for i,text in processed[\"simple\"].items()}\n",
    "processed[\"simple_plus_partial_annotations\"] = {i:\" \".join(flatten([text,all_partial_annotations[i]])) for i,text in processed[\"simple\"].items()}\n",
    "processed[\"full_plus_precise_annotations\"] = {i:\" \".join(flatten([text,all_precise_annotations[i]])) for i,text in processed[\"full\"].items()}\n",
    "processed[\"full_plus_partial_annotations\"] = {i:\" \".join(flatten([text,all_partial_annotations[i]])) for i,text in processed[\"full\"].items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create ontology term annotations dictionaries for all the high confidence annotations present in the dataset.\n",
    "curated_go_annotations = dataset.get_annotations_dictionary(\"GO\")\n",
    "curated_po_annotations = dataset.get_annotations_dictionary(\"PO\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize GO and PO curator annotated ontology terms and map from those to gene identifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a mapping between GO term IDs (like GO:0001234) and the list of gene IDs in this dataset they were annotated to.\n",
    "go_term_to_gene_ids = defaultdict(list)\n",
    "for gene_id, term_list, in curated_go_annotations.items():\n",
    "    for term in term_list: \n",
    "        go_term_to_gene_ids[term].append(gene_id)\n",
    "        \n",
    "# Create a mapping between a new unique identifer for each unique term used and a list with one item, the given term.\n",
    "individual_curated_go_terms = {i:[t] for i,t in enumerate(go_term_to_gene_ids.keys())}  \n",
    "_reverse_mapping = {t[0]:i for i,t in individual_curated_go_terms.items()}\n",
    "gene_id_to_unique_ids_mappings[\"go_terms\"] = {i:[_reverse_mapping[t] for t in terms] for i,terms in curated_go_annotations.items()}\n",
    "\n",
    "# What about genes that don't have any GO terms annotated to them by a curator? That should be accounted for.\n",
    "unique_id_for_emtpy_annotation_list = max(list(individual_curated_go_terms.keys()))+1\n",
    "individual_curated_go_terms[unique_id_for_emtpy_annotation_list] = []\n",
    "for gene_id,uid_list in gene_id_to_unique_ids_mappings[\"go_terms\"].items():\n",
    "    if len(uid_list) == 0:\n",
    "        gene_id_to_unique_ids_mappings[\"go_terms\"][gene_id].append(unique_id_for_emtpy_annotation_list)\n",
    "        \n",
    "        \n",
    "# Make the dictionary reflect inherited terms as well and be a string not a list.\n",
    "individual_curated_go_term_strings = {i:\" \".join(go.inherited(terms)) for i,terms in individual_curated_go_terms.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a mapping between PO term IDs (like PO:0001234) and the list of gene IDs in this dataset they were annotated to.\n",
    "po_term_to_gene_ids = defaultdict(list)\n",
    "for gene_id, term_list, in curated_po_annotations.items():\n",
    "    for term in term_list: \n",
    "        po_term_to_gene_ids[term].append(gene_id)\n",
    "        \n",
    "# Create a mapping between a new unique identifer for each unique term used and a list with one item, the given term.\n",
    "individual_curated_po_terms = {i:[t] for i,t in enumerate(po_term_to_gene_ids.keys())}  \n",
    "_reverse_mapping = {t[0]:i for i,t in individual_curated_po_terms.items()}\n",
    "gene_id_to_unique_ids_mappings[\"po_terms\"] = {i:[_reverse_mapping[t] for t in terms] for i,terms in curated_po_annotations.items()}\n",
    "\n",
    "# What about genes that don't have any GO terms annotated to them by a curator? That should be accounted for.\n",
    "unique_id_for_emtpy_annotation_list = max(list(individual_curated_po_terms.keys()))+1\n",
    "individual_curated_po_terms[unique_id_for_emtpy_annotation_list] = []\n",
    "for gene_id,uid_list in gene_id_to_unique_ids_mappings[\"po_terms\"].items():\n",
    "    if len(uid_list) == 0:\n",
    "        gene_id_to_unique_ids_mappings[\"po_terms\"][gene_id].append(unique_id_for_emtpy_annotation_list)\n",
    "\n",
    "        \n",
    "# Make the dictionary reflect inherited terms as well and be a string not a list.\n",
    "individual_curated_po_term_strings = {i:\" \".join(po.inherited(terms)) for i,terms in individual_curated_po_terms.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "249"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gene_id_to_unique_ids_mappings[\"po_terms\"]\n",
    "unique_id_for_emtpy_annotation_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What about for the union set of GO and PO terms that were annotated by curators?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The goal here is obtain the set of unique term sets, with a mapping from/back to gene IDs, to avoid reduncancy.\n",
    "curated_go_annotation_strings_sorted = {i:\" \".join(sorted(go.inherited(terms))) for i,terms in curated_go_annotations.items()}\n",
    "unique_go_annotation_set_strings = [s for s in list(set(curated_go_annotation_strings_sorted.values()))]\n",
    "unique_id_to_unique_go_annotation_strings = {i:s for i,s in enumerate(unique_go_annotation_set_strings)}\n",
    "_reverse_mapping = {s:i for i,s in unique_id_to_unique_go_annotation_strings.items()}\n",
    "gene_id_to_unique_ids_mappings[\"go_term_sets\"] = {i:[_reverse_mapping[s]] for i,s in curated_go_annotation_strings_sorted.items()}\n",
    "\n",
    "#unique_id_to_unique_go_annotation_strings\n",
    "\n",
    "# The goal here is to obtain the set of unique term sets, with a mapping from/back to gene IDs, to avoid redundancy.\n",
    "#curated_go_annotations_sorted = {i:sorted(l) for i,l in curated_go_annotations.items()}\n",
    "#curated_go_annotations_strings = {i:\" \".join(l) for i,l in curated_go_annotations.items()}\n",
    "#unique_go_annotation_set_strings = [s for s in list(set(curated_go_annotations_strings.values()))]\n",
    "#unique_id_to_unique_go_annotation_strings = {i:s for i,s in enumerate(unique_go_annotation_set_strings)}\n",
    "#unique_id_to_unique_go_annotations = {i:s.split() for i,s in unique_id_to_unique_go_annotation_strings.items()}\n",
    "#_reverse_mapping = {s:i for i,s in unique_id_to_unique_go_annotation_strings.items()}\n",
    "#gene_id_to_unique_ids_mappings[\"go_term_sets\"] = {i:[_reverse_mapping[s]] for i,s in curated_go_annotations_strings.items()}\n",
    "\n",
    "# Data structures generated here that will be referenced later:\n",
    "# unique_id_to_unique_go_annotations: Maps arbitrary unique IDs to unique lists of term IDs and can be passed to oats.\n",
    "# gene_id_to_union_of_go_terms_unique_id: Needed for getting from gene IDs in this dataset to those arbitrary IDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The goal here is to obtain the set of unique term sets, with a mapping from/back to gene IDs, to avoid redundancy.\n",
    "curated_po_annotation_strings_sorted = {i:\" \".join(sorted(po.inherited(terms))) for i,terms in curated_po_annotations.items()}\n",
    "unique_po_annotation_set_strings = [s for s in list(set(curated_po_annotation_strings_sorted.values()))]\n",
    "unique_id_to_unique_po_annotation_strings = {i:s for i,s in enumerate(unique_po_annotation_set_strings)}\n",
    "_reverse_mapping = {s:i for i,s in unique_id_to_unique_po_annotation_strings.items()}\n",
    "gene_id_to_unique_ids_mappings[\"po_term_sets\"] = {i:[_reverse_mapping[s]] for i,s in curated_po_annotation_strings_sorted.items()}\n",
    "\n",
    "#unique_id_to_unique_po_annotation_strings\n",
    "\n",
    "#curated_po_annotations_sorted = {i:sorted(l) for i,l in curated_po_annotations.items()}\n",
    "#curated_po_annotations_strings = {i:\" \".join(l) for i,l in curated_po_annotations.items()}\n",
    "#unique_po_annotation_set_strings = [s for s in list(set(curated_po_annotations_strings.values()))]\n",
    "#unique_id_to_unique_po_annotation_strings = {i:s for i,s in enumerate(unique_po_annotation_set_strings)}\n",
    "#unique_id_to_unique_po_annotations = {i:s.split() for i,s in unique_id_to_unique_po_annotation_strings.items()}\n",
    "#_reverse_mapping = {s:i for i,s in unique_id_to_unique_po_annotation_strings.items()}\n",
    "#gene_id_to_unique_ids_mappings[\"po_term_sets\"] = {i:[_reverse_mapping[s]] for i,s in curated_po_annotations_strings.items()}\n",
    "\n",
    "# Data structures generated here that will be referenced later:\n",
    "# unique_id_to_unique_po_annotations: Maps arbitrary unique IDs to unique lists of term IDs and can be passed to oats.\n",
    "# gene_id_to_union_of_po_terms_unique_id: Needed for getting from gene IDs in this dataset to those arbitrary IDs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"todo\"></a>\n",
    "### Splitting dictionaries back into phenotype and phene specific dictionaries\n",
    "As a preprocessing step, split into a new set of descriptions that's larger. Note that phenotypes are split into phenes, and the phenes that are identical are retained as separate entries in the dataset. This makes the distance matrix calculation more needlessly expensive, because vectors need to be found for the same string more than once, but it simplifies converting the edgelist back to having IDs that reference the genes (full phenotypes) instead of the smaller phenes. If anything, that problem should be addressed in the pairwise functions, not here. (The package should handle it, not when creating input data for those methods)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve dictionaries that refer just to either unique raw whole texts, or unique raw sentences tokenized out.\n",
    "descriptions = unique_id_to_unique_text\n",
    "phenes = unique_id_to_unique_sent\n",
    "\n",
    "# Create the processed text dictionaries that have the same keys are those two, named accordingly for each.\n",
    "processes = list(processed.keys())\n",
    "unmerged = defaultdict(dict)\n",
    "for process,di in processed.items():\n",
    "    unmerged[process] = {i:text for i,text in di.items() if i in unique_whole_ids}\n",
    "    unmerged[\"{}_phenes\".format(process)] = {i:text for i,text in di.items() if i in unique_tokenized_ids}\n",
    "processed = unmerged\n",
    "\n",
    "# Checking to make sure the size of each dictionary is as expected.\n",
    "for process in processes:\n",
    "    assert len(unique_whole_ids) == len(processed[process].keys())\n",
    "    assert len(unique_tokenized_ids) == len(processed[\"{}_phenes\".format(process)].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These should be to sets not lists, don't need the duplicate references.\n",
    "for dtype,mapping in gene_id_to_unique_ids_mappings.items():\n",
    "    for gene_id,unique_ids in mapping.items():\n",
    "        gene_id_to_unique_ids_mappings[dtype][gene_id] = list(set(unique_ids))\n",
    "\n",
    "\n",
    "# What about the mapping from unique IDs of all kinds back to the gene IDs they came from?\n",
    "for dtype,mapping in gene_id_to_unique_ids_mappings.items():\n",
    "    for gene_id,unique_ids in mapping.items():\n",
    "        for unique_id in unique_ids:\n",
    "            unique_id_to_gene_ids_mappings[dtype][unique_id].append(gene_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each of the gene IDs should map to a list of exactly one ID referencing to a unique whole text, or set of terms.\n",
    "assert all([len(unique_ids)==1 for gene_id,unique_ids in gene_id_to_unique_ids_mappings[\"whole_texts\"].items()])\n",
    "assert all([len(unique_ids)==1 for gene_id,unique_ids in gene_id_to_unique_ids_mappings[\"go_term_sets\"].items()])\n",
    "assert all([len(unique_ids)==1 for gene_id,unique_ids in gene_id_to_unique_ids_mappings[\"po_term_sets\"].items()])\n",
    "\n",
    "# For the IDs that reference individual unique sentence tokens or ontology terms, a gene can map to one or more.\n",
    "assert all([len(unique_ids)>=1 for gene_id,unique_ids in gene_id_to_unique_ids_mappings[\"sent_tokens\"].items()])\n",
    "assert all([len(unique_ids)>=1 for gene_id,unique_ids in gene_id_to_unique_ids_mappings[\"go_terms\"].items()])\n",
    "assert all([len(unique_ids)>=1 for gene_id,unique_ids in gene_id_to_unique_ids_mappings[\"po_terms\"].items()])\n",
    "\n",
    "# In those cases, the list of IDs referencing unique terms of strings shouldn't contain any duplicates.\n",
    "assert all([len(unique_ids)==len(set(unique_ids)) for gene_id,unique_ids in gene_id_to_unique_ids_mappings[\"sent_tokens\"].items()])\n",
    "assert all([len(unique_ids)==len(set(unique_ids)) for gene_id,unique_ids in gene_id_to_unique_ids_mappings[\"go_terms\"].items()])\n",
    "assert all([len(unique_ids)==len(set(unique_ids)) for gene_id,unique_ids in gene_id_to_unique_ids_mappings[\"po_terms\"].items()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"part_4\"></a>\n",
    "# Part 4. Generating vector representations and pairwise distances matrices\n",
    "This section uses the text descriptions, preprocessed text descriptions, or ontology term annotations created or read in the previous sections to generate a vector representation for each gene and build a pairwise distance matrix for the whole dataset. Each method specified is a unique combination of a method of vectorization (bag-of-words, n-grams, document embedding model, etc) and distance metric (Euclidean, Jaccard, cosine, etc) applied to those vectors in constructing the pairwise matrix. The method of vectorization here is equivalent to feature selection, so the task is to figure out which type of vectors will encode features that are useful (n-grams, full words, only words from a certain vocabulary, etc).\n",
    "\n",
    "<a id=\"methods\"></a>\n",
    "### Specifying a list of NLP methods to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['something in the dataset three times',\n",
       " 'something in the dataset three times',\n",
       " 'something in the dataset three times',\n",
       " 'something in the dataset only once']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Returns a list of texts, this is necessary for weighting because inverse document frequency won't make sense\n",
    "# unless the texts that appear more than once in the actual dataset are actually account for, rather than treating\n",
    "# them as just one unique text (which is what is done as far as the distance matrix is concerned, in order to save\n",
    "# memory for the really large datasets like sentence tokens).\n",
    "def get_raw_texts_for_term_weighting(documents, unique_id_to_real_ids):\n",
    "    texts = flatten([[text]*len(unique_id_to_real_ids[i]) for i,text in documents.items()])\n",
    "    return(texts)\n",
    "\n",
    "# Quick test for the above method.\n",
    "test_unique_id_to_real_ids = {1:[1,2345,34564], 2:[1332]}\n",
    "test_documents = {1:\"something in the dataset three times\", 2:\"something in the dataset only once\"}\n",
    "get_raw_texts_for_term_weighting(test_documents, test_unique_id_to_real_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2vec_and_word2vec_approaches = [    \n",
    "    Method(\"Doc2Vec\", \"Wikipedia,Size=300\", pw.pairwise_square_doc2vec, {\"model\":doc2vec_wiki_model, \"ids_to_texts\":descriptions, \"metric\":\"cosine\"}, spatial.distance.cosine, tag=\"whole_texts\"),\n",
    "    Method(\"Word2Vec\", \"Wikipedia,Size=300,Mean\", pw.pairwise_square_word2vec, {\"model\":word2vec_model, \"ids_to_texts\":descriptions, \"metric\":\"cosine\", \"method\":\"mean\"}, spatial.distance.cosine, tag=\"whole_texts\"),\n",
    "    Method(\"Word2Vec\", \"Wikipedia,Size=300,Max\", pw.pairwise_square_word2vec, {\"model\":word2vec_model, \"ids_to_texts\":descriptions, \"metric\":\"cosine\", \"method\":\"max\"}, spatial.distance.cosine, tag=\"whole_texts\"),\n",
    "    Method(\"Doc2Vec\", \"Tokenization,Wikipedia,Size=300\", pw.pairwise_square_doc2vec, {\"model\":doc2vec_wiki_model, \"ids_to_texts\":phenes, \"metric\":\"cosine\"}, spatial.distance.cosine, tag=\"sent_tokens\"),\n",
    "    Method(\"Word2Vec\", \"Tokenization,Wikipedia,Size=300,Mean\", pw.pairwise_square_word2vec, {\"model\":word2vec_model, \"ids_to_texts\":phenes, \"metric\":\"cosine\", \"method\":\"mean\"}, spatial.distance.cosine, tag=\"sent_tokens\"),\n",
    "    Method(\"Word2Vec\", \"Tokenization,Wikipedia,Size=300,Max\",  pw.pairwise_square_word2vec, {\"model\":word2vec_model, \"ids_to_texts\":phenes, \"metric\":\"cosine\", \"method\":\"max\"}, spatial.distance.cosine, tag=\"sent_tokens\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "automated_annotation_approaches = [\n",
    "    Method(\"NOBLE Coder\", \"Precise,TFIDF\", pw.pairwise_square_ngrams, {\"ids_to_texts\":processed[\"precise_annotations\"], \"binary\":True, \"analyzer\":\"word\", \"ngram_range\":(1,1), \"max_features\":10000, \"min_df\":2, \"max_df\":0.9, \"metric\":\"cosine\", \"tfidf\":True, \"training_texts\":get_raw_texts_for_term_weighting(processed[\"precise_annotations\"], unique_id_to_gene_ids_mappings[\"whole_texts\"])}, spatial.distance.cosine, tag=\"whole_texts\"),\n",
    "    Method(\"NOBLE Coder\", \"Partial,TFIDF\", pw.pairwise_square_ngrams, {\"ids_to_texts\":processed[\"partial_annotations\"], \"binary\":True, \"analyzer\":\"word\", \"ngram_range\":(1,1), \"max_features\":10000, \"min_df\":2, \"max_df\":0.9, \"metric\":\"cosine\", \"tfidf\":True, \"training_texts\":get_raw_texts_for_term_weighting(processed[\"partial_annotations\"], unique_id_to_gene_ids_mappings[\"whole_texts\"])}, spatial.distance.cosine, tag=\"whole_texts\"),    \n",
    "    Method(\"NOBLE Coder\", \"Tokenization,Precise,TFIDF\", pw.pairwise_square_ngrams, {\"ids_to_texts\":processed[\"precise_annotations_phenes\"], \"binary\":True, \"analyzer\":\"word\", \"ngram_range\":(1,1), \"max_features\":10000, \"min_df\":2, \"max_df\":0.9, \"metric\":\"cosine\", \"tfidf\":True, \"training_texts\":get_raw_texts_for_term_weighting(processed[\"precise_annotations_phenes\"], unique_id_to_gene_ids_mappings[\"sent_tokens\"])}, spatial.distance.cosine, tag=\"sent_tokens\"),\n",
    "    Method(\"NOBLE Coder\", \"Tokenization,Partial,TFIDF\", pw.pairwise_square_ngrams, {\"ids_to_texts\":processed[\"partial_annotations_phenes\"], \"binary\":True, \"analyzer\":\"word\", \"ngram_range\":(1,1), \"max_features\":10000, \"min_df\":2, \"max_df\":0.9, \"metric\":\"cosine\", \"tfidf\":True, \"training_texts\":get_raw_texts_for_term_weighting(processed[\"partial_annotations_phenes\"], unique_id_to_gene_ids_mappings[\"sent_tokens\"])}, spatial.distance.cosine, tag=\"sent_tokens\"),   \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf_topic_modeling_approaches = [\n",
    "    Method(\"Topic Modeling\", \"NMF,Full,Topics=50\", pw.pairwise_square_topic_model, {\"ids_to_texts\":processed[\"full\"], \"metric\":\"cosine\", \"num_topics\":50, \"algorithm\":\"nmf\", \"training_texts\":get_raw_texts_for_term_weighting(processed[\"full\"], unique_id_to_gene_ids_mappings[\"whole_texts\"])}, spatial.distance.cosine, tag=\"whole_texts\"),\n",
    "    Method(\"Topic Modeling\", \"NMF,Full,Topics=100\", pw.pairwise_square_topic_model, {\"ids_to_texts\":processed[\"full\"], \"metric\":\"cosine\", \"num_topics\":100, \"algorithm\":\"nmf\", \"training_texts\":get_raw_texts_for_term_weighting(processed[\"full\"], unique_id_to_gene_ids_mappings[\"whole_texts\"])}, spatial.distance.cosine, tag=\"whole_texts\"),\n",
    "    Method(\"Topic Modeling\", \"Tokenization,NMF,Full,Topics=50\", pw.pairwise_square_topic_model, {\"ids_to_texts\":processed[\"full_phenes\"], \"metric\":\"cosine\", \"num_topics\":50, \"algorithm\":\"nmf\", \"training_texts\":get_raw_texts_for_term_weighting(processed[\"full_phenes\"], unique_id_to_gene_ids_mappings[\"sent_tokens\"])}, spatial.distance.cosine, tag=\"sent_tokens\"),\n",
    "    Method(\"Topic Modeling\", \"Tokenization,NMF,Full,Topics=100\",  pw.pairwise_square_topic_model, {\"ids_to_texts\":processed[\"full_phenes\"], \"metric\":\"cosine\", \"num_topics\":100, \"algorithm\":\"nmf\", \"training_texts\":get_raw_texts_for_term_weighting(processed[\"full_phenes\"], unique_id_to_gene_ids_mappings[\"sent_tokens\"])}, spatial.distance.cosine, tag=\"sent_tokens\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_topic_modeling_approaches = [\n",
    "    Method(\"Topic Modeling\", \"LDA,Full,Topics=50\", pw.pairwise_square_topic_model, {\"ids_to_texts\":processed[\"full\"], \"metric\":\"cosine\", \"num_topics\":50, \"algorithm\":\"lda\", \"training_texts\":get_raw_texts_for_term_weighting(processed[\"full\"], unique_id_to_gene_ids_mappings[\"whole_texts\"])}, spatial.distance.cosine, tag=\"whole_texts\"),\n",
    "    Method(\"Topic Modeling\", \"LDA,Full,Topics=100\", pw.pairwise_square_topic_model, {\"ids_to_texts\":processed[\"full\"], \"metric\":\"cosine\", \"num_topics\":100, \"algorithm\":\"lda\", \"training_texts\":get_raw_texts_for_term_weighting(processed[\"full\"], unique_id_to_gene_ids_mappings[\"whole_texts\"])}, spatial.distance.cosine, tag=\"whole_texts\"),\n",
    "    Method(\"Topic Modeling\", \"Tokenization,LDA,Full,Topics=50\", pw.pairwise_square_topic_model, {\"ids_to_texts\":processed[\"full_phenes\"], \"metric\":\"cosine\", \"num_topics\":50, \"algorithm\":\"lda\", \"training_texts\":get_raw_texts_for_term_weighting(processed[\"full_phenes\"], unique_id_to_gene_ids_mappings[\"sent_tokens\"])}, spatial.distance.cosine, tag=\"sent_tokens\"),\n",
    "    Method(\"Topic Modeling\", \"Tokenization,LDA,Full,Topics=100\", pw.pairwise_square_topic_model, {\"ids_to_texts\":processed[\"full_phenes\"], \"metric\":\"cosine\", \"num_topics\":100, \"algorithm\":\"lda\", \"training_texts\":get_raw_texts_for_term_weighting(processed[\"full_phenes\"], unique_id_to_gene_ids_mappings[\"sent_tokens\"])}, spatial.distance.cosine, tag=\"sent_tokens\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "vanilla_ngrams_approaches = [\n",
    "    Method(\"N-Grams\", \"Full,Words,1-grams,TFIDF\", pw.pairwise_square_ngrams, {\"ids_to_texts\":processed[\"full\"], \"metric\":\"cosine\", \"binary\":False, \"analyzer\":\"word\", \"ngram_range\":(1,1), \"max_features\":10000, \"min_df\":2, \"max_df\":0.9, \"tfidf\":True, \"training_texts\":get_raw_texts_for_term_weighting(processed[\"full\"], unique_id_to_gene_ids_mappings[\"whole_texts\"])}, spatial.distance.cosine, tag=\"whole_texts\"),\n",
    "    Method(\"N-Grams\", \"Full,Words,1-grams,2-grams,TFIDF\", pw.pairwise_square_ngrams, {\"ids_to_texts\":processed[\"full\"], \"metric\":\"cosine\", \"binary\":False, \"analyzer\":\"word\", \"ngram_range\":(1,2), \"max_features\":10000, \"min_df\":2, \"max_df\":0.9, \"tfidf\":True, \"training_texts\":get_raw_texts_for_term_weighting(processed[\"full\"], unique_id_to_gene_ids_mappings[\"whole_texts\"])}, spatial.distance.cosine, tag=\"whole_texts\"),\n",
    "    Method(\"N-Grams\", \"Tokenization,Full,Words,1-grams,TFIDF\", pw.pairwise_square_ngrams, {\"ids_to_texts\":processed[\"full_phenes\"], \"metric\":\"cosine\", \"binary\":False, \"analyzer\":\"word\", \"ngram_range\":(1,1), \"max_features\":10000, \"min_df\":2, \"max_df\":0.9, \"tfidf\":True, \"training_texts\":get_raw_texts_for_term_weighting(processed[\"full_phenes\"], unique_id_to_gene_ids_mappings[\"sent_tokens\"])}, spatial.distance.cosine, tag=\"sent_tokens\"),\n",
    "    Method(\"N-Grams\", \"Tokenization,Full,Words,1-grams,2-grams,TFIDF\", pw.pairwise_square_ngrams, {\"ids_to_texts\":processed[\"full_phenes\"], \"metric\":\"cosine\", \"binary\":False, \"analyzer\":\"word\", \"ngram_range\":(1,2), \"max_features\":10000, \"min_df\":2, \"max_df\":0.9, \"tfidf\":True, \"training_texts\":get_raw_texts_for_term_weighting(processed[\"full_phenes\"], unique_id_to_gene_ids_mappings[\"sent_tokens\"])}, spatial.distance.cosine, tag=\"sent_tokens\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "modified_vocab_approaches = [\n",
    "    \n",
    "    Method(\"N-Grams\", \"Full,Nouns,Adjectives,1-grams\", pw.pairwise_square_ngrams, {\"ids_to_texts\":processed[\"nouns_adjectives_full\"], \"metric\":\"cosine\", \"binary\":False, \"analyzer\":\"word\", \"ngram_range\":(1,1), \"max_features\":10000, \"min_df\":2, \"max_df\":0.9, \"tfidf\":True, \"training_texts\":get_raw_texts_for_term_weighting(processed[\"nouns_adjectives_full\"], unique_id_to_gene_ids_mappings[\"whole_texts\"])}, spatial.distance.cosine, tag=\"whole_texts\"),\n",
    "    Method(\"N-Grams\", \"Linares_Pontes,Words,1-grams\", pw.pairwise_square_ngrams, {\"ids_to_texts\":processed[\"linares_pontes\"], \"metric\":\"cosine\", \"binary\":False, \"analyzer\":\"word\", \"ngram_range\":(1,1), \"max_features\":10000, \"min_df\":2, \"max_df\":0.9, \"tfidf\":True, \"training_texts\":get_raw_texts_for_term_weighting(processed[\"linares_pontes\"], unique_id_to_gene_ids_mappings[\"whole_texts\"])}, spatial.distance.cosine, tag=\"whole_texts\"),\n",
    "    Method(\"N-Grams\", \"Full,Precise_Annotations,Words,1-grams\", pw.pairwise_square_ngrams, {\"ids_to_texts\":processed[\"full_plus_precise_annotations\"], \"metric\":\"cosine\", \"binary\":False, \"analyzer\":\"word\", \"ngram_range\":(1,1), \"max_features\":10000, \"min_df\":2, \"max_df\":0.9, \"tfidf\":True, \"training_texts\":get_raw_texts_for_term_weighting(processed[\"full_plus_precise_annotations\"], unique_id_to_gene_ids_mappings[\"whole_texts\"])}, spatial.distance.cosine, tag=\"whole_texts\"),\n",
    "    Method(\"N-Grams\", \"Full,Partial_Annotations,Words,1-grams\", pw.pairwise_square_ngrams, {\"ids_to_texts\":processed[\"full_plus_partial_annotations\"], \"metric\":\"cosine\", \"binary\":False, \"analyzer\":\"word\", \"ngram_range\":(1,1), \"max_features\":10000, \"min_df\":2, \"max_df\":0.9, \"tfidf\":True, \"training_texts\":get_raw_texts_for_term_weighting(processed[\"full_plus_partial_annotations\"], unique_id_to_gene_ids_mappings[\"whole_texts\"])}, spatial.distance.cosine, tag=\"whole_texts\"),\n",
    "    Method(\"N-Grams\", \"Full,Plant Overrepresented Tokens,1-grams\", pw.pairwise_square_ngrams, {\"ids_to_texts\":processed[\"plant_overrepresented_tokens\"], \"metric\":\"cosine\", \"binary\":False, \"analyzer\":\"word\", \"ngram_range\":(1,1), \"max_features\":10000, \"min_df\":2, \"max_df\":0.9, \"tfidf\":True, \"training_texts\":get_raw_texts_for_term_weighting(processed[\"plant_overrepresented_tokens\"], unique_id_to_gene_ids_mappings[\"whole_texts\"])}, spatial.distance.cosine, tag=\"whole_texts\"),\n",
    "    Method(\"N-Grams\", \"Full,Bio Ontology Tokens,1-grams\", pw.pairwise_square_ngrams, {\"ids_to_texts\":processed[\"bio_ontology_tokens\"], \"metric\":\"cosine\", \"binary\":False, \"analyzer\":\"word\", \"ngram_range\":(1,1), \"max_features\":10000, \"min_df\":2, \"max_df\":0.9, \"tfidf\":True, \"training_texts\":get_raw_texts_for_term_weighting(processed[\"bio_ontology_tokens\"], unique_id_to_gene_ids_mappings[\"whole_texts\"])}, spatial.distance.cosine, tag=\"whole_texts\"),\n",
    "    \n",
    "    Method(\"N-Grams\", \"Tokenization,Full,Nouns,Adjectives,1-grams\", pw.pairwise_square_ngrams, {\"ids_to_texts\":processed[\"nouns_adjectives_full_phenes\"], \"metric\":\"cosine\", \"binary\":False, \"analyzer\":\"word\", \"ngram_range\":(1,1), \"max_features\":10000, \"min_df\":2, \"max_df\":0.9, \"tfidf\":True,  \"training_texts\":get_raw_texts_for_term_weighting(processed[\"nouns_adjectives_full_phenes\"], unique_id_to_gene_ids_mappings[\"sent_tokens\"])}, spatial.distance.cosine, tag=\"sent_tokens\"),\n",
    "    Method(\"N-Grams\", \"Tokenization,Linares_Pontes,Words,1-grams\", pw.pairwise_square_ngrams, {\"ids_to_texts\":processed[\"linares_pontes_phenes\"], \"metric\":\"cosine\", \"binary\":False, \"analyzer\":\"word\", \"ngram_range\":(1,1), \"max_features\":10000, \"min_df\":2, \"max_df\":0.9, \"tfidf\":True, \"training_texts\":get_raw_texts_for_term_weighting(processed[\"linares_pontes_phenes\"], unique_id_to_gene_ids_mappings[\"sent_tokens\"])}, spatial.distance.cosine, tag=\"sent_tokens\"),\n",
    "    Method(\"N-Grams\", \"Tokenization,Full,Precise_Annotations,Words,1-grams\", pw.pairwise_square_ngrams, {\"ids_to_texts\":processed[\"full_plus_precise_annotations_phenes\"], \"metric\":\"cosine\", \"binary\":False, \"analyzer\":\"word\", \"ngram_range\":(1,1), \"max_features\":10000, \"min_df\":2, \"max_df\":0.9, \"tfidf\":True, \"training_texts\":get_raw_texts_for_term_weighting(processed[\"full_plus_precise_annotations_phenes\"], unique_id_to_gene_ids_mappings[\"sent_tokens\"])}, spatial.distance.cosine, tag=\"sent_tokens\"),\n",
    "    Method(\"N-Grams\", \"Tokenization,Full,Partial_Annotations,Words,1-grams\", pw.pairwise_square_ngrams, {\"ids_to_texts\":processed[\"full_plus_partial_annotations_phenes\"], \"metric\":\"cosine\", \"binary\":False, \"analyzer\":\"word\", \"ngram_range\":(1,1), \"max_features\":10000, \"min_df\":2, \"max_df\":0.9, \"tfidf\":True, \"training_texts\":get_raw_texts_for_term_weighting(processed[\"full_plus_partial_annotations_phenes\"], unique_id_to_gene_ids_mappings[\"sent_tokens\"])}, spatial.distance.cosine, tag=\"sent_tokens\"),\n",
    "    Method(\"N-Grams\", \"Tokenization,Full,Plant Overrepresented Tokens,1-grams\", pw.pairwise_square_ngrams, {\"ids_to_texts\":processed[\"plant_overrepresented_tokens_phenes\"], \"metric\":\"cosine\", \"binary\":False, \"analyzer\":\"word\", \"ngram_range\":(1,1), \"max_features\":10000, \"min_df\":2, \"max_df\":0.9, \"tfidf\":True, \"training_texts\":get_raw_texts_for_term_weighting(processed[\"plant_overrepresented_tokens_phenes\"], unique_id_to_gene_ids_mappings[\"sent_tokens\"])}, spatial.distance.cosine, tag=\"sent_tokens\"),\n",
    "    Method(\"N-Grams\", \"Tokenization,Full,Bio Ontology Tokens,1-grams\", pw.pairwise_square_ngrams, {\"ids_to_texts\":processed[\"bio_ontology_tokens_phenes\"], \"metric\":\"cosine\", \"binary\":False, \"analyzer\":\"word\", \"ngram_range\":(1,1), \"max_features\":10000, \"min_df\":2, \"max_df\":0.9, \"tfidf\":True, \"training_texts\":get_raw_texts_for_term_weighting(processed[\"bio_ontology_tokens_phenes\"], unique_id_to_gene_ids_mappings[\"sent_tokens\"])}, spatial.distance.cosine, tag=\"sent_tokens\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_annotation_approaches = [\n",
    "    Method(\"GO\", \"Union\", pw.pairwise_square_ngrams, {\"ids_to_texts\":unique_id_to_unique_go_annotation_strings,  \"metric\":\"cosine\", \"max_features\":10000, \"min_df\":2, \"max_df\":0.9, \"binary\":False, \"analyzer\":\"word\", \"ngram_range\":(1,1), \"tfidf\":True, \"training_texts\":get_raw_texts_for_term_weighting(unique_id_to_unique_go_annotation_strings, unique_id_to_gene_ids_mappings[\"go_term_sets\"])}, spatial.distance.cosine, tag=\"go_term_sets\"),\n",
    "    Method(\"PO\", \"Union\", pw.pairwise_square_ngrams, {\"ids_to_texts\":unique_id_to_unique_po_annotation_strings, \"metric\":\"cosine\", \"max_features\":10000, \"min_df\":2, \"max_df\":0.9, \"binary\":False, \"analyzer\":\"word\", \"ngram_range\":(1,1), \"tfidf\":True, \"training_texts\":get_raw_texts_for_term_weighting(unique_id_to_unique_po_annotation_strings, unique_id_to_gene_ids_mappings[\"po_term_sets\"])}, spatial.distance.cosine, tag=\"po_term_sets\"),\n",
    "    Method(\"GO\", \"Minimum\", pw.pairwise_square_ngrams, {\"ids_to_texts\":individual_curated_go_term_strings, \"metric\":\"cosine\", \"max_features\":10000, \"min_df\":2, \"max_df\":0.9, \"binary\":False, \"analyzer\":\"word\", \"ngram_range\":(1,1), \"tfidf\":True, \"training_texts\":get_raw_texts_for_term_weighting(individual_curated_go_term_strings, unique_id_to_gene_ids_mappings[\"go_terms\"])}, spatial.distance.cosine, tag=\"go_terms\"),\n",
    "    Method(\"PO\", \"Minimum\", pw.pairwise_square_ngrams, {\"ids_to_texts\":individual_curated_po_term_strings, \"metric\":\"cosine\", \"max_features\":10000, \"min_df\":2, \"max_df\":0.9, \"binary\":False, \"analyzer\":\"word\", \"ngram_range\":(1,1), \"tfidf\":True, \"training_texts\":get_raw_texts_for_term_weighting(individual_curated_po_term_strings, unique_id_to_gene_ids_mappings[\"po_terms\"])},spatial.distance.cosine, tag=\"po_terms\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding lists of approaches to the complete set to be run, this is useful when running the notebook as a script.\n",
    "methods = []\n",
    "if args.learning: methods.extend(doc2vec_and_word2vec_approaches)\n",
    "if args.noblecoder: methods.extend(automated_annotation_approaches)\n",
    "if args.nmf: methods.extend(nmf_topic_modeling_approaches)\n",
    "if args.lda: methods.extend(lda_topic_modeling_approaches)\n",
    "if args.vanilla: methods.extend(vanilla_ngrams_approaches)\n",
    "if args.vocab: methods.extend(modified_vocab_approaches)\n",
    "if args.annotations: methods.extend(manual_annotation_approaches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"running\"></a>\n",
    "### Running all of the methods to generate distance matrices\n",
    "Notes- Instead of passing in similarity function like cosine distance that will get evaluated for every possible i,j pair of vetors that are created (this is very big when splitting by phenes), don't use a specific similarity function, but instead let the object use a KNN classifier. pass in some limit for k like 100. then the object uses some more efficient (not brute force) algorithm to set the similarity of some vector v to its 100 nearest neighbors as those 100 probabilities, and sets everything else to 0. This would need to be implemented as a matching but separate function from the get_square_matrix_from_vectors thing. And then this would need to be noted in the similarity function that was used for these in the big table of methods. This won't work because the faster (not brute force algorithms) are not for sparse vectors like n-grams, and the non-sparse embeddings aren't really the problem here because those vectors are relatively much short, even when concatenating BERT encoder layers thats only up to around length of ~1000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doc2vec:wikipedia,size=300                                             00:00:01          300        451\n",
      "word2vec:wikipedia,size=300,mean                                       00:00:00          300        451\n",
      "word2vec:wikipedia,size=300,max                                        00:00:00          300        451\n",
      "doc2vec:tokenization,wikipedia,size=300                                00:00:03          300       2301\n",
      "word2vec:tokenization,wikipedia,size=300,mean                          00:00:02          300       2301\n",
      "word2vec:tokenization,wikipedia,size=300,max                           00:00:03          300       2301\n",
      "noble coder:precise,tfidf                                              00:00:00          795        451\n",
      "noble coder:partial,tfidf                                              00:00:02        10000        451\n",
      "noble coder:tokenization,precise,tfidf                                 00:00:03          928       2301\n",
      "noble coder:tokenization,partial,tfidf                                 00:00:36        10000       2301\n",
      "topic modeling:nmf,full,topics=50                                      00:00:01           50        451\n",
      "topic modeling:nmf,full,topics=100                                     00:00:06          100        451\n",
      "topic modeling:tokenization,nmf,full,topics=50                         00:00:03           50       2301\n",
      "topic modeling:tokenization,nmf,full,topics=100                        00:00:09          100       2301\n",
      "topic modeling:lda,full,topics=50                                      00:00:00           50        451\n",
      "topic modeling:lda,full,topics=100                                     00:00:01          100        451\n",
      "topic modeling:tokenization,lda,full,topics=50                         00:00:04           50       2301\n",
      "topic modeling:tokenization,lda,full,topics=100                        00:00:04          100       2301\n",
      "n-grams:full,words,1-grams,tfidf                                       00:00:00         1041        451\n",
      "n-grams:full,words,1-grams,2-grams,tfidf                               00:00:00         2867        451\n",
      "n-grams:tokenization,full,words,1-grams,tfidf                          00:00:04         1294       2301\n",
      "n-grams:tokenization,full,words,1-grams,2-grams,tfidf                  00:00:12         3599       2301\n",
      "n-grams:full,nouns,adjectives,1-grams                                  00:00:00          748        451\n",
      "n-grams:linares_pontes,words,1-grams                                   00:00:00          884        451\n",
      "n-grams:full,precise_annotations,words,1-grams                         00:00:00         1836        451\n",
      "n-grams:full,partial_annotations,words,1-grams                         00:00:02        10000        451\n",
      "n-grams:full,plant overrepresented tokens,1-grams                      00:00:00          869        451\n",
      "n-grams:full,bio ontology tokens,1-grams                               00:00:00          721        451\n",
      "n-grams:tokenization,full,nouns,adjectives,1-grams                     00:00:04          954       2301\n",
      "n-grams:tokenization,linares_pontes,words,1-grams                      00:00:03          969       2301\n",
      "n-grams:tokenization,full,precise_annotations,words,1-grams            00:00:07         2222       2301\n",
      "n-grams:tokenization,full,partial_annotations,words,1-grams            00:00:35        10000       2301\n",
      "n-grams:tokenization,full,plant overrepresented tokens,1-grams         00:00:04         1042       2301\n",
      "n-grams:tokenization,full,bio ontology tokens,1-grams                  00:00:03          857       2301\n",
      "go:union                                                               00:00:00         1138        364\n",
      "po:union                                                               00:00:00          250        336\n",
      "go:minimum                                                             00:00:00         1162        824\n",
      "po:minimum                                                             00:00:00          249        250\n"
     ]
    }
   ],
   "source": [
    "# Generate all the pairwise distance matrices (not in parallel).\n",
    "graphs = {}\n",
    "names = []\n",
    "durations = []\n",
    "vector_lengths = []\n",
    "array_lengths = []\n",
    "for method in methods:\n",
    "    graph,duration = function_wrapper_with_duration(function=method.function, args=method.kwargs)\n",
    "    graphs[method.name_with_hyperparameters] = graph\n",
    "    names.append(method.name_with_hyperparameters)\n",
    "    durations.append(to_hms(duration))\n",
    "    vector_length = len(list(graph.vector_dictionary.values())[0])\n",
    "    array_length = graph.array.shape[0]\n",
    "    vector_lengths.append(vector_length)\n",
    "    array_lengths.append(array_length)\n",
    "    print(\"{:70} {:10} {:10} {:10}\".format(method.name_with_hyperparameters, to_hms(duration), vector_length, array_length))\n",
    "approaches_df = pd.DataFrame({\"method\":names, \"duration\":durations, \"vector_length\":vector_lengths, \"arr_length\":array_lengths})\n",
    "approaches_df.to_csv(os.path.join(OUTPUT_DIR,\"part_4_approaches.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging all the edgelists together.\n",
    "metric_dict = {method.name_with_hyperparameters:method.metric for method in methods}\n",
    "tags_dict = {method.name_with_hyperparameters:method.tag for method in methods}\n",
    "names = list(graphs.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = dataset.get_ids()\n",
    "from_to_id_pairs = [(i,j) for (i,j) in itertools.combinations(ids, 2)]\n",
    "df = pd.DataFrame(from_to_id_pairs, columns=[\"from\",\"to\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When multiple indices within the array could be part of the data for one particular gene (sentence tokenized).\n",
    "def get_min_of_distances(gene_id_1, gene_id_2, gene_id_to_uids, uid_to_array_index, array):\n",
    "    uids_list_1 = gene_id_to_uids[gene_id_1]\n",
    "    uids_list_2 = gene_id_to_uids[gene_id_2]\n",
    "    possible_uid_combinations = itertools.product(uids_list_1, uids_list_2)\n",
    "    distance = min([array[uid_to_array_index[i],uid_to_array_index[j]] for (i,j) in possible_uid_combinations])\n",
    "    return(distance)\n",
    "\n",
    "\n",
    "# When a single index within the array has to represent entirely the data for one gene (not sentence tokenized).\n",
    "def lookup_distance(gene_id_1, gene_id_2, gene_id_to_uids, uid_to_array_index, array):\n",
    "    assert len(gene_id_to_uids[gene_id_1]) == 1\n",
    "    assert len(gene_id_to_uids[gene_id_2]) == 1\n",
    "    uid_1 = gene_id_to_uids[gene_id_1][0]\n",
    "    uid_2 = gene_id_to_uids[gene_id_2][0]\n",
    "    distance = array[uid_to_array_index[uid_1],uid_to_array_index[uid_2]]\n",
    "    return(distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doc2vec:wikipedia,size=300\n",
      "word2vec:wikipedia,size=300,mean\n",
      "word2vec:wikipedia,size=300,max\n",
      "doc2vec:tokenization,wikipedia,size=300\n",
      "word2vec:tokenization,wikipedia,size=300,mean\n",
      "word2vec:tokenization,wikipedia,size=300,max\n",
      "noble coder:precise,tfidf\n",
      "noble coder:partial,tfidf\n",
      "noble coder:tokenization,precise,tfidf\n",
      "noble coder:tokenization,partial,tfidf\n",
      "topic modeling:nmf,full,topics=50\n",
      "topic modeling:nmf,full,topics=100\n",
      "topic modeling:tokenization,nmf,full,topics=50\n",
      "topic modeling:tokenization,nmf,full,topics=100\n",
      "topic modeling:lda,full,topics=50\n",
      "topic modeling:lda,full,topics=100\n",
      "topic modeling:tokenization,lda,full,topics=50\n",
      "topic modeling:tokenization,lda,full,topics=100\n",
      "n-grams:full,words,1-grams,tfidf\n",
      "n-grams:full,words,1-grams,2-grams,tfidf\n",
      "n-grams:tokenization,full,words,1-grams,tfidf\n",
      "n-grams:tokenization,full,words,1-grams,2-grams,tfidf\n",
      "n-grams:full,nouns,adjectives,1-grams\n",
      "n-grams:linares_pontes,words,1-grams\n",
      "n-grams:full,precise_annotations,words,1-grams\n",
      "n-grams:full,partial_annotations,words,1-grams\n",
      "n-grams:full,plant overrepresented tokens,1-grams\n",
      "n-grams:full,bio ontology tokens,1-grams\n",
      "n-grams:tokenization,full,nouns,adjectives,1-grams\n",
      "n-grams:tokenization,linares_pontes,words,1-grams\n",
      "n-grams:tokenization,full,precise_annotations,words,1-grams\n",
      "n-grams:tokenization,full,partial_annotations,words,1-grams\n",
      "n-grams:tokenization,full,plant overrepresented tokens,1-grams\n",
      "n-grams:tokenization,full,bio ontology tokens,1-grams\n",
      "go:union\n",
      "po:union\n",
      "go:minimum\n",
      "po:minimum\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>from</th>\n",
       "      <th>to</th>\n",
       "      <th>doc2vec:wikipedia,size=300</th>\n",
       "      <th>word2vec:wikipedia,size=300,mean</th>\n",
       "      <th>word2vec:wikipedia,size=300,max</th>\n",
       "      <th>doc2vec:tokenization,wikipedia,size=300</th>\n",
       "      <th>word2vec:tokenization,wikipedia,size=300,mean</th>\n",
       "      <th>word2vec:tokenization,wikipedia,size=300,max</th>\n",
       "      <th>noble coder:precise,tfidf</th>\n",
       "      <th>noble coder:partial,tfidf</th>\n",
       "      <th>noble coder:tokenization,precise,tfidf</th>\n",
       "      <th>noble coder:tokenization,partial,tfidf</th>\n",
       "      <th>topic modeling:nmf,full,topics=50</th>\n",
       "      <th>topic modeling:nmf,full,topics=100</th>\n",
       "      <th>topic modeling:tokenization,nmf,full,topics=50</th>\n",
       "      <th>topic modeling:tokenization,nmf,full,topics=100</th>\n",
       "      <th>topic modeling:lda,full,topics=50</th>\n",
       "      <th>topic modeling:lda,full,topics=100</th>\n",
       "      <th>topic modeling:tokenization,lda,full,topics=50</th>\n",
       "      <th>topic modeling:tokenization,lda,full,topics=100</th>\n",
       "      <th>n-grams:full,words,1-grams,tfidf</th>\n",
       "      <th>n-grams:full,words,1-grams,2-grams,tfidf</th>\n",
       "      <th>n-grams:tokenization,full,words,1-grams,tfidf</th>\n",
       "      <th>n-grams:tokenization,full,words,1-grams,2-grams,tfidf</th>\n",
       "      <th>n-grams:full,nouns,adjectives,1-grams</th>\n",
       "      <th>n-grams:linares_pontes,words,1-grams</th>\n",
       "      <th>n-grams:full,precise_annotations,words,1-grams</th>\n",
       "      <th>n-grams:full,partial_annotations,words,1-grams</th>\n",
       "      <th>n-grams:full,plant overrepresented tokens,1-grams</th>\n",
       "      <th>n-grams:full,bio ontology tokens,1-grams</th>\n",
       "      <th>n-grams:tokenization,full,nouns,adjectives,1-grams</th>\n",
       "      <th>n-grams:tokenization,linares_pontes,words,1-grams</th>\n",
       "      <th>n-grams:tokenization,full,precise_annotations,words,1-grams</th>\n",
       "      <th>n-grams:tokenization,full,partial_annotations,words,1-grams</th>\n",
       "      <th>n-grams:tokenization,full,plant overrepresented tokens,1-grams</th>\n",
       "      <th>n-grams:tokenization,full,bio ontology tokens,1-grams</th>\n",
       "      <th>go:union</th>\n",
       "      <th>po:union</th>\n",
       "      <th>go:minimum</th>\n",
       "      <th>po:minimum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>1145</td>\n",
       "      <td>0.484948</td>\n",
       "      <td>0.503235</td>\n",
       "      <td>0.263459</td>\n",
       "      <td>0.422335</td>\n",
       "      <td>0.478481</td>\n",
       "      <td>0.288674</td>\n",
       "      <td>0.863608</td>\n",
       "      <td>0.927264</td>\n",
       "      <td>0.804840</td>\n",
       "      <td>0.899720</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.985932</td>\n",
       "      <td>0.983500</td>\n",
       "      <td>0.972852</td>\n",
       "      <td>0.986386</td>\n",
       "      <td>0.956351</td>\n",
       "      <td>9.843608e-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.840402</td>\n",
       "      <td>0.568991</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.591617</td>\n",
       "      <td>0.432781</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.199791</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.646186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100</td>\n",
       "      <td>4114</td>\n",
       "      <td>0.343207</td>\n",
       "      <td>0.260014</td>\n",
       "      <td>0.185656</td>\n",
       "      <td>0.260778</td>\n",
       "      <td>0.270105</td>\n",
       "      <td>0.180168</td>\n",
       "      <td>0.936699</td>\n",
       "      <td>0.963473</td>\n",
       "      <td>0.915321</td>\n",
       "      <td>0.957688</td>\n",
       "      <td>0.999937</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.997800</td>\n",
       "      <td>0.984195</td>\n",
       "      <td>0.848661</td>\n",
       "      <td>0.988527</td>\n",
       "      <td>0.969091</td>\n",
       "      <td>9.845576e-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.980422</td>\n",
       "      <td>0.812361</td>\n",
       "      <td>0.422756</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.980264</td>\n",
       "      <td>0.748194</td>\n",
       "      <td>0.437357</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>231</td>\n",
       "      <td>0.424650</td>\n",
       "      <td>0.279231</td>\n",
       "      <td>0.185035</td>\n",
       "      <td>0.296518</td>\n",
       "      <td>0.271672</td>\n",
       "      <td>0.188429</td>\n",
       "      <td>0.888187</td>\n",
       "      <td>0.921801</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.824749</td>\n",
       "      <td>0.978728</td>\n",
       "      <td>0.556710</td>\n",
       "      <td>0.931309</td>\n",
       "      <td>0.668178</td>\n",
       "      <td>0.980502</td>\n",
       "      <td>0.552669</td>\n",
       "      <td>9.768748e-01</td>\n",
       "      <td>0.943099</td>\n",
       "      <td>0.972357</td>\n",
       "      <td>0.885369</td>\n",
       "      <td>0.931381</td>\n",
       "      <td>0.926808</td>\n",
       "      <td>0.896132</td>\n",
       "      <td>0.560416</td>\n",
       "      <td>0.496319</td>\n",
       "      <td>0.943099</td>\n",
       "      <td>0.928882</td>\n",
       "      <td>0.813392</td>\n",
       "      <td>0.868671</td>\n",
       "      <td>0.387241</td>\n",
       "      <td>0.423178</td>\n",
       "      <td>0.885369</td>\n",
       "      <td>0.858600</td>\n",
       "      <td>0.240786</td>\n",
       "      <td>0.097509</td>\n",
       "      <td>0.906796</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100</td>\n",
       "      <td>5244</td>\n",
       "      <td>0.515200</td>\n",
       "      <td>0.602756</td>\n",
       "      <td>0.363885</td>\n",
       "      <td>0.428738</td>\n",
       "      <td>0.607823</td>\n",
       "      <td>0.362408</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.957448</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.944979</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999151</td>\n",
       "      <td>0.965712</td>\n",
       "      <td>0.954950</td>\n",
       "      <td>0.976779</td>\n",
       "      <td>0.950524</td>\n",
       "      <td>9.776629e-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.978017</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.897769</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.367580</td>\n",
       "      <td>0.108020</td>\n",
       "      <td>0.690276</td>\n",
       "      <td>0.474998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100</td>\n",
       "      <td>733</td>\n",
       "      <td>0.527713</td>\n",
       "      <td>0.270065</td>\n",
       "      <td>0.181497</td>\n",
       "      <td>0.355785</td>\n",
       "      <td>0.293558</td>\n",
       "      <td>0.170425</td>\n",
       "      <td>0.899698</td>\n",
       "      <td>0.927390</td>\n",
       "      <td>0.804250</td>\n",
       "      <td>0.918117</td>\n",
       "      <td>0.990412</td>\n",
       "      <td>0.999971</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.491172</td>\n",
       "      <td>0.517408</td>\n",
       "      <td>0.958356</td>\n",
       "      <td>9.761760e-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.877337</td>\n",
       "      <td>0.810659</td>\n",
       "      <td>0.297326</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.866671</td>\n",
       "      <td>0.604588</td>\n",
       "      <td>0.252735</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.202688</td>\n",
       "      <td>0.089205</td>\n",
       "      <td>0.690276</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>100</td>\n",
       "      <td>3896</td>\n",
       "      <td>0.520128</td>\n",
       "      <td>0.536171</td>\n",
       "      <td>0.298879</td>\n",
       "      <td>0.399769</td>\n",
       "      <td>0.590710</td>\n",
       "      <td>0.391840</td>\n",
       "      <td>0.973093</td>\n",
       "      <td>0.970430</td>\n",
       "      <td>0.971126</td>\n",
       "      <td>0.966886</td>\n",
       "      <td>0.981126</td>\n",
       "      <td>0.913819</td>\n",
       "      <td>0.982271</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.967291</td>\n",
       "      <td>0.983562</td>\n",
       "      <td>0.959602</td>\n",
       "      <td>9.657815e-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.921055</td>\n",
       "      <td>0.329352</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.847789</td>\n",
       "      <td>0.309230</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>100</td>\n",
       "      <td>4572</td>\n",
       "      <td>0.490884</td>\n",
       "      <td>0.326860</td>\n",
       "      <td>0.179187</td>\n",
       "      <td>0.310596</td>\n",
       "      <td>0.341777</td>\n",
       "      <td>0.209361</td>\n",
       "      <td>0.956777</td>\n",
       "      <td>0.928798</td>\n",
       "      <td>0.939667</td>\n",
       "      <td>0.925504</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.973819</td>\n",
       "      <td>0.910472</td>\n",
       "      <td>0.965566</td>\n",
       "      <td>0.965742</td>\n",
       "      <td>0.985249</td>\n",
       "      <td>0.941665</td>\n",
       "      <td>9.777083e-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.916390</td>\n",
       "      <td>0.740565</td>\n",
       "      <td>0.356273</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.897864</td>\n",
       "      <td>0.598539</td>\n",
       "      <td>0.266433</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.622213</td>\n",
       "      <td>0.110242</td>\n",
       "      <td>0.956128</td>\n",
       "      <td>0.474998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>100</td>\n",
       "      <td>2823</td>\n",
       "      <td>0.547941</td>\n",
       "      <td>0.272979</td>\n",
       "      <td>0.187657</td>\n",
       "      <td>0.279518</td>\n",
       "      <td>0.278486</td>\n",
       "      <td>0.199103</td>\n",
       "      <td>0.893427</td>\n",
       "      <td>0.902922</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.889492</td>\n",
       "      <td>0.981633</td>\n",
       "      <td>0.978047</td>\n",
       "      <td>0.325492</td>\n",
       "      <td>0.707005</td>\n",
       "      <td>0.970948</td>\n",
       "      <td>0.940419</td>\n",
       "      <td>0.560160</td>\n",
       "      <td>7.171545e-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.974706</td>\n",
       "      <td>0.741642</td>\n",
       "      <td>0.258536</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.949664</td>\n",
       "      <td>0.555684</td>\n",
       "      <td>0.233350</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>100</td>\n",
       "      <td>1592</td>\n",
       "      <td>0.448422</td>\n",
       "      <td>0.438724</td>\n",
       "      <td>0.198668</td>\n",
       "      <td>0.320943</td>\n",
       "      <td>0.365019</td>\n",
       "      <td>0.222920</td>\n",
       "      <td>0.904967</td>\n",
       "      <td>0.925881</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.906443</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998446</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.969069</td>\n",
       "      <td>0.988745</td>\n",
       "      <td>0.959906</td>\n",
       "      <td>9.800199e-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.951814</td>\n",
       "      <td>0.827605</td>\n",
       "      <td>0.342629</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.900542</td>\n",
       "      <td>0.732674</td>\n",
       "      <td>0.251352</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.229783</td>\n",
       "      <td>0.093575</td>\n",
       "      <td>0.484877</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>100</td>\n",
       "      <td>1185</td>\n",
       "      <td>0.450585</td>\n",
       "      <td>0.197340</td>\n",
       "      <td>0.151455</td>\n",
       "      <td>0.301088</td>\n",
       "      <td>0.232980</td>\n",
       "      <td>0.155569</td>\n",
       "      <td>0.909111</td>\n",
       "      <td>0.919647</td>\n",
       "      <td>0.666356</td>\n",
       "      <td>0.911593</td>\n",
       "      <td>0.998078</td>\n",
       "      <td>0.999591</td>\n",
       "      <td>0.828320</td>\n",
       "      <td>0.981882</td>\n",
       "      <td>0.855693</td>\n",
       "      <td>0.859678</td>\n",
       "      <td>0.944414</td>\n",
       "      <td>8.544685e-07</td>\n",
       "      <td>0.977251</td>\n",
       "      <td>0.989587</td>\n",
       "      <td>0.894892</td>\n",
       "      <td>0.957043</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.878630</td>\n",
       "      <td>0.720393</td>\n",
       "      <td>0.329431</td>\n",
       "      <td>0.976848</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.839561</td>\n",
       "      <td>0.424285</td>\n",
       "      <td>0.281615</td>\n",
       "      <td>0.873610</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.218605</td>\n",
       "      <td>0.217137</td>\n",
       "      <td>0.897383</td>\n",
       "      <td>0.539171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>100</td>\n",
       "      <td>883</td>\n",
       "      <td>0.448113</td>\n",
       "      <td>0.601558</td>\n",
       "      <td>0.872109</td>\n",
       "      <td>0.347916</td>\n",
       "      <td>0.597342</td>\n",
       "      <td>0.807199</td>\n",
       "      <td>0.851351</td>\n",
       "      <td>0.933871</td>\n",
       "      <td>0.804250</td>\n",
       "      <td>0.924255</td>\n",
       "      <td>0.999982</td>\n",
       "      <td>0.999745</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.955775</td>\n",
       "      <td>0.983743</td>\n",
       "      <td>0.948569</td>\n",
       "      <td>9.771114e-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.898833</td>\n",
       "      <td>0.295495</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.717540</td>\n",
       "      <td>0.252735</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.323868</td>\n",
       "      <td>0.102040</td>\n",
       "      <td>0.922758</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>100</td>\n",
       "      <td>2456</td>\n",
       "      <td>0.526467</td>\n",
       "      <td>0.186860</td>\n",
       "      <td>0.160455</td>\n",
       "      <td>0.183519</td>\n",
       "      <td>0.194339</td>\n",
       "      <td>0.160468</td>\n",
       "      <td>0.891434</td>\n",
       "      <td>0.870208</td>\n",
       "      <td>0.648624</td>\n",
       "      <td>0.670109</td>\n",
       "      <td>0.753885</td>\n",
       "      <td>0.503019</td>\n",
       "      <td>0.635399</td>\n",
       "      <td>0.461174</td>\n",
       "      <td>0.375986</td>\n",
       "      <td>0.697940</td>\n",
       "      <td>0.903339</td>\n",
       "      <td>9.784185e-01</td>\n",
       "      <td>0.896217</td>\n",
       "      <td>0.943120</td>\n",
       "      <td>0.815489</td>\n",
       "      <td>0.913688</td>\n",
       "      <td>0.894577</td>\n",
       "      <td>0.800705</td>\n",
       "      <td>0.662550</td>\n",
       "      <td>0.281065</td>\n",
       "      <td>0.889426</td>\n",
       "      <td>0.875277</td>\n",
       "      <td>0.711187</td>\n",
       "      <td>0.781553</td>\n",
       "      <td>0.329352</td>\n",
       "      <td>0.220122</td>\n",
       "      <td>0.815489</td>\n",
       "      <td>0.794061</td>\n",
       "      <td>0.160622</td>\n",
       "      <td>0.094031</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>100</td>\n",
       "      <td>5326</td>\n",
       "      <td>0.504994</td>\n",
       "      <td>0.380940</td>\n",
       "      <td>0.186081</td>\n",
       "      <td>0.370751</td>\n",
       "      <td>0.426500</td>\n",
       "      <td>0.226843</td>\n",
       "      <td>0.899571</td>\n",
       "      <td>0.758539</td>\n",
       "      <td>0.825243</td>\n",
       "      <td>0.529266</td>\n",
       "      <td>0.829671</td>\n",
       "      <td>0.994074</td>\n",
       "      <td>0.741820</td>\n",
       "      <td>0.705662</td>\n",
       "      <td>0.969831</td>\n",
       "      <td>0.849728</td>\n",
       "      <td>0.951450</td>\n",
       "      <td>9.775284e-01</td>\n",
       "      <td>0.928885</td>\n",
       "      <td>0.974094</td>\n",
       "      <td>0.856851</td>\n",
       "      <td>0.946249</td>\n",
       "      <td>0.912354</td>\n",
       "      <td>0.921801</td>\n",
       "      <td>0.722733</td>\n",
       "      <td>0.269533</td>\n",
       "      <td>0.924850</td>\n",
       "      <td>0.918991</td>\n",
       "      <td>0.834325</td>\n",
       "      <td>0.844364</td>\n",
       "      <td>0.630280</td>\n",
       "      <td>0.219975</td>\n",
       "      <td>0.830025</td>\n",
       "      <td>0.817266</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.143986</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>100</td>\n",
       "      <td>1389</td>\n",
       "      <td>0.457299</td>\n",
       "      <td>0.173582</td>\n",
       "      <td>0.152193</td>\n",
       "      <td>0.191585</td>\n",
       "      <td>0.158163</td>\n",
       "      <td>0.123656</td>\n",
       "      <td>0.703391</td>\n",
       "      <td>0.821117</td>\n",
       "      <td>0.152634</td>\n",
       "      <td>0.391795</td>\n",
       "      <td>0.576416</td>\n",
       "      <td>0.638776</td>\n",
       "      <td>0.226166</td>\n",
       "      <td>0.145849</td>\n",
       "      <td>0.320535</td>\n",
       "      <td>0.889780</td>\n",
       "      <td>0.051062</td>\n",
       "      <td>8.100848e-02</td>\n",
       "      <td>0.823537</td>\n",
       "      <td>0.892493</td>\n",
       "      <td>0.285404</td>\n",
       "      <td>0.516267</td>\n",
       "      <td>0.857341</td>\n",
       "      <td>0.760775</td>\n",
       "      <td>0.556267</td>\n",
       "      <td>0.266762</td>\n",
       "      <td>0.817845</td>\n",
       "      <td>0.790950</td>\n",
       "      <td>0.375810</td>\n",
       "      <td>0.254872</td>\n",
       "      <td>0.127706</td>\n",
       "      <td>0.116814</td>\n",
       "      <td>0.285404</td>\n",
       "      <td>0.202417</td>\n",
       "      <td>0.152070</td>\n",
       "      <td>0.101173</td>\n",
       "      <td>0.561758</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>100</td>\n",
       "      <td>5153</td>\n",
       "      <td>0.503643</td>\n",
       "      <td>0.255375</td>\n",
       "      <td>0.205944</td>\n",
       "      <td>0.346032</td>\n",
       "      <td>0.248265</td>\n",
       "      <td>0.204870</td>\n",
       "      <td>0.917486</td>\n",
       "      <td>0.947452</td>\n",
       "      <td>0.725425</td>\n",
       "      <td>0.938016</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999361</td>\n",
       "      <td>0.987637</td>\n",
       "      <td>0.967503</td>\n",
       "      <td>0.630591</td>\n",
       "      <td>0.802153</td>\n",
       "      <td>0.957659</td>\n",
       "      <td>9.760884e-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.888076</td>\n",
       "      <td>0.671056</td>\n",
       "      <td>0.357490</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.889625</td>\n",
       "      <td>0.508440</td>\n",
       "      <td>0.312266</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.244869</td>\n",
       "      <td>0.099229</td>\n",
       "      <td>0.895382</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>100</td>\n",
       "      <td>1975</td>\n",
       "      <td>0.529565</td>\n",
       "      <td>0.246333</td>\n",
       "      <td>0.155104</td>\n",
       "      <td>0.356367</td>\n",
       "      <td>0.262292</td>\n",
       "      <td>0.171215</td>\n",
       "      <td>0.872809</td>\n",
       "      <td>0.842285</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.979756</td>\n",
       "      <td>0.994504</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.505226</td>\n",
       "      <td>0.750124</td>\n",
       "      <td>0.552988</td>\n",
       "      <td>7.964698e-01</td>\n",
       "      <td>0.979904</td>\n",
       "      <td>0.989253</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.967475</td>\n",
       "      <td>0.882543</td>\n",
       "      <td>0.683351</td>\n",
       "      <td>0.322125</td>\n",
       "      <td>0.979160</td>\n",
       "      <td>0.971694</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.200952</td>\n",
       "      <td>0.100981</td>\n",
       "      <td>0.843244</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>100</td>\n",
       "      <td>705</td>\n",
       "      <td>0.391949</td>\n",
       "      <td>0.466228</td>\n",
       "      <td>0.296158</td>\n",
       "      <td>0.340712</td>\n",
       "      <td>0.485242</td>\n",
       "      <td>0.402482</td>\n",
       "      <td>0.777286</td>\n",
       "      <td>0.938553</td>\n",
       "      <td>0.700433</td>\n",
       "      <td>0.921546</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999601</td>\n",
       "      <td>0.964791</td>\n",
       "      <td>0.394490</td>\n",
       "      <td>0.975265</td>\n",
       "      <td>0.948569</td>\n",
       "      <td>9.771114e-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.744874</td>\n",
       "      <td>0.291440</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.501246</td>\n",
       "      <td>0.252735</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.176255</td>\n",
       "      <td>0.100868</td>\n",
       "      <td>0.696727</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>100</td>\n",
       "      <td>2465</td>\n",
       "      <td>0.407431</td>\n",
       "      <td>0.496899</td>\n",
       "      <td>0.300016</td>\n",
       "      <td>0.338256</td>\n",
       "      <td>0.486943</td>\n",
       "      <td>0.300016</td>\n",
       "      <td>0.939606</td>\n",
       "      <td>0.967033</td>\n",
       "      <td>0.921855</td>\n",
       "      <td>0.955799</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.967520</td>\n",
       "      <td>0.983678</td>\n",
       "      <td>0.964821</td>\n",
       "      <td>9.842812e-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.963409</td>\n",
       "      <td>0.895578</td>\n",
       "      <td>0.982281</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.950474</td>\n",
       "      <td>0.834275</td>\n",
       "      <td>0.862028</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.258714</td>\n",
       "      <td>0.100062</td>\n",
       "      <td>0.920747</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>100</td>\n",
       "      <td>4826</td>\n",
       "      <td>0.455823</td>\n",
       "      <td>0.314752</td>\n",
       "      <td>0.164622</td>\n",
       "      <td>0.298948</td>\n",
       "      <td>0.263800</td>\n",
       "      <td>0.141633</td>\n",
       "      <td>0.868833</td>\n",
       "      <td>0.827422</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.704945</td>\n",
       "      <td>0.778416</td>\n",
       "      <td>0.529429</td>\n",
       "      <td>0.568717</td>\n",
       "      <td>0.500489</td>\n",
       "      <td>0.689703</td>\n",
       "      <td>0.615027</td>\n",
       "      <td>0.946773</td>\n",
       "      <td>7.259718e-01</td>\n",
       "      <td>0.909810</td>\n",
       "      <td>0.955494</td>\n",
       "      <td>0.800127</td>\n",
       "      <td>0.918973</td>\n",
       "      <td>0.922813</td>\n",
       "      <td>0.851006</td>\n",
       "      <td>0.652218</td>\n",
       "      <td>0.241316</td>\n",
       "      <td>0.902508</td>\n",
       "      <td>0.881335</td>\n",
       "      <td>0.824919</td>\n",
       "      <td>0.738324</td>\n",
       "      <td>0.517975</td>\n",
       "      <td>0.190031</td>\n",
       "      <td>0.800127</td>\n",
       "      <td>0.776915</td>\n",
       "      <td>0.211602</td>\n",
       "      <td>0.100722</td>\n",
       "      <td>0.927618</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>100</td>\n",
       "      <td>4361</td>\n",
       "      <td>0.236921</td>\n",
       "      <td>0.156215</td>\n",
       "      <td>0.192543</td>\n",
       "      <td>0.194459</td>\n",
       "      <td>0.221758</td>\n",
       "      <td>0.182364</td>\n",
       "      <td>0.799354</td>\n",
       "      <td>0.826339</td>\n",
       "      <td>0.736696</td>\n",
       "      <td>0.807197</td>\n",
       "      <td>0.676978</td>\n",
       "      <td>0.620543</td>\n",
       "      <td>0.594695</td>\n",
       "      <td>0.702814</td>\n",
       "      <td>0.466917</td>\n",
       "      <td>0.988845</td>\n",
       "      <td>0.955315</td>\n",
       "      <td>9.816395e-01</td>\n",
       "      <td>0.869828</td>\n",
       "      <td>0.948150</td>\n",
       "      <td>0.836308</td>\n",
       "      <td>0.936795</td>\n",
       "      <td>0.805897</td>\n",
       "      <td>0.713648</td>\n",
       "      <td>0.581492</td>\n",
       "      <td>0.327424</td>\n",
       "      <td>0.869828</td>\n",
       "      <td>0.851196</td>\n",
       "      <td>0.745715</td>\n",
       "      <td>0.583339</td>\n",
       "      <td>0.381752</td>\n",
       "      <td>0.279292</td>\n",
       "      <td>0.836308</td>\n",
       "      <td>0.817298</td>\n",
       "      <td>0.255507</td>\n",
       "      <td>0.100667</td>\n",
       "      <td>0.308610</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    from    to  doc2vec:wikipedia,size=300  word2vec:wikipedia,size=300,mean  word2vec:wikipedia,size=300,max  doc2vec:tokenization,wikipedia,size=300  word2vec:tokenization,wikipedia,size=300,mean  word2vec:tokenization,wikipedia,size=300,max  noble coder:precise,tfidf  noble coder:partial,tfidf  noble coder:tokenization,precise,tfidf  noble coder:tokenization,partial,tfidf  topic modeling:nmf,full,topics=50  topic modeling:nmf,full,topics=100  topic modeling:tokenization,nmf,full,topics=50  topic modeling:tokenization,nmf,full,topics=100  topic modeling:lda,full,topics=50  topic modeling:lda,full,topics=100  topic modeling:tokenization,lda,full,topics=50  topic modeling:tokenization,lda,full,topics=100  n-grams:full,words,1-grams,tfidf  n-grams:full,words,1-grams,2-grams,tfidf  n-grams:tokenization,full,words,1-grams,tfidf  n-grams:tokenization,full,words,1-grams,2-grams,tfidf  n-grams:full,nouns,adjectives,1-grams  n-grams:linares_pontes,words,1-grams  \\\n",
       "0    100  1145                    0.484948                          0.503235                         0.263459                                 0.422335                                       0.478481                                      0.288674                   0.863608                   0.927264                                0.804840                                0.899720                           1.000000                            1.000000                                        0.985932                                         0.983500                           0.972852                            0.986386                                        0.956351                                     9.843608e-01                          1.000000                                  1.000000                                       1.000000                                           1.000000                                   1.000000                              1.000000   \n",
       "1    100  4114                    0.343207                          0.260014                         0.185656                                 0.260778                                       0.270105                                      0.180168                   0.936699                   0.963473                                0.915321                                0.957688                           0.999937                            1.000000                                        0.997800                                         0.984195                           0.848661                            0.988527                                        0.969091                                     9.845576e-01                          1.000000                                  1.000000                                       1.000000                                           1.000000                                   1.000000                              0.980422   \n",
       "2    100   231                    0.424650                          0.279231                         0.185035                                 0.296518                                       0.271672                                      0.188429                   0.888187                   0.921801                                1.000000                                1.000000                           0.824749                            0.978728                                        0.556710                                         0.931309                           0.668178                            0.980502                                        0.552669                                     9.768748e-01                          0.943099                                  0.972357                                       0.885369                                           0.931381                                   0.926808                              0.896132   \n",
       "3    100  5244                    0.515200                          0.602756                         0.363885                                 0.428738                                       0.607823                                      0.362408                   1.000000                   0.957448                                1.000000                                0.944979                           1.000000                            1.000000                                        0.999151                                         0.965712                           0.954950                            0.976779                                        0.950524                                     9.776629e-01                          1.000000                                  1.000000                                       1.000000                                           1.000000                                   1.000000                              1.000000   \n",
       "4    100   733                    0.527713                          0.270065                         0.181497                                 0.355785                                       0.293558                                      0.170425                   0.899698                   0.927390                                0.804250                                0.918117                           0.990412                            0.999971                                        0.999996                                         1.000000                           0.491172                            0.517408                                        0.958356                                     9.761760e-01                          1.000000                                  1.000000                                       1.000000                                           1.000000                                   1.000000                              0.877337   \n",
       "5    100  3896                    0.520128                          0.536171                         0.298879                                 0.399769                                       0.590710                                      0.391840                   0.973093                   0.970430                                0.971126                                0.966886                           0.981126                            0.913819                                        0.982271                                         1.000000                           0.967291                            0.983562                                        0.959602                                     9.657815e-01                          1.000000                                  1.000000                                       1.000000                                           1.000000                                   1.000000                              1.000000   \n",
       "6    100  4572                    0.490884                          0.326860                         0.179187                                 0.310596                                       0.341777                                      0.209361                   0.956777                   0.928798                                0.939667                                0.925504                           1.000000                            0.973819                                        0.910472                                         0.965566                           0.965742                            0.985249                                        0.941665                                     9.777083e-01                          1.000000                                  1.000000                                       1.000000                                           1.000000                                   1.000000                              0.916390   \n",
       "7    100  2823                    0.547941                          0.272979                         0.187657                                 0.279518                                       0.278486                                      0.199103                   0.893427                   0.902922                                1.000000                                0.889492                           0.981633                            0.978047                                        0.325492                                         0.707005                           0.970948                            0.940419                                        0.560160                                     7.171545e-01                          1.000000                                  1.000000                                       1.000000                                           1.000000                                   1.000000                              0.974706   \n",
       "8    100  1592                    0.448422                          0.438724                         0.198668                                 0.320943                                       0.365019                                      0.222920                   0.904967                   0.925881                                1.000000                                0.906443                           1.000000                            1.000000                                        0.998446                                         1.000000                           0.969069                            0.988745                                        0.959906                                     9.800199e-01                          1.000000                                  1.000000                                       1.000000                                           1.000000                                   1.000000                              0.951814   \n",
       "9    100  1185                    0.450585                          0.197340                         0.151455                                 0.301088                                       0.232980                                      0.155569                   0.909111                   0.919647                                0.666356                                0.911593                           0.998078                            0.999591                                        0.828320                                         0.981882                           0.855693                            0.859678                                        0.944414                                     8.544685e-07                          0.977251                                  0.989587                                       0.894892                                           0.957043                                   1.000000                              0.878630   \n",
       "10   100   883                    0.448113                          0.601558                         0.872109                                 0.347916                                       0.597342                                      0.807199                   0.851351                   0.933871                                0.804250                                0.924255                           0.999982                            0.999745                                        1.000000                                         1.000000                           0.955775                            0.983743                                        0.948569                                     9.771114e-01                          1.000000                                  1.000000                                       1.000000                                           1.000000                                   1.000000                              1.000000   \n",
       "11   100  2456                    0.526467                          0.186860                         0.160455                                 0.183519                                       0.194339                                      0.160468                   0.891434                   0.870208                                0.648624                                0.670109                           0.753885                            0.503019                                        0.635399                                         0.461174                           0.375986                            0.697940                                        0.903339                                     9.784185e-01                          0.896217                                  0.943120                                       0.815489                                           0.913688                                   0.894577                              0.800705   \n",
       "12   100  5326                    0.504994                          0.380940                         0.186081                                 0.370751                                       0.426500                                      0.226843                   0.899571                   0.758539                                0.825243                                0.529266                           0.829671                            0.994074                                        0.741820                                         0.705662                           0.969831                            0.849728                                        0.951450                                     9.775284e-01                          0.928885                                  0.974094                                       0.856851                                           0.946249                                   0.912354                              0.921801   \n",
       "13   100  1389                    0.457299                          0.173582                         0.152193                                 0.191585                                       0.158163                                      0.123656                   0.703391                   0.821117                                0.152634                                0.391795                           0.576416                            0.638776                                        0.226166                                         0.145849                           0.320535                            0.889780                                        0.051062                                     8.100848e-02                          0.823537                                  0.892493                                       0.285404                                           0.516267                                   0.857341                              0.760775   \n",
       "14   100  5153                    0.503643                          0.255375                         0.205944                                 0.346032                                       0.248265                                      0.204870                   0.917486                   0.947452                                0.725425                                0.938016                           1.000000                            0.999361                                        0.987637                                         0.967503                           0.630591                            0.802153                                        0.957659                                     9.760884e-01                          1.000000                                  1.000000                                       1.000000                                           1.000000                                   1.000000                              0.888076   \n",
       "15   100  1975                    0.529565                          0.246333                         0.155104                                 0.356367                                       0.262292                                      0.171215                   0.872809                   0.842285                                1.000000                                1.000000                           0.979756                            0.994504                                        1.000000                                         1.000000                           0.505226                            0.750124                                        0.552988                                     7.964698e-01                          0.979904                                  0.989253                                       1.000000                                           1.000000                                   0.967475                              0.882543   \n",
       "16   100   705                    0.391949                          0.466228                         0.296158                                 0.340712                                       0.485242                                      0.402482                   0.777286                   0.938553                                0.700433                                0.921546                           1.000000                            1.000000                                        0.999601                                         0.964791                           0.394490                            0.975265                                        0.948569                                     9.771114e-01                          1.000000                                  1.000000                                       1.000000                                           1.000000                                   1.000000                              1.000000   \n",
       "17   100  2465                    0.407431                          0.496899                         0.300016                                 0.338256                                       0.486943                                      0.300016                   0.939606                   0.967033                                0.921855                                0.955799                           1.000000                            1.000000                                        1.000000                                         1.000000                           0.967520                            0.983678                                        0.964821                                     9.842812e-01                          1.000000                                  1.000000                                       1.000000                                           1.000000                                   1.000000                              0.963409   \n",
       "18   100  4826                    0.455823                          0.314752                         0.164622                                 0.298948                                       0.263800                                      0.141633                   0.868833                   0.827422                                1.000000                                0.704945                           0.778416                            0.529429                                        0.568717                                         0.500489                           0.689703                            0.615027                                        0.946773                                     7.259718e-01                          0.909810                                  0.955494                                       0.800127                                           0.918973                                   0.922813                              0.851006   \n",
       "19   100  4361                    0.236921                          0.156215                         0.192543                                 0.194459                                       0.221758                                      0.182364                   0.799354                   0.826339                                0.736696                                0.807197                           0.676978                            0.620543                                        0.594695                                         0.702814                           0.466917                            0.988845                                        0.955315                                     9.816395e-01                          0.869828                                  0.948150                                       0.836308                                           0.936795                                   0.805897                              0.713648   \n",
       "\n",
       "    n-grams:full,precise_annotations,words,1-grams  n-grams:full,partial_annotations,words,1-grams  n-grams:full,plant overrepresented tokens,1-grams  n-grams:full,bio ontology tokens,1-grams  n-grams:tokenization,full,nouns,adjectives,1-grams  n-grams:tokenization,linares_pontes,words,1-grams  n-grams:tokenization,full,precise_annotations,words,1-grams  n-grams:tokenization,full,partial_annotations,words,1-grams  n-grams:tokenization,full,plant overrepresented tokens,1-grams  n-grams:tokenization,full,bio ontology tokens,1-grams  go:union  po:union  go:minimum  po:minimum  \n",
       "0                                         0.840402                                        0.568991                                           1.000000                                  1.000000                                           1.000000                                            1.000000                                           0.591617                                                     0.432781                                                     1.000000                                                        1.000000      1.000000  0.199791    1.000000    0.646186  \n",
       "1                                         0.812361                                        0.422756                                           1.000000                                  1.000000                                           1.000000                                            0.980264                                           0.748194                                                     0.437357                                                     1.000000                                                        1.000000      1.000000  1.000000    1.000000    1.000000  \n",
       "2                                         0.560416                                        0.496319                                           0.943099                                  0.928882                                           0.813392                                            0.868671                                           0.387241                                                     0.423178                                                     0.885369                                                        0.858600      0.240786  0.097509    0.906796    0.000000  \n",
       "3                                         1.000000                                        0.978017                                           1.000000                                  1.000000                                           1.000000                                            1.000000                                           1.000000                                                     0.897769                                                     1.000000                                                        1.000000      0.367580  0.108020    0.690276    0.474998  \n",
       "4                                         0.810659                                        0.297326                                           1.000000                                  1.000000                                           1.000000                                            0.866671                                           0.604588                                                     0.252735                                                     1.000000                                                        1.000000      0.202688  0.089205    0.690276    0.000000  \n",
       "5                                         0.921055                                        0.329352                                           1.000000                                  1.000000                                           1.000000                                            1.000000                                           0.847789                                                     0.309230                                                     1.000000                                                        1.000000      1.000000  1.000000    1.000000    1.000000  \n",
       "6                                         0.740565                                        0.356273                                           1.000000                                  1.000000                                           1.000000                                            0.897864                                           0.598539                                                     0.266433                                                     1.000000                                                        1.000000      0.622213  0.110242    0.956128    0.474998  \n",
       "7                                         0.741642                                        0.258536                                           1.000000                                  1.000000                                           1.000000                                            0.949664                                           0.555684                                                     0.233350                                                     1.000000                                                        1.000000      1.000000  1.000000    1.000000    1.000000  \n",
       "8                                         0.827605                                        0.342629                                           1.000000                                  1.000000                                           1.000000                                            0.900542                                           0.732674                                                     0.251352                                                     1.000000                                                        1.000000      0.229783  0.093575    0.484877    0.000000  \n",
       "9                                         0.720393                                        0.329431                                           0.976848                                  1.000000                                           1.000000                                            0.839561                                           0.424285                                                     0.281615                                                     0.873610                                                        1.000000      0.218605  0.217137    0.897383    0.539171  \n",
       "10                                        0.898833                                        0.295495                                           1.000000                                  1.000000                                           1.000000                                            1.000000                                           0.717540                                                     0.252735                                                     1.000000                                                        1.000000      0.323868  0.102040    0.922758    0.000000  \n",
       "11                                        0.662550                                        0.281065                                           0.889426                                  0.875277                                           0.711187                                            0.781553                                           0.329352                                                     0.220122                                                     0.815489                                                        0.794061      0.160622  0.094031    0.000000    0.000000  \n",
       "12                                        0.722733                                        0.269533                                           0.924850                                  0.918991                                           0.834325                                            0.844364                                           0.630280                                                     0.219975                                                     0.830025                                                        0.817266      1.000000  0.143986    1.000000    0.000000  \n",
       "13                                        0.556267                                        0.266762                                           0.817845                                  0.790950                                           0.375810                                            0.254872                                           0.127706                                                     0.116814                                                     0.285404                                                        0.202417      0.152070  0.101173    0.561758    0.000000  \n",
       "14                                        0.671056                                        0.357490                                           1.000000                                  1.000000                                           1.000000                                            0.889625                                           0.508440                                                     0.312266                                                     1.000000                                                        1.000000      0.244869  0.099229    0.895382    0.000000  \n",
       "15                                        0.683351                                        0.322125                                           0.979160                                  0.971694                                           1.000000                                            1.000000                                           1.000000                                                     1.000000                                                     1.000000                                                        1.000000      0.200952  0.100981    0.843244    0.000000  \n",
       "16                                        0.744874                                        0.291440                                           1.000000                                  1.000000                                           1.000000                                            1.000000                                           0.501246                                                     0.252735                                                     1.000000                                                        1.000000      0.176255  0.100868    0.696727    0.000000  \n",
       "17                                        0.895578                                        0.982281                                           1.000000                                  1.000000                                           1.000000                                            0.950474                                           0.834275                                                     0.862028                                                     1.000000                                                        1.000000      0.258714  0.100062    0.920747    0.000000  \n",
       "18                                        0.652218                                        0.241316                                           0.902508                                  0.881335                                           0.824919                                            0.738324                                           0.517975                                                     0.190031                                                     0.800127                                                        0.776915      0.211602  0.100722    0.927618    0.000000  \n",
       "19                                        0.581492                                        0.327424                                           0.869828                                  0.851196                                           0.745715                                            0.583339                                           0.381752                                                     0.279292                                                     0.836308                                                        0.817298      0.255507  0.100667    0.308610    0.000000  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Depending on what the IDs in the dictionaries for each approach were referencing, the distance values in the\n",
    "# arrays that were returned mean different things. In some cases, the IDs might refer to unique text strings parsed\n",
    "# from the whole descriptions, or tokenized strings referring to single sentences, or they might be referring to \n",
    "# particular unique gene ontology terms that were used in the curated annotations, or to unique whole sets of terms\n",
    "# that were used in the annotations. This dictionary maps tags associated with each approach to which function and \n",
    "# dictionary for translating between ID types in order to handle each approach appropriately.\n",
    "\n",
    "function_and_mapping_to_use = {\n",
    "    \"sent_tokens\":(get_min_of_distances, gene_id_to_unique_ids_mappings[\"sent_tokens\"]),\n",
    "    \"whole_texts\":(lookup_distance, gene_id_to_unique_ids_mappings[\"whole_texts\"]),\n",
    "    \"go_term_sets\":(lookup_distance, gene_id_to_unique_ids_mappings[\"go_term_sets\"]),\n",
    "    \"po_term_sets\":(lookup_distance, gene_id_to_unique_ids_mappings[\"po_term_sets\"]),\n",
    "    \"go_terms\":(get_min_of_distances, gene_id_to_unique_ids_mappings[\"go_terms\"]),\n",
    "    \"po_terms\":(get_min_of_distances, gene_id_to_unique_ids_mappings[\"po_terms\"])}\n",
    "\n",
    "\n",
    "# Create one new column in the edge list dataframe for each of the approaches that were used.\n",
    "for name,graph in graphs.items():\n",
    "    print(name)\n",
    "    function, mapping = function_and_mapping_to_use[tags_dict[name]]\n",
    "    df[name] = df.apply(lambda x: function(x[\"from\"], x[\"to\"], mapping, graph.id_to_index, graph.array), axis=1)\n",
    "        \n",
    "\n",
    "# Memory cleanup for the extremely large objects returned by the distance matrix generating functions.\n",
    "graphs = None\n",
    "\n",
    "\n",
    "# Because cosine similarity and distance functions are used, vectors with all zeroes will have undefined similarity\n",
    "# to other vectors. This results when empty strings or empty lists are passed to the methods that generate vectors\n",
    "# and distances matrices over this dataset. Therefore those NaNs that result are replaced here with the maximum\n",
    "# distance value, which is set 1 because the range of all the distance functions used is 0 to 1.\n",
    "df.fillna(value=1.000, inplace=True)\n",
    "\n",
    "\n",
    "# Make sure that the edge list contains the expected data types before moving forward.\n",
    "df[\"from\"] = df[\"from\"].astype(\"int64\")\n",
    "df[\"to\"] = df[\"to\"].astype(\"int64\")\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"merging\"></a>\n",
    "### Merging all of the distance matrices into a single dataframe specifying edges\n",
    "This section also handles replacing IDs from the individual methods that are references individual phenes that are part of a larger phenotype, and replacing those IDs with IDs referencing the full phenotypes (one-to-one relationship between phenotypes and genes). In this case, the minimum distance found between any two phenes from those two phenotypes represents the distance between that pair of phenotypes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"ensemble\"></a>\n",
    "### Combining multiple distances measurements into summarizing distance values\n",
    "The purpose of this section is to iteratively train models on subsections of the dataset using simple regression or machine learning approaches to predict a value from zero to one indicating indicating how likely is it that two genes share atleast one of the specified groups in common. The information input to these models is the distance scores provided by each method in some set of all the methods used in this notebook. The purpose is to see whether or not a function of these similarity scores specifically trained to the task of predicting common groupings is better able to used the distance metric information to report a score for this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>from</th>\n",
       "      <th>to</th>\n",
       "      <th>doc2vec:wikipedia,size=300</th>\n",
       "      <th>word2vec:wikipedia,size=300,mean</th>\n",
       "      <th>word2vec:wikipedia,size=300,max</th>\n",
       "      <th>doc2vec:tokenization,wikipedia,size=300</th>\n",
       "      <th>word2vec:tokenization,wikipedia,size=300,mean</th>\n",
       "      <th>word2vec:tokenization,wikipedia,size=300,max</th>\n",
       "      <th>noble coder:precise,tfidf</th>\n",
       "      <th>noble coder:partial,tfidf</th>\n",
       "      <th>noble coder:tokenization,precise,tfidf</th>\n",
       "      <th>noble coder:tokenization,partial,tfidf</th>\n",
       "      <th>topic modeling:nmf,full,topics=50</th>\n",
       "      <th>topic modeling:nmf,full,topics=100</th>\n",
       "      <th>topic modeling:tokenization,nmf,full,topics=50</th>\n",
       "      <th>topic modeling:tokenization,nmf,full,topics=100</th>\n",
       "      <th>topic modeling:lda,full,topics=50</th>\n",
       "      <th>topic modeling:lda,full,topics=100</th>\n",
       "      <th>topic modeling:tokenization,lda,full,topics=50</th>\n",
       "      <th>topic modeling:tokenization,lda,full,topics=100</th>\n",
       "      <th>n-grams:full,words,1-grams,tfidf</th>\n",
       "      <th>n-grams:full,words,1-grams,2-grams,tfidf</th>\n",
       "      <th>n-grams:tokenization,full,words,1-grams,tfidf</th>\n",
       "      <th>n-grams:tokenization,full,words,1-grams,2-grams,tfidf</th>\n",
       "      <th>n-grams:full,nouns,adjectives,1-grams</th>\n",
       "      <th>n-grams:linares_pontes,words,1-grams</th>\n",
       "      <th>n-grams:full,precise_annotations,words,1-grams</th>\n",
       "      <th>n-grams:full,partial_annotations,words,1-grams</th>\n",
       "      <th>n-grams:full,plant overrepresented tokens,1-grams</th>\n",
       "      <th>n-grams:full,bio ontology tokens,1-grams</th>\n",
       "      <th>n-grams:tokenization,full,nouns,adjectives,1-grams</th>\n",
       "      <th>n-grams:tokenization,linares_pontes,words,1-grams</th>\n",
       "      <th>n-grams:tokenization,full,precise_annotations,words,1-grams</th>\n",
       "      <th>n-grams:tokenization,full,partial_annotations,words,1-grams</th>\n",
       "      <th>n-grams:tokenization,full,plant overrepresented tokens,1-grams</th>\n",
       "      <th>n-grams:tokenization,full,bio ontology tokens,1-grams</th>\n",
       "      <th>go:union</th>\n",
       "      <th>po:union</th>\n",
       "      <th>go:minimum</th>\n",
       "      <th>po:minimum</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>1145</td>\n",
       "      <td>0.484948</td>\n",
       "      <td>0.503235</td>\n",
       "      <td>0.263459</td>\n",
       "      <td>0.422335</td>\n",
       "      <td>0.478481</td>\n",
       "      <td>0.288674</td>\n",
       "      <td>0.863608</td>\n",
       "      <td>0.927264</td>\n",
       "      <td>0.804840</td>\n",
       "      <td>0.899720</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.985932</td>\n",
       "      <td>0.983500</td>\n",
       "      <td>0.972852</td>\n",
       "      <td>0.986386</td>\n",
       "      <td>0.956351</td>\n",
       "      <td>9.843608e-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.840402</td>\n",
       "      <td>0.568991</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.591617</td>\n",
       "      <td>0.432781</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.199791</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.646186</td>\n",
       "      <td>0.696545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100</td>\n",
       "      <td>4114</td>\n",
       "      <td>0.343207</td>\n",
       "      <td>0.260014</td>\n",
       "      <td>0.185656</td>\n",
       "      <td>0.260778</td>\n",
       "      <td>0.270105</td>\n",
       "      <td>0.180168</td>\n",
       "      <td>0.936699</td>\n",
       "      <td>0.963473</td>\n",
       "      <td>0.915321</td>\n",
       "      <td>0.957688</td>\n",
       "      <td>0.999937</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.997800</td>\n",
       "      <td>0.984195</td>\n",
       "      <td>0.848661</td>\n",
       "      <td>0.988527</td>\n",
       "      <td>0.969091</td>\n",
       "      <td>9.845576e-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.980422</td>\n",
       "      <td>0.812361</td>\n",
       "      <td>0.422756</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.980264</td>\n",
       "      <td>0.748194</td>\n",
       "      <td>0.437357</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.637134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>231</td>\n",
       "      <td>0.424650</td>\n",
       "      <td>0.279231</td>\n",
       "      <td>0.185035</td>\n",
       "      <td>0.296518</td>\n",
       "      <td>0.271672</td>\n",
       "      <td>0.188429</td>\n",
       "      <td>0.888187</td>\n",
       "      <td>0.921801</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.824749</td>\n",
       "      <td>0.978728</td>\n",
       "      <td>0.556710</td>\n",
       "      <td>0.931309</td>\n",
       "      <td>0.668178</td>\n",
       "      <td>0.980502</td>\n",
       "      <td>0.552669</td>\n",
       "      <td>9.768748e-01</td>\n",
       "      <td>0.943099</td>\n",
       "      <td>0.972357</td>\n",
       "      <td>0.885369</td>\n",
       "      <td>0.931381</td>\n",
       "      <td>0.926808</td>\n",
       "      <td>0.896132</td>\n",
       "      <td>0.560416</td>\n",
       "      <td>0.496319</td>\n",
       "      <td>0.943099</td>\n",
       "      <td>0.928882</td>\n",
       "      <td>0.813392</td>\n",
       "      <td>0.868671</td>\n",
       "      <td>0.387241</td>\n",
       "      <td>0.423178</td>\n",
       "      <td>0.885369</td>\n",
       "      <td>0.858600</td>\n",
       "      <td>0.240786</td>\n",
       "      <td>0.097509</td>\n",
       "      <td>0.906796</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.385529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100</td>\n",
       "      <td>5244</td>\n",
       "      <td>0.515200</td>\n",
       "      <td>0.602756</td>\n",
       "      <td>0.363885</td>\n",
       "      <td>0.428738</td>\n",
       "      <td>0.607823</td>\n",
       "      <td>0.362408</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.957448</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.944979</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999151</td>\n",
       "      <td>0.965712</td>\n",
       "      <td>0.954950</td>\n",
       "      <td>0.976779</td>\n",
       "      <td>0.950524</td>\n",
       "      <td>9.776629e-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.978017</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.897769</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.367580</td>\n",
       "      <td>0.108020</td>\n",
       "      <td>0.690276</td>\n",
       "      <td>0.474998</td>\n",
       "      <td>0.770669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100</td>\n",
       "      <td>733</td>\n",
       "      <td>0.527713</td>\n",
       "      <td>0.270065</td>\n",
       "      <td>0.181497</td>\n",
       "      <td>0.355785</td>\n",
       "      <td>0.293558</td>\n",
       "      <td>0.170425</td>\n",
       "      <td>0.899698</td>\n",
       "      <td>0.927390</td>\n",
       "      <td>0.804250</td>\n",
       "      <td>0.918117</td>\n",
       "      <td>0.990412</td>\n",
       "      <td>0.999971</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.491172</td>\n",
       "      <td>0.517408</td>\n",
       "      <td>0.958356</td>\n",
       "      <td>9.761760e-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.877337</td>\n",
       "      <td>0.810659</td>\n",
       "      <td>0.297326</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.866671</td>\n",
       "      <td>0.604588</td>\n",
       "      <td>0.252735</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.202688</td>\n",
       "      <td>0.089205</td>\n",
       "      <td>0.690276</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.576333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>100</td>\n",
       "      <td>3896</td>\n",
       "      <td>0.520128</td>\n",
       "      <td>0.536171</td>\n",
       "      <td>0.298879</td>\n",
       "      <td>0.399769</td>\n",
       "      <td>0.590710</td>\n",
       "      <td>0.391840</td>\n",
       "      <td>0.973093</td>\n",
       "      <td>0.970430</td>\n",
       "      <td>0.971126</td>\n",
       "      <td>0.966886</td>\n",
       "      <td>0.981126</td>\n",
       "      <td>0.913819</td>\n",
       "      <td>0.982271</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.967291</td>\n",
       "      <td>0.983562</td>\n",
       "      <td>0.959602</td>\n",
       "      <td>9.657815e-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.921055</td>\n",
       "      <td>0.329352</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.847789</td>\n",
       "      <td>0.309230</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.704863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>100</td>\n",
       "      <td>4572</td>\n",
       "      <td>0.490884</td>\n",
       "      <td>0.326860</td>\n",
       "      <td>0.179187</td>\n",
       "      <td>0.310596</td>\n",
       "      <td>0.341777</td>\n",
       "      <td>0.209361</td>\n",
       "      <td>0.956777</td>\n",
       "      <td>0.928798</td>\n",
       "      <td>0.939667</td>\n",
       "      <td>0.925504</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.973819</td>\n",
       "      <td>0.910472</td>\n",
       "      <td>0.965566</td>\n",
       "      <td>0.965742</td>\n",
       "      <td>0.985249</td>\n",
       "      <td>0.941665</td>\n",
       "      <td>9.777083e-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.916390</td>\n",
       "      <td>0.740565</td>\n",
       "      <td>0.356273</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.897864</td>\n",
       "      <td>0.598539</td>\n",
       "      <td>0.266433</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.622213</td>\n",
       "      <td>0.110242</td>\n",
       "      <td>0.956128</td>\n",
       "      <td>0.474998</td>\n",
       "      <td>0.595887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>100</td>\n",
       "      <td>2823</td>\n",
       "      <td>0.547941</td>\n",
       "      <td>0.272979</td>\n",
       "      <td>0.187657</td>\n",
       "      <td>0.279518</td>\n",
       "      <td>0.278486</td>\n",
       "      <td>0.199103</td>\n",
       "      <td>0.893427</td>\n",
       "      <td>0.902922</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.889492</td>\n",
       "      <td>0.981633</td>\n",
       "      <td>0.978047</td>\n",
       "      <td>0.325492</td>\n",
       "      <td>0.707005</td>\n",
       "      <td>0.970948</td>\n",
       "      <td>0.940419</td>\n",
       "      <td>0.560160</td>\n",
       "      <td>7.171545e-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.974706</td>\n",
       "      <td>0.741642</td>\n",
       "      <td>0.258536</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.949664</td>\n",
       "      <td>0.555684</td>\n",
       "      <td>0.233350</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.528961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>100</td>\n",
       "      <td>1592</td>\n",
       "      <td>0.448422</td>\n",
       "      <td>0.438724</td>\n",
       "      <td>0.198668</td>\n",
       "      <td>0.320943</td>\n",
       "      <td>0.365019</td>\n",
       "      <td>0.222920</td>\n",
       "      <td>0.904967</td>\n",
       "      <td>0.925881</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.906443</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998446</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.969069</td>\n",
       "      <td>0.988745</td>\n",
       "      <td>0.959906</td>\n",
       "      <td>9.800199e-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.951814</td>\n",
       "      <td>0.827605</td>\n",
       "      <td>0.342629</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.900542</td>\n",
       "      <td>0.732674</td>\n",
       "      <td>0.251352</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.229783</td>\n",
       "      <td>0.093575</td>\n",
       "      <td>0.484877</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.663482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>100</td>\n",
       "      <td>1185</td>\n",
       "      <td>0.450585</td>\n",
       "      <td>0.197340</td>\n",
       "      <td>0.151455</td>\n",
       "      <td>0.301088</td>\n",
       "      <td>0.232980</td>\n",
       "      <td>0.155569</td>\n",
       "      <td>0.909111</td>\n",
       "      <td>0.919647</td>\n",
       "      <td>0.666356</td>\n",
       "      <td>0.911593</td>\n",
       "      <td>0.998078</td>\n",
       "      <td>0.999591</td>\n",
       "      <td>0.828320</td>\n",
       "      <td>0.981882</td>\n",
       "      <td>0.855693</td>\n",
       "      <td>0.859678</td>\n",
       "      <td>0.944414</td>\n",
       "      <td>8.544685e-07</td>\n",
       "      <td>0.977251</td>\n",
       "      <td>0.989587</td>\n",
       "      <td>0.894892</td>\n",
       "      <td>0.957043</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.878630</td>\n",
       "      <td>0.720393</td>\n",
       "      <td>0.329431</td>\n",
       "      <td>0.976848</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.839561</td>\n",
       "      <td>0.424285</td>\n",
       "      <td>0.281615</td>\n",
       "      <td>0.873610</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.218605</td>\n",
       "      <td>0.217137</td>\n",
       "      <td>0.897383</td>\n",
       "      <td>0.539171</td>\n",
       "      <td>0.429050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>100</td>\n",
       "      <td>883</td>\n",
       "      <td>0.448113</td>\n",
       "      <td>0.601558</td>\n",
       "      <td>0.872109</td>\n",
       "      <td>0.347916</td>\n",
       "      <td>0.597342</td>\n",
       "      <td>0.807199</td>\n",
       "      <td>0.851351</td>\n",
       "      <td>0.933871</td>\n",
       "      <td>0.804250</td>\n",
       "      <td>0.924255</td>\n",
       "      <td>0.999982</td>\n",
       "      <td>0.999745</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.955775</td>\n",
       "      <td>0.983743</td>\n",
       "      <td>0.948569</td>\n",
       "      <td>9.771114e-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.898833</td>\n",
       "      <td>0.295495</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.717540</td>\n",
       "      <td>0.252735</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.323868</td>\n",
       "      <td>0.102040</td>\n",
       "      <td>0.922758</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.690772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>100</td>\n",
       "      <td>2456</td>\n",
       "      <td>0.526467</td>\n",
       "      <td>0.186860</td>\n",
       "      <td>0.160455</td>\n",
       "      <td>0.183519</td>\n",
       "      <td>0.194339</td>\n",
       "      <td>0.160468</td>\n",
       "      <td>0.891434</td>\n",
       "      <td>0.870208</td>\n",
       "      <td>0.648624</td>\n",
       "      <td>0.670109</td>\n",
       "      <td>0.753885</td>\n",
       "      <td>0.503019</td>\n",
       "      <td>0.635399</td>\n",
       "      <td>0.461174</td>\n",
       "      <td>0.375986</td>\n",
       "      <td>0.697940</td>\n",
       "      <td>0.903339</td>\n",
       "      <td>9.784185e-01</td>\n",
       "      <td>0.896217</td>\n",
       "      <td>0.943120</td>\n",
       "      <td>0.815489</td>\n",
       "      <td>0.913688</td>\n",
       "      <td>0.894577</td>\n",
       "      <td>0.800705</td>\n",
       "      <td>0.662550</td>\n",
       "      <td>0.281065</td>\n",
       "      <td>0.889426</td>\n",
       "      <td>0.875277</td>\n",
       "      <td>0.711187</td>\n",
       "      <td>0.781553</td>\n",
       "      <td>0.329352</td>\n",
       "      <td>0.220122</td>\n",
       "      <td>0.815489</td>\n",
       "      <td>0.794061</td>\n",
       "      <td>0.160622</td>\n",
       "      <td>0.094031</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.255310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>100</td>\n",
       "      <td>5326</td>\n",
       "      <td>0.504994</td>\n",
       "      <td>0.380940</td>\n",
       "      <td>0.186081</td>\n",
       "      <td>0.370751</td>\n",
       "      <td>0.426500</td>\n",
       "      <td>0.226843</td>\n",
       "      <td>0.899571</td>\n",
       "      <td>0.758539</td>\n",
       "      <td>0.825243</td>\n",
       "      <td>0.529266</td>\n",
       "      <td>0.829671</td>\n",
       "      <td>0.994074</td>\n",
       "      <td>0.741820</td>\n",
       "      <td>0.705662</td>\n",
       "      <td>0.969831</td>\n",
       "      <td>0.849728</td>\n",
       "      <td>0.951450</td>\n",
       "      <td>9.775284e-01</td>\n",
       "      <td>0.928885</td>\n",
       "      <td>0.974094</td>\n",
       "      <td>0.856851</td>\n",
       "      <td>0.946249</td>\n",
       "      <td>0.912354</td>\n",
       "      <td>0.921801</td>\n",
       "      <td>0.722733</td>\n",
       "      <td>0.269533</td>\n",
       "      <td>0.924850</td>\n",
       "      <td>0.918991</td>\n",
       "      <td>0.834325</td>\n",
       "      <td>0.844364</td>\n",
       "      <td>0.630280</td>\n",
       "      <td>0.219975</td>\n",
       "      <td>0.830025</td>\n",
       "      <td>0.817266</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.143986</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.398353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>100</td>\n",
       "      <td>1389</td>\n",
       "      <td>0.457299</td>\n",
       "      <td>0.173582</td>\n",
       "      <td>0.152193</td>\n",
       "      <td>0.191585</td>\n",
       "      <td>0.158163</td>\n",
       "      <td>0.123656</td>\n",
       "      <td>0.703391</td>\n",
       "      <td>0.821117</td>\n",
       "      <td>0.152634</td>\n",
       "      <td>0.391795</td>\n",
       "      <td>0.576416</td>\n",
       "      <td>0.638776</td>\n",
       "      <td>0.226166</td>\n",
       "      <td>0.145849</td>\n",
       "      <td>0.320535</td>\n",
       "      <td>0.889780</td>\n",
       "      <td>0.051062</td>\n",
       "      <td>8.100848e-02</td>\n",
       "      <td>0.823537</td>\n",
       "      <td>0.892493</td>\n",
       "      <td>0.285404</td>\n",
       "      <td>0.516267</td>\n",
       "      <td>0.857341</td>\n",
       "      <td>0.760775</td>\n",
       "      <td>0.556267</td>\n",
       "      <td>0.266762</td>\n",
       "      <td>0.817845</td>\n",
       "      <td>0.790950</td>\n",
       "      <td>0.375810</td>\n",
       "      <td>0.254872</td>\n",
       "      <td>0.127706</td>\n",
       "      <td>0.116814</td>\n",
       "      <td>0.285404</td>\n",
       "      <td>0.202417</td>\n",
       "      <td>0.152070</td>\n",
       "      <td>0.101173</td>\n",
       "      <td>0.561758</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.114008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>100</td>\n",
       "      <td>5153</td>\n",
       "      <td>0.503643</td>\n",
       "      <td>0.255375</td>\n",
       "      <td>0.205944</td>\n",
       "      <td>0.346032</td>\n",
       "      <td>0.248265</td>\n",
       "      <td>0.204870</td>\n",
       "      <td>0.917486</td>\n",
       "      <td>0.947452</td>\n",
       "      <td>0.725425</td>\n",
       "      <td>0.938016</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999361</td>\n",
       "      <td>0.987637</td>\n",
       "      <td>0.967503</td>\n",
       "      <td>0.630591</td>\n",
       "      <td>0.802153</td>\n",
       "      <td>0.957659</td>\n",
       "      <td>9.760884e-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.888076</td>\n",
       "      <td>0.671056</td>\n",
       "      <td>0.357490</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.889625</td>\n",
       "      <td>0.508440</td>\n",
       "      <td>0.312266</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.244869</td>\n",
       "      <td>0.099229</td>\n",
       "      <td>0.895382</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.573919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>100</td>\n",
       "      <td>1975</td>\n",
       "      <td>0.529565</td>\n",
       "      <td>0.246333</td>\n",
       "      <td>0.155104</td>\n",
       "      <td>0.356367</td>\n",
       "      <td>0.262292</td>\n",
       "      <td>0.171215</td>\n",
       "      <td>0.872809</td>\n",
       "      <td>0.842285</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.979756</td>\n",
       "      <td>0.994504</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.505226</td>\n",
       "      <td>0.750124</td>\n",
       "      <td>0.552988</td>\n",
       "      <td>7.964698e-01</td>\n",
       "      <td>0.979904</td>\n",
       "      <td>0.989253</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.967475</td>\n",
       "      <td>0.882543</td>\n",
       "      <td>0.683351</td>\n",
       "      <td>0.322125</td>\n",
       "      <td>0.979160</td>\n",
       "      <td>0.971694</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.200952</td>\n",
       "      <td>0.100981</td>\n",
       "      <td>0.843244</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.533735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>100</td>\n",
       "      <td>705</td>\n",
       "      <td>0.391949</td>\n",
       "      <td>0.466228</td>\n",
       "      <td>0.296158</td>\n",
       "      <td>0.340712</td>\n",
       "      <td>0.485242</td>\n",
       "      <td>0.402482</td>\n",
       "      <td>0.777286</td>\n",
       "      <td>0.938553</td>\n",
       "      <td>0.700433</td>\n",
       "      <td>0.921546</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999601</td>\n",
       "      <td>0.964791</td>\n",
       "      <td>0.394490</td>\n",
       "      <td>0.975265</td>\n",
       "      <td>0.948569</td>\n",
       "      <td>9.771114e-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.744874</td>\n",
       "      <td>0.291440</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.501246</td>\n",
       "      <td>0.252735</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.176255</td>\n",
       "      <td>0.100868</td>\n",
       "      <td>0.696727</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.619199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>100</td>\n",
       "      <td>2465</td>\n",
       "      <td>0.407431</td>\n",
       "      <td>0.496899</td>\n",
       "      <td>0.300016</td>\n",
       "      <td>0.338256</td>\n",
       "      <td>0.486943</td>\n",
       "      <td>0.300016</td>\n",
       "      <td>0.939606</td>\n",
       "      <td>0.967033</td>\n",
       "      <td>0.921855</td>\n",
       "      <td>0.955799</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.967520</td>\n",
       "      <td>0.983678</td>\n",
       "      <td>0.964821</td>\n",
       "      <td>9.842812e-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.963409</td>\n",
       "      <td>0.895578</td>\n",
       "      <td>0.982281</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.950474</td>\n",
       "      <td>0.834275</td>\n",
       "      <td>0.862028</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.258714</td>\n",
       "      <td>0.100062</td>\n",
       "      <td>0.920747</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.731418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>100</td>\n",
       "      <td>4826</td>\n",
       "      <td>0.455823</td>\n",
       "      <td>0.314752</td>\n",
       "      <td>0.164622</td>\n",
       "      <td>0.298948</td>\n",
       "      <td>0.263800</td>\n",
       "      <td>0.141633</td>\n",
       "      <td>0.868833</td>\n",
       "      <td>0.827422</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.704945</td>\n",
       "      <td>0.778416</td>\n",
       "      <td>0.529429</td>\n",
       "      <td>0.568717</td>\n",
       "      <td>0.500489</td>\n",
       "      <td>0.689703</td>\n",
       "      <td>0.615027</td>\n",
       "      <td>0.946773</td>\n",
       "      <td>7.259718e-01</td>\n",
       "      <td>0.909810</td>\n",
       "      <td>0.955494</td>\n",
       "      <td>0.800127</td>\n",
       "      <td>0.918973</td>\n",
       "      <td>0.922813</td>\n",
       "      <td>0.851006</td>\n",
       "      <td>0.652218</td>\n",
       "      <td>0.241316</td>\n",
       "      <td>0.902508</td>\n",
       "      <td>0.881335</td>\n",
       "      <td>0.824919</td>\n",
       "      <td>0.738324</td>\n",
       "      <td>0.517975</td>\n",
       "      <td>0.190031</td>\n",
       "      <td>0.800127</td>\n",
       "      <td>0.776915</td>\n",
       "      <td>0.211602</td>\n",
       "      <td>0.100722</td>\n",
       "      <td>0.927618</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.280085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>100</td>\n",
       "      <td>4361</td>\n",
       "      <td>0.236921</td>\n",
       "      <td>0.156215</td>\n",
       "      <td>0.192543</td>\n",
       "      <td>0.194459</td>\n",
       "      <td>0.221758</td>\n",
       "      <td>0.182364</td>\n",
       "      <td>0.799354</td>\n",
       "      <td>0.826339</td>\n",
       "      <td>0.736696</td>\n",
       "      <td>0.807197</td>\n",
       "      <td>0.676978</td>\n",
       "      <td>0.620543</td>\n",
       "      <td>0.594695</td>\n",
       "      <td>0.702814</td>\n",
       "      <td>0.466917</td>\n",
       "      <td>0.988845</td>\n",
       "      <td>0.955315</td>\n",
       "      <td>9.816395e-01</td>\n",
       "      <td>0.869828</td>\n",
       "      <td>0.948150</td>\n",
       "      <td>0.836308</td>\n",
       "      <td>0.936795</td>\n",
       "      <td>0.805897</td>\n",
       "      <td>0.713648</td>\n",
       "      <td>0.581492</td>\n",
       "      <td>0.327424</td>\n",
       "      <td>0.869828</td>\n",
       "      <td>0.851196</td>\n",
       "      <td>0.745715</td>\n",
       "      <td>0.583339</td>\n",
       "      <td>0.381752</td>\n",
       "      <td>0.279292</td>\n",
       "      <td>0.836308</td>\n",
       "      <td>0.817298</td>\n",
       "      <td>0.255507</td>\n",
       "      <td>0.100667</td>\n",
       "      <td>0.308610</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.261065</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    from    to  doc2vec:wikipedia,size=300  word2vec:wikipedia,size=300,mean  word2vec:wikipedia,size=300,max  doc2vec:tokenization,wikipedia,size=300  word2vec:tokenization,wikipedia,size=300,mean  word2vec:tokenization,wikipedia,size=300,max  noble coder:precise,tfidf  noble coder:partial,tfidf  noble coder:tokenization,precise,tfidf  noble coder:tokenization,partial,tfidf  topic modeling:nmf,full,topics=50  topic modeling:nmf,full,topics=100  topic modeling:tokenization,nmf,full,topics=50  topic modeling:tokenization,nmf,full,topics=100  topic modeling:lda,full,topics=50  topic modeling:lda,full,topics=100  topic modeling:tokenization,lda,full,topics=50  topic modeling:tokenization,lda,full,topics=100  n-grams:full,words,1-grams,tfidf  n-grams:full,words,1-grams,2-grams,tfidf  n-grams:tokenization,full,words,1-grams,tfidf  n-grams:tokenization,full,words,1-grams,2-grams,tfidf  n-grams:full,nouns,adjectives,1-grams  n-grams:linares_pontes,words,1-grams  \\\n",
       "0    100  1145                    0.484948                          0.503235                         0.263459                                 0.422335                                       0.478481                                      0.288674                   0.863608                   0.927264                                0.804840                                0.899720                           1.000000                            1.000000                                        0.985932                                         0.983500                           0.972852                            0.986386                                        0.956351                                     9.843608e-01                          1.000000                                  1.000000                                       1.000000                                           1.000000                                   1.000000                              1.000000   \n",
       "1    100  4114                    0.343207                          0.260014                         0.185656                                 0.260778                                       0.270105                                      0.180168                   0.936699                   0.963473                                0.915321                                0.957688                           0.999937                            1.000000                                        0.997800                                         0.984195                           0.848661                            0.988527                                        0.969091                                     9.845576e-01                          1.000000                                  1.000000                                       1.000000                                           1.000000                                   1.000000                              0.980422   \n",
       "2    100   231                    0.424650                          0.279231                         0.185035                                 0.296518                                       0.271672                                      0.188429                   0.888187                   0.921801                                1.000000                                1.000000                           0.824749                            0.978728                                        0.556710                                         0.931309                           0.668178                            0.980502                                        0.552669                                     9.768748e-01                          0.943099                                  0.972357                                       0.885369                                           0.931381                                   0.926808                              0.896132   \n",
       "3    100  5244                    0.515200                          0.602756                         0.363885                                 0.428738                                       0.607823                                      0.362408                   1.000000                   0.957448                                1.000000                                0.944979                           1.000000                            1.000000                                        0.999151                                         0.965712                           0.954950                            0.976779                                        0.950524                                     9.776629e-01                          1.000000                                  1.000000                                       1.000000                                           1.000000                                   1.000000                              1.000000   \n",
       "4    100   733                    0.527713                          0.270065                         0.181497                                 0.355785                                       0.293558                                      0.170425                   0.899698                   0.927390                                0.804250                                0.918117                           0.990412                            0.999971                                        0.999996                                         1.000000                           0.491172                            0.517408                                        0.958356                                     9.761760e-01                          1.000000                                  1.000000                                       1.000000                                           1.000000                                   1.000000                              0.877337   \n",
       "5    100  3896                    0.520128                          0.536171                         0.298879                                 0.399769                                       0.590710                                      0.391840                   0.973093                   0.970430                                0.971126                                0.966886                           0.981126                            0.913819                                        0.982271                                         1.000000                           0.967291                            0.983562                                        0.959602                                     9.657815e-01                          1.000000                                  1.000000                                       1.000000                                           1.000000                                   1.000000                              1.000000   \n",
       "6    100  4572                    0.490884                          0.326860                         0.179187                                 0.310596                                       0.341777                                      0.209361                   0.956777                   0.928798                                0.939667                                0.925504                           1.000000                            0.973819                                        0.910472                                         0.965566                           0.965742                            0.985249                                        0.941665                                     9.777083e-01                          1.000000                                  1.000000                                       1.000000                                           1.000000                                   1.000000                              0.916390   \n",
       "7    100  2823                    0.547941                          0.272979                         0.187657                                 0.279518                                       0.278486                                      0.199103                   0.893427                   0.902922                                1.000000                                0.889492                           0.981633                            0.978047                                        0.325492                                         0.707005                           0.970948                            0.940419                                        0.560160                                     7.171545e-01                          1.000000                                  1.000000                                       1.000000                                           1.000000                                   1.000000                              0.974706   \n",
       "8    100  1592                    0.448422                          0.438724                         0.198668                                 0.320943                                       0.365019                                      0.222920                   0.904967                   0.925881                                1.000000                                0.906443                           1.000000                            1.000000                                        0.998446                                         1.000000                           0.969069                            0.988745                                        0.959906                                     9.800199e-01                          1.000000                                  1.000000                                       1.000000                                           1.000000                                   1.000000                              0.951814   \n",
       "9    100  1185                    0.450585                          0.197340                         0.151455                                 0.301088                                       0.232980                                      0.155569                   0.909111                   0.919647                                0.666356                                0.911593                           0.998078                            0.999591                                        0.828320                                         0.981882                           0.855693                            0.859678                                        0.944414                                     8.544685e-07                          0.977251                                  0.989587                                       0.894892                                           0.957043                                   1.000000                              0.878630   \n",
       "10   100   883                    0.448113                          0.601558                         0.872109                                 0.347916                                       0.597342                                      0.807199                   0.851351                   0.933871                                0.804250                                0.924255                           0.999982                            0.999745                                        1.000000                                         1.000000                           0.955775                            0.983743                                        0.948569                                     9.771114e-01                          1.000000                                  1.000000                                       1.000000                                           1.000000                                   1.000000                              1.000000   \n",
       "11   100  2456                    0.526467                          0.186860                         0.160455                                 0.183519                                       0.194339                                      0.160468                   0.891434                   0.870208                                0.648624                                0.670109                           0.753885                            0.503019                                        0.635399                                         0.461174                           0.375986                            0.697940                                        0.903339                                     9.784185e-01                          0.896217                                  0.943120                                       0.815489                                           0.913688                                   0.894577                              0.800705   \n",
       "12   100  5326                    0.504994                          0.380940                         0.186081                                 0.370751                                       0.426500                                      0.226843                   0.899571                   0.758539                                0.825243                                0.529266                           0.829671                            0.994074                                        0.741820                                         0.705662                           0.969831                            0.849728                                        0.951450                                     9.775284e-01                          0.928885                                  0.974094                                       0.856851                                           0.946249                                   0.912354                              0.921801   \n",
       "13   100  1389                    0.457299                          0.173582                         0.152193                                 0.191585                                       0.158163                                      0.123656                   0.703391                   0.821117                                0.152634                                0.391795                           0.576416                            0.638776                                        0.226166                                         0.145849                           0.320535                            0.889780                                        0.051062                                     8.100848e-02                          0.823537                                  0.892493                                       0.285404                                           0.516267                                   0.857341                              0.760775   \n",
       "14   100  5153                    0.503643                          0.255375                         0.205944                                 0.346032                                       0.248265                                      0.204870                   0.917486                   0.947452                                0.725425                                0.938016                           1.000000                            0.999361                                        0.987637                                         0.967503                           0.630591                            0.802153                                        0.957659                                     9.760884e-01                          1.000000                                  1.000000                                       1.000000                                           1.000000                                   1.000000                              0.888076   \n",
       "15   100  1975                    0.529565                          0.246333                         0.155104                                 0.356367                                       0.262292                                      0.171215                   0.872809                   0.842285                                1.000000                                1.000000                           0.979756                            0.994504                                        1.000000                                         1.000000                           0.505226                            0.750124                                        0.552988                                     7.964698e-01                          0.979904                                  0.989253                                       1.000000                                           1.000000                                   0.967475                              0.882543   \n",
       "16   100   705                    0.391949                          0.466228                         0.296158                                 0.340712                                       0.485242                                      0.402482                   0.777286                   0.938553                                0.700433                                0.921546                           1.000000                            1.000000                                        0.999601                                         0.964791                           0.394490                            0.975265                                        0.948569                                     9.771114e-01                          1.000000                                  1.000000                                       1.000000                                           1.000000                                   1.000000                              1.000000   \n",
       "17   100  2465                    0.407431                          0.496899                         0.300016                                 0.338256                                       0.486943                                      0.300016                   0.939606                   0.967033                                0.921855                                0.955799                           1.000000                            1.000000                                        1.000000                                         1.000000                           0.967520                            0.983678                                        0.964821                                     9.842812e-01                          1.000000                                  1.000000                                       1.000000                                           1.000000                                   1.000000                              0.963409   \n",
       "18   100  4826                    0.455823                          0.314752                         0.164622                                 0.298948                                       0.263800                                      0.141633                   0.868833                   0.827422                                1.000000                                0.704945                           0.778416                            0.529429                                        0.568717                                         0.500489                           0.689703                            0.615027                                        0.946773                                     7.259718e-01                          0.909810                                  0.955494                                       0.800127                                           0.918973                                   0.922813                              0.851006   \n",
       "19   100  4361                    0.236921                          0.156215                         0.192543                                 0.194459                                       0.221758                                      0.182364                   0.799354                   0.826339                                0.736696                                0.807197                           0.676978                            0.620543                                        0.594695                                         0.702814                           0.466917                            0.988845                                        0.955315                                     9.816395e-01                          0.869828                                  0.948150                                       0.836308                                           0.936795                                   0.805897                              0.713648   \n",
       "\n",
       "    n-grams:full,precise_annotations,words,1-grams  n-grams:full,partial_annotations,words,1-grams  n-grams:full,plant overrepresented tokens,1-grams  n-grams:full,bio ontology tokens,1-grams  n-grams:tokenization,full,nouns,adjectives,1-grams  n-grams:tokenization,linares_pontes,words,1-grams  n-grams:tokenization,full,precise_annotations,words,1-grams  n-grams:tokenization,full,partial_annotations,words,1-grams  n-grams:tokenization,full,plant overrepresented tokens,1-grams  n-grams:tokenization,full,bio ontology tokens,1-grams  go:union  po:union  go:minimum  po:minimum      mean  \n",
       "0                                         0.840402                                        0.568991                                           1.000000                                  1.000000                                           1.000000                                            1.000000                                           0.591617                                                     0.432781                                                     1.000000                                                        1.000000      1.000000  0.199791    1.000000    0.646186  0.696545  \n",
       "1                                         0.812361                                        0.422756                                           1.000000                                  1.000000                                           1.000000                                            0.980264                                           0.748194                                                     0.437357                                                     1.000000                                                        1.000000      1.000000  1.000000    1.000000    1.000000  0.637134  \n",
       "2                                         0.560416                                        0.496319                                           0.943099                                  0.928882                                           0.813392                                            0.868671                                           0.387241                                                     0.423178                                                     0.885369                                                        0.858600      0.240786  0.097509    0.906796    0.000000  0.385529  \n",
       "3                                         1.000000                                        0.978017                                           1.000000                                  1.000000                                           1.000000                                            1.000000                                           1.000000                                                     0.897769                                                     1.000000                                                        1.000000      0.367580  0.108020    0.690276    0.474998  0.770669  \n",
       "4                                         0.810659                                        0.297326                                           1.000000                                  1.000000                                           1.000000                                            0.866671                                           0.604588                                                     0.252735                                                     1.000000                                                        1.000000      0.202688  0.089205    0.690276    0.000000  0.576333  \n",
       "5                                         0.921055                                        0.329352                                           1.000000                                  1.000000                                           1.000000                                            1.000000                                           0.847789                                                     0.309230                                                     1.000000                                                        1.000000      1.000000  1.000000    1.000000    1.000000  0.704863  \n",
       "6                                         0.740565                                        0.356273                                           1.000000                                  1.000000                                           1.000000                                            0.897864                                           0.598539                                                     0.266433                                                     1.000000                                                        1.000000      0.622213  0.110242    0.956128    0.474998  0.595887  \n",
       "7                                         0.741642                                        0.258536                                           1.000000                                  1.000000                                           1.000000                                            0.949664                                           0.555684                                                     0.233350                                                     1.000000                                                        1.000000      1.000000  1.000000    1.000000    1.000000  0.528961  \n",
       "8                                         0.827605                                        0.342629                                           1.000000                                  1.000000                                           1.000000                                            0.900542                                           0.732674                                                     0.251352                                                     1.000000                                                        1.000000      0.229783  0.093575    0.484877    0.000000  0.663482  \n",
       "9                                         0.720393                                        0.329431                                           0.976848                                  1.000000                                           1.000000                                            0.839561                                           0.424285                                                     0.281615                                                     0.873610                                                        1.000000      0.218605  0.217137    0.897383    0.539171  0.429050  \n",
       "10                                        0.898833                                        0.295495                                           1.000000                                  1.000000                                           1.000000                                            1.000000                                           0.717540                                                     0.252735                                                     1.000000                                                        1.000000      0.323868  0.102040    0.922758    0.000000  0.690772  \n",
       "11                                        0.662550                                        0.281065                                           0.889426                                  0.875277                                           0.711187                                            0.781553                                           0.329352                                                     0.220122                                                     0.815489                                                        0.794061      0.160622  0.094031    0.000000    0.000000  0.255310  \n",
       "12                                        0.722733                                        0.269533                                           0.924850                                  0.918991                                           0.834325                                            0.844364                                           0.630280                                                     0.219975                                                     0.830025                                                        0.817266      1.000000  0.143986    1.000000    0.000000  0.398353  \n",
       "13                                        0.556267                                        0.266762                                           0.817845                                  0.790950                                           0.375810                                            0.254872                                           0.127706                                                     0.116814                                                     0.285404                                                        0.202417      0.152070  0.101173    0.561758    0.000000  0.114008  \n",
       "14                                        0.671056                                        0.357490                                           1.000000                                  1.000000                                           1.000000                                            0.889625                                           0.508440                                                     0.312266                                                     1.000000                                                        1.000000      0.244869  0.099229    0.895382    0.000000  0.573919  \n",
       "15                                        0.683351                                        0.322125                                           0.979160                                  0.971694                                           1.000000                                            1.000000                                           1.000000                                                     1.000000                                                     1.000000                                                        1.000000      0.200952  0.100981    0.843244    0.000000  0.533735  \n",
       "16                                        0.744874                                        0.291440                                           1.000000                                  1.000000                                           1.000000                                            1.000000                                           0.501246                                                     0.252735                                                     1.000000                                                        1.000000      0.176255  0.100868    0.696727    0.000000  0.619199  \n",
       "17                                        0.895578                                        0.982281                                           1.000000                                  1.000000                                           1.000000                                            0.950474                                           0.834275                                                     0.862028                                                     1.000000                                                        1.000000      0.258714  0.100062    0.920747    0.000000  0.731418  \n",
       "18                                        0.652218                                        0.241316                                           0.902508                                  0.881335                                           0.824919                                            0.738324                                           0.517975                                                     0.190031                                                     0.800127                                                        0.776915      0.211602  0.100722    0.927618    0.000000  0.280085  \n",
       "19                                        0.581492                                        0.327424                                           0.869828                                  0.851196                                           0.745715                                            0.583339                                           0.381752                                                     0.279292                                                     0.836308                                                        0.817298      0.255507  0.100667    0.308610    0.000000  0.261065  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the average distance percentile as a means of combining multiple scores.\n",
    "name = \"mean\"\n",
    "names_to_use_for_mean = [name for name in names if (\"go:\" not in name.lower()) and (\"po:\" not in name.lower())]\n",
    "df[name] = df[names_to_use_for_mean].rank(pct=True).mean(axis=1)\n",
    "names.append(name)\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doc2vec:wikipedia,size=300\n",
      "word2vec:wikipedia,size=300,mean\n",
      "word2vec:wikipedia,size=300,max\n",
      "doc2vec:tokenization,wikipedia,size=300\n",
      "word2vec:tokenization,wikipedia,size=300,mean\n",
      "word2vec:tokenization,wikipedia,size=300,max\n",
      "noble coder:precise,tfidf\n",
      "noble coder:partial,tfidf\n",
      "noble coder:tokenization,precise,tfidf\n",
      "noble coder:tokenization,partial,tfidf\n",
      "topic modeling:nmf,full,topics=50\n",
      "topic modeling:nmf,full,topics=100\n",
      "topic modeling:tokenization,nmf,full,topics=50\n",
      "topic modeling:tokenization,nmf,full,topics=100\n",
      "topic modeling:lda,full,topics=50\n",
      "topic modeling:lda,full,topics=100\n",
      "topic modeling:tokenization,lda,full,topics=50\n",
      "topic modeling:tokenization,lda,full,topics=100\n",
      "n-grams:full,words,1-grams,tfidf\n",
      "n-grams:full,words,1-grams,2-grams,tfidf\n",
      "n-grams:tokenization,full,words,1-grams,tfidf\n",
      "n-grams:tokenization,full,words,1-grams,2-grams,tfidf\n",
      "n-grams:full,nouns,adjectives,1-grams\n",
      "n-grams:linares_pontes,words,1-grams\n",
      "n-grams:full,precise_annotations,words,1-grams\n",
      "n-grams:full,partial_annotations,words,1-grams\n",
      "n-grams:full,plant overrepresented tokens,1-grams\n",
      "n-grams:full,bio ontology tokens,1-grams\n",
      "n-grams:tokenization,full,nouns,adjectives,1-grams\n",
      "n-grams:tokenization,linares_pontes,words,1-grams\n",
      "n-grams:tokenization,full,precise_annotations,words,1-grams\n",
      "n-grams:tokenization,full,partial_annotations,words,1-grams\n",
      "n-grams:tokenization,full,plant overrepresented tokens,1-grams\n",
      "n-grams:tokenization,full,bio ontology tokens,1-grams\n",
      "go:union\n",
      "po:union\n",
      "go:minimum\n",
      "po:minimum\n",
      "mean\n"
     ]
    }
   ],
   "source": [
    "# Normalizing all of the array representations of the graphs so they can be combined. Then this version of the arrays\n",
    "# should be used by any other cells that need all of the arrays, rather than the arrays accessed from the graph\n",
    "# objects. This is necessary for this analysis because the distances matrices created and put in the graph objects use\n",
    "# IDs that don't actually reference the genes like the IDs used as nodes in the edgelist dataframe do, they reference \n",
    "# other types of subsets of that data which are smaller for that processing step. This section is included just to \n",
    "# produce a standardized list of arrays which exactly represent the data in the edgelist dataframe. It is redundant,\n",
    "# and could be removed later if necessary for memory constraints, but it is useful to be able to reference this\n",
    "# information sometimes using numpy instead of pandas only.\n",
    "\n",
    "name_to_array = {}\n",
    "ids = dataset.get_ids()\n",
    "n = len(ids)\n",
    "id_to_array_index = {i:idx for idx,i in enumerate(ids)}\n",
    "array_index_to_id = {idx:i for i,idx in id_to_array_index.items()}\n",
    "for name in names:\n",
    "    print(name)\n",
    "    idx = list(df.columns).index(name)+1\n",
    "    arr = np.ones((n, n))\n",
    "    for row in df.itertuples():\n",
    "        arr[id_to_array_index[row[1]]][id_to_array_index[row[2]]] = row[idx]\n",
    "        arr[id_to_array_index[row[2]]][id_to_array_index[row[1]]] = row[idx]\n",
    "    np.fill_diagonal(arr, 0.000) \n",
    "    name_to_array[name] = arr    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding correlations between human and computational approaches for hand-picked phenotype pairs\n",
    "This is only meant to be run in the context of the notebook, and should never be run automatically in the script. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "50",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-59-6091b7e48c0f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtup\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mscore\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpair_to_score\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mid_to_array_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m             \u001b[0mj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mid_to_array_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mname_to_array\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 50"
     ]
    }
   ],
   "source": [
    "if NOTEBOOK:\n",
    "    small_table = defaultdict(dict)\n",
    "    for name in names:\n",
    "        values = []\n",
    "        scores = []\n",
    "        for tup,score in pair_to_score.items():\n",
    "            i = id_to_array_index[tup[0]]\n",
    "            j = id_to_array_index[tup[1]]\n",
    "            value = 1 - name_to_array[name][i,j]\n",
    "            values.append(value)\n",
    "            scores.append(score)\n",
    "        rho,pval = spearmanr(values,scores)\n",
    "        small_table[name] = {\"rho\":rho,\"pval\":pval}\n",
    "    pd.DataFrame(small_table).transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"part_5\"></a>\n",
    "# Part 5. Biological Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>from</th>\n",
       "      <th>to</th>\n",
       "      <th>doc2vec:wikipedia,size=300</th>\n",
       "      <th>word2vec:wikipedia,size=300,mean</th>\n",
       "      <th>word2vec:wikipedia,size=300,max</th>\n",
       "      <th>doc2vec:tokenization,wikipedia,size=300</th>\n",
       "      <th>word2vec:tokenization,wikipedia,size=300,mean</th>\n",
       "      <th>word2vec:tokenization,wikipedia,size=300,max</th>\n",
       "      <th>noble coder:precise,tfidf</th>\n",
       "      <th>noble coder:partial,tfidf</th>\n",
       "      <th>noble coder:tokenization,precise,tfidf</th>\n",
       "      <th>noble coder:tokenization,partial,tfidf</th>\n",
       "      <th>topic modeling:nmf,full,topics=50</th>\n",
       "      <th>topic modeling:nmf,full,topics=100</th>\n",
       "      <th>topic modeling:tokenization,nmf,full,topics=50</th>\n",
       "      <th>topic modeling:tokenization,nmf,full,topics=100</th>\n",
       "      <th>topic modeling:lda,full,topics=50</th>\n",
       "      <th>topic modeling:lda,full,topics=100</th>\n",
       "      <th>topic modeling:tokenization,lda,full,topics=50</th>\n",
       "      <th>topic modeling:tokenization,lda,full,topics=100</th>\n",
       "      <th>n-grams:full,words,1-grams,tfidf</th>\n",
       "      <th>n-grams:full,words,1-grams,2-grams,tfidf</th>\n",
       "      <th>n-grams:tokenization,full,words,1-grams,tfidf</th>\n",
       "      <th>n-grams:tokenization,full,words,1-grams,2-grams,tfidf</th>\n",
       "      <th>n-grams:full,nouns,adjectives,1-grams</th>\n",
       "      <th>n-grams:linares_pontes,words,1-grams</th>\n",
       "      <th>n-grams:full,precise_annotations,words,1-grams</th>\n",
       "      <th>n-grams:full,partial_annotations,words,1-grams</th>\n",
       "      <th>n-grams:full,plant overrepresented tokens,1-grams</th>\n",
       "      <th>n-grams:full,bio ontology tokens,1-grams</th>\n",
       "      <th>n-grams:tokenization,full,nouns,adjectives,1-grams</th>\n",
       "      <th>n-grams:tokenization,linares_pontes,words,1-grams</th>\n",
       "      <th>n-grams:tokenization,full,precise_annotations,words,1-grams</th>\n",
       "      <th>n-grams:tokenization,full,partial_annotations,words,1-grams</th>\n",
       "      <th>n-grams:tokenization,full,plant overrepresented tokens,1-grams</th>\n",
       "      <th>n-grams:tokenization,full,bio ontology tokens,1-grams</th>\n",
       "      <th>go:union</th>\n",
       "      <th>po:union</th>\n",
       "      <th>go:minimum</th>\n",
       "      <th>po:minimum</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>1145</td>\n",
       "      <td>0.484948</td>\n",
       "      <td>0.503235</td>\n",
       "      <td>0.263459</td>\n",
       "      <td>0.422335</td>\n",
       "      <td>0.478481</td>\n",
       "      <td>0.288674</td>\n",
       "      <td>0.863608</td>\n",
       "      <td>0.927264</td>\n",
       "      <td>0.804840</td>\n",
       "      <td>0.899720</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.985932</td>\n",
       "      <td>0.983500</td>\n",
       "      <td>0.972852</td>\n",
       "      <td>0.986386</td>\n",
       "      <td>0.956351</td>\n",
       "      <td>9.843608e-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.840402</td>\n",
       "      <td>0.568991</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.591617</td>\n",
       "      <td>0.432781</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.199791</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.646186</td>\n",
       "      <td>0.696545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100</td>\n",
       "      <td>4114</td>\n",
       "      <td>0.343207</td>\n",
       "      <td>0.260014</td>\n",
       "      <td>0.185656</td>\n",
       "      <td>0.260778</td>\n",
       "      <td>0.270105</td>\n",
       "      <td>0.180168</td>\n",
       "      <td>0.936699</td>\n",
       "      <td>0.963473</td>\n",
       "      <td>0.915321</td>\n",
       "      <td>0.957688</td>\n",
       "      <td>0.999937</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.997800</td>\n",
       "      <td>0.984195</td>\n",
       "      <td>0.848661</td>\n",
       "      <td>0.988527</td>\n",
       "      <td>0.969091</td>\n",
       "      <td>9.845576e-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.980422</td>\n",
       "      <td>0.812361</td>\n",
       "      <td>0.422756</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.980264</td>\n",
       "      <td>0.748194</td>\n",
       "      <td>0.437357</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.637134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>231</td>\n",
       "      <td>0.424650</td>\n",
       "      <td>0.279231</td>\n",
       "      <td>0.185035</td>\n",
       "      <td>0.296518</td>\n",
       "      <td>0.271672</td>\n",
       "      <td>0.188429</td>\n",
       "      <td>0.888187</td>\n",
       "      <td>0.921801</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.824749</td>\n",
       "      <td>0.978728</td>\n",
       "      <td>0.556710</td>\n",
       "      <td>0.931309</td>\n",
       "      <td>0.668178</td>\n",
       "      <td>0.980502</td>\n",
       "      <td>0.552669</td>\n",
       "      <td>9.768748e-01</td>\n",
       "      <td>0.943099</td>\n",
       "      <td>0.972357</td>\n",
       "      <td>0.885369</td>\n",
       "      <td>0.931381</td>\n",
       "      <td>0.926808</td>\n",
       "      <td>0.896132</td>\n",
       "      <td>0.560416</td>\n",
       "      <td>0.496319</td>\n",
       "      <td>0.943099</td>\n",
       "      <td>0.928882</td>\n",
       "      <td>0.813392</td>\n",
       "      <td>0.868671</td>\n",
       "      <td>0.387241</td>\n",
       "      <td>0.423178</td>\n",
       "      <td>0.885369</td>\n",
       "      <td>0.858600</td>\n",
       "      <td>0.240786</td>\n",
       "      <td>0.097509</td>\n",
       "      <td>0.906796</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.385529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100</td>\n",
       "      <td>5244</td>\n",
       "      <td>0.515200</td>\n",
       "      <td>0.602756</td>\n",
       "      <td>0.363885</td>\n",
       "      <td>0.428738</td>\n",
       "      <td>0.607823</td>\n",
       "      <td>0.362408</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.957448</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.944979</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999151</td>\n",
       "      <td>0.965712</td>\n",
       "      <td>0.954950</td>\n",
       "      <td>0.976779</td>\n",
       "      <td>0.950524</td>\n",
       "      <td>9.776629e-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.978017</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.897769</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.367580</td>\n",
       "      <td>0.108020</td>\n",
       "      <td>0.690276</td>\n",
       "      <td>0.474998</td>\n",
       "      <td>0.770669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100</td>\n",
       "      <td>733</td>\n",
       "      <td>0.527713</td>\n",
       "      <td>0.270065</td>\n",
       "      <td>0.181497</td>\n",
       "      <td>0.355785</td>\n",
       "      <td>0.293558</td>\n",
       "      <td>0.170425</td>\n",
       "      <td>0.899698</td>\n",
       "      <td>0.927390</td>\n",
       "      <td>0.804250</td>\n",
       "      <td>0.918117</td>\n",
       "      <td>0.990412</td>\n",
       "      <td>0.999971</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.491172</td>\n",
       "      <td>0.517408</td>\n",
       "      <td>0.958356</td>\n",
       "      <td>9.761760e-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.877337</td>\n",
       "      <td>0.810659</td>\n",
       "      <td>0.297326</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.866671</td>\n",
       "      <td>0.604588</td>\n",
       "      <td>0.252735</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.202688</td>\n",
       "      <td>0.089205</td>\n",
       "      <td>0.690276</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.576333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>100</td>\n",
       "      <td>3896</td>\n",
       "      <td>0.520128</td>\n",
       "      <td>0.536171</td>\n",
       "      <td>0.298879</td>\n",
       "      <td>0.399769</td>\n",
       "      <td>0.590710</td>\n",
       "      <td>0.391840</td>\n",
       "      <td>0.973093</td>\n",
       "      <td>0.970430</td>\n",
       "      <td>0.971126</td>\n",
       "      <td>0.966886</td>\n",
       "      <td>0.981126</td>\n",
       "      <td>0.913819</td>\n",
       "      <td>0.982271</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.967291</td>\n",
       "      <td>0.983562</td>\n",
       "      <td>0.959602</td>\n",
       "      <td>9.657815e-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.921055</td>\n",
       "      <td>0.329352</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.847789</td>\n",
       "      <td>0.309230</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.704863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>100</td>\n",
       "      <td>4572</td>\n",
       "      <td>0.490884</td>\n",
       "      <td>0.326860</td>\n",
       "      <td>0.179187</td>\n",
       "      <td>0.310596</td>\n",
       "      <td>0.341777</td>\n",
       "      <td>0.209361</td>\n",
       "      <td>0.956777</td>\n",
       "      <td>0.928798</td>\n",
       "      <td>0.939667</td>\n",
       "      <td>0.925504</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.973819</td>\n",
       "      <td>0.910472</td>\n",
       "      <td>0.965566</td>\n",
       "      <td>0.965742</td>\n",
       "      <td>0.985249</td>\n",
       "      <td>0.941665</td>\n",
       "      <td>9.777083e-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.916390</td>\n",
       "      <td>0.740565</td>\n",
       "      <td>0.356273</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.897864</td>\n",
       "      <td>0.598539</td>\n",
       "      <td>0.266433</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.622213</td>\n",
       "      <td>0.110242</td>\n",
       "      <td>0.956128</td>\n",
       "      <td>0.474998</td>\n",
       "      <td>0.595887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>100</td>\n",
       "      <td>2823</td>\n",
       "      <td>0.547941</td>\n",
       "      <td>0.272979</td>\n",
       "      <td>0.187657</td>\n",
       "      <td>0.279518</td>\n",
       "      <td>0.278486</td>\n",
       "      <td>0.199103</td>\n",
       "      <td>0.893427</td>\n",
       "      <td>0.902922</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.889492</td>\n",
       "      <td>0.981633</td>\n",
       "      <td>0.978047</td>\n",
       "      <td>0.325492</td>\n",
       "      <td>0.707005</td>\n",
       "      <td>0.970948</td>\n",
       "      <td>0.940419</td>\n",
       "      <td>0.560160</td>\n",
       "      <td>7.171545e-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.974706</td>\n",
       "      <td>0.741642</td>\n",
       "      <td>0.258536</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.949664</td>\n",
       "      <td>0.555684</td>\n",
       "      <td>0.233350</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.528961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>100</td>\n",
       "      <td>1592</td>\n",
       "      <td>0.448422</td>\n",
       "      <td>0.438724</td>\n",
       "      <td>0.198668</td>\n",
       "      <td>0.320943</td>\n",
       "      <td>0.365019</td>\n",
       "      <td>0.222920</td>\n",
       "      <td>0.904967</td>\n",
       "      <td>0.925881</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.906443</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998446</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.969069</td>\n",
       "      <td>0.988745</td>\n",
       "      <td>0.959906</td>\n",
       "      <td>9.800199e-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.951814</td>\n",
       "      <td>0.827605</td>\n",
       "      <td>0.342629</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.900542</td>\n",
       "      <td>0.732674</td>\n",
       "      <td>0.251352</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.229783</td>\n",
       "      <td>0.093575</td>\n",
       "      <td>0.484877</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.663482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>100</td>\n",
       "      <td>1185</td>\n",
       "      <td>0.450585</td>\n",
       "      <td>0.197340</td>\n",
       "      <td>0.151455</td>\n",
       "      <td>0.301088</td>\n",
       "      <td>0.232980</td>\n",
       "      <td>0.155569</td>\n",
       "      <td>0.909111</td>\n",
       "      <td>0.919647</td>\n",
       "      <td>0.666356</td>\n",
       "      <td>0.911593</td>\n",
       "      <td>0.998078</td>\n",
       "      <td>0.999591</td>\n",
       "      <td>0.828320</td>\n",
       "      <td>0.981882</td>\n",
       "      <td>0.855693</td>\n",
       "      <td>0.859678</td>\n",
       "      <td>0.944414</td>\n",
       "      <td>8.544685e-07</td>\n",
       "      <td>0.977251</td>\n",
       "      <td>0.989587</td>\n",
       "      <td>0.894892</td>\n",
       "      <td>0.957043</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.878630</td>\n",
       "      <td>0.720393</td>\n",
       "      <td>0.329431</td>\n",
       "      <td>0.976848</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.839561</td>\n",
       "      <td>0.424285</td>\n",
       "      <td>0.281615</td>\n",
       "      <td>0.873610</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.218605</td>\n",
       "      <td>0.217137</td>\n",
       "      <td>0.897383</td>\n",
       "      <td>0.539171</td>\n",
       "      <td>0.429050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>100</td>\n",
       "      <td>883</td>\n",
       "      <td>0.448113</td>\n",
       "      <td>0.601558</td>\n",
       "      <td>0.872109</td>\n",
       "      <td>0.347916</td>\n",
       "      <td>0.597342</td>\n",
       "      <td>0.807199</td>\n",
       "      <td>0.851351</td>\n",
       "      <td>0.933871</td>\n",
       "      <td>0.804250</td>\n",
       "      <td>0.924255</td>\n",
       "      <td>0.999982</td>\n",
       "      <td>0.999745</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.955775</td>\n",
       "      <td>0.983743</td>\n",
       "      <td>0.948569</td>\n",
       "      <td>9.771114e-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.898833</td>\n",
       "      <td>0.295495</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.717540</td>\n",
       "      <td>0.252735</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.323868</td>\n",
       "      <td>0.102040</td>\n",
       "      <td>0.922758</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.690772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>100</td>\n",
       "      <td>2456</td>\n",
       "      <td>0.526467</td>\n",
       "      <td>0.186860</td>\n",
       "      <td>0.160455</td>\n",
       "      <td>0.183519</td>\n",
       "      <td>0.194339</td>\n",
       "      <td>0.160468</td>\n",
       "      <td>0.891434</td>\n",
       "      <td>0.870208</td>\n",
       "      <td>0.648624</td>\n",
       "      <td>0.670109</td>\n",
       "      <td>0.753885</td>\n",
       "      <td>0.503019</td>\n",
       "      <td>0.635399</td>\n",
       "      <td>0.461174</td>\n",
       "      <td>0.375986</td>\n",
       "      <td>0.697940</td>\n",
       "      <td>0.903339</td>\n",
       "      <td>9.784185e-01</td>\n",
       "      <td>0.896217</td>\n",
       "      <td>0.943120</td>\n",
       "      <td>0.815489</td>\n",
       "      <td>0.913688</td>\n",
       "      <td>0.894577</td>\n",
       "      <td>0.800705</td>\n",
       "      <td>0.662550</td>\n",
       "      <td>0.281065</td>\n",
       "      <td>0.889426</td>\n",
       "      <td>0.875277</td>\n",
       "      <td>0.711187</td>\n",
       "      <td>0.781553</td>\n",
       "      <td>0.329352</td>\n",
       "      <td>0.220122</td>\n",
       "      <td>0.815489</td>\n",
       "      <td>0.794061</td>\n",
       "      <td>0.160622</td>\n",
       "      <td>0.094031</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.255310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>100</td>\n",
       "      <td>5326</td>\n",
       "      <td>0.504994</td>\n",
       "      <td>0.380940</td>\n",
       "      <td>0.186081</td>\n",
       "      <td>0.370751</td>\n",
       "      <td>0.426500</td>\n",
       "      <td>0.226843</td>\n",
       "      <td>0.899571</td>\n",
       "      <td>0.758539</td>\n",
       "      <td>0.825243</td>\n",
       "      <td>0.529266</td>\n",
       "      <td>0.829671</td>\n",
       "      <td>0.994074</td>\n",
       "      <td>0.741820</td>\n",
       "      <td>0.705662</td>\n",
       "      <td>0.969831</td>\n",
       "      <td>0.849728</td>\n",
       "      <td>0.951450</td>\n",
       "      <td>9.775284e-01</td>\n",
       "      <td>0.928885</td>\n",
       "      <td>0.974094</td>\n",
       "      <td>0.856851</td>\n",
       "      <td>0.946249</td>\n",
       "      <td>0.912354</td>\n",
       "      <td>0.921801</td>\n",
       "      <td>0.722733</td>\n",
       "      <td>0.269533</td>\n",
       "      <td>0.924850</td>\n",
       "      <td>0.918991</td>\n",
       "      <td>0.834325</td>\n",
       "      <td>0.844364</td>\n",
       "      <td>0.630280</td>\n",
       "      <td>0.219975</td>\n",
       "      <td>0.830025</td>\n",
       "      <td>0.817266</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.143986</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.398353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>100</td>\n",
       "      <td>1389</td>\n",
       "      <td>0.457299</td>\n",
       "      <td>0.173582</td>\n",
       "      <td>0.152193</td>\n",
       "      <td>0.191585</td>\n",
       "      <td>0.158163</td>\n",
       "      <td>0.123656</td>\n",
       "      <td>0.703391</td>\n",
       "      <td>0.821117</td>\n",
       "      <td>0.152634</td>\n",
       "      <td>0.391795</td>\n",
       "      <td>0.576416</td>\n",
       "      <td>0.638776</td>\n",
       "      <td>0.226166</td>\n",
       "      <td>0.145849</td>\n",
       "      <td>0.320535</td>\n",
       "      <td>0.889780</td>\n",
       "      <td>0.051062</td>\n",
       "      <td>8.100848e-02</td>\n",
       "      <td>0.823537</td>\n",
       "      <td>0.892493</td>\n",
       "      <td>0.285404</td>\n",
       "      <td>0.516267</td>\n",
       "      <td>0.857341</td>\n",
       "      <td>0.760775</td>\n",
       "      <td>0.556267</td>\n",
       "      <td>0.266762</td>\n",
       "      <td>0.817845</td>\n",
       "      <td>0.790950</td>\n",
       "      <td>0.375810</td>\n",
       "      <td>0.254872</td>\n",
       "      <td>0.127706</td>\n",
       "      <td>0.116814</td>\n",
       "      <td>0.285404</td>\n",
       "      <td>0.202417</td>\n",
       "      <td>0.152070</td>\n",
       "      <td>0.101173</td>\n",
       "      <td>0.561758</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.114008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>100</td>\n",
       "      <td>5153</td>\n",
       "      <td>0.503643</td>\n",
       "      <td>0.255375</td>\n",
       "      <td>0.205944</td>\n",
       "      <td>0.346032</td>\n",
       "      <td>0.248265</td>\n",
       "      <td>0.204870</td>\n",
       "      <td>0.917486</td>\n",
       "      <td>0.947452</td>\n",
       "      <td>0.725425</td>\n",
       "      <td>0.938016</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999361</td>\n",
       "      <td>0.987637</td>\n",
       "      <td>0.967503</td>\n",
       "      <td>0.630591</td>\n",
       "      <td>0.802153</td>\n",
       "      <td>0.957659</td>\n",
       "      <td>9.760884e-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.888076</td>\n",
       "      <td>0.671056</td>\n",
       "      <td>0.357490</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.889625</td>\n",
       "      <td>0.508440</td>\n",
       "      <td>0.312266</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.244869</td>\n",
       "      <td>0.099229</td>\n",
       "      <td>0.895382</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.573919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>100</td>\n",
       "      <td>1975</td>\n",
       "      <td>0.529565</td>\n",
       "      <td>0.246333</td>\n",
       "      <td>0.155104</td>\n",
       "      <td>0.356367</td>\n",
       "      <td>0.262292</td>\n",
       "      <td>0.171215</td>\n",
       "      <td>0.872809</td>\n",
       "      <td>0.842285</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.979756</td>\n",
       "      <td>0.994504</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.505226</td>\n",
       "      <td>0.750124</td>\n",
       "      <td>0.552988</td>\n",
       "      <td>7.964698e-01</td>\n",
       "      <td>0.979904</td>\n",
       "      <td>0.989253</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.967475</td>\n",
       "      <td>0.882543</td>\n",
       "      <td>0.683351</td>\n",
       "      <td>0.322125</td>\n",
       "      <td>0.979160</td>\n",
       "      <td>0.971694</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.200952</td>\n",
       "      <td>0.100981</td>\n",
       "      <td>0.843244</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.533735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>100</td>\n",
       "      <td>705</td>\n",
       "      <td>0.391949</td>\n",
       "      <td>0.466228</td>\n",
       "      <td>0.296158</td>\n",
       "      <td>0.340712</td>\n",
       "      <td>0.485242</td>\n",
       "      <td>0.402482</td>\n",
       "      <td>0.777286</td>\n",
       "      <td>0.938553</td>\n",
       "      <td>0.700433</td>\n",
       "      <td>0.921546</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999601</td>\n",
       "      <td>0.964791</td>\n",
       "      <td>0.394490</td>\n",
       "      <td>0.975265</td>\n",
       "      <td>0.948569</td>\n",
       "      <td>9.771114e-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.744874</td>\n",
       "      <td>0.291440</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.501246</td>\n",
       "      <td>0.252735</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.176255</td>\n",
       "      <td>0.100868</td>\n",
       "      <td>0.696727</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.619199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>100</td>\n",
       "      <td>2465</td>\n",
       "      <td>0.407431</td>\n",
       "      <td>0.496899</td>\n",
       "      <td>0.300016</td>\n",
       "      <td>0.338256</td>\n",
       "      <td>0.486943</td>\n",
       "      <td>0.300016</td>\n",
       "      <td>0.939606</td>\n",
       "      <td>0.967033</td>\n",
       "      <td>0.921855</td>\n",
       "      <td>0.955799</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.967520</td>\n",
       "      <td>0.983678</td>\n",
       "      <td>0.964821</td>\n",
       "      <td>9.842812e-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.963409</td>\n",
       "      <td>0.895578</td>\n",
       "      <td>0.982281</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.950474</td>\n",
       "      <td>0.834275</td>\n",
       "      <td>0.862028</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.258714</td>\n",
       "      <td>0.100062</td>\n",
       "      <td>0.920747</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.731418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>100</td>\n",
       "      <td>4826</td>\n",
       "      <td>0.455823</td>\n",
       "      <td>0.314752</td>\n",
       "      <td>0.164622</td>\n",
       "      <td>0.298948</td>\n",
       "      <td>0.263800</td>\n",
       "      <td>0.141633</td>\n",
       "      <td>0.868833</td>\n",
       "      <td>0.827422</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.704945</td>\n",
       "      <td>0.778416</td>\n",
       "      <td>0.529429</td>\n",
       "      <td>0.568717</td>\n",
       "      <td>0.500489</td>\n",
       "      <td>0.689703</td>\n",
       "      <td>0.615027</td>\n",
       "      <td>0.946773</td>\n",
       "      <td>7.259718e-01</td>\n",
       "      <td>0.909810</td>\n",
       "      <td>0.955494</td>\n",
       "      <td>0.800127</td>\n",
       "      <td>0.918973</td>\n",
       "      <td>0.922813</td>\n",
       "      <td>0.851006</td>\n",
       "      <td>0.652218</td>\n",
       "      <td>0.241316</td>\n",
       "      <td>0.902508</td>\n",
       "      <td>0.881335</td>\n",
       "      <td>0.824919</td>\n",
       "      <td>0.738324</td>\n",
       "      <td>0.517975</td>\n",
       "      <td>0.190031</td>\n",
       "      <td>0.800127</td>\n",
       "      <td>0.776915</td>\n",
       "      <td>0.211602</td>\n",
       "      <td>0.100722</td>\n",
       "      <td>0.927618</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.280085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>100</td>\n",
       "      <td>4361</td>\n",
       "      <td>0.236921</td>\n",
       "      <td>0.156215</td>\n",
       "      <td>0.192543</td>\n",
       "      <td>0.194459</td>\n",
       "      <td>0.221758</td>\n",
       "      <td>0.182364</td>\n",
       "      <td>0.799354</td>\n",
       "      <td>0.826339</td>\n",
       "      <td>0.736696</td>\n",
       "      <td>0.807197</td>\n",
       "      <td>0.676978</td>\n",
       "      <td>0.620543</td>\n",
       "      <td>0.594695</td>\n",
       "      <td>0.702814</td>\n",
       "      <td>0.466917</td>\n",
       "      <td>0.988845</td>\n",
       "      <td>0.955315</td>\n",
       "      <td>9.816395e-01</td>\n",
       "      <td>0.869828</td>\n",
       "      <td>0.948150</td>\n",
       "      <td>0.836308</td>\n",
       "      <td>0.936795</td>\n",
       "      <td>0.805897</td>\n",
       "      <td>0.713648</td>\n",
       "      <td>0.581492</td>\n",
       "      <td>0.327424</td>\n",
       "      <td>0.869828</td>\n",
       "      <td>0.851196</td>\n",
       "      <td>0.745715</td>\n",
       "      <td>0.583339</td>\n",
       "      <td>0.381752</td>\n",
       "      <td>0.279292</td>\n",
       "      <td>0.836308</td>\n",
       "      <td>0.817298</td>\n",
       "      <td>0.255507</td>\n",
       "      <td>0.100667</td>\n",
       "      <td>0.308610</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.261065</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    from    to  doc2vec:wikipedia,size=300  word2vec:wikipedia,size=300,mean  word2vec:wikipedia,size=300,max  doc2vec:tokenization,wikipedia,size=300  word2vec:tokenization,wikipedia,size=300,mean  word2vec:tokenization,wikipedia,size=300,max  noble coder:precise,tfidf  noble coder:partial,tfidf  noble coder:tokenization,precise,tfidf  noble coder:tokenization,partial,tfidf  topic modeling:nmf,full,topics=50  topic modeling:nmf,full,topics=100  topic modeling:tokenization,nmf,full,topics=50  topic modeling:tokenization,nmf,full,topics=100  topic modeling:lda,full,topics=50  topic modeling:lda,full,topics=100  topic modeling:tokenization,lda,full,topics=50  topic modeling:tokenization,lda,full,topics=100  n-grams:full,words,1-grams,tfidf  n-grams:full,words,1-grams,2-grams,tfidf  n-grams:tokenization,full,words,1-grams,tfidf  n-grams:tokenization,full,words,1-grams,2-grams,tfidf  n-grams:full,nouns,adjectives,1-grams  n-grams:linares_pontes,words,1-grams  \\\n",
       "0    100  1145                    0.484948                          0.503235                         0.263459                                 0.422335                                       0.478481                                      0.288674                   0.863608                   0.927264                                0.804840                                0.899720                           1.000000                            1.000000                                        0.985932                                         0.983500                           0.972852                            0.986386                                        0.956351                                     9.843608e-01                          1.000000                                  1.000000                                       1.000000                                           1.000000                                   1.000000                              1.000000   \n",
       "1    100  4114                    0.343207                          0.260014                         0.185656                                 0.260778                                       0.270105                                      0.180168                   0.936699                   0.963473                                0.915321                                0.957688                           0.999937                            1.000000                                        0.997800                                         0.984195                           0.848661                            0.988527                                        0.969091                                     9.845576e-01                          1.000000                                  1.000000                                       1.000000                                           1.000000                                   1.000000                              0.980422   \n",
       "2    100   231                    0.424650                          0.279231                         0.185035                                 0.296518                                       0.271672                                      0.188429                   0.888187                   0.921801                                1.000000                                1.000000                           0.824749                            0.978728                                        0.556710                                         0.931309                           0.668178                            0.980502                                        0.552669                                     9.768748e-01                          0.943099                                  0.972357                                       0.885369                                           0.931381                                   0.926808                              0.896132   \n",
       "3    100  5244                    0.515200                          0.602756                         0.363885                                 0.428738                                       0.607823                                      0.362408                   1.000000                   0.957448                                1.000000                                0.944979                           1.000000                            1.000000                                        0.999151                                         0.965712                           0.954950                            0.976779                                        0.950524                                     9.776629e-01                          1.000000                                  1.000000                                       1.000000                                           1.000000                                   1.000000                              1.000000   \n",
       "4    100   733                    0.527713                          0.270065                         0.181497                                 0.355785                                       0.293558                                      0.170425                   0.899698                   0.927390                                0.804250                                0.918117                           0.990412                            0.999971                                        0.999996                                         1.000000                           0.491172                            0.517408                                        0.958356                                     9.761760e-01                          1.000000                                  1.000000                                       1.000000                                           1.000000                                   1.000000                              0.877337   \n",
       "5    100  3896                    0.520128                          0.536171                         0.298879                                 0.399769                                       0.590710                                      0.391840                   0.973093                   0.970430                                0.971126                                0.966886                           0.981126                            0.913819                                        0.982271                                         1.000000                           0.967291                            0.983562                                        0.959602                                     9.657815e-01                          1.000000                                  1.000000                                       1.000000                                           1.000000                                   1.000000                              1.000000   \n",
       "6    100  4572                    0.490884                          0.326860                         0.179187                                 0.310596                                       0.341777                                      0.209361                   0.956777                   0.928798                                0.939667                                0.925504                           1.000000                            0.973819                                        0.910472                                         0.965566                           0.965742                            0.985249                                        0.941665                                     9.777083e-01                          1.000000                                  1.000000                                       1.000000                                           1.000000                                   1.000000                              0.916390   \n",
       "7    100  2823                    0.547941                          0.272979                         0.187657                                 0.279518                                       0.278486                                      0.199103                   0.893427                   0.902922                                1.000000                                0.889492                           0.981633                            0.978047                                        0.325492                                         0.707005                           0.970948                            0.940419                                        0.560160                                     7.171545e-01                          1.000000                                  1.000000                                       1.000000                                           1.000000                                   1.000000                              0.974706   \n",
       "8    100  1592                    0.448422                          0.438724                         0.198668                                 0.320943                                       0.365019                                      0.222920                   0.904967                   0.925881                                1.000000                                0.906443                           1.000000                            1.000000                                        0.998446                                         1.000000                           0.969069                            0.988745                                        0.959906                                     9.800199e-01                          1.000000                                  1.000000                                       1.000000                                           1.000000                                   1.000000                              0.951814   \n",
       "9    100  1185                    0.450585                          0.197340                         0.151455                                 0.301088                                       0.232980                                      0.155569                   0.909111                   0.919647                                0.666356                                0.911593                           0.998078                            0.999591                                        0.828320                                         0.981882                           0.855693                            0.859678                                        0.944414                                     8.544685e-07                          0.977251                                  0.989587                                       0.894892                                           0.957043                                   1.000000                              0.878630   \n",
       "10   100   883                    0.448113                          0.601558                         0.872109                                 0.347916                                       0.597342                                      0.807199                   0.851351                   0.933871                                0.804250                                0.924255                           0.999982                            0.999745                                        1.000000                                         1.000000                           0.955775                            0.983743                                        0.948569                                     9.771114e-01                          1.000000                                  1.000000                                       1.000000                                           1.000000                                   1.000000                              1.000000   \n",
       "11   100  2456                    0.526467                          0.186860                         0.160455                                 0.183519                                       0.194339                                      0.160468                   0.891434                   0.870208                                0.648624                                0.670109                           0.753885                            0.503019                                        0.635399                                         0.461174                           0.375986                            0.697940                                        0.903339                                     9.784185e-01                          0.896217                                  0.943120                                       0.815489                                           0.913688                                   0.894577                              0.800705   \n",
       "12   100  5326                    0.504994                          0.380940                         0.186081                                 0.370751                                       0.426500                                      0.226843                   0.899571                   0.758539                                0.825243                                0.529266                           0.829671                            0.994074                                        0.741820                                         0.705662                           0.969831                            0.849728                                        0.951450                                     9.775284e-01                          0.928885                                  0.974094                                       0.856851                                           0.946249                                   0.912354                              0.921801   \n",
       "13   100  1389                    0.457299                          0.173582                         0.152193                                 0.191585                                       0.158163                                      0.123656                   0.703391                   0.821117                                0.152634                                0.391795                           0.576416                            0.638776                                        0.226166                                         0.145849                           0.320535                            0.889780                                        0.051062                                     8.100848e-02                          0.823537                                  0.892493                                       0.285404                                           0.516267                                   0.857341                              0.760775   \n",
       "14   100  5153                    0.503643                          0.255375                         0.205944                                 0.346032                                       0.248265                                      0.204870                   0.917486                   0.947452                                0.725425                                0.938016                           1.000000                            0.999361                                        0.987637                                         0.967503                           0.630591                            0.802153                                        0.957659                                     9.760884e-01                          1.000000                                  1.000000                                       1.000000                                           1.000000                                   1.000000                              0.888076   \n",
       "15   100  1975                    0.529565                          0.246333                         0.155104                                 0.356367                                       0.262292                                      0.171215                   0.872809                   0.842285                                1.000000                                1.000000                           0.979756                            0.994504                                        1.000000                                         1.000000                           0.505226                            0.750124                                        0.552988                                     7.964698e-01                          0.979904                                  0.989253                                       1.000000                                           1.000000                                   0.967475                              0.882543   \n",
       "16   100   705                    0.391949                          0.466228                         0.296158                                 0.340712                                       0.485242                                      0.402482                   0.777286                   0.938553                                0.700433                                0.921546                           1.000000                            1.000000                                        0.999601                                         0.964791                           0.394490                            0.975265                                        0.948569                                     9.771114e-01                          1.000000                                  1.000000                                       1.000000                                           1.000000                                   1.000000                              1.000000   \n",
       "17   100  2465                    0.407431                          0.496899                         0.300016                                 0.338256                                       0.486943                                      0.300016                   0.939606                   0.967033                                0.921855                                0.955799                           1.000000                            1.000000                                        1.000000                                         1.000000                           0.967520                            0.983678                                        0.964821                                     9.842812e-01                          1.000000                                  1.000000                                       1.000000                                           1.000000                                   1.000000                              0.963409   \n",
       "18   100  4826                    0.455823                          0.314752                         0.164622                                 0.298948                                       0.263800                                      0.141633                   0.868833                   0.827422                                1.000000                                0.704945                           0.778416                            0.529429                                        0.568717                                         0.500489                           0.689703                            0.615027                                        0.946773                                     7.259718e-01                          0.909810                                  0.955494                                       0.800127                                           0.918973                                   0.922813                              0.851006   \n",
       "19   100  4361                    0.236921                          0.156215                         0.192543                                 0.194459                                       0.221758                                      0.182364                   0.799354                   0.826339                                0.736696                                0.807197                           0.676978                            0.620543                                        0.594695                                         0.702814                           0.466917                            0.988845                                        0.955315                                     9.816395e-01                          0.869828                                  0.948150                                       0.836308                                           0.936795                                   0.805897                              0.713648   \n",
       "\n",
       "    n-grams:full,precise_annotations,words,1-grams  n-grams:full,partial_annotations,words,1-grams  n-grams:full,plant overrepresented tokens,1-grams  n-grams:full,bio ontology tokens,1-grams  n-grams:tokenization,full,nouns,adjectives,1-grams  n-grams:tokenization,linares_pontes,words,1-grams  n-grams:tokenization,full,precise_annotations,words,1-grams  n-grams:tokenization,full,partial_annotations,words,1-grams  n-grams:tokenization,full,plant overrepresented tokens,1-grams  n-grams:tokenization,full,bio ontology tokens,1-grams  go:union  po:union  go:minimum  po:minimum      mean  \n",
       "0                                         0.840402                                        0.568991                                           1.000000                                  1.000000                                           1.000000                                            1.000000                                           0.591617                                                     0.432781                                                     1.000000                                                        1.000000      1.000000  0.199791    1.000000    0.646186  0.696545  \n",
       "1                                         0.812361                                        0.422756                                           1.000000                                  1.000000                                           1.000000                                            0.980264                                           0.748194                                                     0.437357                                                     1.000000                                                        1.000000      1.000000  1.000000    1.000000    1.000000  0.637134  \n",
       "2                                         0.560416                                        0.496319                                           0.943099                                  0.928882                                           0.813392                                            0.868671                                           0.387241                                                     0.423178                                                     0.885369                                                        0.858600      0.240786  0.097509    0.906796    0.000000  0.385529  \n",
       "3                                         1.000000                                        0.978017                                           1.000000                                  1.000000                                           1.000000                                            1.000000                                           1.000000                                                     0.897769                                                     1.000000                                                        1.000000      0.367580  0.108020    0.690276    0.474998  0.770669  \n",
       "4                                         0.810659                                        0.297326                                           1.000000                                  1.000000                                           1.000000                                            0.866671                                           0.604588                                                     0.252735                                                     1.000000                                                        1.000000      0.202688  0.089205    0.690276    0.000000  0.576333  \n",
       "5                                         0.921055                                        0.329352                                           1.000000                                  1.000000                                           1.000000                                            1.000000                                           0.847789                                                     0.309230                                                     1.000000                                                        1.000000      1.000000  1.000000    1.000000    1.000000  0.704863  \n",
       "6                                         0.740565                                        0.356273                                           1.000000                                  1.000000                                           1.000000                                            0.897864                                           0.598539                                                     0.266433                                                     1.000000                                                        1.000000      0.622213  0.110242    0.956128    0.474998  0.595887  \n",
       "7                                         0.741642                                        0.258536                                           1.000000                                  1.000000                                           1.000000                                            0.949664                                           0.555684                                                     0.233350                                                     1.000000                                                        1.000000      1.000000  1.000000    1.000000    1.000000  0.528961  \n",
       "8                                         0.827605                                        0.342629                                           1.000000                                  1.000000                                           1.000000                                            0.900542                                           0.732674                                                     0.251352                                                     1.000000                                                        1.000000      0.229783  0.093575    0.484877    0.000000  0.663482  \n",
       "9                                         0.720393                                        0.329431                                           0.976848                                  1.000000                                           1.000000                                            0.839561                                           0.424285                                                     0.281615                                                     0.873610                                                        1.000000      0.218605  0.217137    0.897383    0.539171  0.429050  \n",
       "10                                        0.898833                                        0.295495                                           1.000000                                  1.000000                                           1.000000                                            1.000000                                           0.717540                                                     0.252735                                                     1.000000                                                        1.000000      0.323868  0.102040    0.922758    0.000000  0.690772  \n",
       "11                                        0.662550                                        0.281065                                           0.889426                                  0.875277                                           0.711187                                            0.781553                                           0.329352                                                     0.220122                                                     0.815489                                                        0.794061      0.160622  0.094031    0.000000    0.000000  0.255310  \n",
       "12                                        0.722733                                        0.269533                                           0.924850                                  0.918991                                           0.834325                                            0.844364                                           0.630280                                                     0.219975                                                     0.830025                                                        0.817266      1.000000  0.143986    1.000000    0.000000  0.398353  \n",
       "13                                        0.556267                                        0.266762                                           0.817845                                  0.790950                                           0.375810                                            0.254872                                           0.127706                                                     0.116814                                                     0.285404                                                        0.202417      0.152070  0.101173    0.561758    0.000000  0.114008  \n",
       "14                                        0.671056                                        0.357490                                           1.000000                                  1.000000                                           1.000000                                            0.889625                                           0.508440                                                     0.312266                                                     1.000000                                                        1.000000      0.244869  0.099229    0.895382    0.000000  0.573919  \n",
       "15                                        0.683351                                        0.322125                                           0.979160                                  0.971694                                           1.000000                                            1.000000                                           1.000000                                                     1.000000                                                     1.000000                                                        1.000000      0.200952  0.100981    0.843244    0.000000  0.533735  \n",
       "16                                        0.744874                                        0.291440                                           1.000000                                  1.000000                                           1.000000                                            1.000000                                           0.501246                                                     0.252735                                                     1.000000                                                        1.000000      0.176255  0.100868    0.696727    0.000000  0.619199  \n",
       "17                                        0.895578                                        0.982281                                           1.000000                                  1.000000                                           1.000000                                            0.950474                                           0.834275                                                     0.862028                                                     1.000000                                                        1.000000      0.258714  0.100062    0.920747    0.000000  0.731418  \n",
       "18                                        0.652218                                        0.241316                                           0.902508                                  0.881335                                           0.824919                                            0.738324                                           0.517975                                                     0.190031                                                     0.800127                                                        0.776915      0.211602  0.100722    0.927618    0.000000  0.280085  \n",
       "19                                        0.581492                                        0.327424                                           0.869828                                  0.851196                                           0.745715                                            0.583339                                           0.381752                                                     0.279292                                                     0.836308                                                        0.817298      0.255507  0.100667    0.308610    0.000000  0.261065  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"species\"></a>\n",
    "### Checking whether gene pairs are intraspecies or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>from</th>\n",
       "      <th>to</th>\n",
       "      <th>doc2vec:wikipedia,size=300</th>\n",
       "      <th>word2vec:wikipedia,size=300,mean</th>\n",
       "      <th>word2vec:wikipedia,size=300,max</th>\n",
       "      <th>doc2vec:tokenization,wikipedia,size=300</th>\n",
       "      <th>word2vec:tokenization,wikipedia,size=300,mean</th>\n",
       "      <th>word2vec:tokenization,wikipedia,size=300,max</th>\n",
       "      <th>noble coder:precise,tfidf</th>\n",
       "      <th>noble coder:partial,tfidf</th>\n",
       "      <th>noble coder:tokenization,precise,tfidf</th>\n",
       "      <th>noble coder:tokenization,partial,tfidf</th>\n",
       "      <th>topic modeling:nmf,full,topics=50</th>\n",
       "      <th>topic modeling:nmf,full,topics=100</th>\n",
       "      <th>topic modeling:tokenization,nmf,full,topics=50</th>\n",
       "      <th>topic modeling:tokenization,nmf,full,topics=100</th>\n",
       "      <th>topic modeling:lda,full,topics=50</th>\n",
       "      <th>topic modeling:lda,full,topics=100</th>\n",
       "      <th>topic modeling:tokenization,lda,full,topics=50</th>\n",
       "      <th>topic modeling:tokenization,lda,full,topics=100</th>\n",
       "      <th>n-grams:full,words,1-grams,tfidf</th>\n",
       "      <th>n-grams:full,words,1-grams,2-grams,tfidf</th>\n",
       "      <th>n-grams:tokenization,full,words,1-grams,tfidf</th>\n",
       "      <th>n-grams:tokenization,full,words,1-grams,2-grams,tfidf</th>\n",
       "      <th>n-grams:full,nouns,adjectives,1-grams</th>\n",
       "      <th>n-grams:linares_pontes,words,1-grams</th>\n",
       "      <th>n-grams:full,precise_annotations,words,1-grams</th>\n",
       "      <th>n-grams:full,partial_annotations,words,1-grams</th>\n",
       "      <th>n-grams:full,plant overrepresented tokens,1-grams</th>\n",
       "      <th>n-grams:full,bio ontology tokens,1-grams</th>\n",
       "      <th>n-grams:tokenization,full,nouns,adjectives,1-grams</th>\n",
       "      <th>n-grams:tokenization,linares_pontes,words,1-grams</th>\n",
       "      <th>n-grams:tokenization,full,precise_annotations,words,1-grams</th>\n",
       "      <th>n-grams:tokenization,full,partial_annotations,words,1-grams</th>\n",
       "      <th>n-grams:tokenization,full,plant overrepresented tokens,1-grams</th>\n",
       "      <th>n-grams:tokenization,full,bio ontology tokens,1-grams</th>\n",
       "      <th>go:union</th>\n",
       "      <th>po:union</th>\n",
       "      <th>go:minimum</th>\n",
       "      <th>po:minimum</th>\n",
       "      <th>mean</th>\n",
       "      <th>same</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>1145</td>\n",
       "      <td>0.484948</td>\n",
       "      <td>0.503235</td>\n",
       "      <td>0.263459</td>\n",
       "      <td>0.422335</td>\n",
       "      <td>0.478481</td>\n",
       "      <td>0.288674</td>\n",
       "      <td>0.863608</td>\n",
       "      <td>0.927264</td>\n",
       "      <td>0.804840</td>\n",
       "      <td>0.899720</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.985932</td>\n",
       "      <td>0.983500</td>\n",
       "      <td>0.972852</td>\n",
       "      <td>0.986386</td>\n",
       "      <td>0.956351</td>\n",
       "      <td>9.843608e-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.840402</td>\n",
       "      <td>0.568991</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.591617</td>\n",
       "      <td>0.432781</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.199791</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.646186</td>\n",
       "      <td>0.696545</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100</td>\n",
       "      <td>4114</td>\n",
       "      <td>0.343207</td>\n",
       "      <td>0.260014</td>\n",
       "      <td>0.185656</td>\n",
       "      <td>0.260778</td>\n",
       "      <td>0.270105</td>\n",
       "      <td>0.180168</td>\n",
       "      <td>0.936699</td>\n",
       "      <td>0.963473</td>\n",
       "      <td>0.915321</td>\n",
       "      <td>0.957688</td>\n",
       "      <td>0.999937</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.997800</td>\n",
       "      <td>0.984195</td>\n",
       "      <td>0.848661</td>\n",
       "      <td>0.988527</td>\n",
       "      <td>0.969091</td>\n",
       "      <td>9.845576e-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.980422</td>\n",
       "      <td>0.812361</td>\n",
       "      <td>0.422756</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.980264</td>\n",
       "      <td>0.748194</td>\n",
       "      <td>0.437357</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.637134</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>231</td>\n",
       "      <td>0.424650</td>\n",
       "      <td>0.279231</td>\n",
       "      <td>0.185035</td>\n",
       "      <td>0.296518</td>\n",
       "      <td>0.271672</td>\n",
       "      <td>0.188429</td>\n",
       "      <td>0.888187</td>\n",
       "      <td>0.921801</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.824749</td>\n",
       "      <td>0.978728</td>\n",
       "      <td>0.556710</td>\n",
       "      <td>0.931309</td>\n",
       "      <td>0.668178</td>\n",
       "      <td>0.980502</td>\n",
       "      <td>0.552669</td>\n",
       "      <td>9.768748e-01</td>\n",
       "      <td>0.943099</td>\n",
       "      <td>0.972357</td>\n",
       "      <td>0.885369</td>\n",
       "      <td>0.931381</td>\n",
       "      <td>0.926808</td>\n",
       "      <td>0.896132</td>\n",
       "      <td>0.560416</td>\n",
       "      <td>0.496319</td>\n",
       "      <td>0.943099</td>\n",
       "      <td>0.928882</td>\n",
       "      <td>0.813392</td>\n",
       "      <td>0.868671</td>\n",
       "      <td>0.387241</td>\n",
       "      <td>0.423178</td>\n",
       "      <td>0.885369</td>\n",
       "      <td>0.8586</td>\n",
       "      <td>0.240786</td>\n",
       "      <td>0.097509</td>\n",
       "      <td>0.906796</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.385529</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100</td>\n",
       "      <td>5244</td>\n",
       "      <td>0.515200</td>\n",
       "      <td>0.602756</td>\n",
       "      <td>0.363885</td>\n",
       "      <td>0.428738</td>\n",
       "      <td>0.607823</td>\n",
       "      <td>0.362408</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.957448</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.944979</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999151</td>\n",
       "      <td>0.965712</td>\n",
       "      <td>0.954950</td>\n",
       "      <td>0.976779</td>\n",
       "      <td>0.950524</td>\n",
       "      <td>9.776629e-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.978017</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.897769</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.367580</td>\n",
       "      <td>0.108020</td>\n",
       "      <td>0.690276</td>\n",
       "      <td>0.474998</td>\n",
       "      <td>0.770669</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100</td>\n",
       "      <td>733</td>\n",
       "      <td>0.527713</td>\n",
       "      <td>0.270065</td>\n",
       "      <td>0.181497</td>\n",
       "      <td>0.355785</td>\n",
       "      <td>0.293558</td>\n",
       "      <td>0.170425</td>\n",
       "      <td>0.899698</td>\n",
       "      <td>0.927390</td>\n",
       "      <td>0.804250</td>\n",
       "      <td>0.918117</td>\n",
       "      <td>0.990412</td>\n",
       "      <td>0.999971</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.491172</td>\n",
       "      <td>0.517408</td>\n",
       "      <td>0.958356</td>\n",
       "      <td>9.761760e-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.877337</td>\n",
       "      <td>0.810659</td>\n",
       "      <td>0.297326</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.866671</td>\n",
       "      <td>0.604588</td>\n",
       "      <td>0.252735</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.202688</td>\n",
       "      <td>0.089205</td>\n",
       "      <td>0.690276</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.576333</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>100</td>\n",
       "      <td>3896</td>\n",
       "      <td>0.520128</td>\n",
       "      <td>0.536171</td>\n",
       "      <td>0.298879</td>\n",
       "      <td>0.399769</td>\n",
       "      <td>0.590710</td>\n",
       "      <td>0.391840</td>\n",
       "      <td>0.973093</td>\n",
       "      <td>0.970430</td>\n",
       "      <td>0.971126</td>\n",
       "      <td>0.966886</td>\n",
       "      <td>0.981126</td>\n",
       "      <td>0.913819</td>\n",
       "      <td>0.982271</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.967291</td>\n",
       "      <td>0.983562</td>\n",
       "      <td>0.959602</td>\n",
       "      <td>9.657815e-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.921055</td>\n",
       "      <td>0.329352</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.847789</td>\n",
       "      <td>0.309230</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.704863</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>100</td>\n",
       "      <td>4572</td>\n",
       "      <td>0.490884</td>\n",
       "      <td>0.326860</td>\n",
       "      <td>0.179187</td>\n",
       "      <td>0.310596</td>\n",
       "      <td>0.341777</td>\n",
       "      <td>0.209361</td>\n",
       "      <td>0.956777</td>\n",
       "      <td>0.928798</td>\n",
       "      <td>0.939667</td>\n",
       "      <td>0.925504</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.973819</td>\n",
       "      <td>0.910472</td>\n",
       "      <td>0.965566</td>\n",
       "      <td>0.965742</td>\n",
       "      <td>0.985249</td>\n",
       "      <td>0.941665</td>\n",
       "      <td>9.777083e-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.916390</td>\n",
       "      <td>0.740565</td>\n",
       "      <td>0.356273</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.897864</td>\n",
       "      <td>0.598539</td>\n",
       "      <td>0.266433</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.622213</td>\n",
       "      <td>0.110242</td>\n",
       "      <td>0.956128</td>\n",
       "      <td>0.474998</td>\n",
       "      <td>0.595887</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>100</td>\n",
       "      <td>2823</td>\n",
       "      <td>0.547941</td>\n",
       "      <td>0.272979</td>\n",
       "      <td>0.187657</td>\n",
       "      <td>0.279518</td>\n",
       "      <td>0.278486</td>\n",
       "      <td>0.199103</td>\n",
       "      <td>0.893427</td>\n",
       "      <td>0.902922</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.889492</td>\n",
       "      <td>0.981633</td>\n",
       "      <td>0.978047</td>\n",
       "      <td>0.325492</td>\n",
       "      <td>0.707005</td>\n",
       "      <td>0.970948</td>\n",
       "      <td>0.940419</td>\n",
       "      <td>0.560160</td>\n",
       "      <td>7.171545e-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.974706</td>\n",
       "      <td>0.741642</td>\n",
       "      <td>0.258536</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.949664</td>\n",
       "      <td>0.555684</td>\n",
       "      <td>0.233350</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.528961</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>100</td>\n",
       "      <td>1592</td>\n",
       "      <td>0.448422</td>\n",
       "      <td>0.438724</td>\n",
       "      <td>0.198668</td>\n",
       "      <td>0.320943</td>\n",
       "      <td>0.365019</td>\n",
       "      <td>0.222920</td>\n",
       "      <td>0.904967</td>\n",
       "      <td>0.925881</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.906443</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998446</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.969069</td>\n",
       "      <td>0.988745</td>\n",
       "      <td>0.959906</td>\n",
       "      <td>9.800199e-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.951814</td>\n",
       "      <td>0.827605</td>\n",
       "      <td>0.342629</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.900542</td>\n",
       "      <td>0.732674</td>\n",
       "      <td>0.251352</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.229783</td>\n",
       "      <td>0.093575</td>\n",
       "      <td>0.484877</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.663482</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>100</td>\n",
       "      <td>1185</td>\n",
       "      <td>0.450585</td>\n",
       "      <td>0.197340</td>\n",
       "      <td>0.151455</td>\n",
       "      <td>0.301088</td>\n",
       "      <td>0.232980</td>\n",
       "      <td>0.155569</td>\n",
       "      <td>0.909111</td>\n",
       "      <td>0.919647</td>\n",
       "      <td>0.666356</td>\n",
       "      <td>0.911593</td>\n",
       "      <td>0.998078</td>\n",
       "      <td>0.999591</td>\n",
       "      <td>0.828320</td>\n",
       "      <td>0.981882</td>\n",
       "      <td>0.855693</td>\n",
       "      <td>0.859678</td>\n",
       "      <td>0.944414</td>\n",
       "      <td>8.544685e-07</td>\n",
       "      <td>0.977251</td>\n",
       "      <td>0.989587</td>\n",
       "      <td>0.894892</td>\n",
       "      <td>0.957043</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.878630</td>\n",
       "      <td>0.720393</td>\n",
       "      <td>0.329431</td>\n",
       "      <td>0.976848</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.839561</td>\n",
       "      <td>0.424285</td>\n",
       "      <td>0.281615</td>\n",
       "      <td>0.873610</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.218605</td>\n",
       "      <td>0.217137</td>\n",
       "      <td>0.897383</td>\n",
       "      <td>0.539171</td>\n",
       "      <td>0.429050</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   from    to  doc2vec:wikipedia,size=300  word2vec:wikipedia,size=300,mean  word2vec:wikipedia,size=300,max  doc2vec:tokenization,wikipedia,size=300  word2vec:tokenization,wikipedia,size=300,mean  word2vec:tokenization,wikipedia,size=300,max  noble coder:precise,tfidf  noble coder:partial,tfidf  noble coder:tokenization,precise,tfidf  noble coder:tokenization,partial,tfidf  topic modeling:nmf,full,topics=50  topic modeling:nmf,full,topics=100  topic modeling:tokenization,nmf,full,topics=50  topic modeling:tokenization,nmf,full,topics=100  topic modeling:lda,full,topics=50  topic modeling:lda,full,topics=100  topic modeling:tokenization,lda,full,topics=50  topic modeling:tokenization,lda,full,topics=100  n-grams:full,words,1-grams,tfidf  n-grams:full,words,1-grams,2-grams,tfidf  n-grams:tokenization,full,words,1-grams,tfidf  n-grams:tokenization,full,words,1-grams,2-grams,tfidf  n-grams:full,nouns,adjectives,1-grams  n-grams:linares_pontes,words,1-grams  \\\n",
       "0   100  1145                    0.484948                          0.503235                         0.263459                                 0.422335                                       0.478481                                      0.288674                   0.863608                   0.927264                                0.804840                                0.899720                           1.000000                            1.000000                                        0.985932                                         0.983500                           0.972852                            0.986386                                        0.956351                                     9.843608e-01                          1.000000                                  1.000000                                       1.000000                                           1.000000                                   1.000000                              1.000000   \n",
       "1   100  4114                    0.343207                          0.260014                         0.185656                                 0.260778                                       0.270105                                      0.180168                   0.936699                   0.963473                                0.915321                                0.957688                           0.999937                            1.000000                                        0.997800                                         0.984195                           0.848661                            0.988527                                        0.969091                                     9.845576e-01                          1.000000                                  1.000000                                       1.000000                                           1.000000                                   1.000000                              0.980422   \n",
       "2   100   231                    0.424650                          0.279231                         0.185035                                 0.296518                                       0.271672                                      0.188429                   0.888187                   0.921801                                1.000000                                1.000000                           0.824749                            0.978728                                        0.556710                                         0.931309                           0.668178                            0.980502                                        0.552669                                     9.768748e-01                          0.943099                                  0.972357                                       0.885369                                           0.931381                                   0.926808                              0.896132   \n",
       "3   100  5244                    0.515200                          0.602756                         0.363885                                 0.428738                                       0.607823                                      0.362408                   1.000000                   0.957448                                1.000000                                0.944979                           1.000000                            1.000000                                        0.999151                                         0.965712                           0.954950                            0.976779                                        0.950524                                     9.776629e-01                          1.000000                                  1.000000                                       1.000000                                           1.000000                                   1.000000                              1.000000   \n",
       "4   100   733                    0.527713                          0.270065                         0.181497                                 0.355785                                       0.293558                                      0.170425                   0.899698                   0.927390                                0.804250                                0.918117                           0.990412                            0.999971                                        0.999996                                         1.000000                           0.491172                            0.517408                                        0.958356                                     9.761760e-01                          1.000000                                  1.000000                                       1.000000                                           1.000000                                   1.000000                              0.877337   \n",
       "5   100  3896                    0.520128                          0.536171                         0.298879                                 0.399769                                       0.590710                                      0.391840                   0.973093                   0.970430                                0.971126                                0.966886                           0.981126                            0.913819                                        0.982271                                         1.000000                           0.967291                            0.983562                                        0.959602                                     9.657815e-01                          1.000000                                  1.000000                                       1.000000                                           1.000000                                   1.000000                              1.000000   \n",
       "6   100  4572                    0.490884                          0.326860                         0.179187                                 0.310596                                       0.341777                                      0.209361                   0.956777                   0.928798                                0.939667                                0.925504                           1.000000                            0.973819                                        0.910472                                         0.965566                           0.965742                            0.985249                                        0.941665                                     9.777083e-01                          1.000000                                  1.000000                                       1.000000                                           1.000000                                   1.000000                              0.916390   \n",
       "7   100  2823                    0.547941                          0.272979                         0.187657                                 0.279518                                       0.278486                                      0.199103                   0.893427                   0.902922                                1.000000                                0.889492                           0.981633                            0.978047                                        0.325492                                         0.707005                           0.970948                            0.940419                                        0.560160                                     7.171545e-01                          1.000000                                  1.000000                                       1.000000                                           1.000000                                   1.000000                              0.974706   \n",
       "8   100  1592                    0.448422                          0.438724                         0.198668                                 0.320943                                       0.365019                                      0.222920                   0.904967                   0.925881                                1.000000                                0.906443                           1.000000                            1.000000                                        0.998446                                         1.000000                           0.969069                            0.988745                                        0.959906                                     9.800199e-01                          1.000000                                  1.000000                                       1.000000                                           1.000000                                   1.000000                              0.951814   \n",
       "9   100  1185                    0.450585                          0.197340                         0.151455                                 0.301088                                       0.232980                                      0.155569                   0.909111                   0.919647                                0.666356                                0.911593                           0.998078                            0.999591                                        0.828320                                         0.981882                           0.855693                            0.859678                                        0.944414                                     8.544685e-07                          0.977251                                  0.989587                                       0.894892                                           0.957043                                   1.000000                              0.878630   \n",
       "\n",
       "   n-grams:full,precise_annotations,words,1-grams  n-grams:full,partial_annotations,words,1-grams  n-grams:full,plant overrepresented tokens,1-grams  n-grams:full,bio ontology tokens,1-grams  n-grams:tokenization,full,nouns,adjectives,1-grams  n-grams:tokenization,linares_pontes,words,1-grams  n-grams:tokenization,full,precise_annotations,words,1-grams  n-grams:tokenization,full,partial_annotations,words,1-grams  n-grams:tokenization,full,plant overrepresented tokens,1-grams  n-grams:tokenization,full,bio ontology tokens,1-grams  go:union  po:union  go:minimum  po:minimum      mean   same  \n",
       "0                                        0.840402                                        0.568991                                           1.000000                                  1.000000                                           1.000000                                            1.000000                                           0.591617                                                     0.432781                                                     1.000000                                                          1.0000      1.000000  0.199791    1.000000    0.646186  0.696545  False  \n",
       "1                                        0.812361                                        0.422756                                           1.000000                                  1.000000                                           1.000000                                            0.980264                                           0.748194                                                     0.437357                                                     1.000000                                                          1.0000      1.000000  1.000000    1.000000    1.000000  0.637134   True  \n",
       "2                                        0.560416                                        0.496319                                           0.943099                                  0.928882                                           0.813392                                            0.868671                                           0.387241                                                     0.423178                                                     0.885369                                                          0.8586      0.240786  0.097509    0.906796    0.000000  0.385529   True  \n",
       "3                                        1.000000                                        0.978017                                           1.000000                                  1.000000                                           1.000000                                            1.000000                                           1.000000                                                     0.897769                                                     1.000000                                                          1.0000      0.367580  0.108020    0.690276    0.474998  0.770669   True  \n",
       "4                                        0.810659                                        0.297326                                           1.000000                                  1.000000                                           1.000000                                            0.866671                                           0.604588                                                     0.252735                                                     1.000000                                                          1.0000      0.202688  0.089205    0.690276    0.000000  0.576333   True  \n",
       "5                                        0.921055                                        0.329352                                           1.000000                                  1.000000                                           1.000000                                            1.000000                                           0.847789                                                     0.309230                                                     1.000000                                                          1.0000      1.000000  1.000000    1.000000    1.000000  0.704863  False  \n",
       "6                                        0.740565                                        0.356273                                           1.000000                                  1.000000                                           1.000000                                            0.897864                                           0.598539                                                     0.266433                                                     1.000000                                                          1.0000      0.622213  0.110242    0.956128    0.474998  0.595887   True  \n",
       "7                                        0.741642                                        0.258536                                           1.000000                                  1.000000                                           1.000000                                            0.949664                                           0.555684                                                     0.233350                                                     1.000000                                                          1.0000      1.000000  1.000000    1.000000    1.000000  0.528961  False  \n",
       "8                                        0.827605                                        0.342629                                           1.000000                                  1.000000                                           1.000000                                            0.900542                                           0.732674                                                     0.251352                                                     1.000000                                                          1.0000      0.229783  0.093575    0.484877    0.000000  0.663482   True  \n",
       "9                                        0.720393                                        0.329431                                           0.976848                                  1.000000                                           1.000000                                            0.839561                                           0.424285                                                     0.281615                                                     0.873610                                                          1.0000      0.218605  0.217137    0.897383    0.539171  0.429050   True  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "species_dict = dataset.get_species_dictionary()\n",
    "df[\"same\"] = df[[\"from\",\"to\"]].apply(lambda x: species_dict[x[\"from\"]]==species_dict[x[\"to\"]],axis=1)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"pathway_objective\"></a>\n",
    "### Using shared pathway membership (PlantCyc and KEGG) as the objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a column that indicates whether or not both genes of the pair mapped to a pathway resource.\n",
    "pathway_mapped_ids = set(kegg_mapped_ids+pmn_mapped_ids)\n",
    "df[\"from_is_valid\"] = df[\"from\"].map(lambda x: x in pathway_mapped_ids)\n",
    "df[\"to_is_valid\"] = df[\"to\"].map(lambda x: x in pathway_mapped_ids)\n",
    "df[\"pair_is_valid\"] = df[\"from_is_valid\"]*df[\"to_is_valid\"]\n",
    "\n",
    "\n",
    "# Add a column giving the actual target output value for this biological task, with -1 for the irrelevant rows.\n",
    "df[\"pathways\"] = -1\n",
    "id_to_kegg_group_ids, kegg_group_id_to_ids = kegg_groups.get_groupings_for_dataset(dataset)\n",
    "id_to_pmn_group_ids, pmn_group_id_to_ids = pmn_groups.get_groupings_for_dataset(dataset)\n",
    "id_to_group_ids = {i:flatten([id_to_kegg_group_ids[i],id_to_pmn_group_ids[i]]) for i in dataset.get_ids()}\n",
    "df.loc[(df[\"pair_is_valid\"]==True),\"pathways\"] = df[[\"from\",\"to\"]].apply(lambda x: len(set(id_to_group_ids[x[\"from\"]]).intersection(set(id_to_group_ids[x[\"to\"]])))>0, axis=1)*1\n",
    "df.drop(labels=[\"from_is_valid\",\"to_is_valid\",\"pair_is_valid\"], axis=\"columns\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a column that indicates whether or not both genes of the pair mapped to a pathway resource.\n",
    "pathway_mapped_ids = set(kegg_mapped_ids)\n",
    "df[\"from_is_valid\"] = df[\"from\"].map(lambda x: x in pathway_mapped_ids)\n",
    "df[\"to_is_valid\"] = df[\"to\"].map(lambda x: x in pathway_mapped_ids)\n",
    "df[\"pair_is_valid\"] = df[\"from_is_valid\"]*df[\"to_is_valid\"]\n",
    "\n",
    "\n",
    "# Add a column giving the actual target output value for this biological task, with -1 for the irrelevant rows.\n",
    "df[\"kegg_only\"] = -1\n",
    "id_to_kegg_group_ids, kegg_group_id_to_ids = kegg_groups.get_groupings_for_dataset(dataset)\n",
    "id_to_pmn_group_ids, pmn_group_id_to_ids = pmn_groups.get_groupings_for_dataset(dataset)\n",
    "id_to_group_ids = {i:flatten([id_to_kegg_group_ids[i],id_to_pmn_group_ids[i]]) for i in dataset.get_ids()}\n",
    "df.loc[(df[\"pair_is_valid\"]==True),\"kegg_only\"] = df[[\"from\",\"to\"]].apply(lambda x: len(set(id_to_group_ids[x[\"from\"]]).intersection(set(id_to_group_ids[x[\"to\"]])))>0, axis=1)*1\n",
    "df.drop(labels=[\"from_is_valid\",\"to_is_valid\",\"pair_is_valid\"], axis=\"columns\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>from</th>\n",
       "      <th>to</th>\n",
       "      <th>doc2vec:wikipedia,size=300</th>\n",
       "      <th>word2vec:wikipedia,size=300,mean</th>\n",
       "      <th>word2vec:wikipedia,size=300,max</th>\n",
       "      <th>doc2vec:tokenization,wikipedia,size=300</th>\n",
       "      <th>word2vec:tokenization,wikipedia,size=300,mean</th>\n",
       "      <th>word2vec:tokenization,wikipedia,size=300,max</th>\n",
       "      <th>noble coder:precise,tfidf</th>\n",
       "      <th>noble coder:partial,tfidf</th>\n",
       "      <th>noble coder:tokenization,precise,tfidf</th>\n",
       "      <th>noble coder:tokenization,partial,tfidf</th>\n",
       "      <th>topic modeling:nmf,full,topics=50</th>\n",
       "      <th>topic modeling:nmf,full,topics=100</th>\n",
       "      <th>topic modeling:tokenization,nmf,full,topics=50</th>\n",
       "      <th>topic modeling:tokenization,nmf,full,topics=100</th>\n",
       "      <th>topic modeling:lda,full,topics=50</th>\n",
       "      <th>topic modeling:lda,full,topics=100</th>\n",
       "      <th>topic modeling:tokenization,lda,full,topics=50</th>\n",
       "      <th>topic modeling:tokenization,lda,full,topics=100</th>\n",
       "      <th>n-grams:full,words,1-grams,tfidf</th>\n",
       "      <th>n-grams:full,words,1-grams,2-grams,tfidf</th>\n",
       "      <th>n-grams:tokenization,full,words,1-grams,tfidf</th>\n",
       "      <th>n-grams:tokenization,full,words,1-grams,2-grams,tfidf</th>\n",
       "      <th>n-grams:full,nouns,adjectives,1-grams</th>\n",
       "      <th>n-grams:linares_pontes,words,1-grams</th>\n",
       "      <th>n-grams:full,precise_annotations,words,1-grams</th>\n",
       "      <th>n-grams:full,partial_annotations,words,1-grams</th>\n",
       "      <th>n-grams:full,plant overrepresented tokens,1-grams</th>\n",
       "      <th>n-grams:full,bio ontology tokens,1-grams</th>\n",
       "      <th>n-grams:tokenization,full,nouns,adjectives,1-grams</th>\n",
       "      <th>n-grams:tokenization,linares_pontes,words,1-grams</th>\n",
       "      <th>n-grams:tokenization,full,precise_annotations,words,1-grams</th>\n",
       "      <th>n-grams:tokenization,full,partial_annotations,words,1-grams</th>\n",
       "      <th>n-grams:tokenization,full,plant overrepresented tokens,1-grams</th>\n",
       "      <th>n-grams:tokenization,full,bio ontology tokens,1-grams</th>\n",
       "      <th>go:union</th>\n",
       "      <th>po:union</th>\n",
       "      <th>go:minimum</th>\n",
       "      <th>po:minimum</th>\n",
       "      <th>mean</th>\n",
       "      <th>same</th>\n",
       "      <th>pathways</th>\n",
       "      <th>kegg_only</th>\n",
       "      <th>pmn_only</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>1145</td>\n",
       "      <td>0.484948</td>\n",
       "      <td>0.503235</td>\n",
       "      <td>0.263459</td>\n",
       "      <td>0.422335</td>\n",
       "      <td>0.478481</td>\n",
       "      <td>0.288674</td>\n",
       "      <td>0.863608</td>\n",
       "      <td>0.927264</td>\n",
       "      <td>0.804840</td>\n",
       "      <td>0.899720</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.985932</td>\n",
       "      <td>0.983500</td>\n",
       "      <td>0.972852</td>\n",
       "      <td>0.986386</td>\n",
       "      <td>0.956351</td>\n",
       "      <td>9.843608e-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.840402</td>\n",
       "      <td>0.568991</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.591617</td>\n",
       "      <td>0.432781</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.199791</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.646186</td>\n",
       "      <td>0.696545</td>\n",
       "      <td>False</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100</td>\n",
       "      <td>4114</td>\n",
       "      <td>0.343207</td>\n",
       "      <td>0.260014</td>\n",
       "      <td>0.185656</td>\n",
       "      <td>0.260778</td>\n",
       "      <td>0.270105</td>\n",
       "      <td>0.180168</td>\n",
       "      <td>0.936699</td>\n",
       "      <td>0.963473</td>\n",
       "      <td>0.915321</td>\n",
       "      <td>0.957688</td>\n",
       "      <td>0.999937</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.997800</td>\n",
       "      <td>0.984195</td>\n",
       "      <td>0.848661</td>\n",
       "      <td>0.988527</td>\n",
       "      <td>0.969091</td>\n",
       "      <td>9.845576e-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.980422</td>\n",
       "      <td>0.812361</td>\n",
       "      <td>0.422756</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.980264</td>\n",
       "      <td>0.748194</td>\n",
       "      <td>0.437357</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.637134</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>231</td>\n",
       "      <td>0.424650</td>\n",
       "      <td>0.279231</td>\n",
       "      <td>0.185035</td>\n",
       "      <td>0.296518</td>\n",
       "      <td>0.271672</td>\n",
       "      <td>0.188429</td>\n",
       "      <td>0.888187</td>\n",
       "      <td>0.921801</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.824749</td>\n",
       "      <td>0.978728</td>\n",
       "      <td>0.556710</td>\n",
       "      <td>0.931309</td>\n",
       "      <td>0.668178</td>\n",
       "      <td>0.980502</td>\n",
       "      <td>0.552669</td>\n",
       "      <td>9.768748e-01</td>\n",
       "      <td>0.943099</td>\n",
       "      <td>0.972357</td>\n",
       "      <td>0.885369</td>\n",
       "      <td>0.931381</td>\n",
       "      <td>0.926808</td>\n",
       "      <td>0.896132</td>\n",
       "      <td>0.560416</td>\n",
       "      <td>0.496319</td>\n",
       "      <td>0.943099</td>\n",
       "      <td>0.928882</td>\n",
       "      <td>0.813392</td>\n",
       "      <td>0.868671</td>\n",
       "      <td>0.387241</td>\n",
       "      <td>0.423178</td>\n",
       "      <td>0.885369</td>\n",
       "      <td>0.858600</td>\n",
       "      <td>0.240786</td>\n",
       "      <td>0.097509</td>\n",
       "      <td>0.906796</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.385529</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100</td>\n",
       "      <td>5244</td>\n",
       "      <td>0.515200</td>\n",
       "      <td>0.602756</td>\n",
       "      <td>0.363885</td>\n",
       "      <td>0.428738</td>\n",
       "      <td>0.607823</td>\n",
       "      <td>0.362408</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.957448</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.944979</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999151</td>\n",
       "      <td>0.965712</td>\n",
       "      <td>0.954950</td>\n",
       "      <td>0.976779</td>\n",
       "      <td>0.950524</td>\n",
       "      <td>9.776629e-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.978017</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.897769</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.367580</td>\n",
       "      <td>0.108020</td>\n",
       "      <td>0.690276</td>\n",
       "      <td>0.474998</td>\n",
       "      <td>0.770669</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100</td>\n",
       "      <td>733</td>\n",
       "      <td>0.527713</td>\n",
       "      <td>0.270065</td>\n",
       "      <td>0.181497</td>\n",
       "      <td>0.355785</td>\n",
       "      <td>0.293558</td>\n",
       "      <td>0.170425</td>\n",
       "      <td>0.899698</td>\n",
       "      <td>0.927390</td>\n",
       "      <td>0.804250</td>\n",
       "      <td>0.918117</td>\n",
       "      <td>0.990412</td>\n",
       "      <td>0.999971</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.491172</td>\n",
       "      <td>0.517408</td>\n",
       "      <td>0.958356</td>\n",
       "      <td>9.761760e-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.877337</td>\n",
       "      <td>0.810659</td>\n",
       "      <td>0.297326</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.866671</td>\n",
       "      <td>0.604588</td>\n",
       "      <td>0.252735</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.202688</td>\n",
       "      <td>0.089205</td>\n",
       "      <td>0.690276</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.576333</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>100</td>\n",
       "      <td>3896</td>\n",
       "      <td>0.520128</td>\n",
       "      <td>0.536171</td>\n",
       "      <td>0.298879</td>\n",
       "      <td>0.399769</td>\n",
       "      <td>0.590710</td>\n",
       "      <td>0.391840</td>\n",
       "      <td>0.973093</td>\n",
       "      <td>0.970430</td>\n",
       "      <td>0.971126</td>\n",
       "      <td>0.966886</td>\n",
       "      <td>0.981126</td>\n",
       "      <td>0.913819</td>\n",
       "      <td>0.982271</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.967291</td>\n",
       "      <td>0.983562</td>\n",
       "      <td>0.959602</td>\n",
       "      <td>9.657815e-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.921055</td>\n",
       "      <td>0.329352</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.847789</td>\n",
       "      <td>0.309230</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.704863</td>\n",
       "      <td>False</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>100</td>\n",
       "      <td>4572</td>\n",
       "      <td>0.490884</td>\n",
       "      <td>0.326860</td>\n",
       "      <td>0.179187</td>\n",
       "      <td>0.310596</td>\n",
       "      <td>0.341777</td>\n",
       "      <td>0.209361</td>\n",
       "      <td>0.956777</td>\n",
       "      <td>0.928798</td>\n",
       "      <td>0.939667</td>\n",
       "      <td>0.925504</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.973819</td>\n",
       "      <td>0.910472</td>\n",
       "      <td>0.965566</td>\n",
       "      <td>0.965742</td>\n",
       "      <td>0.985249</td>\n",
       "      <td>0.941665</td>\n",
       "      <td>9.777083e-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.916390</td>\n",
       "      <td>0.740565</td>\n",
       "      <td>0.356273</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.897864</td>\n",
       "      <td>0.598539</td>\n",
       "      <td>0.266433</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.622213</td>\n",
       "      <td>0.110242</td>\n",
       "      <td>0.956128</td>\n",
       "      <td>0.474998</td>\n",
       "      <td>0.595887</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>100</td>\n",
       "      <td>2823</td>\n",
       "      <td>0.547941</td>\n",
       "      <td>0.272979</td>\n",
       "      <td>0.187657</td>\n",
       "      <td>0.279518</td>\n",
       "      <td>0.278486</td>\n",
       "      <td>0.199103</td>\n",
       "      <td>0.893427</td>\n",
       "      <td>0.902922</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.889492</td>\n",
       "      <td>0.981633</td>\n",
       "      <td>0.978047</td>\n",
       "      <td>0.325492</td>\n",
       "      <td>0.707005</td>\n",
       "      <td>0.970948</td>\n",
       "      <td>0.940419</td>\n",
       "      <td>0.560160</td>\n",
       "      <td>7.171545e-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.974706</td>\n",
       "      <td>0.741642</td>\n",
       "      <td>0.258536</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.949664</td>\n",
       "      <td>0.555684</td>\n",
       "      <td>0.233350</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.528961</td>\n",
       "      <td>False</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>100</td>\n",
       "      <td>1592</td>\n",
       "      <td>0.448422</td>\n",
       "      <td>0.438724</td>\n",
       "      <td>0.198668</td>\n",
       "      <td>0.320943</td>\n",
       "      <td>0.365019</td>\n",
       "      <td>0.222920</td>\n",
       "      <td>0.904967</td>\n",
       "      <td>0.925881</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.906443</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998446</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.969069</td>\n",
       "      <td>0.988745</td>\n",
       "      <td>0.959906</td>\n",
       "      <td>9.800199e-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.951814</td>\n",
       "      <td>0.827605</td>\n",
       "      <td>0.342629</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.900542</td>\n",
       "      <td>0.732674</td>\n",
       "      <td>0.251352</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.229783</td>\n",
       "      <td>0.093575</td>\n",
       "      <td>0.484877</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.663482</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>100</td>\n",
       "      <td>1185</td>\n",
       "      <td>0.450585</td>\n",
       "      <td>0.197340</td>\n",
       "      <td>0.151455</td>\n",
       "      <td>0.301088</td>\n",
       "      <td>0.232980</td>\n",
       "      <td>0.155569</td>\n",
       "      <td>0.909111</td>\n",
       "      <td>0.919647</td>\n",
       "      <td>0.666356</td>\n",
       "      <td>0.911593</td>\n",
       "      <td>0.998078</td>\n",
       "      <td>0.999591</td>\n",
       "      <td>0.828320</td>\n",
       "      <td>0.981882</td>\n",
       "      <td>0.855693</td>\n",
       "      <td>0.859678</td>\n",
       "      <td>0.944414</td>\n",
       "      <td>8.544685e-07</td>\n",
       "      <td>0.977251</td>\n",
       "      <td>0.989587</td>\n",
       "      <td>0.894892</td>\n",
       "      <td>0.957043</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.878630</td>\n",
       "      <td>0.720393</td>\n",
       "      <td>0.329431</td>\n",
       "      <td>0.976848</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.839561</td>\n",
       "      <td>0.424285</td>\n",
       "      <td>0.281615</td>\n",
       "      <td>0.873610</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.218605</td>\n",
       "      <td>0.217137</td>\n",
       "      <td>0.897383</td>\n",
       "      <td>0.539171</td>\n",
       "      <td>0.429050</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>100</td>\n",
       "      <td>883</td>\n",
       "      <td>0.448113</td>\n",
       "      <td>0.601558</td>\n",
       "      <td>0.872109</td>\n",
       "      <td>0.347916</td>\n",
       "      <td>0.597342</td>\n",
       "      <td>0.807199</td>\n",
       "      <td>0.851351</td>\n",
       "      <td>0.933871</td>\n",
       "      <td>0.804250</td>\n",
       "      <td>0.924255</td>\n",
       "      <td>0.999982</td>\n",
       "      <td>0.999745</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.955775</td>\n",
       "      <td>0.983743</td>\n",
       "      <td>0.948569</td>\n",
       "      <td>9.771114e-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.898833</td>\n",
       "      <td>0.295495</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.717540</td>\n",
       "      <td>0.252735</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.323868</td>\n",
       "      <td>0.102040</td>\n",
       "      <td>0.922758</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.690772</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>100</td>\n",
       "      <td>2456</td>\n",
       "      <td>0.526467</td>\n",
       "      <td>0.186860</td>\n",
       "      <td>0.160455</td>\n",
       "      <td>0.183519</td>\n",
       "      <td>0.194339</td>\n",
       "      <td>0.160468</td>\n",
       "      <td>0.891434</td>\n",
       "      <td>0.870208</td>\n",
       "      <td>0.648624</td>\n",
       "      <td>0.670109</td>\n",
       "      <td>0.753885</td>\n",
       "      <td>0.503019</td>\n",
       "      <td>0.635399</td>\n",
       "      <td>0.461174</td>\n",
       "      <td>0.375986</td>\n",
       "      <td>0.697940</td>\n",
       "      <td>0.903339</td>\n",
       "      <td>9.784185e-01</td>\n",
       "      <td>0.896217</td>\n",
       "      <td>0.943120</td>\n",
       "      <td>0.815489</td>\n",
       "      <td>0.913688</td>\n",
       "      <td>0.894577</td>\n",
       "      <td>0.800705</td>\n",
       "      <td>0.662550</td>\n",
       "      <td>0.281065</td>\n",
       "      <td>0.889426</td>\n",
       "      <td>0.875277</td>\n",
       "      <td>0.711187</td>\n",
       "      <td>0.781553</td>\n",
       "      <td>0.329352</td>\n",
       "      <td>0.220122</td>\n",
       "      <td>0.815489</td>\n",
       "      <td>0.794061</td>\n",
       "      <td>0.160622</td>\n",
       "      <td>0.094031</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.255310</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>100</td>\n",
       "      <td>5326</td>\n",
       "      <td>0.504994</td>\n",
       "      <td>0.380940</td>\n",
       "      <td>0.186081</td>\n",
       "      <td>0.370751</td>\n",
       "      <td>0.426500</td>\n",
       "      <td>0.226843</td>\n",
       "      <td>0.899571</td>\n",
       "      <td>0.758539</td>\n",
       "      <td>0.825243</td>\n",
       "      <td>0.529266</td>\n",
       "      <td>0.829671</td>\n",
       "      <td>0.994074</td>\n",
       "      <td>0.741820</td>\n",
       "      <td>0.705662</td>\n",
       "      <td>0.969831</td>\n",
       "      <td>0.849728</td>\n",
       "      <td>0.951450</td>\n",
       "      <td>9.775284e-01</td>\n",
       "      <td>0.928885</td>\n",
       "      <td>0.974094</td>\n",
       "      <td>0.856851</td>\n",
       "      <td>0.946249</td>\n",
       "      <td>0.912354</td>\n",
       "      <td>0.921801</td>\n",
       "      <td>0.722733</td>\n",
       "      <td>0.269533</td>\n",
       "      <td>0.924850</td>\n",
       "      <td>0.918991</td>\n",
       "      <td>0.834325</td>\n",
       "      <td>0.844364</td>\n",
       "      <td>0.630280</td>\n",
       "      <td>0.219975</td>\n",
       "      <td>0.830025</td>\n",
       "      <td>0.817266</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.143986</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.398353</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>100</td>\n",
       "      <td>1389</td>\n",
       "      <td>0.457299</td>\n",
       "      <td>0.173582</td>\n",
       "      <td>0.152193</td>\n",
       "      <td>0.191585</td>\n",
       "      <td>0.158163</td>\n",
       "      <td>0.123656</td>\n",
       "      <td>0.703391</td>\n",
       "      <td>0.821117</td>\n",
       "      <td>0.152634</td>\n",
       "      <td>0.391795</td>\n",
       "      <td>0.576416</td>\n",
       "      <td>0.638776</td>\n",
       "      <td>0.226166</td>\n",
       "      <td>0.145849</td>\n",
       "      <td>0.320535</td>\n",
       "      <td>0.889780</td>\n",
       "      <td>0.051062</td>\n",
       "      <td>8.100848e-02</td>\n",
       "      <td>0.823537</td>\n",
       "      <td>0.892493</td>\n",
       "      <td>0.285404</td>\n",
       "      <td>0.516267</td>\n",
       "      <td>0.857341</td>\n",
       "      <td>0.760775</td>\n",
       "      <td>0.556267</td>\n",
       "      <td>0.266762</td>\n",
       "      <td>0.817845</td>\n",
       "      <td>0.790950</td>\n",
       "      <td>0.375810</td>\n",
       "      <td>0.254872</td>\n",
       "      <td>0.127706</td>\n",
       "      <td>0.116814</td>\n",
       "      <td>0.285404</td>\n",
       "      <td>0.202417</td>\n",
       "      <td>0.152070</td>\n",
       "      <td>0.101173</td>\n",
       "      <td>0.561758</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.114008</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>100</td>\n",
       "      <td>5153</td>\n",
       "      <td>0.503643</td>\n",
       "      <td>0.255375</td>\n",
       "      <td>0.205944</td>\n",
       "      <td>0.346032</td>\n",
       "      <td>0.248265</td>\n",
       "      <td>0.204870</td>\n",
       "      <td>0.917486</td>\n",
       "      <td>0.947452</td>\n",
       "      <td>0.725425</td>\n",
       "      <td>0.938016</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999361</td>\n",
       "      <td>0.987637</td>\n",
       "      <td>0.967503</td>\n",
       "      <td>0.630591</td>\n",
       "      <td>0.802153</td>\n",
       "      <td>0.957659</td>\n",
       "      <td>9.760884e-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.888076</td>\n",
       "      <td>0.671056</td>\n",
       "      <td>0.357490</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.889625</td>\n",
       "      <td>0.508440</td>\n",
       "      <td>0.312266</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.244869</td>\n",
       "      <td>0.099229</td>\n",
       "      <td>0.895382</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.573919</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>100</td>\n",
       "      <td>1975</td>\n",
       "      <td>0.529565</td>\n",
       "      <td>0.246333</td>\n",
       "      <td>0.155104</td>\n",
       "      <td>0.356367</td>\n",
       "      <td>0.262292</td>\n",
       "      <td>0.171215</td>\n",
       "      <td>0.872809</td>\n",
       "      <td>0.842285</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.979756</td>\n",
       "      <td>0.994504</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.505226</td>\n",
       "      <td>0.750124</td>\n",
       "      <td>0.552988</td>\n",
       "      <td>7.964698e-01</td>\n",
       "      <td>0.979904</td>\n",
       "      <td>0.989253</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.967475</td>\n",
       "      <td>0.882543</td>\n",
       "      <td>0.683351</td>\n",
       "      <td>0.322125</td>\n",
       "      <td>0.979160</td>\n",
       "      <td>0.971694</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.200952</td>\n",
       "      <td>0.100981</td>\n",
       "      <td>0.843244</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.533735</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>100</td>\n",
       "      <td>705</td>\n",
       "      <td>0.391949</td>\n",
       "      <td>0.466228</td>\n",
       "      <td>0.296158</td>\n",
       "      <td>0.340712</td>\n",
       "      <td>0.485242</td>\n",
       "      <td>0.402482</td>\n",
       "      <td>0.777286</td>\n",
       "      <td>0.938553</td>\n",
       "      <td>0.700433</td>\n",
       "      <td>0.921546</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999601</td>\n",
       "      <td>0.964791</td>\n",
       "      <td>0.394490</td>\n",
       "      <td>0.975265</td>\n",
       "      <td>0.948569</td>\n",
       "      <td>9.771114e-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.744874</td>\n",
       "      <td>0.291440</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.501246</td>\n",
       "      <td>0.252735</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.176255</td>\n",
       "      <td>0.100868</td>\n",
       "      <td>0.696727</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.619199</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>100</td>\n",
       "      <td>2465</td>\n",
       "      <td>0.407431</td>\n",
       "      <td>0.496899</td>\n",
       "      <td>0.300016</td>\n",
       "      <td>0.338256</td>\n",
       "      <td>0.486943</td>\n",
       "      <td>0.300016</td>\n",
       "      <td>0.939606</td>\n",
       "      <td>0.967033</td>\n",
       "      <td>0.921855</td>\n",
       "      <td>0.955799</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.967520</td>\n",
       "      <td>0.983678</td>\n",
       "      <td>0.964821</td>\n",
       "      <td>9.842812e-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.963409</td>\n",
       "      <td>0.895578</td>\n",
       "      <td>0.982281</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.950474</td>\n",
       "      <td>0.834275</td>\n",
       "      <td>0.862028</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.258714</td>\n",
       "      <td>0.100062</td>\n",
       "      <td>0.920747</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.731418</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>100</td>\n",
       "      <td>4826</td>\n",
       "      <td>0.455823</td>\n",
       "      <td>0.314752</td>\n",
       "      <td>0.164622</td>\n",
       "      <td>0.298948</td>\n",
       "      <td>0.263800</td>\n",
       "      <td>0.141633</td>\n",
       "      <td>0.868833</td>\n",
       "      <td>0.827422</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.704945</td>\n",
       "      <td>0.778416</td>\n",
       "      <td>0.529429</td>\n",
       "      <td>0.568717</td>\n",
       "      <td>0.500489</td>\n",
       "      <td>0.689703</td>\n",
       "      <td>0.615027</td>\n",
       "      <td>0.946773</td>\n",
       "      <td>7.259718e-01</td>\n",
       "      <td>0.909810</td>\n",
       "      <td>0.955494</td>\n",
       "      <td>0.800127</td>\n",
       "      <td>0.918973</td>\n",
       "      <td>0.922813</td>\n",
       "      <td>0.851006</td>\n",
       "      <td>0.652218</td>\n",
       "      <td>0.241316</td>\n",
       "      <td>0.902508</td>\n",
       "      <td>0.881335</td>\n",
       "      <td>0.824919</td>\n",
       "      <td>0.738324</td>\n",
       "      <td>0.517975</td>\n",
       "      <td>0.190031</td>\n",
       "      <td>0.800127</td>\n",
       "      <td>0.776915</td>\n",
       "      <td>0.211602</td>\n",
       "      <td>0.100722</td>\n",
       "      <td>0.927618</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.280085</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>100</td>\n",
       "      <td>4361</td>\n",
       "      <td>0.236921</td>\n",
       "      <td>0.156215</td>\n",
       "      <td>0.192543</td>\n",
       "      <td>0.194459</td>\n",
       "      <td>0.221758</td>\n",
       "      <td>0.182364</td>\n",
       "      <td>0.799354</td>\n",
       "      <td>0.826339</td>\n",
       "      <td>0.736696</td>\n",
       "      <td>0.807197</td>\n",
       "      <td>0.676978</td>\n",
       "      <td>0.620543</td>\n",
       "      <td>0.594695</td>\n",
       "      <td>0.702814</td>\n",
       "      <td>0.466917</td>\n",
       "      <td>0.988845</td>\n",
       "      <td>0.955315</td>\n",
       "      <td>9.816395e-01</td>\n",
       "      <td>0.869828</td>\n",
       "      <td>0.948150</td>\n",
       "      <td>0.836308</td>\n",
       "      <td>0.936795</td>\n",
       "      <td>0.805897</td>\n",
       "      <td>0.713648</td>\n",
       "      <td>0.581492</td>\n",
       "      <td>0.327424</td>\n",
       "      <td>0.869828</td>\n",
       "      <td>0.851196</td>\n",
       "      <td>0.745715</td>\n",
       "      <td>0.583339</td>\n",
       "      <td>0.381752</td>\n",
       "      <td>0.279292</td>\n",
       "      <td>0.836308</td>\n",
       "      <td>0.817298</td>\n",
       "      <td>0.255507</td>\n",
       "      <td>0.100667</td>\n",
       "      <td>0.308610</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.261065</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    from    to  doc2vec:wikipedia,size=300  word2vec:wikipedia,size=300,mean  word2vec:wikipedia,size=300,max  doc2vec:tokenization,wikipedia,size=300  word2vec:tokenization,wikipedia,size=300,mean  word2vec:tokenization,wikipedia,size=300,max  noble coder:precise,tfidf  noble coder:partial,tfidf  noble coder:tokenization,precise,tfidf  noble coder:tokenization,partial,tfidf  topic modeling:nmf,full,topics=50  topic modeling:nmf,full,topics=100  topic modeling:tokenization,nmf,full,topics=50  topic modeling:tokenization,nmf,full,topics=100  topic modeling:lda,full,topics=50  topic modeling:lda,full,topics=100  topic modeling:tokenization,lda,full,topics=50  topic modeling:tokenization,lda,full,topics=100  n-grams:full,words,1-grams,tfidf  n-grams:full,words,1-grams,2-grams,tfidf  n-grams:tokenization,full,words,1-grams,tfidf  n-grams:tokenization,full,words,1-grams,2-grams,tfidf  n-grams:full,nouns,adjectives,1-grams  n-grams:linares_pontes,words,1-grams  \\\n",
       "0    100  1145                    0.484948                          0.503235                         0.263459                                 0.422335                                       0.478481                                      0.288674                   0.863608                   0.927264                                0.804840                                0.899720                           1.000000                            1.000000                                        0.985932                                         0.983500                           0.972852                            0.986386                                        0.956351                                     9.843608e-01                          1.000000                                  1.000000                                       1.000000                                           1.000000                                   1.000000                              1.000000   \n",
       "1    100  4114                    0.343207                          0.260014                         0.185656                                 0.260778                                       0.270105                                      0.180168                   0.936699                   0.963473                                0.915321                                0.957688                           0.999937                            1.000000                                        0.997800                                         0.984195                           0.848661                            0.988527                                        0.969091                                     9.845576e-01                          1.000000                                  1.000000                                       1.000000                                           1.000000                                   1.000000                              0.980422   \n",
       "2    100   231                    0.424650                          0.279231                         0.185035                                 0.296518                                       0.271672                                      0.188429                   0.888187                   0.921801                                1.000000                                1.000000                           0.824749                            0.978728                                        0.556710                                         0.931309                           0.668178                            0.980502                                        0.552669                                     9.768748e-01                          0.943099                                  0.972357                                       0.885369                                           0.931381                                   0.926808                              0.896132   \n",
       "3    100  5244                    0.515200                          0.602756                         0.363885                                 0.428738                                       0.607823                                      0.362408                   1.000000                   0.957448                                1.000000                                0.944979                           1.000000                            1.000000                                        0.999151                                         0.965712                           0.954950                            0.976779                                        0.950524                                     9.776629e-01                          1.000000                                  1.000000                                       1.000000                                           1.000000                                   1.000000                              1.000000   \n",
       "4    100   733                    0.527713                          0.270065                         0.181497                                 0.355785                                       0.293558                                      0.170425                   0.899698                   0.927390                                0.804250                                0.918117                           0.990412                            0.999971                                        0.999996                                         1.000000                           0.491172                            0.517408                                        0.958356                                     9.761760e-01                          1.000000                                  1.000000                                       1.000000                                           1.000000                                   1.000000                              0.877337   \n",
       "5    100  3896                    0.520128                          0.536171                         0.298879                                 0.399769                                       0.590710                                      0.391840                   0.973093                   0.970430                                0.971126                                0.966886                           0.981126                            0.913819                                        0.982271                                         1.000000                           0.967291                            0.983562                                        0.959602                                     9.657815e-01                          1.000000                                  1.000000                                       1.000000                                           1.000000                                   1.000000                              1.000000   \n",
       "6    100  4572                    0.490884                          0.326860                         0.179187                                 0.310596                                       0.341777                                      0.209361                   0.956777                   0.928798                                0.939667                                0.925504                           1.000000                            0.973819                                        0.910472                                         0.965566                           0.965742                            0.985249                                        0.941665                                     9.777083e-01                          1.000000                                  1.000000                                       1.000000                                           1.000000                                   1.000000                              0.916390   \n",
       "7    100  2823                    0.547941                          0.272979                         0.187657                                 0.279518                                       0.278486                                      0.199103                   0.893427                   0.902922                                1.000000                                0.889492                           0.981633                            0.978047                                        0.325492                                         0.707005                           0.970948                            0.940419                                        0.560160                                     7.171545e-01                          1.000000                                  1.000000                                       1.000000                                           1.000000                                   1.000000                              0.974706   \n",
       "8    100  1592                    0.448422                          0.438724                         0.198668                                 0.320943                                       0.365019                                      0.222920                   0.904967                   0.925881                                1.000000                                0.906443                           1.000000                            1.000000                                        0.998446                                         1.000000                           0.969069                            0.988745                                        0.959906                                     9.800199e-01                          1.000000                                  1.000000                                       1.000000                                           1.000000                                   1.000000                              0.951814   \n",
       "9    100  1185                    0.450585                          0.197340                         0.151455                                 0.301088                                       0.232980                                      0.155569                   0.909111                   0.919647                                0.666356                                0.911593                           0.998078                            0.999591                                        0.828320                                         0.981882                           0.855693                            0.859678                                        0.944414                                     8.544685e-07                          0.977251                                  0.989587                                       0.894892                                           0.957043                                   1.000000                              0.878630   \n",
       "10   100   883                    0.448113                          0.601558                         0.872109                                 0.347916                                       0.597342                                      0.807199                   0.851351                   0.933871                                0.804250                                0.924255                           0.999982                            0.999745                                        1.000000                                         1.000000                           0.955775                            0.983743                                        0.948569                                     9.771114e-01                          1.000000                                  1.000000                                       1.000000                                           1.000000                                   1.000000                              1.000000   \n",
       "11   100  2456                    0.526467                          0.186860                         0.160455                                 0.183519                                       0.194339                                      0.160468                   0.891434                   0.870208                                0.648624                                0.670109                           0.753885                            0.503019                                        0.635399                                         0.461174                           0.375986                            0.697940                                        0.903339                                     9.784185e-01                          0.896217                                  0.943120                                       0.815489                                           0.913688                                   0.894577                              0.800705   \n",
       "12   100  5326                    0.504994                          0.380940                         0.186081                                 0.370751                                       0.426500                                      0.226843                   0.899571                   0.758539                                0.825243                                0.529266                           0.829671                            0.994074                                        0.741820                                         0.705662                           0.969831                            0.849728                                        0.951450                                     9.775284e-01                          0.928885                                  0.974094                                       0.856851                                           0.946249                                   0.912354                              0.921801   \n",
       "13   100  1389                    0.457299                          0.173582                         0.152193                                 0.191585                                       0.158163                                      0.123656                   0.703391                   0.821117                                0.152634                                0.391795                           0.576416                            0.638776                                        0.226166                                         0.145849                           0.320535                            0.889780                                        0.051062                                     8.100848e-02                          0.823537                                  0.892493                                       0.285404                                           0.516267                                   0.857341                              0.760775   \n",
       "14   100  5153                    0.503643                          0.255375                         0.205944                                 0.346032                                       0.248265                                      0.204870                   0.917486                   0.947452                                0.725425                                0.938016                           1.000000                            0.999361                                        0.987637                                         0.967503                           0.630591                            0.802153                                        0.957659                                     9.760884e-01                          1.000000                                  1.000000                                       1.000000                                           1.000000                                   1.000000                              0.888076   \n",
       "15   100  1975                    0.529565                          0.246333                         0.155104                                 0.356367                                       0.262292                                      0.171215                   0.872809                   0.842285                                1.000000                                1.000000                           0.979756                            0.994504                                        1.000000                                         1.000000                           0.505226                            0.750124                                        0.552988                                     7.964698e-01                          0.979904                                  0.989253                                       1.000000                                           1.000000                                   0.967475                              0.882543   \n",
       "16   100   705                    0.391949                          0.466228                         0.296158                                 0.340712                                       0.485242                                      0.402482                   0.777286                   0.938553                                0.700433                                0.921546                           1.000000                            1.000000                                        0.999601                                         0.964791                           0.394490                            0.975265                                        0.948569                                     9.771114e-01                          1.000000                                  1.000000                                       1.000000                                           1.000000                                   1.000000                              1.000000   \n",
       "17   100  2465                    0.407431                          0.496899                         0.300016                                 0.338256                                       0.486943                                      0.300016                   0.939606                   0.967033                                0.921855                                0.955799                           1.000000                            1.000000                                        1.000000                                         1.000000                           0.967520                            0.983678                                        0.964821                                     9.842812e-01                          1.000000                                  1.000000                                       1.000000                                           1.000000                                   1.000000                              0.963409   \n",
       "18   100  4826                    0.455823                          0.314752                         0.164622                                 0.298948                                       0.263800                                      0.141633                   0.868833                   0.827422                                1.000000                                0.704945                           0.778416                            0.529429                                        0.568717                                         0.500489                           0.689703                            0.615027                                        0.946773                                     7.259718e-01                          0.909810                                  0.955494                                       0.800127                                           0.918973                                   0.922813                              0.851006   \n",
       "19   100  4361                    0.236921                          0.156215                         0.192543                                 0.194459                                       0.221758                                      0.182364                   0.799354                   0.826339                                0.736696                                0.807197                           0.676978                            0.620543                                        0.594695                                         0.702814                           0.466917                            0.988845                                        0.955315                                     9.816395e-01                          0.869828                                  0.948150                                       0.836308                                           0.936795                                   0.805897                              0.713648   \n",
       "\n",
       "    n-grams:full,precise_annotations,words,1-grams  n-grams:full,partial_annotations,words,1-grams  n-grams:full,plant overrepresented tokens,1-grams  n-grams:full,bio ontology tokens,1-grams  n-grams:tokenization,full,nouns,adjectives,1-grams  n-grams:tokenization,linares_pontes,words,1-grams  n-grams:tokenization,full,precise_annotations,words,1-grams  n-grams:tokenization,full,partial_annotations,words,1-grams  n-grams:tokenization,full,plant overrepresented tokens,1-grams  n-grams:tokenization,full,bio ontology tokens,1-grams  go:union  po:union  go:minimum  po:minimum      mean   same  pathways  kegg_only  pmn_only  \n",
       "0                                         0.840402                                        0.568991                                           1.000000                                  1.000000                                           1.000000                                            1.000000                                           0.591617                                                     0.432781                                                     1.000000                                                        1.000000      1.000000  0.199791    1.000000    0.646186  0.696545  False        -1         -1        -1  \n",
       "1                                         0.812361                                        0.422756                                           1.000000                                  1.000000                                           1.000000                                            0.980264                                           0.748194                                                     0.437357                                                     1.000000                                                        1.000000      1.000000  1.000000    1.000000    1.000000  0.637134   True        -1         -1        -1  \n",
       "2                                         0.560416                                        0.496319                                           0.943099                                  0.928882                                           0.813392                                            0.868671                                           0.387241                                                     0.423178                                                     0.885369                                                        0.858600      0.240786  0.097509    0.906796    0.000000  0.385529   True        -1         -1        -1  \n",
       "3                                         1.000000                                        0.978017                                           1.000000                                  1.000000                                           1.000000                                            1.000000                                           1.000000                                                     0.897769                                                     1.000000                                                        1.000000      0.367580  0.108020    0.690276    0.474998  0.770669   True        -1         -1        -1  \n",
       "4                                         0.810659                                        0.297326                                           1.000000                                  1.000000                                           1.000000                                            0.866671                                           0.604588                                                     0.252735                                                     1.000000                                                        1.000000      0.202688  0.089205    0.690276    0.000000  0.576333   True        -1         -1        -1  \n",
       "5                                         0.921055                                        0.329352                                           1.000000                                  1.000000                                           1.000000                                            1.000000                                           0.847789                                                     0.309230                                                     1.000000                                                        1.000000      1.000000  1.000000    1.000000    1.000000  0.704863  False        -1         -1        -1  \n",
       "6                                         0.740565                                        0.356273                                           1.000000                                  1.000000                                           1.000000                                            0.897864                                           0.598539                                                     0.266433                                                     1.000000                                                        1.000000      0.622213  0.110242    0.956128    0.474998  0.595887   True        -1         -1        -1  \n",
       "7                                         0.741642                                        0.258536                                           1.000000                                  1.000000                                           1.000000                                            0.949664                                           0.555684                                                     0.233350                                                     1.000000                                                        1.000000      1.000000  1.000000    1.000000    1.000000  0.528961  False        -1         -1        -1  \n",
       "8                                         0.827605                                        0.342629                                           1.000000                                  1.000000                                           1.000000                                            0.900542                                           0.732674                                                     0.251352                                                     1.000000                                                        1.000000      0.229783  0.093575    0.484877    0.000000  0.663482   True        -1         -1        -1  \n",
       "9                                         0.720393                                        0.329431                                           0.976848                                  1.000000                                           1.000000                                            0.839561                                           0.424285                                                     0.281615                                                     0.873610                                                        1.000000      0.218605  0.217137    0.897383    0.539171  0.429050   True        -1         -1        -1  \n",
       "10                                        0.898833                                        0.295495                                           1.000000                                  1.000000                                           1.000000                                            1.000000                                           0.717540                                                     0.252735                                                     1.000000                                                        1.000000      0.323868  0.102040    0.922758    0.000000  0.690772   True        -1         -1        -1  \n",
       "11                                        0.662550                                        0.281065                                           0.889426                                  0.875277                                           0.711187                                            0.781553                                           0.329352                                                     0.220122                                                     0.815489                                                        0.794061      0.160622  0.094031    0.000000    0.000000  0.255310   True        -1         -1        -1  \n",
       "12                                        0.722733                                        0.269533                                           0.924850                                  0.918991                                           0.834325                                            0.844364                                           0.630280                                                     0.219975                                                     0.830025                                                        0.817266      1.000000  0.143986    1.000000    0.000000  0.398353   True        -1         -1        -1  \n",
       "13                                        0.556267                                        0.266762                                           0.817845                                  0.790950                                           0.375810                                            0.254872                                           0.127706                                                     0.116814                                                     0.285404                                                        0.202417      0.152070  0.101173    0.561758    0.000000  0.114008   True        -1         -1        -1  \n",
       "14                                        0.671056                                        0.357490                                           1.000000                                  1.000000                                           1.000000                                            0.889625                                           0.508440                                                     0.312266                                                     1.000000                                                        1.000000      0.244869  0.099229    0.895382    0.000000  0.573919   True        -1         -1        -1  \n",
       "15                                        0.683351                                        0.322125                                           0.979160                                  0.971694                                           1.000000                                            1.000000                                           1.000000                                                     1.000000                                                     1.000000                                                        1.000000      0.200952  0.100981    0.843244    0.000000  0.533735   True        -1         -1        -1  \n",
       "16                                        0.744874                                        0.291440                                           1.000000                                  1.000000                                           1.000000                                            1.000000                                           0.501246                                                     0.252735                                                     1.000000                                                        1.000000      0.176255  0.100868    0.696727    0.000000  0.619199   True        -1         -1        -1  \n",
       "17                                        0.895578                                        0.982281                                           1.000000                                  1.000000                                           1.000000                                            0.950474                                           0.834275                                                     0.862028                                                     1.000000                                                        1.000000      0.258714  0.100062    0.920747    0.000000  0.731418   True        -1         -1        -1  \n",
       "18                                        0.652218                                        0.241316                                           0.902508                                  0.881335                                           0.824919                                            0.738324                                           0.517975                                                     0.190031                                                     0.800127                                                        0.776915      0.211602  0.100722    0.927618    0.000000  0.280085   True        -1         -1        -1  \n",
       "19                                        0.581492                                        0.327424                                           0.869828                                  0.851196                                           0.745715                                            0.583339                                           0.381752                                                     0.279292                                                     0.836308                                                        0.817298      0.255507  0.100667    0.308610    0.000000  0.261065   True        -1         -1        -1  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add a column that indicates whether or not both genes of the pair mapped to a pathway resource.\n",
    "pathway_mapped_ids = set(pmn_mapped_ids)\n",
    "df[\"from_is_valid\"] = df[\"from\"].map(lambda x: x in pathway_mapped_ids)\n",
    "df[\"to_is_valid\"] = df[\"to\"].map(lambda x: x in pathway_mapped_ids)\n",
    "df[\"pair_is_valid\"] = df[\"from_is_valid\"]*df[\"to_is_valid\"]\n",
    "\n",
    "\n",
    "# Add a column giving the actual target output value for this biological task, with -1 for the irrelevant rows.\n",
    "df[\"pmn_only\"] = -1\n",
    "id_to_kegg_group_ids, kegg_group_id_to_ids = kegg_groups.get_groupings_for_dataset(dataset)\n",
    "id_to_pmn_group_ids, pmn_group_id_to_ids = pmn_groups.get_groupings_for_dataset(dataset)\n",
    "id_to_group_ids = {i:flatten([id_to_kegg_group_ids[i],id_to_pmn_group_ids[i]]) for i in dataset.get_ids()}\n",
    "df.loc[(df[\"pair_is_valid\"]==True),\"pmn_only\"] = df[[\"from\",\"to\"]].apply(lambda x: len(set(id_to_group_ids[x[\"from\"]]).intersection(set(id_to_group_ids[x[\"to\"]])))>0, axis=1)*1\n",
    "df.drop(labels=[\"from_is_valid\",\"to_is_valid\",\"pair_is_valid\"], axis=\"columns\", inplace=True)\n",
    "\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"subset_objective\"></a>\n",
    "### Using shared phenotype classification (Lloyd and Meinke et al., 2012) as the objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>from</th>\n",
       "      <th>to</th>\n",
       "      <th>doc2vec:wikipedia,size=300</th>\n",
       "      <th>word2vec:wikipedia,size=300,mean</th>\n",
       "      <th>word2vec:wikipedia,size=300,max</th>\n",
       "      <th>doc2vec:tokenization,wikipedia,size=300</th>\n",
       "      <th>word2vec:tokenization,wikipedia,size=300,mean</th>\n",
       "      <th>word2vec:tokenization,wikipedia,size=300,max</th>\n",
       "      <th>noble coder:precise,tfidf</th>\n",
       "      <th>noble coder:partial,tfidf</th>\n",
       "      <th>noble coder:tokenization,precise,tfidf</th>\n",
       "      <th>noble coder:tokenization,partial,tfidf</th>\n",
       "      <th>topic modeling:nmf,full,topics=50</th>\n",
       "      <th>topic modeling:nmf,full,topics=100</th>\n",
       "      <th>topic modeling:tokenization,nmf,full,topics=50</th>\n",
       "      <th>topic modeling:tokenization,nmf,full,topics=100</th>\n",
       "      <th>topic modeling:lda,full,topics=50</th>\n",
       "      <th>topic modeling:lda,full,topics=100</th>\n",
       "      <th>topic modeling:tokenization,lda,full,topics=50</th>\n",
       "      <th>topic modeling:tokenization,lda,full,topics=100</th>\n",
       "      <th>n-grams:full,words,1-grams,tfidf</th>\n",
       "      <th>n-grams:full,words,1-grams,2-grams,tfidf</th>\n",
       "      <th>n-grams:tokenization,full,words,1-grams,tfidf</th>\n",
       "      <th>n-grams:tokenization,full,words,1-grams,2-grams,tfidf</th>\n",
       "      <th>n-grams:full,nouns,adjectives,1-grams</th>\n",
       "      <th>n-grams:linares_pontes,words,1-grams</th>\n",
       "      <th>n-grams:full,precise_annotations,words,1-grams</th>\n",
       "      <th>n-grams:full,partial_annotations,words,1-grams</th>\n",
       "      <th>n-grams:full,plant overrepresented tokens,1-grams</th>\n",
       "      <th>n-grams:full,bio ontology tokens,1-grams</th>\n",
       "      <th>n-grams:tokenization,full,nouns,adjectives,1-grams</th>\n",
       "      <th>n-grams:tokenization,linares_pontes,words,1-grams</th>\n",
       "      <th>n-grams:tokenization,full,precise_annotations,words,1-grams</th>\n",
       "      <th>n-grams:tokenization,full,partial_annotations,words,1-grams</th>\n",
       "      <th>n-grams:tokenization,full,plant overrepresented tokens,1-grams</th>\n",
       "      <th>n-grams:tokenization,full,bio ontology tokens,1-grams</th>\n",
       "      <th>go:union</th>\n",
       "      <th>po:union</th>\n",
       "      <th>go:minimum</th>\n",
       "      <th>po:minimum</th>\n",
       "      <th>mean</th>\n",
       "      <th>same</th>\n",
       "      <th>pathways</th>\n",
       "      <th>kegg_only</th>\n",
       "      <th>pmn_only</th>\n",
       "      <th>subsets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>1145</td>\n",
       "      <td>0.484948</td>\n",
       "      <td>0.503235</td>\n",
       "      <td>0.263459</td>\n",
       "      <td>0.422335</td>\n",
       "      <td>0.478481</td>\n",
       "      <td>0.288674</td>\n",
       "      <td>0.863608</td>\n",
       "      <td>0.927264</td>\n",
       "      <td>0.804840</td>\n",
       "      <td>0.899720</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.985932</td>\n",
       "      <td>0.983500</td>\n",
       "      <td>0.972852</td>\n",
       "      <td>0.986386</td>\n",
       "      <td>0.956351</td>\n",
       "      <td>9.843608e-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.840402</td>\n",
       "      <td>0.568991</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.591617</td>\n",
       "      <td>0.432781</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.199791</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.646186</td>\n",
       "      <td>0.696545</td>\n",
       "      <td>False</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100</td>\n",
       "      <td>4114</td>\n",
       "      <td>0.343207</td>\n",
       "      <td>0.260014</td>\n",
       "      <td>0.185656</td>\n",
       "      <td>0.260778</td>\n",
       "      <td>0.270105</td>\n",
       "      <td>0.180168</td>\n",
       "      <td>0.936699</td>\n",
       "      <td>0.963473</td>\n",
       "      <td>0.915321</td>\n",
       "      <td>0.957688</td>\n",
       "      <td>0.999937</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.997800</td>\n",
       "      <td>0.984195</td>\n",
       "      <td>0.848661</td>\n",
       "      <td>0.988527</td>\n",
       "      <td>0.969091</td>\n",
       "      <td>9.845576e-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.980422</td>\n",
       "      <td>0.812361</td>\n",
       "      <td>0.422756</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.980264</td>\n",
       "      <td>0.748194</td>\n",
       "      <td>0.437357</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.637134</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>231</td>\n",
       "      <td>0.424650</td>\n",
       "      <td>0.279231</td>\n",
       "      <td>0.185035</td>\n",
       "      <td>0.296518</td>\n",
       "      <td>0.271672</td>\n",
       "      <td>0.188429</td>\n",
       "      <td>0.888187</td>\n",
       "      <td>0.921801</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.824749</td>\n",
       "      <td>0.978728</td>\n",
       "      <td>0.556710</td>\n",
       "      <td>0.931309</td>\n",
       "      <td>0.668178</td>\n",
       "      <td>0.980502</td>\n",
       "      <td>0.552669</td>\n",
       "      <td>9.768748e-01</td>\n",
       "      <td>0.943099</td>\n",
       "      <td>0.972357</td>\n",
       "      <td>0.885369</td>\n",
       "      <td>0.931381</td>\n",
       "      <td>0.926808</td>\n",
       "      <td>0.896132</td>\n",
       "      <td>0.560416</td>\n",
       "      <td>0.496319</td>\n",
       "      <td>0.943099</td>\n",
       "      <td>0.928882</td>\n",
       "      <td>0.813392</td>\n",
       "      <td>0.868671</td>\n",
       "      <td>0.387241</td>\n",
       "      <td>0.423178</td>\n",
       "      <td>0.885369</td>\n",
       "      <td>0.858600</td>\n",
       "      <td>0.240786</td>\n",
       "      <td>0.097509</td>\n",
       "      <td>0.906796</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.385529</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100</td>\n",
       "      <td>5244</td>\n",
       "      <td>0.515200</td>\n",
       "      <td>0.602756</td>\n",
       "      <td>0.363885</td>\n",
       "      <td>0.428738</td>\n",
       "      <td>0.607823</td>\n",
       "      <td>0.362408</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.957448</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.944979</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999151</td>\n",
       "      <td>0.965712</td>\n",
       "      <td>0.954950</td>\n",
       "      <td>0.976779</td>\n",
       "      <td>0.950524</td>\n",
       "      <td>9.776629e-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.978017</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.897769</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.367580</td>\n",
       "      <td>0.108020</td>\n",
       "      <td>0.690276</td>\n",
       "      <td>0.474998</td>\n",
       "      <td>0.770669</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100</td>\n",
       "      <td>733</td>\n",
       "      <td>0.527713</td>\n",
       "      <td>0.270065</td>\n",
       "      <td>0.181497</td>\n",
       "      <td>0.355785</td>\n",
       "      <td>0.293558</td>\n",
       "      <td>0.170425</td>\n",
       "      <td>0.899698</td>\n",
       "      <td>0.927390</td>\n",
       "      <td>0.804250</td>\n",
       "      <td>0.918117</td>\n",
       "      <td>0.990412</td>\n",
       "      <td>0.999971</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.491172</td>\n",
       "      <td>0.517408</td>\n",
       "      <td>0.958356</td>\n",
       "      <td>9.761760e-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.877337</td>\n",
       "      <td>0.810659</td>\n",
       "      <td>0.297326</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.866671</td>\n",
       "      <td>0.604588</td>\n",
       "      <td>0.252735</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.202688</td>\n",
       "      <td>0.089205</td>\n",
       "      <td>0.690276</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.576333</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>100</td>\n",
       "      <td>3896</td>\n",
       "      <td>0.520128</td>\n",
       "      <td>0.536171</td>\n",
       "      <td>0.298879</td>\n",
       "      <td>0.399769</td>\n",
       "      <td>0.590710</td>\n",
       "      <td>0.391840</td>\n",
       "      <td>0.973093</td>\n",
       "      <td>0.970430</td>\n",
       "      <td>0.971126</td>\n",
       "      <td>0.966886</td>\n",
       "      <td>0.981126</td>\n",
       "      <td>0.913819</td>\n",
       "      <td>0.982271</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.967291</td>\n",
       "      <td>0.983562</td>\n",
       "      <td>0.959602</td>\n",
       "      <td>9.657815e-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.921055</td>\n",
       "      <td>0.329352</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.847789</td>\n",
       "      <td>0.309230</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.704863</td>\n",
       "      <td>False</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>100</td>\n",
       "      <td>4572</td>\n",
       "      <td>0.490884</td>\n",
       "      <td>0.326860</td>\n",
       "      <td>0.179187</td>\n",
       "      <td>0.310596</td>\n",
       "      <td>0.341777</td>\n",
       "      <td>0.209361</td>\n",
       "      <td>0.956777</td>\n",
       "      <td>0.928798</td>\n",
       "      <td>0.939667</td>\n",
       "      <td>0.925504</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.973819</td>\n",
       "      <td>0.910472</td>\n",
       "      <td>0.965566</td>\n",
       "      <td>0.965742</td>\n",
       "      <td>0.985249</td>\n",
       "      <td>0.941665</td>\n",
       "      <td>9.777083e-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.916390</td>\n",
       "      <td>0.740565</td>\n",
       "      <td>0.356273</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.897864</td>\n",
       "      <td>0.598539</td>\n",
       "      <td>0.266433</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.622213</td>\n",
       "      <td>0.110242</td>\n",
       "      <td>0.956128</td>\n",
       "      <td>0.474998</td>\n",
       "      <td>0.595887</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>100</td>\n",
       "      <td>2823</td>\n",
       "      <td>0.547941</td>\n",
       "      <td>0.272979</td>\n",
       "      <td>0.187657</td>\n",
       "      <td>0.279518</td>\n",
       "      <td>0.278486</td>\n",
       "      <td>0.199103</td>\n",
       "      <td>0.893427</td>\n",
       "      <td>0.902922</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.889492</td>\n",
       "      <td>0.981633</td>\n",
       "      <td>0.978047</td>\n",
       "      <td>0.325492</td>\n",
       "      <td>0.707005</td>\n",
       "      <td>0.970948</td>\n",
       "      <td>0.940419</td>\n",
       "      <td>0.560160</td>\n",
       "      <td>7.171545e-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.974706</td>\n",
       "      <td>0.741642</td>\n",
       "      <td>0.258536</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.949664</td>\n",
       "      <td>0.555684</td>\n",
       "      <td>0.233350</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.528961</td>\n",
       "      <td>False</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>100</td>\n",
       "      <td>1592</td>\n",
       "      <td>0.448422</td>\n",
       "      <td>0.438724</td>\n",
       "      <td>0.198668</td>\n",
       "      <td>0.320943</td>\n",
       "      <td>0.365019</td>\n",
       "      <td>0.222920</td>\n",
       "      <td>0.904967</td>\n",
       "      <td>0.925881</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.906443</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998446</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.969069</td>\n",
       "      <td>0.988745</td>\n",
       "      <td>0.959906</td>\n",
       "      <td>9.800199e-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.951814</td>\n",
       "      <td>0.827605</td>\n",
       "      <td>0.342629</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.900542</td>\n",
       "      <td>0.732674</td>\n",
       "      <td>0.251352</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.229783</td>\n",
       "      <td>0.093575</td>\n",
       "      <td>0.484877</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.663482</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>100</td>\n",
       "      <td>1185</td>\n",
       "      <td>0.450585</td>\n",
       "      <td>0.197340</td>\n",
       "      <td>0.151455</td>\n",
       "      <td>0.301088</td>\n",
       "      <td>0.232980</td>\n",
       "      <td>0.155569</td>\n",
       "      <td>0.909111</td>\n",
       "      <td>0.919647</td>\n",
       "      <td>0.666356</td>\n",
       "      <td>0.911593</td>\n",
       "      <td>0.998078</td>\n",
       "      <td>0.999591</td>\n",
       "      <td>0.828320</td>\n",
       "      <td>0.981882</td>\n",
       "      <td>0.855693</td>\n",
       "      <td>0.859678</td>\n",
       "      <td>0.944414</td>\n",
       "      <td>8.544685e-07</td>\n",
       "      <td>0.977251</td>\n",
       "      <td>0.989587</td>\n",
       "      <td>0.894892</td>\n",
       "      <td>0.957043</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.878630</td>\n",
       "      <td>0.720393</td>\n",
       "      <td>0.329431</td>\n",
       "      <td>0.976848</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.839561</td>\n",
       "      <td>0.424285</td>\n",
       "      <td>0.281615</td>\n",
       "      <td>0.873610</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.218605</td>\n",
       "      <td>0.217137</td>\n",
       "      <td>0.897383</td>\n",
       "      <td>0.539171</td>\n",
       "      <td>0.429050</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>100</td>\n",
       "      <td>883</td>\n",
       "      <td>0.448113</td>\n",
       "      <td>0.601558</td>\n",
       "      <td>0.872109</td>\n",
       "      <td>0.347916</td>\n",
       "      <td>0.597342</td>\n",
       "      <td>0.807199</td>\n",
       "      <td>0.851351</td>\n",
       "      <td>0.933871</td>\n",
       "      <td>0.804250</td>\n",
       "      <td>0.924255</td>\n",
       "      <td>0.999982</td>\n",
       "      <td>0.999745</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.955775</td>\n",
       "      <td>0.983743</td>\n",
       "      <td>0.948569</td>\n",
       "      <td>9.771114e-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.898833</td>\n",
       "      <td>0.295495</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.717540</td>\n",
       "      <td>0.252735</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.323868</td>\n",
       "      <td>0.102040</td>\n",
       "      <td>0.922758</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.690772</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>100</td>\n",
       "      <td>2456</td>\n",
       "      <td>0.526467</td>\n",
       "      <td>0.186860</td>\n",
       "      <td>0.160455</td>\n",
       "      <td>0.183519</td>\n",
       "      <td>0.194339</td>\n",
       "      <td>0.160468</td>\n",
       "      <td>0.891434</td>\n",
       "      <td>0.870208</td>\n",
       "      <td>0.648624</td>\n",
       "      <td>0.670109</td>\n",
       "      <td>0.753885</td>\n",
       "      <td>0.503019</td>\n",
       "      <td>0.635399</td>\n",
       "      <td>0.461174</td>\n",
       "      <td>0.375986</td>\n",
       "      <td>0.697940</td>\n",
       "      <td>0.903339</td>\n",
       "      <td>9.784185e-01</td>\n",
       "      <td>0.896217</td>\n",
       "      <td>0.943120</td>\n",
       "      <td>0.815489</td>\n",
       "      <td>0.913688</td>\n",
       "      <td>0.894577</td>\n",
       "      <td>0.800705</td>\n",
       "      <td>0.662550</td>\n",
       "      <td>0.281065</td>\n",
       "      <td>0.889426</td>\n",
       "      <td>0.875277</td>\n",
       "      <td>0.711187</td>\n",
       "      <td>0.781553</td>\n",
       "      <td>0.329352</td>\n",
       "      <td>0.220122</td>\n",
       "      <td>0.815489</td>\n",
       "      <td>0.794061</td>\n",
       "      <td>0.160622</td>\n",
       "      <td>0.094031</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.255310</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>100</td>\n",
       "      <td>5326</td>\n",
       "      <td>0.504994</td>\n",
       "      <td>0.380940</td>\n",
       "      <td>0.186081</td>\n",
       "      <td>0.370751</td>\n",
       "      <td>0.426500</td>\n",
       "      <td>0.226843</td>\n",
       "      <td>0.899571</td>\n",
       "      <td>0.758539</td>\n",
       "      <td>0.825243</td>\n",
       "      <td>0.529266</td>\n",
       "      <td>0.829671</td>\n",
       "      <td>0.994074</td>\n",
       "      <td>0.741820</td>\n",
       "      <td>0.705662</td>\n",
       "      <td>0.969831</td>\n",
       "      <td>0.849728</td>\n",
       "      <td>0.951450</td>\n",
       "      <td>9.775284e-01</td>\n",
       "      <td>0.928885</td>\n",
       "      <td>0.974094</td>\n",
       "      <td>0.856851</td>\n",
       "      <td>0.946249</td>\n",
       "      <td>0.912354</td>\n",
       "      <td>0.921801</td>\n",
       "      <td>0.722733</td>\n",
       "      <td>0.269533</td>\n",
       "      <td>0.924850</td>\n",
       "      <td>0.918991</td>\n",
       "      <td>0.834325</td>\n",
       "      <td>0.844364</td>\n",
       "      <td>0.630280</td>\n",
       "      <td>0.219975</td>\n",
       "      <td>0.830025</td>\n",
       "      <td>0.817266</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.143986</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.398353</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>100</td>\n",
       "      <td>1389</td>\n",
       "      <td>0.457299</td>\n",
       "      <td>0.173582</td>\n",
       "      <td>0.152193</td>\n",
       "      <td>0.191585</td>\n",
       "      <td>0.158163</td>\n",
       "      <td>0.123656</td>\n",
       "      <td>0.703391</td>\n",
       "      <td>0.821117</td>\n",
       "      <td>0.152634</td>\n",
       "      <td>0.391795</td>\n",
       "      <td>0.576416</td>\n",
       "      <td>0.638776</td>\n",
       "      <td>0.226166</td>\n",
       "      <td>0.145849</td>\n",
       "      <td>0.320535</td>\n",
       "      <td>0.889780</td>\n",
       "      <td>0.051062</td>\n",
       "      <td>8.100848e-02</td>\n",
       "      <td>0.823537</td>\n",
       "      <td>0.892493</td>\n",
       "      <td>0.285404</td>\n",
       "      <td>0.516267</td>\n",
       "      <td>0.857341</td>\n",
       "      <td>0.760775</td>\n",
       "      <td>0.556267</td>\n",
       "      <td>0.266762</td>\n",
       "      <td>0.817845</td>\n",
       "      <td>0.790950</td>\n",
       "      <td>0.375810</td>\n",
       "      <td>0.254872</td>\n",
       "      <td>0.127706</td>\n",
       "      <td>0.116814</td>\n",
       "      <td>0.285404</td>\n",
       "      <td>0.202417</td>\n",
       "      <td>0.152070</td>\n",
       "      <td>0.101173</td>\n",
       "      <td>0.561758</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.114008</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>100</td>\n",
       "      <td>5153</td>\n",
       "      <td>0.503643</td>\n",
       "      <td>0.255375</td>\n",
       "      <td>0.205944</td>\n",
       "      <td>0.346032</td>\n",
       "      <td>0.248265</td>\n",
       "      <td>0.204870</td>\n",
       "      <td>0.917486</td>\n",
       "      <td>0.947452</td>\n",
       "      <td>0.725425</td>\n",
       "      <td>0.938016</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999361</td>\n",
       "      <td>0.987637</td>\n",
       "      <td>0.967503</td>\n",
       "      <td>0.630591</td>\n",
       "      <td>0.802153</td>\n",
       "      <td>0.957659</td>\n",
       "      <td>9.760884e-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.888076</td>\n",
       "      <td>0.671056</td>\n",
       "      <td>0.357490</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.889625</td>\n",
       "      <td>0.508440</td>\n",
       "      <td>0.312266</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.244869</td>\n",
       "      <td>0.099229</td>\n",
       "      <td>0.895382</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.573919</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>100</td>\n",
       "      <td>1975</td>\n",
       "      <td>0.529565</td>\n",
       "      <td>0.246333</td>\n",
       "      <td>0.155104</td>\n",
       "      <td>0.356367</td>\n",
       "      <td>0.262292</td>\n",
       "      <td>0.171215</td>\n",
       "      <td>0.872809</td>\n",
       "      <td>0.842285</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.979756</td>\n",
       "      <td>0.994504</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.505226</td>\n",
       "      <td>0.750124</td>\n",
       "      <td>0.552988</td>\n",
       "      <td>7.964698e-01</td>\n",
       "      <td>0.979904</td>\n",
       "      <td>0.989253</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.967475</td>\n",
       "      <td>0.882543</td>\n",
       "      <td>0.683351</td>\n",
       "      <td>0.322125</td>\n",
       "      <td>0.979160</td>\n",
       "      <td>0.971694</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.200952</td>\n",
       "      <td>0.100981</td>\n",
       "      <td>0.843244</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.533735</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>100</td>\n",
       "      <td>705</td>\n",
       "      <td>0.391949</td>\n",
       "      <td>0.466228</td>\n",
       "      <td>0.296158</td>\n",
       "      <td>0.340712</td>\n",
       "      <td>0.485242</td>\n",
       "      <td>0.402482</td>\n",
       "      <td>0.777286</td>\n",
       "      <td>0.938553</td>\n",
       "      <td>0.700433</td>\n",
       "      <td>0.921546</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999601</td>\n",
       "      <td>0.964791</td>\n",
       "      <td>0.394490</td>\n",
       "      <td>0.975265</td>\n",
       "      <td>0.948569</td>\n",
       "      <td>9.771114e-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.744874</td>\n",
       "      <td>0.291440</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.501246</td>\n",
       "      <td>0.252735</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.176255</td>\n",
       "      <td>0.100868</td>\n",
       "      <td>0.696727</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.619199</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>100</td>\n",
       "      <td>2465</td>\n",
       "      <td>0.407431</td>\n",
       "      <td>0.496899</td>\n",
       "      <td>0.300016</td>\n",
       "      <td>0.338256</td>\n",
       "      <td>0.486943</td>\n",
       "      <td>0.300016</td>\n",
       "      <td>0.939606</td>\n",
       "      <td>0.967033</td>\n",
       "      <td>0.921855</td>\n",
       "      <td>0.955799</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.967520</td>\n",
       "      <td>0.983678</td>\n",
       "      <td>0.964821</td>\n",
       "      <td>9.842812e-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.963409</td>\n",
       "      <td>0.895578</td>\n",
       "      <td>0.982281</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.950474</td>\n",
       "      <td>0.834275</td>\n",
       "      <td>0.862028</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.258714</td>\n",
       "      <td>0.100062</td>\n",
       "      <td>0.920747</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.731418</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>100</td>\n",
       "      <td>4826</td>\n",
       "      <td>0.455823</td>\n",
       "      <td>0.314752</td>\n",
       "      <td>0.164622</td>\n",
       "      <td>0.298948</td>\n",
       "      <td>0.263800</td>\n",
       "      <td>0.141633</td>\n",
       "      <td>0.868833</td>\n",
       "      <td>0.827422</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.704945</td>\n",
       "      <td>0.778416</td>\n",
       "      <td>0.529429</td>\n",
       "      <td>0.568717</td>\n",
       "      <td>0.500489</td>\n",
       "      <td>0.689703</td>\n",
       "      <td>0.615027</td>\n",
       "      <td>0.946773</td>\n",
       "      <td>7.259718e-01</td>\n",
       "      <td>0.909810</td>\n",
       "      <td>0.955494</td>\n",
       "      <td>0.800127</td>\n",
       "      <td>0.918973</td>\n",
       "      <td>0.922813</td>\n",
       "      <td>0.851006</td>\n",
       "      <td>0.652218</td>\n",
       "      <td>0.241316</td>\n",
       "      <td>0.902508</td>\n",
       "      <td>0.881335</td>\n",
       "      <td>0.824919</td>\n",
       "      <td>0.738324</td>\n",
       "      <td>0.517975</td>\n",
       "      <td>0.190031</td>\n",
       "      <td>0.800127</td>\n",
       "      <td>0.776915</td>\n",
       "      <td>0.211602</td>\n",
       "      <td>0.100722</td>\n",
       "      <td>0.927618</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.280085</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>100</td>\n",
       "      <td>4361</td>\n",
       "      <td>0.236921</td>\n",
       "      <td>0.156215</td>\n",
       "      <td>0.192543</td>\n",
       "      <td>0.194459</td>\n",
       "      <td>0.221758</td>\n",
       "      <td>0.182364</td>\n",
       "      <td>0.799354</td>\n",
       "      <td>0.826339</td>\n",
       "      <td>0.736696</td>\n",
       "      <td>0.807197</td>\n",
       "      <td>0.676978</td>\n",
       "      <td>0.620543</td>\n",
       "      <td>0.594695</td>\n",
       "      <td>0.702814</td>\n",
       "      <td>0.466917</td>\n",
       "      <td>0.988845</td>\n",
       "      <td>0.955315</td>\n",
       "      <td>9.816395e-01</td>\n",
       "      <td>0.869828</td>\n",
       "      <td>0.948150</td>\n",
       "      <td>0.836308</td>\n",
       "      <td>0.936795</td>\n",
       "      <td>0.805897</td>\n",
       "      <td>0.713648</td>\n",
       "      <td>0.581492</td>\n",
       "      <td>0.327424</td>\n",
       "      <td>0.869828</td>\n",
       "      <td>0.851196</td>\n",
       "      <td>0.745715</td>\n",
       "      <td>0.583339</td>\n",
       "      <td>0.381752</td>\n",
       "      <td>0.279292</td>\n",
       "      <td>0.836308</td>\n",
       "      <td>0.817298</td>\n",
       "      <td>0.255507</td>\n",
       "      <td>0.100667</td>\n",
       "      <td>0.308610</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.261065</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    from    to  doc2vec:wikipedia,size=300  word2vec:wikipedia,size=300,mean  word2vec:wikipedia,size=300,max  doc2vec:tokenization,wikipedia,size=300  word2vec:tokenization,wikipedia,size=300,mean  word2vec:tokenization,wikipedia,size=300,max  noble coder:precise,tfidf  noble coder:partial,tfidf  noble coder:tokenization,precise,tfidf  noble coder:tokenization,partial,tfidf  topic modeling:nmf,full,topics=50  topic modeling:nmf,full,topics=100  topic modeling:tokenization,nmf,full,topics=50  topic modeling:tokenization,nmf,full,topics=100  topic modeling:lda,full,topics=50  topic modeling:lda,full,topics=100  topic modeling:tokenization,lda,full,topics=50  topic modeling:tokenization,lda,full,topics=100  n-grams:full,words,1-grams,tfidf  n-grams:full,words,1-grams,2-grams,tfidf  n-grams:tokenization,full,words,1-grams,tfidf  n-grams:tokenization,full,words,1-grams,2-grams,tfidf  n-grams:full,nouns,adjectives,1-grams  n-grams:linares_pontes,words,1-grams  \\\n",
       "0    100  1145                    0.484948                          0.503235                         0.263459                                 0.422335                                       0.478481                                      0.288674                   0.863608                   0.927264                                0.804840                                0.899720                           1.000000                            1.000000                                        0.985932                                         0.983500                           0.972852                            0.986386                                        0.956351                                     9.843608e-01                          1.000000                                  1.000000                                       1.000000                                           1.000000                                   1.000000                              1.000000   \n",
       "1    100  4114                    0.343207                          0.260014                         0.185656                                 0.260778                                       0.270105                                      0.180168                   0.936699                   0.963473                                0.915321                                0.957688                           0.999937                            1.000000                                        0.997800                                         0.984195                           0.848661                            0.988527                                        0.969091                                     9.845576e-01                          1.000000                                  1.000000                                       1.000000                                           1.000000                                   1.000000                              0.980422   \n",
       "2    100   231                    0.424650                          0.279231                         0.185035                                 0.296518                                       0.271672                                      0.188429                   0.888187                   0.921801                                1.000000                                1.000000                           0.824749                            0.978728                                        0.556710                                         0.931309                           0.668178                            0.980502                                        0.552669                                     9.768748e-01                          0.943099                                  0.972357                                       0.885369                                           0.931381                                   0.926808                              0.896132   \n",
       "3    100  5244                    0.515200                          0.602756                         0.363885                                 0.428738                                       0.607823                                      0.362408                   1.000000                   0.957448                                1.000000                                0.944979                           1.000000                            1.000000                                        0.999151                                         0.965712                           0.954950                            0.976779                                        0.950524                                     9.776629e-01                          1.000000                                  1.000000                                       1.000000                                           1.000000                                   1.000000                              1.000000   \n",
       "4    100   733                    0.527713                          0.270065                         0.181497                                 0.355785                                       0.293558                                      0.170425                   0.899698                   0.927390                                0.804250                                0.918117                           0.990412                            0.999971                                        0.999996                                         1.000000                           0.491172                            0.517408                                        0.958356                                     9.761760e-01                          1.000000                                  1.000000                                       1.000000                                           1.000000                                   1.000000                              0.877337   \n",
       "5    100  3896                    0.520128                          0.536171                         0.298879                                 0.399769                                       0.590710                                      0.391840                   0.973093                   0.970430                                0.971126                                0.966886                           0.981126                            0.913819                                        0.982271                                         1.000000                           0.967291                            0.983562                                        0.959602                                     9.657815e-01                          1.000000                                  1.000000                                       1.000000                                           1.000000                                   1.000000                              1.000000   \n",
       "6    100  4572                    0.490884                          0.326860                         0.179187                                 0.310596                                       0.341777                                      0.209361                   0.956777                   0.928798                                0.939667                                0.925504                           1.000000                            0.973819                                        0.910472                                         0.965566                           0.965742                            0.985249                                        0.941665                                     9.777083e-01                          1.000000                                  1.000000                                       1.000000                                           1.000000                                   1.000000                              0.916390   \n",
       "7    100  2823                    0.547941                          0.272979                         0.187657                                 0.279518                                       0.278486                                      0.199103                   0.893427                   0.902922                                1.000000                                0.889492                           0.981633                            0.978047                                        0.325492                                         0.707005                           0.970948                            0.940419                                        0.560160                                     7.171545e-01                          1.000000                                  1.000000                                       1.000000                                           1.000000                                   1.000000                              0.974706   \n",
       "8    100  1592                    0.448422                          0.438724                         0.198668                                 0.320943                                       0.365019                                      0.222920                   0.904967                   0.925881                                1.000000                                0.906443                           1.000000                            1.000000                                        0.998446                                         1.000000                           0.969069                            0.988745                                        0.959906                                     9.800199e-01                          1.000000                                  1.000000                                       1.000000                                           1.000000                                   1.000000                              0.951814   \n",
       "9    100  1185                    0.450585                          0.197340                         0.151455                                 0.301088                                       0.232980                                      0.155569                   0.909111                   0.919647                                0.666356                                0.911593                           0.998078                            0.999591                                        0.828320                                         0.981882                           0.855693                            0.859678                                        0.944414                                     8.544685e-07                          0.977251                                  0.989587                                       0.894892                                           0.957043                                   1.000000                              0.878630   \n",
       "10   100   883                    0.448113                          0.601558                         0.872109                                 0.347916                                       0.597342                                      0.807199                   0.851351                   0.933871                                0.804250                                0.924255                           0.999982                            0.999745                                        1.000000                                         1.000000                           0.955775                            0.983743                                        0.948569                                     9.771114e-01                          1.000000                                  1.000000                                       1.000000                                           1.000000                                   1.000000                              1.000000   \n",
       "11   100  2456                    0.526467                          0.186860                         0.160455                                 0.183519                                       0.194339                                      0.160468                   0.891434                   0.870208                                0.648624                                0.670109                           0.753885                            0.503019                                        0.635399                                         0.461174                           0.375986                            0.697940                                        0.903339                                     9.784185e-01                          0.896217                                  0.943120                                       0.815489                                           0.913688                                   0.894577                              0.800705   \n",
       "12   100  5326                    0.504994                          0.380940                         0.186081                                 0.370751                                       0.426500                                      0.226843                   0.899571                   0.758539                                0.825243                                0.529266                           0.829671                            0.994074                                        0.741820                                         0.705662                           0.969831                            0.849728                                        0.951450                                     9.775284e-01                          0.928885                                  0.974094                                       0.856851                                           0.946249                                   0.912354                              0.921801   \n",
       "13   100  1389                    0.457299                          0.173582                         0.152193                                 0.191585                                       0.158163                                      0.123656                   0.703391                   0.821117                                0.152634                                0.391795                           0.576416                            0.638776                                        0.226166                                         0.145849                           0.320535                            0.889780                                        0.051062                                     8.100848e-02                          0.823537                                  0.892493                                       0.285404                                           0.516267                                   0.857341                              0.760775   \n",
       "14   100  5153                    0.503643                          0.255375                         0.205944                                 0.346032                                       0.248265                                      0.204870                   0.917486                   0.947452                                0.725425                                0.938016                           1.000000                            0.999361                                        0.987637                                         0.967503                           0.630591                            0.802153                                        0.957659                                     9.760884e-01                          1.000000                                  1.000000                                       1.000000                                           1.000000                                   1.000000                              0.888076   \n",
       "15   100  1975                    0.529565                          0.246333                         0.155104                                 0.356367                                       0.262292                                      0.171215                   0.872809                   0.842285                                1.000000                                1.000000                           0.979756                            0.994504                                        1.000000                                         1.000000                           0.505226                            0.750124                                        0.552988                                     7.964698e-01                          0.979904                                  0.989253                                       1.000000                                           1.000000                                   0.967475                              0.882543   \n",
       "16   100   705                    0.391949                          0.466228                         0.296158                                 0.340712                                       0.485242                                      0.402482                   0.777286                   0.938553                                0.700433                                0.921546                           1.000000                            1.000000                                        0.999601                                         0.964791                           0.394490                            0.975265                                        0.948569                                     9.771114e-01                          1.000000                                  1.000000                                       1.000000                                           1.000000                                   1.000000                              1.000000   \n",
       "17   100  2465                    0.407431                          0.496899                         0.300016                                 0.338256                                       0.486943                                      0.300016                   0.939606                   0.967033                                0.921855                                0.955799                           1.000000                            1.000000                                        1.000000                                         1.000000                           0.967520                            0.983678                                        0.964821                                     9.842812e-01                          1.000000                                  1.000000                                       1.000000                                           1.000000                                   1.000000                              0.963409   \n",
       "18   100  4826                    0.455823                          0.314752                         0.164622                                 0.298948                                       0.263800                                      0.141633                   0.868833                   0.827422                                1.000000                                0.704945                           0.778416                            0.529429                                        0.568717                                         0.500489                           0.689703                            0.615027                                        0.946773                                     7.259718e-01                          0.909810                                  0.955494                                       0.800127                                           0.918973                                   0.922813                              0.851006   \n",
       "19   100  4361                    0.236921                          0.156215                         0.192543                                 0.194459                                       0.221758                                      0.182364                   0.799354                   0.826339                                0.736696                                0.807197                           0.676978                            0.620543                                        0.594695                                         0.702814                           0.466917                            0.988845                                        0.955315                                     9.816395e-01                          0.869828                                  0.948150                                       0.836308                                           0.936795                                   0.805897                              0.713648   \n",
       "\n",
       "    n-grams:full,precise_annotations,words,1-grams  n-grams:full,partial_annotations,words,1-grams  n-grams:full,plant overrepresented tokens,1-grams  n-grams:full,bio ontology tokens,1-grams  n-grams:tokenization,full,nouns,adjectives,1-grams  n-grams:tokenization,linares_pontes,words,1-grams  n-grams:tokenization,full,precise_annotations,words,1-grams  n-grams:tokenization,full,partial_annotations,words,1-grams  n-grams:tokenization,full,plant overrepresented tokens,1-grams  n-grams:tokenization,full,bio ontology tokens,1-grams  go:union  po:union  go:minimum  po:minimum      mean   same  pathways  kegg_only  pmn_only  subsets  \n",
       "0                                         0.840402                                        0.568991                                           1.000000                                  1.000000                                           1.000000                                            1.000000                                           0.591617                                                     0.432781                                                     1.000000                                                        1.000000      1.000000  0.199791    1.000000    0.646186  0.696545  False        -1         -1        -1       -1  \n",
       "1                                         0.812361                                        0.422756                                           1.000000                                  1.000000                                           1.000000                                            0.980264                                           0.748194                                                     0.437357                                                     1.000000                                                        1.000000      1.000000  1.000000    1.000000    1.000000  0.637134   True        -1         -1        -1       -1  \n",
       "2                                         0.560416                                        0.496319                                           0.943099                                  0.928882                                           0.813392                                            0.868671                                           0.387241                                                     0.423178                                                     0.885369                                                        0.858600      0.240786  0.097509    0.906796    0.000000  0.385529   True        -1         -1        -1        0  \n",
       "3                                         1.000000                                        0.978017                                           1.000000                                  1.000000                                           1.000000                                            1.000000                                           1.000000                                                     0.897769                                                     1.000000                                                        1.000000      0.367580  0.108020    0.690276    0.474998  0.770669   True        -1         -1        -1       -1  \n",
       "4                                         0.810659                                        0.297326                                           1.000000                                  1.000000                                           1.000000                                            0.866671                                           0.604588                                                     0.252735                                                     1.000000                                                        1.000000      0.202688  0.089205    0.690276    0.000000  0.576333   True        -1         -1        -1        0  \n",
       "5                                         0.921055                                        0.329352                                           1.000000                                  1.000000                                           1.000000                                            1.000000                                           0.847789                                                     0.309230                                                     1.000000                                                        1.000000      1.000000  1.000000    1.000000    1.000000  0.704863  False        -1         -1        -1       -1  \n",
       "6                                         0.740565                                        0.356273                                           1.000000                                  1.000000                                           1.000000                                            0.897864                                           0.598539                                                     0.266433                                                     1.000000                                                        1.000000      0.622213  0.110242    0.956128    0.474998  0.595887   True        -1         -1        -1       -1  \n",
       "7                                         0.741642                                        0.258536                                           1.000000                                  1.000000                                           1.000000                                            0.949664                                           0.555684                                                     0.233350                                                     1.000000                                                        1.000000      1.000000  1.000000    1.000000    1.000000  0.528961  False        -1         -1        -1       -1  \n",
       "8                                         0.827605                                        0.342629                                           1.000000                                  1.000000                                           1.000000                                            0.900542                                           0.732674                                                     0.251352                                                     1.000000                                                        1.000000      0.229783  0.093575    0.484877    0.000000  0.663482   True        -1         -1        -1        0  \n",
       "9                                         0.720393                                        0.329431                                           0.976848                                  1.000000                                           1.000000                                            0.839561                                           0.424285                                                     0.281615                                                     0.873610                                                        1.000000      0.218605  0.217137    0.897383    0.539171  0.429050   True        -1         -1        -1        0  \n",
       "10                                        0.898833                                        0.295495                                           1.000000                                  1.000000                                           1.000000                                            1.000000                                           0.717540                                                     0.252735                                                     1.000000                                                        1.000000      0.323868  0.102040    0.922758    0.000000  0.690772   True        -1         -1        -1        0  \n",
       "11                                        0.662550                                        0.281065                                           0.889426                                  0.875277                                           0.711187                                            0.781553                                           0.329352                                                     0.220122                                                     0.815489                                                        0.794061      0.160622  0.094031    0.000000    0.000000  0.255310   True        -1         -1        -1        1  \n",
       "12                                        0.722733                                        0.269533                                           0.924850                                  0.918991                                           0.834325                                            0.844364                                           0.630280                                                     0.219975                                                     0.830025                                                        0.817266      1.000000  0.143986    1.000000    0.000000  0.398353   True        -1         -1        -1       -1  \n",
       "13                                        0.556267                                        0.266762                                           0.817845                                  0.790950                                           0.375810                                            0.254872                                           0.127706                                                     0.116814                                                     0.285404                                                        0.202417      0.152070  0.101173    0.561758    0.000000  0.114008   True        -1         -1        -1        1  \n",
       "14                                        0.671056                                        0.357490                                           1.000000                                  1.000000                                           1.000000                                            0.889625                                           0.508440                                                     0.312266                                                     1.000000                                                        1.000000      0.244869  0.099229    0.895382    0.000000  0.573919   True        -1         -1        -1       -1  \n",
       "15                                        0.683351                                        0.322125                                           0.979160                                  0.971694                                           1.000000                                            1.000000                                           1.000000                                                     1.000000                                                     1.000000                                                        1.000000      0.200952  0.100981    0.843244    0.000000  0.533735   True        -1         -1        -1        0  \n",
       "16                                        0.744874                                        0.291440                                           1.000000                                  1.000000                                           1.000000                                            1.000000                                           0.501246                                                     0.252735                                                     1.000000                                                        1.000000      0.176255  0.100868    0.696727    0.000000  0.619199   True        -1         -1        -1        0  \n",
       "17                                        0.895578                                        0.982281                                           1.000000                                  1.000000                                           1.000000                                            0.950474                                           0.834275                                                     0.862028                                                     1.000000                                                        1.000000      0.258714  0.100062    0.920747    0.000000  0.731418   True        -1         -1        -1        0  \n",
       "18                                        0.652218                                        0.241316                                           0.902508                                  0.881335                                           0.824919                                            0.738324                                           0.517975                                                     0.190031                                                     0.800127                                                        0.776915      0.211602  0.100722    0.927618    0.000000  0.280085   True        -1         -1        -1       -1  \n",
       "19                                        0.581492                                        0.327424                                           0.869828                                  0.851196                                           0.745715                                            0.583339                                           0.381752                                                     0.279292                                                     0.836308                                                        0.817298      0.255507  0.100667    0.308610    0.000000  0.261065   True        -1         -1        -1       -1  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add a column that indicates whether or not both genes of the pair are mapped to a phenotype classification.\n",
    "relevant_ids = set(subsets_mapped_ids)\n",
    "df[\"from_is_valid\"] = df[\"from\"].map(lambda x: x in relevant_ids)\n",
    "df[\"to_is_valid\"] = df[\"to\"].map(lambda x: x in relevant_ids)\n",
    "df[\"pair_is_valid\"] = df[\"from_is_valid\"]*df[\"to_is_valid\"]\n",
    "\n",
    "# Add a column giving the actual target output value for this biological task, with -1 for the irrelevant rows.\n",
    "df[\"subsets\"] = -1\n",
    "id_to_group_ids,_ = phe_subsets_groups.get_groupings_for_dataset(dataset)\n",
    "df.loc[(df[\"pair_is_valid\"]==True),\"subsets\"] = df[[\"from\",\"to\"]].apply(lambda x: len(set(id_to_group_ids[x[\"from\"]]).intersection(set(id_to_group_ids[x[\"to\"]])))>0, axis=1)*1\n",
    "df.drop(labels=[\"from_is_valid\",\"to_is_valid\", \"pair_is_valid\"], axis=\"columns\", inplace=True)\n",
    "\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"association_objective\"></a>\n",
    "### Using protein assocations (STRING) as the objective "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>from</th>\n",
       "      <th>to</th>\n",
       "      <th>doc2vec:wikipedia,size=300</th>\n",
       "      <th>word2vec:wikipedia,size=300,mean</th>\n",
       "      <th>word2vec:wikipedia,size=300,max</th>\n",
       "      <th>doc2vec:tokenization,wikipedia,size=300</th>\n",
       "      <th>word2vec:tokenization,wikipedia,size=300,mean</th>\n",
       "      <th>word2vec:tokenization,wikipedia,size=300,max</th>\n",
       "      <th>noble coder:precise,tfidf</th>\n",
       "      <th>noble coder:partial,tfidf</th>\n",
       "      <th>noble coder:tokenization,precise,tfidf</th>\n",
       "      <th>noble coder:tokenization,partial,tfidf</th>\n",
       "      <th>topic modeling:nmf,full,topics=50</th>\n",
       "      <th>topic modeling:nmf,full,topics=100</th>\n",
       "      <th>topic modeling:tokenization,nmf,full,topics=50</th>\n",
       "      <th>topic modeling:tokenization,nmf,full,topics=100</th>\n",
       "      <th>topic modeling:lda,full,topics=50</th>\n",
       "      <th>topic modeling:lda,full,topics=100</th>\n",
       "      <th>topic modeling:tokenization,lda,full,topics=50</th>\n",
       "      <th>topic modeling:tokenization,lda,full,topics=100</th>\n",
       "      <th>n-grams:full,words,1-grams,tfidf</th>\n",
       "      <th>n-grams:full,words,1-grams,2-grams,tfidf</th>\n",
       "      <th>n-grams:tokenization,full,words,1-grams,tfidf</th>\n",
       "      <th>n-grams:tokenization,full,words,1-grams,2-grams,tfidf</th>\n",
       "      <th>n-grams:full,nouns,adjectives,1-grams</th>\n",
       "      <th>n-grams:linares_pontes,words,1-grams</th>\n",
       "      <th>n-grams:full,precise_annotations,words,1-grams</th>\n",
       "      <th>n-grams:full,partial_annotations,words,1-grams</th>\n",
       "      <th>n-grams:full,plant overrepresented tokens,1-grams</th>\n",
       "      <th>n-grams:full,bio ontology tokens,1-grams</th>\n",
       "      <th>n-grams:tokenization,full,nouns,adjectives,1-grams</th>\n",
       "      <th>n-grams:tokenization,linares_pontes,words,1-grams</th>\n",
       "      <th>n-grams:tokenization,full,precise_annotations,words,1-grams</th>\n",
       "      <th>n-grams:tokenization,full,partial_annotations,words,1-grams</th>\n",
       "      <th>n-grams:tokenization,full,plant overrepresented tokens,1-grams</th>\n",
       "      <th>n-grams:tokenization,full,bio ontology tokens,1-grams</th>\n",
       "      <th>go:union</th>\n",
       "      <th>po:union</th>\n",
       "      <th>go:minimum</th>\n",
       "      <th>po:minimum</th>\n",
       "      <th>mean</th>\n",
       "      <th>same</th>\n",
       "      <th>pathways</th>\n",
       "      <th>kegg_only</th>\n",
       "      <th>pmn_only</th>\n",
       "      <th>subsets</th>\n",
       "      <th>known</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>1145</td>\n",
       "      <td>0.484948</td>\n",
       "      <td>0.503235</td>\n",
       "      <td>0.263459</td>\n",
       "      <td>0.422335</td>\n",
       "      <td>0.478481</td>\n",
       "      <td>0.288674</td>\n",
       "      <td>0.863608</td>\n",
       "      <td>0.927264</td>\n",
       "      <td>0.804840</td>\n",
       "      <td>0.899720</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.985932</td>\n",
       "      <td>0.983500</td>\n",
       "      <td>0.972852</td>\n",
       "      <td>0.986386</td>\n",
       "      <td>0.956351</td>\n",
       "      <td>9.843608e-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.840402</td>\n",
       "      <td>0.568991</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.591617</td>\n",
       "      <td>0.432781</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.199791</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.646186</td>\n",
       "      <td>0.696545</td>\n",
       "      <td>False</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100</td>\n",
       "      <td>4114</td>\n",
       "      <td>0.343207</td>\n",
       "      <td>0.260014</td>\n",
       "      <td>0.185656</td>\n",
       "      <td>0.260778</td>\n",
       "      <td>0.270105</td>\n",
       "      <td>0.180168</td>\n",
       "      <td>0.936699</td>\n",
       "      <td>0.963473</td>\n",
       "      <td>0.915321</td>\n",
       "      <td>0.957688</td>\n",
       "      <td>0.999937</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.997800</td>\n",
       "      <td>0.984195</td>\n",
       "      <td>0.848661</td>\n",
       "      <td>0.988527</td>\n",
       "      <td>0.969091</td>\n",
       "      <td>9.845576e-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.980422</td>\n",
       "      <td>0.812361</td>\n",
       "      <td>0.422756</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.980264</td>\n",
       "      <td>0.748194</td>\n",
       "      <td>0.437357</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.637134</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>231</td>\n",
       "      <td>0.424650</td>\n",
       "      <td>0.279231</td>\n",
       "      <td>0.185035</td>\n",
       "      <td>0.296518</td>\n",
       "      <td>0.271672</td>\n",
       "      <td>0.188429</td>\n",
       "      <td>0.888187</td>\n",
       "      <td>0.921801</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.824749</td>\n",
       "      <td>0.978728</td>\n",
       "      <td>0.556710</td>\n",
       "      <td>0.931309</td>\n",
       "      <td>0.668178</td>\n",
       "      <td>0.980502</td>\n",
       "      <td>0.552669</td>\n",
       "      <td>9.768748e-01</td>\n",
       "      <td>0.943099</td>\n",
       "      <td>0.972357</td>\n",
       "      <td>0.885369</td>\n",
       "      <td>0.931381</td>\n",
       "      <td>0.926808</td>\n",
       "      <td>0.896132</td>\n",
       "      <td>0.560416</td>\n",
       "      <td>0.496319</td>\n",
       "      <td>0.943099</td>\n",
       "      <td>0.928882</td>\n",
       "      <td>0.813392</td>\n",
       "      <td>0.868671</td>\n",
       "      <td>0.387241</td>\n",
       "      <td>0.423178</td>\n",
       "      <td>0.885369</td>\n",
       "      <td>0.858600</td>\n",
       "      <td>0.240786</td>\n",
       "      <td>0.097509</td>\n",
       "      <td>0.906796</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.385529</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100</td>\n",
       "      <td>5244</td>\n",
       "      <td>0.515200</td>\n",
       "      <td>0.602756</td>\n",
       "      <td>0.363885</td>\n",
       "      <td>0.428738</td>\n",
       "      <td>0.607823</td>\n",
       "      <td>0.362408</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.957448</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.944979</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999151</td>\n",
       "      <td>0.965712</td>\n",
       "      <td>0.954950</td>\n",
       "      <td>0.976779</td>\n",
       "      <td>0.950524</td>\n",
       "      <td>9.776629e-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.978017</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.897769</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.367580</td>\n",
       "      <td>0.108020</td>\n",
       "      <td>0.690276</td>\n",
       "      <td>0.474998</td>\n",
       "      <td>0.770669</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100</td>\n",
       "      <td>733</td>\n",
       "      <td>0.527713</td>\n",
       "      <td>0.270065</td>\n",
       "      <td>0.181497</td>\n",
       "      <td>0.355785</td>\n",
       "      <td>0.293558</td>\n",
       "      <td>0.170425</td>\n",
       "      <td>0.899698</td>\n",
       "      <td>0.927390</td>\n",
       "      <td>0.804250</td>\n",
       "      <td>0.918117</td>\n",
       "      <td>0.990412</td>\n",
       "      <td>0.999971</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.491172</td>\n",
       "      <td>0.517408</td>\n",
       "      <td>0.958356</td>\n",
       "      <td>9.761760e-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.877337</td>\n",
       "      <td>0.810659</td>\n",
       "      <td>0.297326</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.866671</td>\n",
       "      <td>0.604588</td>\n",
       "      <td>0.252735</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.202688</td>\n",
       "      <td>0.089205</td>\n",
       "      <td>0.690276</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.576333</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>100</td>\n",
       "      <td>3896</td>\n",
       "      <td>0.520128</td>\n",
       "      <td>0.536171</td>\n",
       "      <td>0.298879</td>\n",
       "      <td>0.399769</td>\n",
       "      <td>0.590710</td>\n",
       "      <td>0.391840</td>\n",
       "      <td>0.973093</td>\n",
       "      <td>0.970430</td>\n",
       "      <td>0.971126</td>\n",
       "      <td>0.966886</td>\n",
       "      <td>0.981126</td>\n",
       "      <td>0.913819</td>\n",
       "      <td>0.982271</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.967291</td>\n",
       "      <td>0.983562</td>\n",
       "      <td>0.959602</td>\n",
       "      <td>9.657815e-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.921055</td>\n",
       "      <td>0.329352</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.847789</td>\n",
       "      <td>0.309230</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.704863</td>\n",
       "      <td>False</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>100</td>\n",
       "      <td>4572</td>\n",
       "      <td>0.490884</td>\n",
       "      <td>0.326860</td>\n",
       "      <td>0.179187</td>\n",
       "      <td>0.310596</td>\n",
       "      <td>0.341777</td>\n",
       "      <td>0.209361</td>\n",
       "      <td>0.956777</td>\n",
       "      <td>0.928798</td>\n",
       "      <td>0.939667</td>\n",
       "      <td>0.925504</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.973819</td>\n",
       "      <td>0.910472</td>\n",
       "      <td>0.965566</td>\n",
       "      <td>0.965742</td>\n",
       "      <td>0.985249</td>\n",
       "      <td>0.941665</td>\n",
       "      <td>9.777083e-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.916390</td>\n",
       "      <td>0.740565</td>\n",
       "      <td>0.356273</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.897864</td>\n",
       "      <td>0.598539</td>\n",
       "      <td>0.266433</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.622213</td>\n",
       "      <td>0.110242</td>\n",
       "      <td>0.956128</td>\n",
       "      <td>0.474998</td>\n",
       "      <td>0.595887</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>100</td>\n",
       "      <td>2823</td>\n",
       "      <td>0.547941</td>\n",
       "      <td>0.272979</td>\n",
       "      <td>0.187657</td>\n",
       "      <td>0.279518</td>\n",
       "      <td>0.278486</td>\n",
       "      <td>0.199103</td>\n",
       "      <td>0.893427</td>\n",
       "      <td>0.902922</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.889492</td>\n",
       "      <td>0.981633</td>\n",
       "      <td>0.978047</td>\n",
       "      <td>0.325492</td>\n",
       "      <td>0.707005</td>\n",
       "      <td>0.970948</td>\n",
       "      <td>0.940419</td>\n",
       "      <td>0.560160</td>\n",
       "      <td>7.171545e-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.974706</td>\n",
       "      <td>0.741642</td>\n",
       "      <td>0.258536</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.949664</td>\n",
       "      <td>0.555684</td>\n",
       "      <td>0.233350</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.528961</td>\n",
       "      <td>False</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>100</td>\n",
       "      <td>1592</td>\n",
       "      <td>0.448422</td>\n",
       "      <td>0.438724</td>\n",
       "      <td>0.198668</td>\n",
       "      <td>0.320943</td>\n",
       "      <td>0.365019</td>\n",
       "      <td>0.222920</td>\n",
       "      <td>0.904967</td>\n",
       "      <td>0.925881</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.906443</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998446</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.969069</td>\n",
       "      <td>0.988745</td>\n",
       "      <td>0.959906</td>\n",
       "      <td>9.800199e-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.951814</td>\n",
       "      <td>0.827605</td>\n",
       "      <td>0.342629</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.900542</td>\n",
       "      <td>0.732674</td>\n",
       "      <td>0.251352</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.229783</td>\n",
       "      <td>0.093575</td>\n",
       "      <td>0.484877</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.663482</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>100</td>\n",
       "      <td>1185</td>\n",
       "      <td>0.450585</td>\n",
       "      <td>0.197340</td>\n",
       "      <td>0.151455</td>\n",
       "      <td>0.301088</td>\n",
       "      <td>0.232980</td>\n",
       "      <td>0.155569</td>\n",
       "      <td>0.909111</td>\n",
       "      <td>0.919647</td>\n",
       "      <td>0.666356</td>\n",
       "      <td>0.911593</td>\n",
       "      <td>0.998078</td>\n",
       "      <td>0.999591</td>\n",
       "      <td>0.828320</td>\n",
       "      <td>0.981882</td>\n",
       "      <td>0.855693</td>\n",
       "      <td>0.859678</td>\n",
       "      <td>0.944414</td>\n",
       "      <td>8.544685e-07</td>\n",
       "      <td>0.977251</td>\n",
       "      <td>0.989587</td>\n",
       "      <td>0.894892</td>\n",
       "      <td>0.957043</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.878630</td>\n",
       "      <td>0.720393</td>\n",
       "      <td>0.329431</td>\n",
       "      <td>0.976848</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.839561</td>\n",
       "      <td>0.424285</td>\n",
       "      <td>0.281615</td>\n",
       "      <td>0.873610</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.218605</td>\n",
       "      <td>0.217137</td>\n",
       "      <td>0.897383</td>\n",
       "      <td>0.539171</td>\n",
       "      <td>0.429050</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>100</td>\n",
       "      <td>883</td>\n",
       "      <td>0.448113</td>\n",
       "      <td>0.601558</td>\n",
       "      <td>0.872109</td>\n",
       "      <td>0.347916</td>\n",
       "      <td>0.597342</td>\n",
       "      <td>0.807199</td>\n",
       "      <td>0.851351</td>\n",
       "      <td>0.933871</td>\n",
       "      <td>0.804250</td>\n",
       "      <td>0.924255</td>\n",
       "      <td>0.999982</td>\n",
       "      <td>0.999745</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.955775</td>\n",
       "      <td>0.983743</td>\n",
       "      <td>0.948569</td>\n",
       "      <td>9.771114e-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.898833</td>\n",
       "      <td>0.295495</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.717540</td>\n",
       "      <td>0.252735</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.323868</td>\n",
       "      <td>0.102040</td>\n",
       "      <td>0.922758</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.690772</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>100</td>\n",
       "      <td>2456</td>\n",
       "      <td>0.526467</td>\n",
       "      <td>0.186860</td>\n",
       "      <td>0.160455</td>\n",
       "      <td>0.183519</td>\n",
       "      <td>0.194339</td>\n",
       "      <td>0.160468</td>\n",
       "      <td>0.891434</td>\n",
       "      <td>0.870208</td>\n",
       "      <td>0.648624</td>\n",
       "      <td>0.670109</td>\n",
       "      <td>0.753885</td>\n",
       "      <td>0.503019</td>\n",
       "      <td>0.635399</td>\n",
       "      <td>0.461174</td>\n",
       "      <td>0.375986</td>\n",
       "      <td>0.697940</td>\n",
       "      <td>0.903339</td>\n",
       "      <td>9.784185e-01</td>\n",
       "      <td>0.896217</td>\n",
       "      <td>0.943120</td>\n",
       "      <td>0.815489</td>\n",
       "      <td>0.913688</td>\n",
       "      <td>0.894577</td>\n",
       "      <td>0.800705</td>\n",
       "      <td>0.662550</td>\n",
       "      <td>0.281065</td>\n",
       "      <td>0.889426</td>\n",
       "      <td>0.875277</td>\n",
       "      <td>0.711187</td>\n",
       "      <td>0.781553</td>\n",
       "      <td>0.329352</td>\n",
       "      <td>0.220122</td>\n",
       "      <td>0.815489</td>\n",
       "      <td>0.794061</td>\n",
       "      <td>0.160622</td>\n",
       "      <td>0.094031</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.255310</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>100</td>\n",
       "      <td>5326</td>\n",
       "      <td>0.504994</td>\n",
       "      <td>0.380940</td>\n",
       "      <td>0.186081</td>\n",
       "      <td>0.370751</td>\n",
       "      <td>0.426500</td>\n",
       "      <td>0.226843</td>\n",
       "      <td>0.899571</td>\n",
       "      <td>0.758539</td>\n",
       "      <td>0.825243</td>\n",
       "      <td>0.529266</td>\n",
       "      <td>0.829671</td>\n",
       "      <td>0.994074</td>\n",
       "      <td>0.741820</td>\n",
       "      <td>0.705662</td>\n",
       "      <td>0.969831</td>\n",
       "      <td>0.849728</td>\n",
       "      <td>0.951450</td>\n",
       "      <td>9.775284e-01</td>\n",
       "      <td>0.928885</td>\n",
       "      <td>0.974094</td>\n",
       "      <td>0.856851</td>\n",
       "      <td>0.946249</td>\n",
       "      <td>0.912354</td>\n",
       "      <td>0.921801</td>\n",
       "      <td>0.722733</td>\n",
       "      <td>0.269533</td>\n",
       "      <td>0.924850</td>\n",
       "      <td>0.918991</td>\n",
       "      <td>0.834325</td>\n",
       "      <td>0.844364</td>\n",
       "      <td>0.630280</td>\n",
       "      <td>0.219975</td>\n",
       "      <td>0.830025</td>\n",
       "      <td>0.817266</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.143986</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.398353</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>100</td>\n",
       "      <td>1389</td>\n",
       "      <td>0.457299</td>\n",
       "      <td>0.173582</td>\n",
       "      <td>0.152193</td>\n",
       "      <td>0.191585</td>\n",
       "      <td>0.158163</td>\n",
       "      <td>0.123656</td>\n",
       "      <td>0.703391</td>\n",
       "      <td>0.821117</td>\n",
       "      <td>0.152634</td>\n",
       "      <td>0.391795</td>\n",
       "      <td>0.576416</td>\n",
       "      <td>0.638776</td>\n",
       "      <td>0.226166</td>\n",
       "      <td>0.145849</td>\n",
       "      <td>0.320535</td>\n",
       "      <td>0.889780</td>\n",
       "      <td>0.051062</td>\n",
       "      <td>8.100848e-02</td>\n",
       "      <td>0.823537</td>\n",
       "      <td>0.892493</td>\n",
       "      <td>0.285404</td>\n",
       "      <td>0.516267</td>\n",
       "      <td>0.857341</td>\n",
       "      <td>0.760775</td>\n",
       "      <td>0.556267</td>\n",
       "      <td>0.266762</td>\n",
       "      <td>0.817845</td>\n",
       "      <td>0.790950</td>\n",
       "      <td>0.375810</td>\n",
       "      <td>0.254872</td>\n",
       "      <td>0.127706</td>\n",
       "      <td>0.116814</td>\n",
       "      <td>0.285404</td>\n",
       "      <td>0.202417</td>\n",
       "      <td>0.152070</td>\n",
       "      <td>0.101173</td>\n",
       "      <td>0.561758</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.114008</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>100</td>\n",
       "      <td>5153</td>\n",
       "      <td>0.503643</td>\n",
       "      <td>0.255375</td>\n",
       "      <td>0.205944</td>\n",
       "      <td>0.346032</td>\n",
       "      <td>0.248265</td>\n",
       "      <td>0.204870</td>\n",
       "      <td>0.917486</td>\n",
       "      <td>0.947452</td>\n",
       "      <td>0.725425</td>\n",
       "      <td>0.938016</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999361</td>\n",
       "      <td>0.987637</td>\n",
       "      <td>0.967503</td>\n",
       "      <td>0.630591</td>\n",
       "      <td>0.802153</td>\n",
       "      <td>0.957659</td>\n",
       "      <td>9.760884e-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.888076</td>\n",
       "      <td>0.671056</td>\n",
       "      <td>0.357490</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.889625</td>\n",
       "      <td>0.508440</td>\n",
       "      <td>0.312266</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.244869</td>\n",
       "      <td>0.099229</td>\n",
       "      <td>0.895382</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.573919</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>100</td>\n",
       "      <td>1975</td>\n",
       "      <td>0.529565</td>\n",
       "      <td>0.246333</td>\n",
       "      <td>0.155104</td>\n",
       "      <td>0.356367</td>\n",
       "      <td>0.262292</td>\n",
       "      <td>0.171215</td>\n",
       "      <td>0.872809</td>\n",
       "      <td>0.842285</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.979756</td>\n",
       "      <td>0.994504</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.505226</td>\n",
       "      <td>0.750124</td>\n",
       "      <td>0.552988</td>\n",
       "      <td>7.964698e-01</td>\n",
       "      <td>0.979904</td>\n",
       "      <td>0.989253</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.967475</td>\n",
       "      <td>0.882543</td>\n",
       "      <td>0.683351</td>\n",
       "      <td>0.322125</td>\n",
       "      <td>0.979160</td>\n",
       "      <td>0.971694</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.200952</td>\n",
       "      <td>0.100981</td>\n",
       "      <td>0.843244</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.533735</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>100</td>\n",
       "      <td>705</td>\n",
       "      <td>0.391949</td>\n",
       "      <td>0.466228</td>\n",
       "      <td>0.296158</td>\n",
       "      <td>0.340712</td>\n",
       "      <td>0.485242</td>\n",
       "      <td>0.402482</td>\n",
       "      <td>0.777286</td>\n",
       "      <td>0.938553</td>\n",
       "      <td>0.700433</td>\n",
       "      <td>0.921546</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999601</td>\n",
       "      <td>0.964791</td>\n",
       "      <td>0.394490</td>\n",
       "      <td>0.975265</td>\n",
       "      <td>0.948569</td>\n",
       "      <td>9.771114e-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.744874</td>\n",
       "      <td>0.291440</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.501246</td>\n",
       "      <td>0.252735</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.176255</td>\n",
       "      <td>0.100868</td>\n",
       "      <td>0.696727</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.619199</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>100</td>\n",
       "      <td>2465</td>\n",
       "      <td>0.407431</td>\n",
       "      <td>0.496899</td>\n",
       "      <td>0.300016</td>\n",
       "      <td>0.338256</td>\n",
       "      <td>0.486943</td>\n",
       "      <td>0.300016</td>\n",
       "      <td>0.939606</td>\n",
       "      <td>0.967033</td>\n",
       "      <td>0.921855</td>\n",
       "      <td>0.955799</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.967520</td>\n",
       "      <td>0.983678</td>\n",
       "      <td>0.964821</td>\n",
       "      <td>9.842812e-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.963409</td>\n",
       "      <td>0.895578</td>\n",
       "      <td>0.982281</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.950474</td>\n",
       "      <td>0.834275</td>\n",
       "      <td>0.862028</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.258714</td>\n",
       "      <td>0.100062</td>\n",
       "      <td>0.920747</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.731418</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>100</td>\n",
       "      <td>4826</td>\n",
       "      <td>0.455823</td>\n",
       "      <td>0.314752</td>\n",
       "      <td>0.164622</td>\n",
       "      <td>0.298948</td>\n",
       "      <td>0.263800</td>\n",
       "      <td>0.141633</td>\n",
       "      <td>0.868833</td>\n",
       "      <td>0.827422</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.704945</td>\n",
       "      <td>0.778416</td>\n",
       "      <td>0.529429</td>\n",
       "      <td>0.568717</td>\n",
       "      <td>0.500489</td>\n",
       "      <td>0.689703</td>\n",
       "      <td>0.615027</td>\n",
       "      <td>0.946773</td>\n",
       "      <td>7.259718e-01</td>\n",
       "      <td>0.909810</td>\n",
       "      <td>0.955494</td>\n",
       "      <td>0.800127</td>\n",
       "      <td>0.918973</td>\n",
       "      <td>0.922813</td>\n",
       "      <td>0.851006</td>\n",
       "      <td>0.652218</td>\n",
       "      <td>0.241316</td>\n",
       "      <td>0.902508</td>\n",
       "      <td>0.881335</td>\n",
       "      <td>0.824919</td>\n",
       "      <td>0.738324</td>\n",
       "      <td>0.517975</td>\n",
       "      <td>0.190031</td>\n",
       "      <td>0.800127</td>\n",
       "      <td>0.776915</td>\n",
       "      <td>0.211602</td>\n",
       "      <td>0.100722</td>\n",
       "      <td>0.927618</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.280085</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>100</td>\n",
       "      <td>4361</td>\n",
       "      <td>0.236921</td>\n",
       "      <td>0.156215</td>\n",
       "      <td>0.192543</td>\n",
       "      <td>0.194459</td>\n",
       "      <td>0.221758</td>\n",
       "      <td>0.182364</td>\n",
       "      <td>0.799354</td>\n",
       "      <td>0.826339</td>\n",
       "      <td>0.736696</td>\n",
       "      <td>0.807197</td>\n",
       "      <td>0.676978</td>\n",
       "      <td>0.620543</td>\n",
       "      <td>0.594695</td>\n",
       "      <td>0.702814</td>\n",
       "      <td>0.466917</td>\n",
       "      <td>0.988845</td>\n",
       "      <td>0.955315</td>\n",
       "      <td>9.816395e-01</td>\n",
       "      <td>0.869828</td>\n",
       "      <td>0.948150</td>\n",
       "      <td>0.836308</td>\n",
       "      <td>0.936795</td>\n",
       "      <td>0.805897</td>\n",
       "      <td>0.713648</td>\n",
       "      <td>0.581492</td>\n",
       "      <td>0.327424</td>\n",
       "      <td>0.869828</td>\n",
       "      <td>0.851196</td>\n",
       "      <td>0.745715</td>\n",
       "      <td>0.583339</td>\n",
       "      <td>0.381752</td>\n",
       "      <td>0.279292</td>\n",
       "      <td>0.836308</td>\n",
       "      <td>0.817298</td>\n",
       "      <td>0.255507</td>\n",
       "      <td>0.100667</td>\n",
       "      <td>0.308610</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.261065</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    from    to  doc2vec:wikipedia,size=300  word2vec:wikipedia,size=300,mean  word2vec:wikipedia,size=300,max  doc2vec:tokenization,wikipedia,size=300  word2vec:tokenization,wikipedia,size=300,mean  word2vec:tokenization,wikipedia,size=300,max  noble coder:precise,tfidf  noble coder:partial,tfidf  noble coder:tokenization,precise,tfidf  noble coder:tokenization,partial,tfidf  topic modeling:nmf,full,topics=50  topic modeling:nmf,full,topics=100  topic modeling:tokenization,nmf,full,topics=50  topic modeling:tokenization,nmf,full,topics=100  topic modeling:lda,full,topics=50  topic modeling:lda,full,topics=100  topic modeling:tokenization,lda,full,topics=50  topic modeling:tokenization,lda,full,topics=100  n-grams:full,words,1-grams,tfidf  n-grams:full,words,1-grams,2-grams,tfidf  n-grams:tokenization,full,words,1-grams,tfidf  n-grams:tokenization,full,words,1-grams,2-grams,tfidf  n-grams:full,nouns,adjectives,1-grams  n-grams:linares_pontes,words,1-grams  \\\n",
       "0    100  1145                    0.484948                          0.503235                         0.263459                                 0.422335                                       0.478481                                      0.288674                   0.863608                   0.927264                                0.804840                                0.899720                           1.000000                            1.000000                                        0.985932                                         0.983500                           0.972852                            0.986386                                        0.956351                                     9.843608e-01                          1.000000                                  1.000000                                       1.000000                                           1.000000                                   1.000000                              1.000000   \n",
       "1    100  4114                    0.343207                          0.260014                         0.185656                                 0.260778                                       0.270105                                      0.180168                   0.936699                   0.963473                                0.915321                                0.957688                           0.999937                            1.000000                                        0.997800                                         0.984195                           0.848661                            0.988527                                        0.969091                                     9.845576e-01                          1.000000                                  1.000000                                       1.000000                                           1.000000                                   1.000000                              0.980422   \n",
       "2    100   231                    0.424650                          0.279231                         0.185035                                 0.296518                                       0.271672                                      0.188429                   0.888187                   0.921801                                1.000000                                1.000000                           0.824749                            0.978728                                        0.556710                                         0.931309                           0.668178                            0.980502                                        0.552669                                     9.768748e-01                          0.943099                                  0.972357                                       0.885369                                           0.931381                                   0.926808                              0.896132   \n",
       "3    100  5244                    0.515200                          0.602756                         0.363885                                 0.428738                                       0.607823                                      0.362408                   1.000000                   0.957448                                1.000000                                0.944979                           1.000000                            1.000000                                        0.999151                                         0.965712                           0.954950                            0.976779                                        0.950524                                     9.776629e-01                          1.000000                                  1.000000                                       1.000000                                           1.000000                                   1.000000                              1.000000   \n",
       "4    100   733                    0.527713                          0.270065                         0.181497                                 0.355785                                       0.293558                                      0.170425                   0.899698                   0.927390                                0.804250                                0.918117                           0.990412                            0.999971                                        0.999996                                         1.000000                           0.491172                            0.517408                                        0.958356                                     9.761760e-01                          1.000000                                  1.000000                                       1.000000                                           1.000000                                   1.000000                              0.877337   \n",
       "5    100  3896                    0.520128                          0.536171                         0.298879                                 0.399769                                       0.590710                                      0.391840                   0.973093                   0.970430                                0.971126                                0.966886                           0.981126                            0.913819                                        0.982271                                         1.000000                           0.967291                            0.983562                                        0.959602                                     9.657815e-01                          1.000000                                  1.000000                                       1.000000                                           1.000000                                   1.000000                              1.000000   \n",
       "6    100  4572                    0.490884                          0.326860                         0.179187                                 0.310596                                       0.341777                                      0.209361                   0.956777                   0.928798                                0.939667                                0.925504                           1.000000                            0.973819                                        0.910472                                         0.965566                           0.965742                            0.985249                                        0.941665                                     9.777083e-01                          1.000000                                  1.000000                                       1.000000                                           1.000000                                   1.000000                              0.916390   \n",
       "7    100  2823                    0.547941                          0.272979                         0.187657                                 0.279518                                       0.278486                                      0.199103                   0.893427                   0.902922                                1.000000                                0.889492                           0.981633                            0.978047                                        0.325492                                         0.707005                           0.970948                            0.940419                                        0.560160                                     7.171545e-01                          1.000000                                  1.000000                                       1.000000                                           1.000000                                   1.000000                              0.974706   \n",
       "8    100  1592                    0.448422                          0.438724                         0.198668                                 0.320943                                       0.365019                                      0.222920                   0.904967                   0.925881                                1.000000                                0.906443                           1.000000                            1.000000                                        0.998446                                         1.000000                           0.969069                            0.988745                                        0.959906                                     9.800199e-01                          1.000000                                  1.000000                                       1.000000                                           1.000000                                   1.000000                              0.951814   \n",
       "9    100  1185                    0.450585                          0.197340                         0.151455                                 0.301088                                       0.232980                                      0.155569                   0.909111                   0.919647                                0.666356                                0.911593                           0.998078                            0.999591                                        0.828320                                         0.981882                           0.855693                            0.859678                                        0.944414                                     8.544685e-07                          0.977251                                  0.989587                                       0.894892                                           0.957043                                   1.000000                              0.878630   \n",
       "10   100   883                    0.448113                          0.601558                         0.872109                                 0.347916                                       0.597342                                      0.807199                   0.851351                   0.933871                                0.804250                                0.924255                           0.999982                            0.999745                                        1.000000                                         1.000000                           0.955775                            0.983743                                        0.948569                                     9.771114e-01                          1.000000                                  1.000000                                       1.000000                                           1.000000                                   1.000000                              1.000000   \n",
       "11   100  2456                    0.526467                          0.186860                         0.160455                                 0.183519                                       0.194339                                      0.160468                   0.891434                   0.870208                                0.648624                                0.670109                           0.753885                            0.503019                                        0.635399                                         0.461174                           0.375986                            0.697940                                        0.903339                                     9.784185e-01                          0.896217                                  0.943120                                       0.815489                                           0.913688                                   0.894577                              0.800705   \n",
       "12   100  5326                    0.504994                          0.380940                         0.186081                                 0.370751                                       0.426500                                      0.226843                   0.899571                   0.758539                                0.825243                                0.529266                           0.829671                            0.994074                                        0.741820                                         0.705662                           0.969831                            0.849728                                        0.951450                                     9.775284e-01                          0.928885                                  0.974094                                       0.856851                                           0.946249                                   0.912354                              0.921801   \n",
       "13   100  1389                    0.457299                          0.173582                         0.152193                                 0.191585                                       0.158163                                      0.123656                   0.703391                   0.821117                                0.152634                                0.391795                           0.576416                            0.638776                                        0.226166                                         0.145849                           0.320535                            0.889780                                        0.051062                                     8.100848e-02                          0.823537                                  0.892493                                       0.285404                                           0.516267                                   0.857341                              0.760775   \n",
       "14   100  5153                    0.503643                          0.255375                         0.205944                                 0.346032                                       0.248265                                      0.204870                   0.917486                   0.947452                                0.725425                                0.938016                           1.000000                            0.999361                                        0.987637                                         0.967503                           0.630591                            0.802153                                        0.957659                                     9.760884e-01                          1.000000                                  1.000000                                       1.000000                                           1.000000                                   1.000000                              0.888076   \n",
       "15   100  1975                    0.529565                          0.246333                         0.155104                                 0.356367                                       0.262292                                      0.171215                   0.872809                   0.842285                                1.000000                                1.000000                           0.979756                            0.994504                                        1.000000                                         1.000000                           0.505226                            0.750124                                        0.552988                                     7.964698e-01                          0.979904                                  0.989253                                       1.000000                                           1.000000                                   0.967475                              0.882543   \n",
       "16   100   705                    0.391949                          0.466228                         0.296158                                 0.340712                                       0.485242                                      0.402482                   0.777286                   0.938553                                0.700433                                0.921546                           1.000000                            1.000000                                        0.999601                                         0.964791                           0.394490                            0.975265                                        0.948569                                     9.771114e-01                          1.000000                                  1.000000                                       1.000000                                           1.000000                                   1.000000                              1.000000   \n",
       "17   100  2465                    0.407431                          0.496899                         0.300016                                 0.338256                                       0.486943                                      0.300016                   0.939606                   0.967033                                0.921855                                0.955799                           1.000000                            1.000000                                        1.000000                                         1.000000                           0.967520                            0.983678                                        0.964821                                     9.842812e-01                          1.000000                                  1.000000                                       1.000000                                           1.000000                                   1.000000                              0.963409   \n",
       "18   100  4826                    0.455823                          0.314752                         0.164622                                 0.298948                                       0.263800                                      0.141633                   0.868833                   0.827422                                1.000000                                0.704945                           0.778416                            0.529429                                        0.568717                                         0.500489                           0.689703                            0.615027                                        0.946773                                     7.259718e-01                          0.909810                                  0.955494                                       0.800127                                           0.918973                                   0.922813                              0.851006   \n",
       "19   100  4361                    0.236921                          0.156215                         0.192543                                 0.194459                                       0.221758                                      0.182364                   0.799354                   0.826339                                0.736696                                0.807197                           0.676978                            0.620543                                        0.594695                                         0.702814                           0.466917                            0.988845                                        0.955315                                     9.816395e-01                          0.869828                                  0.948150                                       0.836308                                           0.936795                                   0.805897                              0.713648   \n",
       "\n",
       "    n-grams:full,precise_annotations,words,1-grams  n-grams:full,partial_annotations,words,1-grams  n-grams:full,plant overrepresented tokens,1-grams  n-grams:full,bio ontology tokens,1-grams  n-grams:tokenization,full,nouns,adjectives,1-grams  n-grams:tokenization,linares_pontes,words,1-grams  n-grams:tokenization,full,precise_annotations,words,1-grams  n-grams:tokenization,full,partial_annotations,words,1-grams  n-grams:tokenization,full,plant overrepresented tokens,1-grams  n-grams:tokenization,full,bio ontology tokens,1-grams  go:union  po:union  go:minimum  po:minimum      mean   same  pathways  kegg_only  pmn_only  subsets  known  predicted  \n",
       "0                                         0.840402                                        0.568991                                           1.000000                                  1.000000                                           1.000000                                            1.000000                                           0.591617                                                     0.432781                                                     1.000000                                                        1.000000      1.000000  0.199791    1.000000    0.646186  0.696545  False        -1         -1        -1       -1   -1.0       -1.0  \n",
       "1                                         0.812361                                        0.422756                                           1.000000                                  1.000000                                           1.000000                                            0.980264                                           0.748194                                                     0.437357                                                     1.000000                                                        1.000000      1.000000  1.000000    1.000000    1.000000  0.637134   True        -1         -1        -1       -1    0.0        0.0  \n",
       "2                                         0.560416                                        0.496319                                           0.943099                                  0.928882                                           0.813392                                            0.868671                                           0.387241                                                     0.423178                                                     0.885369                                                        0.858600      0.240786  0.097509    0.906796    0.000000  0.385529   True        -1         -1        -1        0    0.0        0.0  \n",
       "3                                         1.000000                                        0.978017                                           1.000000                                  1.000000                                           1.000000                                            1.000000                                           1.000000                                                     0.897769                                                     1.000000                                                        1.000000      0.367580  0.108020    0.690276    0.474998  0.770669   True        -1         -1        -1       -1    0.0        0.0  \n",
       "4                                         0.810659                                        0.297326                                           1.000000                                  1.000000                                           1.000000                                            0.866671                                           0.604588                                                     0.252735                                                     1.000000                                                        1.000000      0.202688  0.089205    0.690276    0.000000  0.576333   True        -1         -1        -1        0    0.0        0.0  \n",
       "5                                         0.921055                                        0.329352                                           1.000000                                  1.000000                                           1.000000                                            1.000000                                           0.847789                                                     0.309230                                                     1.000000                                                        1.000000      1.000000  1.000000    1.000000    1.000000  0.704863  False        -1         -1        -1       -1   -1.0       -1.0  \n",
       "6                                         0.740565                                        0.356273                                           1.000000                                  1.000000                                           1.000000                                            0.897864                                           0.598539                                                     0.266433                                                     1.000000                                                        1.000000      0.622213  0.110242    0.956128    0.474998  0.595887   True        -1         -1        -1       -1    0.0        0.0  \n",
       "7                                         0.741642                                        0.258536                                           1.000000                                  1.000000                                           1.000000                                            0.949664                                           0.555684                                                     0.233350                                                     1.000000                                                        1.000000      1.000000  1.000000    1.000000    1.000000  0.528961  False        -1         -1        -1       -1   -1.0       -1.0  \n",
       "8                                         0.827605                                        0.342629                                           1.000000                                  1.000000                                           1.000000                                            0.900542                                           0.732674                                                     0.251352                                                     1.000000                                                        1.000000      0.229783  0.093575    0.484877    0.000000  0.663482   True        -1         -1        -1        0    0.0        0.0  \n",
       "9                                         0.720393                                        0.329431                                           0.976848                                  1.000000                                           1.000000                                            0.839561                                           0.424285                                                     0.281615                                                     0.873610                                                        1.000000      0.218605  0.217137    0.897383    0.539171  0.429050   True        -1         -1        -1        0    0.0        0.0  \n",
       "10                                        0.898833                                        0.295495                                           1.000000                                  1.000000                                           1.000000                                            1.000000                                           0.717540                                                     0.252735                                                     1.000000                                                        1.000000      0.323868  0.102040    0.922758    0.000000  0.690772   True        -1         -1        -1        0    0.0        0.0  \n",
       "11                                        0.662550                                        0.281065                                           0.889426                                  0.875277                                           0.711187                                            0.781553                                           0.329352                                                     0.220122                                                     0.815489                                                        0.794061      0.160622  0.094031    0.000000    0.000000  0.255310   True        -1         -1        -1        1    0.0        0.0  \n",
       "12                                        0.722733                                        0.269533                                           0.924850                                  0.918991                                           0.834325                                            0.844364                                           0.630280                                                     0.219975                                                     0.830025                                                        0.817266      1.000000  0.143986    1.000000    0.000000  0.398353   True        -1         -1        -1       -1    0.0        0.0  \n",
       "13                                        0.556267                                        0.266762                                           0.817845                                  0.790950                                           0.375810                                            0.254872                                           0.127706                                                     0.116814                                                     0.285404                                                        0.202417      0.152070  0.101173    0.561758    0.000000  0.114008   True        -1         -1        -1        1    0.0        0.0  \n",
       "14                                        0.671056                                        0.357490                                           1.000000                                  1.000000                                           1.000000                                            0.889625                                           0.508440                                                     0.312266                                                     1.000000                                                        1.000000      0.244869  0.099229    0.895382    0.000000  0.573919   True        -1         -1        -1       -1    0.0        0.0  \n",
       "15                                        0.683351                                        0.322125                                           0.979160                                  0.971694                                           1.000000                                            1.000000                                           1.000000                                                     1.000000                                                     1.000000                                                        1.000000      0.200952  0.100981    0.843244    0.000000  0.533735   True        -1         -1        -1        0    0.0        0.0  \n",
       "16                                        0.744874                                        0.291440                                           1.000000                                  1.000000                                           1.000000                                            1.000000                                           0.501246                                                     0.252735                                                     1.000000                                                        1.000000      0.176255  0.100868    0.696727    0.000000  0.619199   True        -1         -1        -1        0    0.0        0.0  \n",
       "17                                        0.895578                                        0.982281                                           1.000000                                  1.000000                                           1.000000                                            0.950474                                           0.834275                                                     0.862028                                                     1.000000                                                        1.000000      0.258714  0.100062    0.920747    0.000000  0.731418   True        -1         -1        -1        0    0.0        0.0  \n",
       "18                                        0.652218                                        0.241316                                           0.902508                                  0.881335                                           0.824919                                            0.738324                                           0.517975                                                     0.190031                                                     0.800127                                                        0.776915      0.211602  0.100722    0.927618    0.000000  0.280085   True        -1         -1        -1       -1    0.0        0.0  \n",
       "19                                        0.581492                                        0.327424                                           0.869828                                  0.851196                                           0.745715                                            0.583339                                           0.381752                                                     0.279292                                                     0.836308                                                        0.817298      0.255507  0.100667    0.308610    0.000000  0.261065   True        -1         -1        -1       -1    0.0        0.0  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add a column that indicates whether or not both genes of the pair are mapped to a phenotype classification.\n",
    "relevant_ids = set(string_edgelist.ids)\n",
    "df[\"from_is_valid\"] = df[\"from\"].map(lambda x: x in relevant_ids)\n",
    "df[\"to_is_valid\"] = df[\"to\"].map(lambda x: x in relevant_ids)\n",
    "df[\"pair_is_valid\"] = df[\"from_is_valid\"]*df[\"to_is_valid\"]*df[\"same\"]\n",
    "\n",
    "# Add a column giving the actual target output value for this biological task, with -1 for the irrelevant rows.\n",
    "df[\"known\"] = -1\n",
    "df[\"predicted\"] = -1\n",
    "df = df.merge(right=string_edgelist.df, how=\"left\", on=[\"from\",\"to\"])\n",
    "df[\"known_associations\"].fillna(value=0, inplace=True)\n",
    "df[\"predicted_associations\"].fillna(value=0, inplace=True)\n",
    "df.loc[(df[\"pair_is_valid\"]==True),\"known\"] = df[\"known_associations\"]\n",
    "df.loc[(df[\"pair_is_valid\"]==True),\"predicted\"] = df[\"predicted_associations\"]\n",
    "\n",
    "# Convert all the positive values from string on range 0 to arbitrary n to be equal to 1.\n",
    "df.loc[df[\"known\"] >= 1, \"known\"] = 1 \n",
    "df.loc[df[\"predicted\"] >= 1, \"predicted\"] = 1 \n",
    "df.drop(labels=[\"from_is_valid\",\"to_is_valid\",\"pair_is_valid\",\"known_associations\",\"predicted_associations\"], axis=\"columns\", inplace=True)\n",
    "\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"ortholog_objective\"></a>\n",
    "### Using orthology between genes (PANTHER) as the objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>from</th>\n",
       "      <th>to</th>\n",
       "      <th>doc2vec:wikipedia,size=300</th>\n",
       "      <th>word2vec:wikipedia,size=300,mean</th>\n",
       "      <th>word2vec:wikipedia,size=300,max</th>\n",
       "      <th>doc2vec:tokenization,wikipedia,size=300</th>\n",
       "      <th>word2vec:tokenization,wikipedia,size=300,mean</th>\n",
       "      <th>word2vec:tokenization,wikipedia,size=300,max</th>\n",
       "      <th>noble coder:precise,tfidf</th>\n",
       "      <th>noble coder:partial,tfidf</th>\n",
       "      <th>noble coder:tokenization,precise,tfidf</th>\n",
       "      <th>noble coder:tokenization,partial,tfidf</th>\n",
       "      <th>topic modeling:nmf,full,topics=50</th>\n",
       "      <th>topic modeling:nmf,full,topics=100</th>\n",
       "      <th>topic modeling:tokenization,nmf,full,topics=50</th>\n",
       "      <th>topic modeling:tokenization,nmf,full,topics=100</th>\n",
       "      <th>topic modeling:lda,full,topics=50</th>\n",
       "      <th>topic modeling:lda,full,topics=100</th>\n",
       "      <th>topic modeling:tokenization,lda,full,topics=50</th>\n",
       "      <th>topic modeling:tokenization,lda,full,topics=100</th>\n",
       "      <th>n-grams:full,words,1-grams,tfidf</th>\n",
       "      <th>n-grams:full,words,1-grams,2-grams,tfidf</th>\n",
       "      <th>n-grams:tokenization,full,words,1-grams,tfidf</th>\n",
       "      <th>n-grams:tokenization,full,words,1-grams,2-grams,tfidf</th>\n",
       "      <th>n-grams:full,nouns,adjectives,1-grams</th>\n",
       "      <th>n-grams:linares_pontes,words,1-grams</th>\n",
       "      <th>n-grams:full,precise_annotations,words,1-grams</th>\n",
       "      <th>n-grams:full,partial_annotations,words,1-grams</th>\n",
       "      <th>n-grams:full,plant overrepresented tokens,1-grams</th>\n",
       "      <th>n-grams:full,bio ontology tokens,1-grams</th>\n",
       "      <th>n-grams:tokenization,full,nouns,adjectives,1-grams</th>\n",
       "      <th>n-grams:tokenization,linares_pontes,words,1-grams</th>\n",
       "      <th>n-grams:tokenization,full,precise_annotations,words,1-grams</th>\n",
       "      <th>n-grams:tokenization,full,partial_annotations,words,1-grams</th>\n",
       "      <th>n-grams:tokenization,full,plant overrepresented tokens,1-grams</th>\n",
       "      <th>n-grams:tokenization,full,bio ontology tokens,1-grams</th>\n",
       "      <th>go:union</th>\n",
       "      <th>po:union</th>\n",
       "      <th>go:minimum</th>\n",
       "      <th>po:minimum</th>\n",
       "      <th>mean</th>\n",
       "      <th>same</th>\n",
       "      <th>pathways</th>\n",
       "      <th>kegg_only</th>\n",
       "      <th>pmn_only</th>\n",
       "      <th>subsets</th>\n",
       "      <th>known</th>\n",
       "      <th>predicted</th>\n",
       "      <th>orthologs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>1145</td>\n",
       "      <td>0.484948</td>\n",
       "      <td>0.503235</td>\n",
       "      <td>0.263459</td>\n",
       "      <td>0.422335</td>\n",
       "      <td>0.478481</td>\n",
       "      <td>0.288674</td>\n",
       "      <td>0.863608</td>\n",
       "      <td>0.927264</td>\n",
       "      <td>0.804840</td>\n",
       "      <td>0.899720</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.985932</td>\n",
       "      <td>0.983500</td>\n",
       "      <td>0.972852</td>\n",
       "      <td>0.986386</td>\n",
       "      <td>0.956351</td>\n",
       "      <td>9.843608e-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.840402</td>\n",
       "      <td>0.568991</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.591617</td>\n",
       "      <td>0.432781</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.199791</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.646186</td>\n",
       "      <td>0.696545</td>\n",
       "      <td>False</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100</td>\n",
       "      <td>4114</td>\n",
       "      <td>0.343207</td>\n",
       "      <td>0.260014</td>\n",
       "      <td>0.185656</td>\n",
       "      <td>0.260778</td>\n",
       "      <td>0.270105</td>\n",
       "      <td>0.180168</td>\n",
       "      <td>0.936699</td>\n",
       "      <td>0.963473</td>\n",
       "      <td>0.915321</td>\n",
       "      <td>0.957688</td>\n",
       "      <td>0.999937</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.997800</td>\n",
       "      <td>0.984195</td>\n",
       "      <td>0.848661</td>\n",
       "      <td>0.988527</td>\n",
       "      <td>0.969091</td>\n",
       "      <td>9.845576e-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.980422</td>\n",
       "      <td>0.812361</td>\n",
       "      <td>0.422756</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.980264</td>\n",
       "      <td>0.748194</td>\n",
       "      <td>0.437357</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.637134</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>231</td>\n",
       "      <td>0.424650</td>\n",
       "      <td>0.279231</td>\n",
       "      <td>0.185035</td>\n",
       "      <td>0.296518</td>\n",
       "      <td>0.271672</td>\n",
       "      <td>0.188429</td>\n",
       "      <td>0.888187</td>\n",
       "      <td>0.921801</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.824749</td>\n",
       "      <td>0.978728</td>\n",
       "      <td>0.556710</td>\n",
       "      <td>0.931309</td>\n",
       "      <td>0.668178</td>\n",
       "      <td>0.980502</td>\n",
       "      <td>0.552669</td>\n",
       "      <td>9.768748e-01</td>\n",
       "      <td>0.943099</td>\n",
       "      <td>0.972357</td>\n",
       "      <td>0.885369</td>\n",
       "      <td>0.931381</td>\n",
       "      <td>0.926808</td>\n",
       "      <td>0.896132</td>\n",
       "      <td>0.560416</td>\n",
       "      <td>0.496319</td>\n",
       "      <td>0.943099</td>\n",
       "      <td>0.928882</td>\n",
       "      <td>0.813392</td>\n",
       "      <td>0.868671</td>\n",
       "      <td>0.387241</td>\n",
       "      <td>0.423178</td>\n",
       "      <td>0.885369</td>\n",
       "      <td>0.858600</td>\n",
       "      <td>0.240786</td>\n",
       "      <td>0.097509</td>\n",
       "      <td>0.906796</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.385529</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100</td>\n",
       "      <td>5244</td>\n",
       "      <td>0.515200</td>\n",
       "      <td>0.602756</td>\n",
       "      <td>0.363885</td>\n",
       "      <td>0.428738</td>\n",
       "      <td>0.607823</td>\n",
       "      <td>0.362408</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.957448</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.944979</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999151</td>\n",
       "      <td>0.965712</td>\n",
       "      <td>0.954950</td>\n",
       "      <td>0.976779</td>\n",
       "      <td>0.950524</td>\n",
       "      <td>9.776629e-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.978017</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.897769</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.367580</td>\n",
       "      <td>0.108020</td>\n",
       "      <td>0.690276</td>\n",
       "      <td>0.474998</td>\n",
       "      <td>0.770669</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100</td>\n",
       "      <td>733</td>\n",
       "      <td>0.527713</td>\n",
       "      <td>0.270065</td>\n",
       "      <td>0.181497</td>\n",
       "      <td>0.355785</td>\n",
       "      <td>0.293558</td>\n",
       "      <td>0.170425</td>\n",
       "      <td>0.899698</td>\n",
       "      <td>0.927390</td>\n",
       "      <td>0.804250</td>\n",
       "      <td>0.918117</td>\n",
       "      <td>0.990412</td>\n",
       "      <td>0.999971</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.491172</td>\n",
       "      <td>0.517408</td>\n",
       "      <td>0.958356</td>\n",
       "      <td>9.761760e-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.877337</td>\n",
       "      <td>0.810659</td>\n",
       "      <td>0.297326</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.866671</td>\n",
       "      <td>0.604588</td>\n",
       "      <td>0.252735</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.202688</td>\n",
       "      <td>0.089205</td>\n",
       "      <td>0.690276</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.576333</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>100</td>\n",
       "      <td>3896</td>\n",
       "      <td>0.520128</td>\n",
       "      <td>0.536171</td>\n",
       "      <td>0.298879</td>\n",
       "      <td>0.399769</td>\n",
       "      <td>0.590710</td>\n",
       "      <td>0.391840</td>\n",
       "      <td>0.973093</td>\n",
       "      <td>0.970430</td>\n",
       "      <td>0.971126</td>\n",
       "      <td>0.966886</td>\n",
       "      <td>0.981126</td>\n",
       "      <td>0.913819</td>\n",
       "      <td>0.982271</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.967291</td>\n",
       "      <td>0.983562</td>\n",
       "      <td>0.959602</td>\n",
       "      <td>9.657815e-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.921055</td>\n",
       "      <td>0.329352</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.847789</td>\n",
       "      <td>0.309230</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.704863</td>\n",
       "      <td>False</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>100</td>\n",
       "      <td>4572</td>\n",
       "      <td>0.490884</td>\n",
       "      <td>0.326860</td>\n",
       "      <td>0.179187</td>\n",
       "      <td>0.310596</td>\n",
       "      <td>0.341777</td>\n",
       "      <td>0.209361</td>\n",
       "      <td>0.956777</td>\n",
       "      <td>0.928798</td>\n",
       "      <td>0.939667</td>\n",
       "      <td>0.925504</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.973819</td>\n",
       "      <td>0.910472</td>\n",
       "      <td>0.965566</td>\n",
       "      <td>0.965742</td>\n",
       "      <td>0.985249</td>\n",
       "      <td>0.941665</td>\n",
       "      <td>9.777083e-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.916390</td>\n",
       "      <td>0.740565</td>\n",
       "      <td>0.356273</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.897864</td>\n",
       "      <td>0.598539</td>\n",
       "      <td>0.266433</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.622213</td>\n",
       "      <td>0.110242</td>\n",
       "      <td>0.956128</td>\n",
       "      <td>0.474998</td>\n",
       "      <td>0.595887</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>100</td>\n",
       "      <td>2823</td>\n",
       "      <td>0.547941</td>\n",
       "      <td>0.272979</td>\n",
       "      <td>0.187657</td>\n",
       "      <td>0.279518</td>\n",
       "      <td>0.278486</td>\n",
       "      <td>0.199103</td>\n",
       "      <td>0.893427</td>\n",
       "      <td>0.902922</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.889492</td>\n",
       "      <td>0.981633</td>\n",
       "      <td>0.978047</td>\n",
       "      <td>0.325492</td>\n",
       "      <td>0.707005</td>\n",
       "      <td>0.970948</td>\n",
       "      <td>0.940419</td>\n",
       "      <td>0.560160</td>\n",
       "      <td>7.171545e-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.974706</td>\n",
       "      <td>0.741642</td>\n",
       "      <td>0.258536</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.949664</td>\n",
       "      <td>0.555684</td>\n",
       "      <td>0.233350</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.528961</td>\n",
       "      <td>False</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>100</td>\n",
       "      <td>1592</td>\n",
       "      <td>0.448422</td>\n",
       "      <td>0.438724</td>\n",
       "      <td>0.198668</td>\n",
       "      <td>0.320943</td>\n",
       "      <td>0.365019</td>\n",
       "      <td>0.222920</td>\n",
       "      <td>0.904967</td>\n",
       "      <td>0.925881</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.906443</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998446</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.969069</td>\n",
       "      <td>0.988745</td>\n",
       "      <td>0.959906</td>\n",
       "      <td>9.800199e-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.951814</td>\n",
       "      <td>0.827605</td>\n",
       "      <td>0.342629</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.900542</td>\n",
       "      <td>0.732674</td>\n",
       "      <td>0.251352</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.229783</td>\n",
       "      <td>0.093575</td>\n",
       "      <td>0.484877</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.663482</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>100</td>\n",
       "      <td>1185</td>\n",
       "      <td>0.450585</td>\n",
       "      <td>0.197340</td>\n",
       "      <td>0.151455</td>\n",
       "      <td>0.301088</td>\n",
       "      <td>0.232980</td>\n",
       "      <td>0.155569</td>\n",
       "      <td>0.909111</td>\n",
       "      <td>0.919647</td>\n",
       "      <td>0.666356</td>\n",
       "      <td>0.911593</td>\n",
       "      <td>0.998078</td>\n",
       "      <td>0.999591</td>\n",
       "      <td>0.828320</td>\n",
       "      <td>0.981882</td>\n",
       "      <td>0.855693</td>\n",
       "      <td>0.859678</td>\n",
       "      <td>0.944414</td>\n",
       "      <td>8.544685e-07</td>\n",
       "      <td>0.977251</td>\n",
       "      <td>0.989587</td>\n",
       "      <td>0.894892</td>\n",
       "      <td>0.957043</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.878630</td>\n",
       "      <td>0.720393</td>\n",
       "      <td>0.329431</td>\n",
       "      <td>0.976848</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.839561</td>\n",
       "      <td>0.424285</td>\n",
       "      <td>0.281615</td>\n",
       "      <td>0.873610</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.218605</td>\n",
       "      <td>0.217137</td>\n",
       "      <td>0.897383</td>\n",
       "      <td>0.539171</td>\n",
       "      <td>0.429050</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>100</td>\n",
       "      <td>883</td>\n",
       "      <td>0.448113</td>\n",
       "      <td>0.601558</td>\n",
       "      <td>0.872109</td>\n",
       "      <td>0.347916</td>\n",
       "      <td>0.597342</td>\n",
       "      <td>0.807199</td>\n",
       "      <td>0.851351</td>\n",
       "      <td>0.933871</td>\n",
       "      <td>0.804250</td>\n",
       "      <td>0.924255</td>\n",
       "      <td>0.999982</td>\n",
       "      <td>0.999745</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.955775</td>\n",
       "      <td>0.983743</td>\n",
       "      <td>0.948569</td>\n",
       "      <td>9.771114e-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.898833</td>\n",
       "      <td>0.295495</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.717540</td>\n",
       "      <td>0.252735</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.323868</td>\n",
       "      <td>0.102040</td>\n",
       "      <td>0.922758</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.690772</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>100</td>\n",
       "      <td>2456</td>\n",
       "      <td>0.526467</td>\n",
       "      <td>0.186860</td>\n",
       "      <td>0.160455</td>\n",
       "      <td>0.183519</td>\n",
       "      <td>0.194339</td>\n",
       "      <td>0.160468</td>\n",
       "      <td>0.891434</td>\n",
       "      <td>0.870208</td>\n",
       "      <td>0.648624</td>\n",
       "      <td>0.670109</td>\n",
       "      <td>0.753885</td>\n",
       "      <td>0.503019</td>\n",
       "      <td>0.635399</td>\n",
       "      <td>0.461174</td>\n",
       "      <td>0.375986</td>\n",
       "      <td>0.697940</td>\n",
       "      <td>0.903339</td>\n",
       "      <td>9.784185e-01</td>\n",
       "      <td>0.896217</td>\n",
       "      <td>0.943120</td>\n",
       "      <td>0.815489</td>\n",
       "      <td>0.913688</td>\n",
       "      <td>0.894577</td>\n",
       "      <td>0.800705</td>\n",
       "      <td>0.662550</td>\n",
       "      <td>0.281065</td>\n",
       "      <td>0.889426</td>\n",
       "      <td>0.875277</td>\n",
       "      <td>0.711187</td>\n",
       "      <td>0.781553</td>\n",
       "      <td>0.329352</td>\n",
       "      <td>0.220122</td>\n",
       "      <td>0.815489</td>\n",
       "      <td>0.794061</td>\n",
       "      <td>0.160622</td>\n",
       "      <td>0.094031</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.255310</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>100</td>\n",
       "      <td>5326</td>\n",
       "      <td>0.504994</td>\n",
       "      <td>0.380940</td>\n",
       "      <td>0.186081</td>\n",
       "      <td>0.370751</td>\n",
       "      <td>0.426500</td>\n",
       "      <td>0.226843</td>\n",
       "      <td>0.899571</td>\n",
       "      <td>0.758539</td>\n",
       "      <td>0.825243</td>\n",
       "      <td>0.529266</td>\n",
       "      <td>0.829671</td>\n",
       "      <td>0.994074</td>\n",
       "      <td>0.741820</td>\n",
       "      <td>0.705662</td>\n",
       "      <td>0.969831</td>\n",
       "      <td>0.849728</td>\n",
       "      <td>0.951450</td>\n",
       "      <td>9.775284e-01</td>\n",
       "      <td>0.928885</td>\n",
       "      <td>0.974094</td>\n",
       "      <td>0.856851</td>\n",
       "      <td>0.946249</td>\n",
       "      <td>0.912354</td>\n",
       "      <td>0.921801</td>\n",
       "      <td>0.722733</td>\n",
       "      <td>0.269533</td>\n",
       "      <td>0.924850</td>\n",
       "      <td>0.918991</td>\n",
       "      <td>0.834325</td>\n",
       "      <td>0.844364</td>\n",
       "      <td>0.630280</td>\n",
       "      <td>0.219975</td>\n",
       "      <td>0.830025</td>\n",
       "      <td>0.817266</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.143986</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.398353</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>100</td>\n",
       "      <td>1389</td>\n",
       "      <td>0.457299</td>\n",
       "      <td>0.173582</td>\n",
       "      <td>0.152193</td>\n",
       "      <td>0.191585</td>\n",
       "      <td>0.158163</td>\n",
       "      <td>0.123656</td>\n",
       "      <td>0.703391</td>\n",
       "      <td>0.821117</td>\n",
       "      <td>0.152634</td>\n",
       "      <td>0.391795</td>\n",
       "      <td>0.576416</td>\n",
       "      <td>0.638776</td>\n",
       "      <td>0.226166</td>\n",
       "      <td>0.145849</td>\n",
       "      <td>0.320535</td>\n",
       "      <td>0.889780</td>\n",
       "      <td>0.051062</td>\n",
       "      <td>8.100848e-02</td>\n",
       "      <td>0.823537</td>\n",
       "      <td>0.892493</td>\n",
       "      <td>0.285404</td>\n",
       "      <td>0.516267</td>\n",
       "      <td>0.857341</td>\n",
       "      <td>0.760775</td>\n",
       "      <td>0.556267</td>\n",
       "      <td>0.266762</td>\n",
       "      <td>0.817845</td>\n",
       "      <td>0.790950</td>\n",
       "      <td>0.375810</td>\n",
       "      <td>0.254872</td>\n",
       "      <td>0.127706</td>\n",
       "      <td>0.116814</td>\n",
       "      <td>0.285404</td>\n",
       "      <td>0.202417</td>\n",
       "      <td>0.152070</td>\n",
       "      <td>0.101173</td>\n",
       "      <td>0.561758</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.114008</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>100</td>\n",
       "      <td>5153</td>\n",
       "      <td>0.503643</td>\n",
       "      <td>0.255375</td>\n",
       "      <td>0.205944</td>\n",
       "      <td>0.346032</td>\n",
       "      <td>0.248265</td>\n",
       "      <td>0.204870</td>\n",
       "      <td>0.917486</td>\n",
       "      <td>0.947452</td>\n",
       "      <td>0.725425</td>\n",
       "      <td>0.938016</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999361</td>\n",
       "      <td>0.987637</td>\n",
       "      <td>0.967503</td>\n",
       "      <td>0.630591</td>\n",
       "      <td>0.802153</td>\n",
       "      <td>0.957659</td>\n",
       "      <td>9.760884e-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.888076</td>\n",
       "      <td>0.671056</td>\n",
       "      <td>0.357490</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.889625</td>\n",
       "      <td>0.508440</td>\n",
       "      <td>0.312266</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.244869</td>\n",
       "      <td>0.099229</td>\n",
       "      <td>0.895382</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.573919</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>100</td>\n",
       "      <td>1975</td>\n",
       "      <td>0.529565</td>\n",
       "      <td>0.246333</td>\n",
       "      <td>0.155104</td>\n",
       "      <td>0.356367</td>\n",
       "      <td>0.262292</td>\n",
       "      <td>0.171215</td>\n",
       "      <td>0.872809</td>\n",
       "      <td>0.842285</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.979756</td>\n",
       "      <td>0.994504</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.505226</td>\n",
       "      <td>0.750124</td>\n",
       "      <td>0.552988</td>\n",
       "      <td>7.964698e-01</td>\n",
       "      <td>0.979904</td>\n",
       "      <td>0.989253</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.967475</td>\n",
       "      <td>0.882543</td>\n",
       "      <td>0.683351</td>\n",
       "      <td>0.322125</td>\n",
       "      <td>0.979160</td>\n",
       "      <td>0.971694</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.200952</td>\n",
       "      <td>0.100981</td>\n",
       "      <td>0.843244</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.533735</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>100</td>\n",
       "      <td>705</td>\n",
       "      <td>0.391949</td>\n",
       "      <td>0.466228</td>\n",
       "      <td>0.296158</td>\n",
       "      <td>0.340712</td>\n",
       "      <td>0.485242</td>\n",
       "      <td>0.402482</td>\n",
       "      <td>0.777286</td>\n",
       "      <td>0.938553</td>\n",
       "      <td>0.700433</td>\n",
       "      <td>0.921546</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999601</td>\n",
       "      <td>0.964791</td>\n",
       "      <td>0.394490</td>\n",
       "      <td>0.975265</td>\n",
       "      <td>0.948569</td>\n",
       "      <td>9.771114e-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.744874</td>\n",
       "      <td>0.291440</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.501246</td>\n",
       "      <td>0.252735</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.176255</td>\n",
       "      <td>0.100868</td>\n",
       "      <td>0.696727</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.619199</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>100</td>\n",
       "      <td>2465</td>\n",
       "      <td>0.407431</td>\n",
       "      <td>0.496899</td>\n",
       "      <td>0.300016</td>\n",
       "      <td>0.338256</td>\n",
       "      <td>0.486943</td>\n",
       "      <td>0.300016</td>\n",
       "      <td>0.939606</td>\n",
       "      <td>0.967033</td>\n",
       "      <td>0.921855</td>\n",
       "      <td>0.955799</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.967520</td>\n",
       "      <td>0.983678</td>\n",
       "      <td>0.964821</td>\n",
       "      <td>9.842812e-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.963409</td>\n",
       "      <td>0.895578</td>\n",
       "      <td>0.982281</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.950474</td>\n",
       "      <td>0.834275</td>\n",
       "      <td>0.862028</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.258714</td>\n",
       "      <td>0.100062</td>\n",
       "      <td>0.920747</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.731418</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>100</td>\n",
       "      <td>4826</td>\n",
       "      <td>0.455823</td>\n",
       "      <td>0.314752</td>\n",
       "      <td>0.164622</td>\n",
       "      <td>0.298948</td>\n",
       "      <td>0.263800</td>\n",
       "      <td>0.141633</td>\n",
       "      <td>0.868833</td>\n",
       "      <td>0.827422</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.704945</td>\n",
       "      <td>0.778416</td>\n",
       "      <td>0.529429</td>\n",
       "      <td>0.568717</td>\n",
       "      <td>0.500489</td>\n",
       "      <td>0.689703</td>\n",
       "      <td>0.615027</td>\n",
       "      <td>0.946773</td>\n",
       "      <td>7.259718e-01</td>\n",
       "      <td>0.909810</td>\n",
       "      <td>0.955494</td>\n",
       "      <td>0.800127</td>\n",
       "      <td>0.918973</td>\n",
       "      <td>0.922813</td>\n",
       "      <td>0.851006</td>\n",
       "      <td>0.652218</td>\n",
       "      <td>0.241316</td>\n",
       "      <td>0.902508</td>\n",
       "      <td>0.881335</td>\n",
       "      <td>0.824919</td>\n",
       "      <td>0.738324</td>\n",
       "      <td>0.517975</td>\n",
       "      <td>0.190031</td>\n",
       "      <td>0.800127</td>\n",
       "      <td>0.776915</td>\n",
       "      <td>0.211602</td>\n",
       "      <td>0.100722</td>\n",
       "      <td>0.927618</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.280085</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>100</td>\n",
       "      <td>4361</td>\n",
       "      <td>0.236921</td>\n",
       "      <td>0.156215</td>\n",
       "      <td>0.192543</td>\n",
       "      <td>0.194459</td>\n",
       "      <td>0.221758</td>\n",
       "      <td>0.182364</td>\n",
       "      <td>0.799354</td>\n",
       "      <td>0.826339</td>\n",
       "      <td>0.736696</td>\n",
       "      <td>0.807197</td>\n",
       "      <td>0.676978</td>\n",
       "      <td>0.620543</td>\n",
       "      <td>0.594695</td>\n",
       "      <td>0.702814</td>\n",
       "      <td>0.466917</td>\n",
       "      <td>0.988845</td>\n",
       "      <td>0.955315</td>\n",
       "      <td>9.816395e-01</td>\n",
       "      <td>0.869828</td>\n",
       "      <td>0.948150</td>\n",
       "      <td>0.836308</td>\n",
       "      <td>0.936795</td>\n",
       "      <td>0.805897</td>\n",
       "      <td>0.713648</td>\n",
       "      <td>0.581492</td>\n",
       "      <td>0.327424</td>\n",
       "      <td>0.869828</td>\n",
       "      <td>0.851196</td>\n",
       "      <td>0.745715</td>\n",
       "      <td>0.583339</td>\n",
       "      <td>0.381752</td>\n",
       "      <td>0.279292</td>\n",
       "      <td>0.836308</td>\n",
       "      <td>0.817298</td>\n",
       "      <td>0.255507</td>\n",
       "      <td>0.100667</td>\n",
       "      <td>0.308610</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.261065</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    from    to  doc2vec:wikipedia,size=300  word2vec:wikipedia,size=300,mean  word2vec:wikipedia,size=300,max  doc2vec:tokenization,wikipedia,size=300  word2vec:tokenization,wikipedia,size=300,mean  word2vec:tokenization,wikipedia,size=300,max  noble coder:precise,tfidf  noble coder:partial,tfidf  noble coder:tokenization,precise,tfidf  noble coder:tokenization,partial,tfidf  topic modeling:nmf,full,topics=50  topic modeling:nmf,full,topics=100  topic modeling:tokenization,nmf,full,topics=50  topic modeling:tokenization,nmf,full,topics=100  topic modeling:lda,full,topics=50  topic modeling:lda,full,topics=100  topic modeling:tokenization,lda,full,topics=50  topic modeling:tokenization,lda,full,topics=100  n-grams:full,words,1-grams,tfidf  n-grams:full,words,1-grams,2-grams,tfidf  n-grams:tokenization,full,words,1-grams,tfidf  n-grams:tokenization,full,words,1-grams,2-grams,tfidf  n-grams:full,nouns,adjectives,1-grams  n-grams:linares_pontes,words,1-grams  \\\n",
       "0    100  1145                    0.484948                          0.503235                         0.263459                                 0.422335                                       0.478481                                      0.288674                   0.863608                   0.927264                                0.804840                                0.899720                           1.000000                            1.000000                                        0.985932                                         0.983500                           0.972852                            0.986386                                        0.956351                                     9.843608e-01                          1.000000                                  1.000000                                       1.000000                                           1.000000                                   1.000000                              1.000000   \n",
       "1    100  4114                    0.343207                          0.260014                         0.185656                                 0.260778                                       0.270105                                      0.180168                   0.936699                   0.963473                                0.915321                                0.957688                           0.999937                            1.000000                                        0.997800                                         0.984195                           0.848661                            0.988527                                        0.969091                                     9.845576e-01                          1.000000                                  1.000000                                       1.000000                                           1.000000                                   1.000000                              0.980422   \n",
       "2    100   231                    0.424650                          0.279231                         0.185035                                 0.296518                                       0.271672                                      0.188429                   0.888187                   0.921801                                1.000000                                1.000000                           0.824749                            0.978728                                        0.556710                                         0.931309                           0.668178                            0.980502                                        0.552669                                     9.768748e-01                          0.943099                                  0.972357                                       0.885369                                           0.931381                                   0.926808                              0.896132   \n",
       "3    100  5244                    0.515200                          0.602756                         0.363885                                 0.428738                                       0.607823                                      0.362408                   1.000000                   0.957448                                1.000000                                0.944979                           1.000000                            1.000000                                        0.999151                                         0.965712                           0.954950                            0.976779                                        0.950524                                     9.776629e-01                          1.000000                                  1.000000                                       1.000000                                           1.000000                                   1.000000                              1.000000   \n",
       "4    100   733                    0.527713                          0.270065                         0.181497                                 0.355785                                       0.293558                                      0.170425                   0.899698                   0.927390                                0.804250                                0.918117                           0.990412                            0.999971                                        0.999996                                         1.000000                           0.491172                            0.517408                                        0.958356                                     9.761760e-01                          1.000000                                  1.000000                                       1.000000                                           1.000000                                   1.000000                              0.877337   \n",
       "5    100  3896                    0.520128                          0.536171                         0.298879                                 0.399769                                       0.590710                                      0.391840                   0.973093                   0.970430                                0.971126                                0.966886                           0.981126                            0.913819                                        0.982271                                         1.000000                           0.967291                            0.983562                                        0.959602                                     9.657815e-01                          1.000000                                  1.000000                                       1.000000                                           1.000000                                   1.000000                              1.000000   \n",
       "6    100  4572                    0.490884                          0.326860                         0.179187                                 0.310596                                       0.341777                                      0.209361                   0.956777                   0.928798                                0.939667                                0.925504                           1.000000                            0.973819                                        0.910472                                         0.965566                           0.965742                            0.985249                                        0.941665                                     9.777083e-01                          1.000000                                  1.000000                                       1.000000                                           1.000000                                   1.000000                              0.916390   \n",
       "7    100  2823                    0.547941                          0.272979                         0.187657                                 0.279518                                       0.278486                                      0.199103                   0.893427                   0.902922                                1.000000                                0.889492                           0.981633                            0.978047                                        0.325492                                         0.707005                           0.970948                            0.940419                                        0.560160                                     7.171545e-01                          1.000000                                  1.000000                                       1.000000                                           1.000000                                   1.000000                              0.974706   \n",
       "8    100  1592                    0.448422                          0.438724                         0.198668                                 0.320943                                       0.365019                                      0.222920                   0.904967                   0.925881                                1.000000                                0.906443                           1.000000                            1.000000                                        0.998446                                         1.000000                           0.969069                            0.988745                                        0.959906                                     9.800199e-01                          1.000000                                  1.000000                                       1.000000                                           1.000000                                   1.000000                              0.951814   \n",
       "9    100  1185                    0.450585                          0.197340                         0.151455                                 0.301088                                       0.232980                                      0.155569                   0.909111                   0.919647                                0.666356                                0.911593                           0.998078                            0.999591                                        0.828320                                         0.981882                           0.855693                            0.859678                                        0.944414                                     8.544685e-07                          0.977251                                  0.989587                                       0.894892                                           0.957043                                   1.000000                              0.878630   \n",
       "10   100   883                    0.448113                          0.601558                         0.872109                                 0.347916                                       0.597342                                      0.807199                   0.851351                   0.933871                                0.804250                                0.924255                           0.999982                            0.999745                                        1.000000                                         1.000000                           0.955775                            0.983743                                        0.948569                                     9.771114e-01                          1.000000                                  1.000000                                       1.000000                                           1.000000                                   1.000000                              1.000000   \n",
       "11   100  2456                    0.526467                          0.186860                         0.160455                                 0.183519                                       0.194339                                      0.160468                   0.891434                   0.870208                                0.648624                                0.670109                           0.753885                            0.503019                                        0.635399                                         0.461174                           0.375986                            0.697940                                        0.903339                                     9.784185e-01                          0.896217                                  0.943120                                       0.815489                                           0.913688                                   0.894577                              0.800705   \n",
       "12   100  5326                    0.504994                          0.380940                         0.186081                                 0.370751                                       0.426500                                      0.226843                   0.899571                   0.758539                                0.825243                                0.529266                           0.829671                            0.994074                                        0.741820                                         0.705662                           0.969831                            0.849728                                        0.951450                                     9.775284e-01                          0.928885                                  0.974094                                       0.856851                                           0.946249                                   0.912354                              0.921801   \n",
       "13   100  1389                    0.457299                          0.173582                         0.152193                                 0.191585                                       0.158163                                      0.123656                   0.703391                   0.821117                                0.152634                                0.391795                           0.576416                            0.638776                                        0.226166                                         0.145849                           0.320535                            0.889780                                        0.051062                                     8.100848e-02                          0.823537                                  0.892493                                       0.285404                                           0.516267                                   0.857341                              0.760775   \n",
       "14   100  5153                    0.503643                          0.255375                         0.205944                                 0.346032                                       0.248265                                      0.204870                   0.917486                   0.947452                                0.725425                                0.938016                           1.000000                            0.999361                                        0.987637                                         0.967503                           0.630591                            0.802153                                        0.957659                                     9.760884e-01                          1.000000                                  1.000000                                       1.000000                                           1.000000                                   1.000000                              0.888076   \n",
       "15   100  1975                    0.529565                          0.246333                         0.155104                                 0.356367                                       0.262292                                      0.171215                   0.872809                   0.842285                                1.000000                                1.000000                           0.979756                            0.994504                                        1.000000                                         1.000000                           0.505226                            0.750124                                        0.552988                                     7.964698e-01                          0.979904                                  0.989253                                       1.000000                                           1.000000                                   0.967475                              0.882543   \n",
       "16   100   705                    0.391949                          0.466228                         0.296158                                 0.340712                                       0.485242                                      0.402482                   0.777286                   0.938553                                0.700433                                0.921546                           1.000000                            1.000000                                        0.999601                                         0.964791                           0.394490                            0.975265                                        0.948569                                     9.771114e-01                          1.000000                                  1.000000                                       1.000000                                           1.000000                                   1.000000                              1.000000   \n",
       "17   100  2465                    0.407431                          0.496899                         0.300016                                 0.338256                                       0.486943                                      0.300016                   0.939606                   0.967033                                0.921855                                0.955799                           1.000000                            1.000000                                        1.000000                                         1.000000                           0.967520                            0.983678                                        0.964821                                     9.842812e-01                          1.000000                                  1.000000                                       1.000000                                           1.000000                                   1.000000                              0.963409   \n",
       "18   100  4826                    0.455823                          0.314752                         0.164622                                 0.298948                                       0.263800                                      0.141633                   0.868833                   0.827422                                1.000000                                0.704945                           0.778416                            0.529429                                        0.568717                                         0.500489                           0.689703                            0.615027                                        0.946773                                     7.259718e-01                          0.909810                                  0.955494                                       0.800127                                           0.918973                                   0.922813                              0.851006   \n",
       "19   100  4361                    0.236921                          0.156215                         0.192543                                 0.194459                                       0.221758                                      0.182364                   0.799354                   0.826339                                0.736696                                0.807197                           0.676978                            0.620543                                        0.594695                                         0.702814                           0.466917                            0.988845                                        0.955315                                     9.816395e-01                          0.869828                                  0.948150                                       0.836308                                           0.936795                                   0.805897                              0.713648   \n",
       "\n",
       "    n-grams:full,precise_annotations,words,1-grams  n-grams:full,partial_annotations,words,1-grams  n-grams:full,plant overrepresented tokens,1-grams  n-grams:full,bio ontology tokens,1-grams  n-grams:tokenization,full,nouns,adjectives,1-grams  n-grams:tokenization,linares_pontes,words,1-grams  n-grams:tokenization,full,precise_annotations,words,1-grams  n-grams:tokenization,full,partial_annotations,words,1-grams  n-grams:tokenization,full,plant overrepresented tokens,1-grams  n-grams:tokenization,full,bio ontology tokens,1-grams  go:union  po:union  go:minimum  po:minimum      mean   same  pathways  kegg_only  pmn_only  subsets  known  predicted  orthologs  \n",
       "0                                         0.840402                                        0.568991                                           1.000000                                  1.000000                                           1.000000                                            1.000000                                           0.591617                                                     0.432781                                                     1.000000                                                        1.000000      1.000000  0.199791    1.000000    0.646186  0.696545  False        -1         -1        -1       -1   -1.0       -1.0       -1.0  \n",
       "1                                         0.812361                                        0.422756                                           1.000000                                  1.000000                                           1.000000                                            0.980264                                           0.748194                                                     0.437357                                                     1.000000                                                        1.000000      1.000000  1.000000    1.000000    1.000000  0.637134   True        -1         -1        -1       -1    0.0        0.0       -1.0  \n",
       "2                                         0.560416                                        0.496319                                           0.943099                                  0.928882                                           0.813392                                            0.868671                                           0.387241                                                     0.423178                                                     0.885369                                                        0.858600      0.240786  0.097509    0.906796    0.000000  0.385529   True        -1         -1        -1        0    0.0        0.0       -1.0  \n",
       "3                                         1.000000                                        0.978017                                           1.000000                                  1.000000                                           1.000000                                            1.000000                                           1.000000                                                     0.897769                                                     1.000000                                                        1.000000      0.367580  0.108020    0.690276    0.474998  0.770669   True        -1         -1        -1       -1    0.0        0.0       -1.0  \n",
       "4                                         0.810659                                        0.297326                                           1.000000                                  1.000000                                           1.000000                                            0.866671                                           0.604588                                                     0.252735                                                     1.000000                                                        1.000000      0.202688  0.089205    0.690276    0.000000  0.576333   True        -1         -1        -1        0    0.0        0.0       -1.0  \n",
       "5                                         0.921055                                        0.329352                                           1.000000                                  1.000000                                           1.000000                                            1.000000                                           0.847789                                                     0.309230                                                     1.000000                                                        1.000000      1.000000  1.000000    1.000000    1.000000  0.704863  False        -1         -1        -1       -1   -1.0       -1.0       -1.0  \n",
       "6                                         0.740565                                        0.356273                                           1.000000                                  1.000000                                           1.000000                                            0.897864                                           0.598539                                                     0.266433                                                     1.000000                                                        1.000000      0.622213  0.110242    0.956128    0.474998  0.595887   True        -1         -1        -1       -1    0.0        0.0       -1.0  \n",
       "7                                         0.741642                                        0.258536                                           1.000000                                  1.000000                                           1.000000                                            0.949664                                           0.555684                                                     0.233350                                                     1.000000                                                        1.000000      1.000000  1.000000    1.000000    1.000000  0.528961  False        -1         -1        -1       -1   -1.0       -1.0       -1.0  \n",
       "8                                         0.827605                                        0.342629                                           1.000000                                  1.000000                                           1.000000                                            0.900542                                           0.732674                                                     0.251352                                                     1.000000                                                        1.000000      0.229783  0.093575    0.484877    0.000000  0.663482   True        -1         -1        -1        0    0.0        0.0       -1.0  \n",
       "9                                         0.720393                                        0.329431                                           0.976848                                  1.000000                                           1.000000                                            0.839561                                           0.424285                                                     0.281615                                                     0.873610                                                        1.000000      0.218605  0.217137    0.897383    0.539171  0.429050   True        -1         -1        -1        0    0.0        0.0       -1.0  \n",
       "10                                        0.898833                                        0.295495                                           1.000000                                  1.000000                                           1.000000                                            1.000000                                           0.717540                                                     0.252735                                                     1.000000                                                        1.000000      0.323868  0.102040    0.922758    0.000000  0.690772   True        -1         -1        -1        0    0.0        0.0       -1.0  \n",
       "11                                        0.662550                                        0.281065                                           0.889426                                  0.875277                                           0.711187                                            0.781553                                           0.329352                                                     0.220122                                                     0.815489                                                        0.794061      0.160622  0.094031    0.000000    0.000000  0.255310   True        -1         -1        -1        1    0.0        0.0       -1.0  \n",
       "12                                        0.722733                                        0.269533                                           0.924850                                  0.918991                                           0.834325                                            0.844364                                           0.630280                                                     0.219975                                                     0.830025                                                        0.817266      1.000000  0.143986    1.000000    0.000000  0.398353   True        -1         -1        -1       -1    0.0        0.0       -1.0  \n",
       "13                                        0.556267                                        0.266762                                           0.817845                                  0.790950                                           0.375810                                            0.254872                                           0.127706                                                     0.116814                                                     0.285404                                                        0.202417      0.152070  0.101173    0.561758    0.000000  0.114008   True        -1         -1        -1        1    0.0        0.0       -1.0  \n",
       "14                                        0.671056                                        0.357490                                           1.000000                                  1.000000                                           1.000000                                            0.889625                                           0.508440                                                     0.312266                                                     1.000000                                                        1.000000      0.244869  0.099229    0.895382    0.000000  0.573919   True        -1         -1        -1       -1    0.0        0.0       -1.0  \n",
       "15                                        0.683351                                        0.322125                                           0.979160                                  0.971694                                           1.000000                                            1.000000                                           1.000000                                                     1.000000                                                     1.000000                                                        1.000000      0.200952  0.100981    0.843244    0.000000  0.533735   True        -1         -1        -1        0    0.0        0.0       -1.0  \n",
       "16                                        0.744874                                        0.291440                                           1.000000                                  1.000000                                           1.000000                                            1.000000                                           0.501246                                                     0.252735                                                     1.000000                                                        1.000000      0.176255  0.100868    0.696727    0.000000  0.619199   True        -1         -1        -1        0    0.0        0.0       -1.0  \n",
       "17                                        0.895578                                        0.982281                                           1.000000                                  1.000000                                           1.000000                                            0.950474                                           0.834275                                                     0.862028                                                     1.000000                                                        1.000000      0.258714  0.100062    0.920747    0.000000  0.731418   True        -1         -1        -1        0    0.0        0.0       -1.0  \n",
       "18                                        0.652218                                        0.241316                                           0.902508                                  0.881335                                           0.824919                                            0.738324                                           0.517975                                                     0.190031                                                     0.800127                                                        0.776915      0.211602  0.100722    0.927618    0.000000  0.280085   True        -1         -1        -1       -1    0.0        0.0       -1.0  \n",
       "19                                        0.581492                                        0.327424                                           0.869828                                  0.851196                                           0.745715                                            0.583339                                           0.381752                                                     0.279292                                                     0.836308                                                        0.817298      0.255507  0.100667    0.308610    0.000000  0.261065   True        -1         -1        -1       -1    0.0        0.0       -1.0  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add a column that indicates whether or not both genes of the pair are mapped to a phenotype classification.\n",
    "relevant_ids = set(panther_edgelist.ids)\n",
    "df[\"from_is_valid\"] = df[\"from\"].map(lambda x: x in relevant_ids)\n",
    "df[\"to_is_valid\"] = df[\"to\"].map(lambda x: x in relevant_ids)\n",
    "df[\"pair_is_valid\"] = df[\"from_is_valid\"]*df[\"to_is_valid\"]*~df[\"same\"]\n",
    "\n",
    "# Add a column giving the actual target output value for this biological task, with -1 for the irrelevant rows.\n",
    "df[\"orthologs\"] = -1\n",
    "df = df.merge(right=panther_edgelist.df, how=\"left\", on=[\"from\",\"to\"])\n",
    "df[\"value\"].fillna(value=0, inplace=True)\n",
    "df.loc[(df[\"pair_is_valid\"]==True),\"orthologs\"] = df[\"value\"]\n",
    "df.drop(labels=[\"from_is_valid\",\"to_is_valid\",\"pair_is_valid\",\"value\"], axis=\"columns\", inplace=True)\n",
    "\n",
    "df.head(20)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"eq_sim\"></a>\n",
    "### Curator-derived similarity values from Oellrich, Walls et al., 2015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>from</th>\n",
       "      <th>to</th>\n",
       "      <th>doc2vec:wikipedia,size=300</th>\n",
       "      <th>word2vec:wikipedia,size=300,mean</th>\n",
       "      <th>word2vec:wikipedia,size=300,max</th>\n",
       "      <th>doc2vec:tokenization,wikipedia,size=300</th>\n",
       "      <th>word2vec:tokenization,wikipedia,size=300,mean</th>\n",
       "      <th>word2vec:tokenization,wikipedia,size=300,max</th>\n",
       "      <th>noble coder:precise,tfidf</th>\n",
       "      <th>noble coder:partial,tfidf</th>\n",
       "      <th>noble coder:tokenization,precise,tfidf</th>\n",
       "      <th>noble coder:tokenization,partial,tfidf</th>\n",
       "      <th>topic modeling:nmf,full,topics=50</th>\n",
       "      <th>topic modeling:nmf,full,topics=100</th>\n",
       "      <th>topic modeling:tokenization,nmf,full,topics=50</th>\n",
       "      <th>topic modeling:tokenization,nmf,full,topics=100</th>\n",
       "      <th>topic modeling:lda,full,topics=50</th>\n",
       "      <th>topic modeling:lda,full,topics=100</th>\n",
       "      <th>topic modeling:tokenization,lda,full,topics=50</th>\n",
       "      <th>topic modeling:tokenization,lda,full,topics=100</th>\n",
       "      <th>n-grams:full,words,1-grams,tfidf</th>\n",
       "      <th>n-grams:full,words,1-grams,2-grams,tfidf</th>\n",
       "      <th>n-grams:tokenization,full,words,1-grams,tfidf</th>\n",
       "      <th>n-grams:tokenization,full,words,1-grams,2-grams,tfidf</th>\n",
       "      <th>n-grams:full,nouns,adjectives,1-grams</th>\n",
       "      <th>n-grams:linares_pontes,words,1-grams</th>\n",
       "      <th>n-grams:full,precise_annotations,words,1-grams</th>\n",
       "      <th>n-grams:full,partial_annotations,words,1-grams</th>\n",
       "      <th>n-grams:full,plant overrepresented tokens,1-grams</th>\n",
       "      <th>n-grams:full,bio ontology tokens,1-grams</th>\n",
       "      <th>n-grams:tokenization,full,nouns,adjectives,1-grams</th>\n",
       "      <th>n-grams:tokenization,linares_pontes,words,1-grams</th>\n",
       "      <th>n-grams:tokenization,full,precise_annotations,words,1-grams</th>\n",
       "      <th>n-grams:tokenization,full,partial_annotations,words,1-grams</th>\n",
       "      <th>n-grams:tokenization,full,plant overrepresented tokens,1-grams</th>\n",
       "      <th>n-grams:tokenization,full,bio ontology tokens,1-grams</th>\n",
       "      <th>go:union</th>\n",
       "      <th>po:union</th>\n",
       "      <th>go:minimum</th>\n",
       "      <th>po:minimum</th>\n",
       "      <th>mean</th>\n",
       "      <th>same</th>\n",
       "      <th>pathways</th>\n",
       "      <th>kegg_only</th>\n",
       "      <th>pmn_only</th>\n",
       "      <th>subsets</th>\n",
       "      <th>known</th>\n",
       "      <th>predicted</th>\n",
       "      <th>orthologs</th>\n",
       "      <th>eqs_distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>1145</td>\n",
       "      <td>0.484948</td>\n",
       "      <td>0.503235</td>\n",
       "      <td>0.263459</td>\n",
       "      <td>0.422335</td>\n",
       "      <td>0.478481</td>\n",
       "      <td>0.288674</td>\n",
       "      <td>0.863608</td>\n",
       "      <td>0.927264</td>\n",
       "      <td>0.804840</td>\n",
       "      <td>0.899720</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.985932</td>\n",
       "      <td>0.983500</td>\n",
       "      <td>0.972852</td>\n",
       "      <td>0.986386</td>\n",
       "      <td>0.956351</td>\n",
       "      <td>9.843608e-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.840402</td>\n",
       "      <td>0.568991</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.591617</td>\n",
       "      <td>0.432781</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.199791</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.646186</td>\n",
       "      <td>0.696545</td>\n",
       "      <td>False</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100</td>\n",
       "      <td>4114</td>\n",
       "      <td>0.343207</td>\n",
       "      <td>0.260014</td>\n",
       "      <td>0.185656</td>\n",
       "      <td>0.260778</td>\n",
       "      <td>0.270105</td>\n",
       "      <td>0.180168</td>\n",
       "      <td>0.936699</td>\n",
       "      <td>0.963473</td>\n",
       "      <td>0.915321</td>\n",
       "      <td>0.957688</td>\n",
       "      <td>0.999937</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.997800</td>\n",
       "      <td>0.984195</td>\n",
       "      <td>0.848661</td>\n",
       "      <td>0.988527</td>\n",
       "      <td>0.969091</td>\n",
       "      <td>9.845576e-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.980422</td>\n",
       "      <td>0.812361</td>\n",
       "      <td>0.422756</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.980264</td>\n",
       "      <td>0.748194</td>\n",
       "      <td>0.437357</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.637134</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>231</td>\n",
       "      <td>0.424650</td>\n",
       "      <td>0.279231</td>\n",
       "      <td>0.185035</td>\n",
       "      <td>0.296518</td>\n",
       "      <td>0.271672</td>\n",
       "      <td>0.188429</td>\n",
       "      <td>0.888187</td>\n",
       "      <td>0.921801</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.824749</td>\n",
       "      <td>0.978728</td>\n",
       "      <td>0.556710</td>\n",
       "      <td>0.931309</td>\n",
       "      <td>0.668178</td>\n",
       "      <td>0.980502</td>\n",
       "      <td>0.552669</td>\n",
       "      <td>9.768748e-01</td>\n",
       "      <td>0.943099</td>\n",
       "      <td>0.972357</td>\n",
       "      <td>0.885369</td>\n",
       "      <td>0.931381</td>\n",
       "      <td>0.926808</td>\n",
       "      <td>0.896132</td>\n",
       "      <td>0.560416</td>\n",
       "      <td>0.496319</td>\n",
       "      <td>0.943099</td>\n",
       "      <td>0.928882</td>\n",
       "      <td>0.813392</td>\n",
       "      <td>0.868671</td>\n",
       "      <td>0.387241</td>\n",
       "      <td>0.423178</td>\n",
       "      <td>0.885369</td>\n",
       "      <td>0.858600</td>\n",
       "      <td>0.240786</td>\n",
       "      <td>0.097509</td>\n",
       "      <td>0.906796</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.385529</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100</td>\n",
       "      <td>5244</td>\n",
       "      <td>0.515200</td>\n",
       "      <td>0.602756</td>\n",
       "      <td>0.363885</td>\n",
       "      <td>0.428738</td>\n",
       "      <td>0.607823</td>\n",
       "      <td>0.362408</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.957448</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.944979</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999151</td>\n",
       "      <td>0.965712</td>\n",
       "      <td>0.954950</td>\n",
       "      <td>0.976779</td>\n",
       "      <td>0.950524</td>\n",
       "      <td>9.776629e-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.978017</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.897769</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.367580</td>\n",
       "      <td>0.108020</td>\n",
       "      <td>0.690276</td>\n",
       "      <td>0.474998</td>\n",
       "      <td>0.770669</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100</td>\n",
       "      <td>733</td>\n",
       "      <td>0.527713</td>\n",
       "      <td>0.270065</td>\n",
       "      <td>0.181497</td>\n",
       "      <td>0.355785</td>\n",
       "      <td>0.293558</td>\n",
       "      <td>0.170425</td>\n",
       "      <td>0.899698</td>\n",
       "      <td>0.927390</td>\n",
       "      <td>0.804250</td>\n",
       "      <td>0.918117</td>\n",
       "      <td>0.990412</td>\n",
       "      <td>0.999971</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.491172</td>\n",
       "      <td>0.517408</td>\n",
       "      <td>0.958356</td>\n",
       "      <td>9.761760e-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.877337</td>\n",
       "      <td>0.810659</td>\n",
       "      <td>0.297326</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.866671</td>\n",
       "      <td>0.604588</td>\n",
       "      <td>0.252735</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.202688</td>\n",
       "      <td>0.089205</td>\n",
       "      <td>0.690276</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.576333</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>100</td>\n",
       "      <td>3896</td>\n",
       "      <td>0.520128</td>\n",
       "      <td>0.536171</td>\n",
       "      <td>0.298879</td>\n",
       "      <td>0.399769</td>\n",
       "      <td>0.590710</td>\n",
       "      <td>0.391840</td>\n",
       "      <td>0.973093</td>\n",
       "      <td>0.970430</td>\n",
       "      <td>0.971126</td>\n",
       "      <td>0.966886</td>\n",
       "      <td>0.981126</td>\n",
       "      <td>0.913819</td>\n",
       "      <td>0.982271</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.967291</td>\n",
       "      <td>0.983562</td>\n",
       "      <td>0.959602</td>\n",
       "      <td>9.657815e-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.921055</td>\n",
       "      <td>0.329352</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.847789</td>\n",
       "      <td>0.309230</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.704863</td>\n",
       "      <td>False</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>100</td>\n",
       "      <td>4572</td>\n",
       "      <td>0.490884</td>\n",
       "      <td>0.326860</td>\n",
       "      <td>0.179187</td>\n",
       "      <td>0.310596</td>\n",
       "      <td>0.341777</td>\n",
       "      <td>0.209361</td>\n",
       "      <td>0.956777</td>\n",
       "      <td>0.928798</td>\n",
       "      <td>0.939667</td>\n",
       "      <td>0.925504</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.973819</td>\n",
       "      <td>0.910472</td>\n",
       "      <td>0.965566</td>\n",
       "      <td>0.965742</td>\n",
       "      <td>0.985249</td>\n",
       "      <td>0.941665</td>\n",
       "      <td>9.777083e-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.916390</td>\n",
       "      <td>0.740565</td>\n",
       "      <td>0.356273</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.897864</td>\n",
       "      <td>0.598539</td>\n",
       "      <td>0.266433</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.622213</td>\n",
       "      <td>0.110242</td>\n",
       "      <td>0.956128</td>\n",
       "      <td>0.474998</td>\n",
       "      <td>0.595887</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>100</td>\n",
       "      <td>2823</td>\n",
       "      <td>0.547941</td>\n",
       "      <td>0.272979</td>\n",
       "      <td>0.187657</td>\n",
       "      <td>0.279518</td>\n",
       "      <td>0.278486</td>\n",
       "      <td>0.199103</td>\n",
       "      <td>0.893427</td>\n",
       "      <td>0.902922</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.889492</td>\n",
       "      <td>0.981633</td>\n",
       "      <td>0.978047</td>\n",
       "      <td>0.325492</td>\n",
       "      <td>0.707005</td>\n",
       "      <td>0.970948</td>\n",
       "      <td>0.940419</td>\n",
       "      <td>0.560160</td>\n",
       "      <td>7.171545e-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.974706</td>\n",
       "      <td>0.741642</td>\n",
       "      <td>0.258536</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.949664</td>\n",
       "      <td>0.555684</td>\n",
       "      <td>0.233350</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.528961</td>\n",
       "      <td>False</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>100</td>\n",
       "      <td>1592</td>\n",
       "      <td>0.448422</td>\n",
       "      <td>0.438724</td>\n",
       "      <td>0.198668</td>\n",
       "      <td>0.320943</td>\n",
       "      <td>0.365019</td>\n",
       "      <td>0.222920</td>\n",
       "      <td>0.904967</td>\n",
       "      <td>0.925881</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.906443</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998446</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.969069</td>\n",
       "      <td>0.988745</td>\n",
       "      <td>0.959906</td>\n",
       "      <td>9.800199e-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.951814</td>\n",
       "      <td>0.827605</td>\n",
       "      <td>0.342629</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.900542</td>\n",
       "      <td>0.732674</td>\n",
       "      <td>0.251352</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.229783</td>\n",
       "      <td>0.093575</td>\n",
       "      <td>0.484877</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.663482</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>100</td>\n",
       "      <td>1185</td>\n",
       "      <td>0.450585</td>\n",
       "      <td>0.197340</td>\n",
       "      <td>0.151455</td>\n",
       "      <td>0.301088</td>\n",
       "      <td>0.232980</td>\n",
       "      <td>0.155569</td>\n",
       "      <td>0.909111</td>\n",
       "      <td>0.919647</td>\n",
       "      <td>0.666356</td>\n",
       "      <td>0.911593</td>\n",
       "      <td>0.998078</td>\n",
       "      <td>0.999591</td>\n",
       "      <td>0.828320</td>\n",
       "      <td>0.981882</td>\n",
       "      <td>0.855693</td>\n",
       "      <td>0.859678</td>\n",
       "      <td>0.944414</td>\n",
       "      <td>8.544685e-07</td>\n",
       "      <td>0.977251</td>\n",
       "      <td>0.989587</td>\n",
       "      <td>0.894892</td>\n",
       "      <td>0.957043</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.878630</td>\n",
       "      <td>0.720393</td>\n",
       "      <td>0.329431</td>\n",
       "      <td>0.976848</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.839561</td>\n",
       "      <td>0.424285</td>\n",
       "      <td>0.281615</td>\n",
       "      <td>0.873610</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.218605</td>\n",
       "      <td>0.217137</td>\n",
       "      <td>0.897383</td>\n",
       "      <td>0.539171</td>\n",
       "      <td>0.429050</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>100</td>\n",
       "      <td>883</td>\n",
       "      <td>0.448113</td>\n",
       "      <td>0.601558</td>\n",
       "      <td>0.872109</td>\n",
       "      <td>0.347916</td>\n",
       "      <td>0.597342</td>\n",
       "      <td>0.807199</td>\n",
       "      <td>0.851351</td>\n",
       "      <td>0.933871</td>\n",
       "      <td>0.804250</td>\n",
       "      <td>0.924255</td>\n",
       "      <td>0.999982</td>\n",
       "      <td>0.999745</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.955775</td>\n",
       "      <td>0.983743</td>\n",
       "      <td>0.948569</td>\n",
       "      <td>9.771114e-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.898833</td>\n",
       "      <td>0.295495</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.717540</td>\n",
       "      <td>0.252735</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.323868</td>\n",
       "      <td>0.102040</td>\n",
       "      <td>0.922758</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.690772</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>100</td>\n",
       "      <td>2456</td>\n",
       "      <td>0.526467</td>\n",
       "      <td>0.186860</td>\n",
       "      <td>0.160455</td>\n",
       "      <td>0.183519</td>\n",
       "      <td>0.194339</td>\n",
       "      <td>0.160468</td>\n",
       "      <td>0.891434</td>\n",
       "      <td>0.870208</td>\n",
       "      <td>0.648624</td>\n",
       "      <td>0.670109</td>\n",
       "      <td>0.753885</td>\n",
       "      <td>0.503019</td>\n",
       "      <td>0.635399</td>\n",
       "      <td>0.461174</td>\n",
       "      <td>0.375986</td>\n",
       "      <td>0.697940</td>\n",
       "      <td>0.903339</td>\n",
       "      <td>9.784185e-01</td>\n",
       "      <td>0.896217</td>\n",
       "      <td>0.943120</td>\n",
       "      <td>0.815489</td>\n",
       "      <td>0.913688</td>\n",
       "      <td>0.894577</td>\n",
       "      <td>0.800705</td>\n",
       "      <td>0.662550</td>\n",
       "      <td>0.281065</td>\n",
       "      <td>0.889426</td>\n",
       "      <td>0.875277</td>\n",
       "      <td>0.711187</td>\n",
       "      <td>0.781553</td>\n",
       "      <td>0.329352</td>\n",
       "      <td>0.220122</td>\n",
       "      <td>0.815489</td>\n",
       "      <td>0.794061</td>\n",
       "      <td>0.160622</td>\n",
       "      <td>0.094031</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.255310</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>100</td>\n",
       "      <td>5326</td>\n",
       "      <td>0.504994</td>\n",
       "      <td>0.380940</td>\n",
       "      <td>0.186081</td>\n",
       "      <td>0.370751</td>\n",
       "      <td>0.426500</td>\n",
       "      <td>0.226843</td>\n",
       "      <td>0.899571</td>\n",
       "      <td>0.758539</td>\n",
       "      <td>0.825243</td>\n",
       "      <td>0.529266</td>\n",
       "      <td>0.829671</td>\n",
       "      <td>0.994074</td>\n",
       "      <td>0.741820</td>\n",
       "      <td>0.705662</td>\n",
       "      <td>0.969831</td>\n",
       "      <td>0.849728</td>\n",
       "      <td>0.951450</td>\n",
       "      <td>9.775284e-01</td>\n",
       "      <td>0.928885</td>\n",
       "      <td>0.974094</td>\n",
       "      <td>0.856851</td>\n",
       "      <td>0.946249</td>\n",
       "      <td>0.912354</td>\n",
       "      <td>0.921801</td>\n",
       "      <td>0.722733</td>\n",
       "      <td>0.269533</td>\n",
       "      <td>0.924850</td>\n",
       "      <td>0.918991</td>\n",
       "      <td>0.834325</td>\n",
       "      <td>0.844364</td>\n",
       "      <td>0.630280</td>\n",
       "      <td>0.219975</td>\n",
       "      <td>0.830025</td>\n",
       "      <td>0.817266</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.143986</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.398353</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>100</td>\n",
       "      <td>1389</td>\n",
       "      <td>0.457299</td>\n",
       "      <td>0.173582</td>\n",
       "      <td>0.152193</td>\n",
       "      <td>0.191585</td>\n",
       "      <td>0.158163</td>\n",
       "      <td>0.123656</td>\n",
       "      <td>0.703391</td>\n",
       "      <td>0.821117</td>\n",
       "      <td>0.152634</td>\n",
       "      <td>0.391795</td>\n",
       "      <td>0.576416</td>\n",
       "      <td>0.638776</td>\n",
       "      <td>0.226166</td>\n",
       "      <td>0.145849</td>\n",
       "      <td>0.320535</td>\n",
       "      <td>0.889780</td>\n",
       "      <td>0.051062</td>\n",
       "      <td>8.100848e-02</td>\n",
       "      <td>0.823537</td>\n",
       "      <td>0.892493</td>\n",
       "      <td>0.285404</td>\n",
       "      <td>0.516267</td>\n",
       "      <td>0.857341</td>\n",
       "      <td>0.760775</td>\n",
       "      <td>0.556267</td>\n",
       "      <td>0.266762</td>\n",
       "      <td>0.817845</td>\n",
       "      <td>0.790950</td>\n",
       "      <td>0.375810</td>\n",
       "      <td>0.254872</td>\n",
       "      <td>0.127706</td>\n",
       "      <td>0.116814</td>\n",
       "      <td>0.285404</td>\n",
       "      <td>0.202417</td>\n",
       "      <td>0.152070</td>\n",
       "      <td>0.101173</td>\n",
       "      <td>0.561758</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.114008</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>100</td>\n",
       "      <td>5153</td>\n",
       "      <td>0.503643</td>\n",
       "      <td>0.255375</td>\n",
       "      <td>0.205944</td>\n",
       "      <td>0.346032</td>\n",
       "      <td>0.248265</td>\n",
       "      <td>0.204870</td>\n",
       "      <td>0.917486</td>\n",
       "      <td>0.947452</td>\n",
       "      <td>0.725425</td>\n",
       "      <td>0.938016</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999361</td>\n",
       "      <td>0.987637</td>\n",
       "      <td>0.967503</td>\n",
       "      <td>0.630591</td>\n",
       "      <td>0.802153</td>\n",
       "      <td>0.957659</td>\n",
       "      <td>9.760884e-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.888076</td>\n",
       "      <td>0.671056</td>\n",
       "      <td>0.357490</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.889625</td>\n",
       "      <td>0.508440</td>\n",
       "      <td>0.312266</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.244869</td>\n",
       "      <td>0.099229</td>\n",
       "      <td>0.895382</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.573919</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>100</td>\n",
       "      <td>1975</td>\n",
       "      <td>0.529565</td>\n",
       "      <td>0.246333</td>\n",
       "      <td>0.155104</td>\n",
       "      <td>0.356367</td>\n",
       "      <td>0.262292</td>\n",
       "      <td>0.171215</td>\n",
       "      <td>0.872809</td>\n",
       "      <td>0.842285</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.979756</td>\n",
       "      <td>0.994504</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.505226</td>\n",
       "      <td>0.750124</td>\n",
       "      <td>0.552988</td>\n",
       "      <td>7.964698e-01</td>\n",
       "      <td>0.979904</td>\n",
       "      <td>0.989253</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.967475</td>\n",
       "      <td>0.882543</td>\n",
       "      <td>0.683351</td>\n",
       "      <td>0.322125</td>\n",
       "      <td>0.979160</td>\n",
       "      <td>0.971694</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.200952</td>\n",
       "      <td>0.100981</td>\n",
       "      <td>0.843244</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.533735</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>100</td>\n",
       "      <td>705</td>\n",
       "      <td>0.391949</td>\n",
       "      <td>0.466228</td>\n",
       "      <td>0.296158</td>\n",
       "      <td>0.340712</td>\n",
       "      <td>0.485242</td>\n",
       "      <td>0.402482</td>\n",
       "      <td>0.777286</td>\n",
       "      <td>0.938553</td>\n",
       "      <td>0.700433</td>\n",
       "      <td>0.921546</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999601</td>\n",
       "      <td>0.964791</td>\n",
       "      <td>0.394490</td>\n",
       "      <td>0.975265</td>\n",
       "      <td>0.948569</td>\n",
       "      <td>9.771114e-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.744874</td>\n",
       "      <td>0.291440</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.501246</td>\n",
       "      <td>0.252735</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.176255</td>\n",
       "      <td>0.100868</td>\n",
       "      <td>0.696727</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.619199</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>100</td>\n",
       "      <td>2465</td>\n",
       "      <td>0.407431</td>\n",
       "      <td>0.496899</td>\n",
       "      <td>0.300016</td>\n",
       "      <td>0.338256</td>\n",
       "      <td>0.486943</td>\n",
       "      <td>0.300016</td>\n",
       "      <td>0.939606</td>\n",
       "      <td>0.967033</td>\n",
       "      <td>0.921855</td>\n",
       "      <td>0.955799</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.967520</td>\n",
       "      <td>0.983678</td>\n",
       "      <td>0.964821</td>\n",
       "      <td>9.842812e-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.963409</td>\n",
       "      <td>0.895578</td>\n",
       "      <td>0.982281</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.950474</td>\n",
       "      <td>0.834275</td>\n",
       "      <td>0.862028</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.258714</td>\n",
       "      <td>0.100062</td>\n",
       "      <td>0.920747</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.731418</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>100</td>\n",
       "      <td>4826</td>\n",
       "      <td>0.455823</td>\n",
       "      <td>0.314752</td>\n",
       "      <td>0.164622</td>\n",
       "      <td>0.298948</td>\n",
       "      <td>0.263800</td>\n",
       "      <td>0.141633</td>\n",
       "      <td>0.868833</td>\n",
       "      <td>0.827422</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.704945</td>\n",
       "      <td>0.778416</td>\n",
       "      <td>0.529429</td>\n",
       "      <td>0.568717</td>\n",
       "      <td>0.500489</td>\n",
       "      <td>0.689703</td>\n",
       "      <td>0.615027</td>\n",
       "      <td>0.946773</td>\n",
       "      <td>7.259718e-01</td>\n",
       "      <td>0.909810</td>\n",
       "      <td>0.955494</td>\n",
       "      <td>0.800127</td>\n",
       "      <td>0.918973</td>\n",
       "      <td>0.922813</td>\n",
       "      <td>0.851006</td>\n",
       "      <td>0.652218</td>\n",
       "      <td>0.241316</td>\n",
       "      <td>0.902508</td>\n",
       "      <td>0.881335</td>\n",
       "      <td>0.824919</td>\n",
       "      <td>0.738324</td>\n",
       "      <td>0.517975</td>\n",
       "      <td>0.190031</td>\n",
       "      <td>0.800127</td>\n",
       "      <td>0.776915</td>\n",
       "      <td>0.211602</td>\n",
       "      <td>0.100722</td>\n",
       "      <td>0.927618</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.280085</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>100</td>\n",
       "      <td>4361</td>\n",
       "      <td>0.236921</td>\n",
       "      <td>0.156215</td>\n",
       "      <td>0.192543</td>\n",
       "      <td>0.194459</td>\n",
       "      <td>0.221758</td>\n",
       "      <td>0.182364</td>\n",
       "      <td>0.799354</td>\n",
       "      <td>0.826339</td>\n",
       "      <td>0.736696</td>\n",
       "      <td>0.807197</td>\n",
       "      <td>0.676978</td>\n",
       "      <td>0.620543</td>\n",
       "      <td>0.594695</td>\n",
       "      <td>0.702814</td>\n",
       "      <td>0.466917</td>\n",
       "      <td>0.988845</td>\n",
       "      <td>0.955315</td>\n",
       "      <td>9.816395e-01</td>\n",
       "      <td>0.869828</td>\n",
       "      <td>0.948150</td>\n",
       "      <td>0.836308</td>\n",
       "      <td>0.936795</td>\n",
       "      <td>0.805897</td>\n",
       "      <td>0.713648</td>\n",
       "      <td>0.581492</td>\n",
       "      <td>0.327424</td>\n",
       "      <td>0.869828</td>\n",
       "      <td>0.851196</td>\n",
       "      <td>0.745715</td>\n",
       "      <td>0.583339</td>\n",
       "      <td>0.381752</td>\n",
       "      <td>0.279292</td>\n",
       "      <td>0.836308</td>\n",
       "      <td>0.817298</td>\n",
       "      <td>0.255507</td>\n",
       "      <td>0.100667</td>\n",
       "      <td>0.308610</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.261065</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    from    to  doc2vec:wikipedia,size=300  word2vec:wikipedia,size=300,mean  word2vec:wikipedia,size=300,max  doc2vec:tokenization,wikipedia,size=300  word2vec:tokenization,wikipedia,size=300,mean  word2vec:tokenization,wikipedia,size=300,max  noble coder:precise,tfidf  noble coder:partial,tfidf  noble coder:tokenization,precise,tfidf  noble coder:tokenization,partial,tfidf  topic modeling:nmf,full,topics=50  topic modeling:nmf,full,topics=100  topic modeling:tokenization,nmf,full,topics=50  topic modeling:tokenization,nmf,full,topics=100  topic modeling:lda,full,topics=50  topic modeling:lda,full,topics=100  topic modeling:tokenization,lda,full,topics=50  topic modeling:tokenization,lda,full,topics=100  n-grams:full,words,1-grams,tfidf  n-grams:full,words,1-grams,2-grams,tfidf  n-grams:tokenization,full,words,1-grams,tfidf  n-grams:tokenization,full,words,1-grams,2-grams,tfidf  n-grams:full,nouns,adjectives,1-grams  n-grams:linares_pontes,words,1-grams  \\\n",
       "0    100  1145                    0.484948                          0.503235                         0.263459                                 0.422335                                       0.478481                                      0.288674                   0.863608                   0.927264                                0.804840                                0.899720                           1.000000                            1.000000                                        0.985932                                         0.983500                           0.972852                            0.986386                                        0.956351                                     9.843608e-01                          1.000000                                  1.000000                                       1.000000                                           1.000000                                   1.000000                              1.000000   \n",
       "1    100  4114                    0.343207                          0.260014                         0.185656                                 0.260778                                       0.270105                                      0.180168                   0.936699                   0.963473                                0.915321                                0.957688                           0.999937                            1.000000                                        0.997800                                         0.984195                           0.848661                            0.988527                                        0.969091                                     9.845576e-01                          1.000000                                  1.000000                                       1.000000                                           1.000000                                   1.000000                              0.980422   \n",
       "2    100   231                    0.424650                          0.279231                         0.185035                                 0.296518                                       0.271672                                      0.188429                   0.888187                   0.921801                                1.000000                                1.000000                           0.824749                            0.978728                                        0.556710                                         0.931309                           0.668178                            0.980502                                        0.552669                                     9.768748e-01                          0.943099                                  0.972357                                       0.885369                                           0.931381                                   0.926808                              0.896132   \n",
       "3    100  5244                    0.515200                          0.602756                         0.363885                                 0.428738                                       0.607823                                      0.362408                   1.000000                   0.957448                                1.000000                                0.944979                           1.000000                            1.000000                                        0.999151                                         0.965712                           0.954950                            0.976779                                        0.950524                                     9.776629e-01                          1.000000                                  1.000000                                       1.000000                                           1.000000                                   1.000000                              1.000000   \n",
       "4    100   733                    0.527713                          0.270065                         0.181497                                 0.355785                                       0.293558                                      0.170425                   0.899698                   0.927390                                0.804250                                0.918117                           0.990412                            0.999971                                        0.999996                                         1.000000                           0.491172                            0.517408                                        0.958356                                     9.761760e-01                          1.000000                                  1.000000                                       1.000000                                           1.000000                                   1.000000                              0.877337   \n",
       "5    100  3896                    0.520128                          0.536171                         0.298879                                 0.399769                                       0.590710                                      0.391840                   0.973093                   0.970430                                0.971126                                0.966886                           0.981126                            0.913819                                        0.982271                                         1.000000                           0.967291                            0.983562                                        0.959602                                     9.657815e-01                          1.000000                                  1.000000                                       1.000000                                           1.000000                                   1.000000                              1.000000   \n",
       "6    100  4572                    0.490884                          0.326860                         0.179187                                 0.310596                                       0.341777                                      0.209361                   0.956777                   0.928798                                0.939667                                0.925504                           1.000000                            0.973819                                        0.910472                                         0.965566                           0.965742                            0.985249                                        0.941665                                     9.777083e-01                          1.000000                                  1.000000                                       1.000000                                           1.000000                                   1.000000                              0.916390   \n",
       "7    100  2823                    0.547941                          0.272979                         0.187657                                 0.279518                                       0.278486                                      0.199103                   0.893427                   0.902922                                1.000000                                0.889492                           0.981633                            0.978047                                        0.325492                                         0.707005                           0.970948                            0.940419                                        0.560160                                     7.171545e-01                          1.000000                                  1.000000                                       1.000000                                           1.000000                                   1.000000                              0.974706   \n",
       "8    100  1592                    0.448422                          0.438724                         0.198668                                 0.320943                                       0.365019                                      0.222920                   0.904967                   0.925881                                1.000000                                0.906443                           1.000000                            1.000000                                        0.998446                                         1.000000                           0.969069                            0.988745                                        0.959906                                     9.800199e-01                          1.000000                                  1.000000                                       1.000000                                           1.000000                                   1.000000                              0.951814   \n",
       "9    100  1185                    0.450585                          0.197340                         0.151455                                 0.301088                                       0.232980                                      0.155569                   0.909111                   0.919647                                0.666356                                0.911593                           0.998078                            0.999591                                        0.828320                                         0.981882                           0.855693                            0.859678                                        0.944414                                     8.544685e-07                          0.977251                                  0.989587                                       0.894892                                           0.957043                                   1.000000                              0.878630   \n",
       "10   100   883                    0.448113                          0.601558                         0.872109                                 0.347916                                       0.597342                                      0.807199                   0.851351                   0.933871                                0.804250                                0.924255                           0.999982                            0.999745                                        1.000000                                         1.000000                           0.955775                            0.983743                                        0.948569                                     9.771114e-01                          1.000000                                  1.000000                                       1.000000                                           1.000000                                   1.000000                              1.000000   \n",
       "11   100  2456                    0.526467                          0.186860                         0.160455                                 0.183519                                       0.194339                                      0.160468                   0.891434                   0.870208                                0.648624                                0.670109                           0.753885                            0.503019                                        0.635399                                         0.461174                           0.375986                            0.697940                                        0.903339                                     9.784185e-01                          0.896217                                  0.943120                                       0.815489                                           0.913688                                   0.894577                              0.800705   \n",
       "12   100  5326                    0.504994                          0.380940                         0.186081                                 0.370751                                       0.426500                                      0.226843                   0.899571                   0.758539                                0.825243                                0.529266                           0.829671                            0.994074                                        0.741820                                         0.705662                           0.969831                            0.849728                                        0.951450                                     9.775284e-01                          0.928885                                  0.974094                                       0.856851                                           0.946249                                   0.912354                              0.921801   \n",
       "13   100  1389                    0.457299                          0.173582                         0.152193                                 0.191585                                       0.158163                                      0.123656                   0.703391                   0.821117                                0.152634                                0.391795                           0.576416                            0.638776                                        0.226166                                         0.145849                           0.320535                            0.889780                                        0.051062                                     8.100848e-02                          0.823537                                  0.892493                                       0.285404                                           0.516267                                   0.857341                              0.760775   \n",
       "14   100  5153                    0.503643                          0.255375                         0.205944                                 0.346032                                       0.248265                                      0.204870                   0.917486                   0.947452                                0.725425                                0.938016                           1.000000                            0.999361                                        0.987637                                         0.967503                           0.630591                            0.802153                                        0.957659                                     9.760884e-01                          1.000000                                  1.000000                                       1.000000                                           1.000000                                   1.000000                              0.888076   \n",
       "15   100  1975                    0.529565                          0.246333                         0.155104                                 0.356367                                       0.262292                                      0.171215                   0.872809                   0.842285                                1.000000                                1.000000                           0.979756                            0.994504                                        1.000000                                         1.000000                           0.505226                            0.750124                                        0.552988                                     7.964698e-01                          0.979904                                  0.989253                                       1.000000                                           1.000000                                   0.967475                              0.882543   \n",
       "16   100   705                    0.391949                          0.466228                         0.296158                                 0.340712                                       0.485242                                      0.402482                   0.777286                   0.938553                                0.700433                                0.921546                           1.000000                            1.000000                                        0.999601                                         0.964791                           0.394490                            0.975265                                        0.948569                                     9.771114e-01                          1.000000                                  1.000000                                       1.000000                                           1.000000                                   1.000000                              1.000000   \n",
       "17   100  2465                    0.407431                          0.496899                         0.300016                                 0.338256                                       0.486943                                      0.300016                   0.939606                   0.967033                                0.921855                                0.955799                           1.000000                            1.000000                                        1.000000                                         1.000000                           0.967520                            0.983678                                        0.964821                                     9.842812e-01                          1.000000                                  1.000000                                       1.000000                                           1.000000                                   1.000000                              0.963409   \n",
       "18   100  4826                    0.455823                          0.314752                         0.164622                                 0.298948                                       0.263800                                      0.141633                   0.868833                   0.827422                                1.000000                                0.704945                           0.778416                            0.529429                                        0.568717                                         0.500489                           0.689703                            0.615027                                        0.946773                                     7.259718e-01                          0.909810                                  0.955494                                       0.800127                                           0.918973                                   0.922813                              0.851006   \n",
       "19   100  4361                    0.236921                          0.156215                         0.192543                                 0.194459                                       0.221758                                      0.182364                   0.799354                   0.826339                                0.736696                                0.807197                           0.676978                            0.620543                                        0.594695                                         0.702814                           0.466917                            0.988845                                        0.955315                                     9.816395e-01                          0.869828                                  0.948150                                       0.836308                                           0.936795                                   0.805897                              0.713648   \n",
       "\n",
       "    n-grams:full,precise_annotations,words,1-grams  n-grams:full,partial_annotations,words,1-grams  n-grams:full,plant overrepresented tokens,1-grams  n-grams:full,bio ontology tokens,1-grams  n-grams:tokenization,full,nouns,adjectives,1-grams  n-grams:tokenization,linares_pontes,words,1-grams  n-grams:tokenization,full,precise_annotations,words,1-grams  n-grams:tokenization,full,partial_annotations,words,1-grams  n-grams:tokenization,full,plant overrepresented tokens,1-grams  n-grams:tokenization,full,bio ontology tokens,1-grams  go:union  po:union  go:minimum  po:minimum      mean   same  pathways  kegg_only  pmn_only  subsets  known  predicted  orthologs  eqs_distance  \n",
       "0                                         0.840402                                        0.568991                                           1.000000                                  1.000000                                           1.000000                                            1.000000                                           0.591617                                                     0.432781                                                     1.000000                                                        1.000000      1.000000  0.199791    1.000000    0.646186  0.696545  False        -1         -1        -1       -1   -1.0       -1.0       -1.0           1.0  \n",
       "1                                         0.812361                                        0.422756                                           1.000000                                  1.000000                                           1.000000                                            0.980264                                           0.748194                                                     0.437357                                                     1.000000                                                        1.000000      1.000000  1.000000    1.000000    1.000000  0.637134   True        -1         -1        -1       -1    0.0        0.0       -1.0          -1.0  \n",
       "2                                         0.560416                                        0.496319                                           0.943099                                  0.928882                                           0.813392                                            0.868671                                           0.387241                                                     0.423178                                                     0.885369                                                        0.858600      0.240786  0.097509    0.906796    0.000000  0.385529   True        -1         -1        -1        0    0.0        0.0       -1.0           1.0  \n",
       "3                                         1.000000                                        0.978017                                           1.000000                                  1.000000                                           1.000000                                            1.000000                                           1.000000                                                     0.897769                                                     1.000000                                                        1.000000      0.367580  0.108020    0.690276    0.474998  0.770669   True        -1         -1        -1       -1    0.0        0.0       -1.0          -1.0  \n",
       "4                                         0.810659                                        0.297326                                           1.000000                                  1.000000                                           1.000000                                            0.866671                                           0.604588                                                     0.252735                                                     1.000000                                                        1.000000      0.202688  0.089205    0.690276    0.000000  0.576333   True        -1         -1        -1        0    0.0        0.0       -1.0           1.0  \n",
       "5                                         0.921055                                        0.329352                                           1.000000                                  1.000000                                           1.000000                                            1.000000                                           0.847789                                                     0.309230                                                     1.000000                                                        1.000000      1.000000  1.000000    1.000000    1.000000  0.704863  False        -1         -1        -1       -1   -1.0       -1.0       -1.0          -1.0  \n",
       "6                                         0.740565                                        0.356273                                           1.000000                                  1.000000                                           1.000000                                            0.897864                                           0.598539                                                     0.266433                                                     1.000000                                                        1.000000      0.622213  0.110242    0.956128    0.474998  0.595887   True        -1         -1        -1       -1    0.0        0.0       -1.0          -1.0  \n",
       "7                                         0.741642                                        0.258536                                           1.000000                                  1.000000                                           1.000000                                            0.949664                                           0.555684                                                     0.233350                                                     1.000000                                                        1.000000      1.000000  1.000000    1.000000    1.000000  0.528961  False        -1         -1        -1       -1   -1.0       -1.0       -1.0          -1.0  \n",
       "8                                         0.827605                                        0.342629                                           1.000000                                  1.000000                                           1.000000                                            0.900542                                           0.732674                                                     0.251352                                                     1.000000                                                        1.000000      0.229783  0.093575    0.484877    0.000000  0.663482   True        -1         -1        -1        0    0.0        0.0       -1.0           1.0  \n",
       "9                                         0.720393                                        0.329431                                           0.976848                                  1.000000                                           1.000000                                            0.839561                                           0.424285                                                     0.281615                                                     0.873610                                                        1.000000      0.218605  0.217137    0.897383    0.539171  0.429050   True        -1         -1        -1        0    0.0        0.0       -1.0           1.0  \n",
       "10                                        0.898833                                        0.295495                                           1.000000                                  1.000000                                           1.000000                                            1.000000                                           0.717540                                                     0.252735                                                     1.000000                                                        1.000000      0.323868  0.102040    0.922758    0.000000  0.690772   True        -1         -1        -1        0    0.0        0.0       -1.0           1.0  \n",
       "11                                        0.662550                                        0.281065                                           0.889426                                  0.875277                                           0.711187                                            0.781553                                           0.329352                                                     0.220122                                                     0.815489                                                        0.794061      0.160622  0.094031    0.000000    0.000000  0.255310   True        -1         -1        -1        1    0.0        0.0       -1.0           1.0  \n",
       "12                                        0.722733                                        0.269533                                           0.924850                                  0.918991                                           0.834325                                            0.844364                                           0.630280                                                     0.219975                                                     0.830025                                                        0.817266      1.000000  0.143986    1.000000    0.000000  0.398353   True        -1         -1        -1       -1    0.0        0.0       -1.0          -1.0  \n",
       "13                                        0.556267                                        0.266762                                           0.817845                                  0.790950                                           0.375810                                            0.254872                                           0.127706                                                     0.116814                                                     0.285404                                                        0.202417      0.152070  0.101173    0.561758    0.000000  0.114008   True        -1         -1        -1        1    0.0        0.0       -1.0           1.0  \n",
       "14                                        0.671056                                        0.357490                                           1.000000                                  1.000000                                           1.000000                                            0.889625                                           0.508440                                                     0.312266                                                     1.000000                                                        1.000000      0.244869  0.099229    0.895382    0.000000  0.573919   True        -1         -1        -1       -1    0.0        0.0       -1.0          -1.0  \n",
       "15                                        0.683351                                        0.322125                                           0.979160                                  0.971694                                           1.000000                                            1.000000                                           1.000000                                                     1.000000                                                     1.000000                                                        1.000000      0.200952  0.100981    0.843244    0.000000  0.533735   True        -1         -1        -1        0    0.0        0.0       -1.0           1.0  \n",
       "16                                        0.744874                                        0.291440                                           1.000000                                  1.000000                                           1.000000                                            1.000000                                           0.501246                                                     0.252735                                                     1.000000                                                        1.000000      0.176255  0.100868    0.696727    0.000000  0.619199   True        -1         -1        -1        0    0.0        0.0       -1.0           1.0  \n",
       "17                                        0.895578                                        0.982281                                           1.000000                                  1.000000                                           1.000000                                            0.950474                                           0.834275                                                     0.862028                                                     1.000000                                                        1.000000      0.258714  0.100062    0.920747    0.000000  0.731418   True        -1         -1        -1        0    0.0        0.0       -1.0           1.0  \n",
       "18                                        0.652218                                        0.241316                                           0.902508                                  0.881335                                           0.824919                                            0.738324                                           0.517975                                                     0.190031                                                     0.800127                                                        0.776915      0.211602  0.100722    0.927618    0.000000  0.280085   True        -1         -1        -1       -1    0.0        0.0       -1.0          -1.0  \n",
       "19                                        0.581492                                        0.327424                                           0.869828                                  0.851196                                           0.745715                                            0.583339                                           0.381752                                                     0.279292                                                     0.836308                                                        0.817298      0.255507  0.100667    0.308610    0.000000  0.261065   True        -1         -1        -1       -1    0.0        0.0       -1.0          -1.0  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add a column that indicates whether or not both genes of the pair are mapped to all the curation types.\n",
    "relevant_ids = set(ow_edgelist.ids)\n",
    "df[\"from_is_valid\"] = df[\"from\"].map(lambda x: x in relevant_ids)\n",
    "df[\"to_is_valid\"] = df[\"to\"].map(lambda x: x in relevant_ids)\n",
    "df[\"pair_is_valid\"] = df[\"from_is_valid\"]*df[\"to_is_valid\"]\n",
    "\n",
    "# Add a column giving the actual target output value for this biological task, with -1 for the irrelevant rows.\n",
    "df[\"eqs_distance\"] = -1\n",
    "df = df.merge(right=ow_edgelist.df, how=\"left\", on=[\"from\",\"to\"])\n",
    "df[\"value\"].fillna(value=0, inplace=True)\n",
    "df.loc[(df[\"pair_is_valid\"]==True),\"eqs_distance\"] = 1-df[\"value\"]\n",
    "df.drop(labels=[\"from_is_valid\",\"to_is_valid\",\"pair_is_valid\",\"value\"], axis=\"columns\", inplace=True)\n",
    "\n",
    "# Also, add the curated EQ approach to the list of column names that reference approaches to be evaluated.\n",
    "names.append(\"eqs_distance\")\n",
    "\n",
    "df.head(20)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"curated\"></a>\n",
    "### Checking whether gene pairs are considered curated or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>from</th>\n",
       "      <th>to</th>\n",
       "      <th>doc2vec:wikipedia,size=300</th>\n",
       "      <th>word2vec:wikipedia,size=300,mean</th>\n",
       "      <th>word2vec:wikipedia,size=300,max</th>\n",
       "      <th>doc2vec:tokenization,wikipedia,size=300</th>\n",
       "      <th>word2vec:tokenization,wikipedia,size=300,mean</th>\n",
       "      <th>word2vec:tokenization,wikipedia,size=300,max</th>\n",
       "      <th>noble coder:precise,tfidf</th>\n",
       "      <th>noble coder:partial,tfidf</th>\n",
       "      <th>noble coder:tokenization,precise,tfidf</th>\n",
       "      <th>noble coder:tokenization,partial,tfidf</th>\n",
       "      <th>topic modeling:nmf,full,topics=50</th>\n",
       "      <th>topic modeling:nmf,full,topics=100</th>\n",
       "      <th>topic modeling:tokenization,nmf,full,topics=50</th>\n",
       "      <th>topic modeling:tokenization,nmf,full,topics=100</th>\n",
       "      <th>topic modeling:lda,full,topics=50</th>\n",
       "      <th>topic modeling:lda,full,topics=100</th>\n",
       "      <th>topic modeling:tokenization,lda,full,topics=50</th>\n",
       "      <th>topic modeling:tokenization,lda,full,topics=100</th>\n",
       "      <th>n-grams:full,words,1-grams,tfidf</th>\n",
       "      <th>n-grams:full,words,1-grams,2-grams,tfidf</th>\n",
       "      <th>n-grams:tokenization,full,words,1-grams,tfidf</th>\n",
       "      <th>n-grams:tokenization,full,words,1-grams,2-grams,tfidf</th>\n",
       "      <th>n-grams:full,nouns,adjectives,1-grams</th>\n",
       "      <th>n-grams:linares_pontes,words,1-grams</th>\n",
       "      <th>n-grams:full,precise_annotations,words,1-grams</th>\n",
       "      <th>n-grams:full,partial_annotations,words,1-grams</th>\n",
       "      <th>n-grams:full,plant overrepresented tokens,1-grams</th>\n",
       "      <th>n-grams:full,bio ontology tokens,1-grams</th>\n",
       "      <th>n-grams:tokenization,full,nouns,adjectives,1-grams</th>\n",
       "      <th>n-grams:tokenization,linares_pontes,words,1-grams</th>\n",
       "      <th>n-grams:tokenization,full,precise_annotations,words,1-grams</th>\n",
       "      <th>n-grams:tokenization,full,partial_annotations,words,1-grams</th>\n",
       "      <th>n-grams:tokenization,full,plant overrepresented tokens,1-grams</th>\n",
       "      <th>n-grams:tokenization,full,bio ontology tokens,1-grams</th>\n",
       "      <th>go:union</th>\n",
       "      <th>po:union</th>\n",
       "      <th>go:minimum</th>\n",
       "      <th>po:minimum</th>\n",
       "      <th>mean</th>\n",
       "      <th>same</th>\n",
       "      <th>pathways</th>\n",
       "      <th>kegg_only</th>\n",
       "      <th>pmn_only</th>\n",
       "      <th>subsets</th>\n",
       "      <th>known</th>\n",
       "      <th>predicted</th>\n",
       "      <th>orthologs</th>\n",
       "      <th>eqs_distance</th>\n",
       "      <th>curated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>1145</td>\n",
       "      <td>0.484948</td>\n",
       "      <td>0.503235</td>\n",
       "      <td>0.263459</td>\n",
       "      <td>0.422335</td>\n",
       "      <td>0.478481</td>\n",
       "      <td>0.288674</td>\n",
       "      <td>0.863608</td>\n",
       "      <td>0.927264</td>\n",
       "      <td>0.804840</td>\n",
       "      <td>0.899720</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.985932</td>\n",
       "      <td>0.983500</td>\n",
       "      <td>0.972852</td>\n",
       "      <td>0.986386</td>\n",
       "      <td>0.956351</td>\n",
       "      <td>9.843608e-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.840402</td>\n",
       "      <td>0.568991</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.591617</td>\n",
       "      <td>0.432781</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.199791</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.646186</td>\n",
       "      <td>0.696545</td>\n",
       "      <td>False</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100</td>\n",
       "      <td>4114</td>\n",
       "      <td>0.343207</td>\n",
       "      <td>0.260014</td>\n",
       "      <td>0.185656</td>\n",
       "      <td>0.260778</td>\n",
       "      <td>0.270105</td>\n",
       "      <td>0.180168</td>\n",
       "      <td>0.936699</td>\n",
       "      <td>0.963473</td>\n",
       "      <td>0.915321</td>\n",
       "      <td>0.957688</td>\n",
       "      <td>0.999937</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.997800</td>\n",
       "      <td>0.984195</td>\n",
       "      <td>0.848661</td>\n",
       "      <td>0.988527</td>\n",
       "      <td>0.969091</td>\n",
       "      <td>9.845576e-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.980422</td>\n",
       "      <td>0.812361</td>\n",
       "      <td>0.422756</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.980264</td>\n",
       "      <td>0.748194</td>\n",
       "      <td>0.437357</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.637134</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>231</td>\n",
       "      <td>0.424650</td>\n",
       "      <td>0.279231</td>\n",
       "      <td>0.185035</td>\n",
       "      <td>0.296518</td>\n",
       "      <td>0.271672</td>\n",
       "      <td>0.188429</td>\n",
       "      <td>0.888187</td>\n",
       "      <td>0.921801</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.824749</td>\n",
       "      <td>0.978728</td>\n",
       "      <td>0.556710</td>\n",
       "      <td>0.931309</td>\n",
       "      <td>0.668178</td>\n",
       "      <td>0.980502</td>\n",
       "      <td>0.552669</td>\n",
       "      <td>9.768748e-01</td>\n",
       "      <td>0.943099</td>\n",
       "      <td>0.972357</td>\n",
       "      <td>0.885369</td>\n",
       "      <td>0.931381</td>\n",
       "      <td>0.926808</td>\n",
       "      <td>0.896132</td>\n",
       "      <td>0.560416</td>\n",
       "      <td>0.496319</td>\n",
       "      <td>0.943099</td>\n",
       "      <td>0.928882</td>\n",
       "      <td>0.813392</td>\n",
       "      <td>0.868671</td>\n",
       "      <td>0.387241</td>\n",
       "      <td>0.423178</td>\n",
       "      <td>0.885369</td>\n",
       "      <td>0.8586</td>\n",
       "      <td>0.240786</td>\n",
       "      <td>0.097509</td>\n",
       "      <td>0.906796</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.385529</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100</td>\n",
       "      <td>5244</td>\n",
       "      <td>0.515200</td>\n",
       "      <td>0.602756</td>\n",
       "      <td>0.363885</td>\n",
       "      <td>0.428738</td>\n",
       "      <td>0.607823</td>\n",
       "      <td>0.362408</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.957448</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.944979</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999151</td>\n",
       "      <td>0.965712</td>\n",
       "      <td>0.954950</td>\n",
       "      <td>0.976779</td>\n",
       "      <td>0.950524</td>\n",
       "      <td>9.776629e-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.978017</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.897769</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.367580</td>\n",
       "      <td>0.108020</td>\n",
       "      <td>0.690276</td>\n",
       "      <td>0.474998</td>\n",
       "      <td>0.770669</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100</td>\n",
       "      <td>733</td>\n",
       "      <td>0.527713</td>\n",
       "      <td>0.270065</td>\n",
       "      <td>0.181497</td>\n",
       "      <td>0.355785</td>\n",
       "      <td>0.293558</td>\n",
       "      <td>0.170425</td>\n",
       "      <td>0.899698</td>\n",
       "      <td>0.927390</td>\n",
       "      <td>0.804250</td>\n",
       "      <td>0.918117</td>\n",
       "      <td>0.990412</td>\n",
       "      <td>0.999971</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.491172</td>\n",
       "      <td>0.517408</td>\n",
       "      <td>0.958356</td>\n",
       "      <td>9.761760e-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.877337</td>\n",
       "      <td>0.810659</td>\n",
       "      <td>0.297326</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.866671</td>\n",
       "      <td>0.604588</td>\n",
       "      <td>0.252735</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.202688</td>\n",
       "      <td>0.089205</td>\n",
       "      <td>0.690276</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.576333</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>100</td>\n",
       "      <td>3896</td>\n",
       "      <td>0.520128</td>\n",
       "      <td>0.536171</td>\n",
       "      <td>0.298879</td>\n",
       "      <td>0.399769</td>\n",
       "      <td>0.590710</td>\n",
       "      <td>0.391840</td>\n",
       "      <td>0.973093</td>\n",
       "      <td>0.970430</td>\n",
       "      <td>0.971126</td>\n",
       "      <td>0.966886</td>\n",
       "      <td>0.981126</td>\n",
       "      <td>0.913819</td>\n",
       "      <td>0.982271</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.967291</td>\n",
       "      <td>0.983562</td>\n",
       "      <td>0.959602</td>\n",
       "      <td>9.657815e-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.921055</td>\n",
       "      <td>0.329352</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.847789</td>\n",
       "      <td>0.309230</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.704863</td>\n",
       "      <td>False</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>100</td>\n",
       "      <td>4572</td>\n",
       "      <td>0.490884</td>\n",
       "      <td>0.326860</td>\n",
       "      <td>0.179187</td>\n",
       "      <td>0.310596</td>\n",
       "      <td>0.341777</td>\n",
       "      <td>0.209361</td>\n",
       "      <td>0.956777</td>\n",
       "      <td>0.928798</td>\n",
       "      <td>0.939667</td>\n",
       "      <td>0.925504</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.973819</td>\n",
       "      <td>0.910472</td>\n",
       "      <td>0.965566</td>\n",
       "      <td>0.965742</td>\n",
       "      <td>0.985249</td>\n",
       "      <td>0.941665</td>\n",
       "      <td>9.777083e-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.916390</td>\n",
       "      <td>0.740565</td>\n",
       "      <td>0.356273</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.897864</td>\n",
       "      <td>0.598539</td>\n",
       "      <td>0.266433</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.622213</td>\n",
       "      <td>0.110242</td>\n",
       "      <td>0.956128</td>\n",
       "      <td>0.474998</td>\n",
       "      <td>0.595887</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>100</td>\n",
       "      <td>2823</td>\n",
       "      <td>0.547941</td>\n",
       "      <td>0.272979</td>\n",
       "      <td>0.187657</td>\n",
       "      <td>0.279518</td>\n",
       "      <td>0.278486</td>\n",
       "      <td>0.199103</td>\n",
       "      <td>0.893427</td>\n",
       "      <td>0.902922</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.889492</td>\n",
       "      <td>0.981633</td>\n",
       "      <td>0.978047</td>\n",
       "      <td>0.325492</td>\n",
       "      <td>0.707005</td>\n",
       "      <td>0.970948</td>\n",
       "      <td>0.940419</td>\n",
       "      <td>0.560160</td>\n",
       "      <td>7.171545e-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.974706</td>\n",
       "      <td>0.741642</td>\n",
       "      <td>0.258536</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.949664</td>\n",
       "      <td>0.555684</td>\n",
       "      <td>0.233350</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.528961</td>\n",
       "      <td>False</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>100</td>\n",
       "      <td>1592</td>\n",
       "      <td>0.448422</td>\n",
       "      <td>0.438724</td>\n",
       "      <td>0.198668</td>\n",
       "      <td>0.320943</td>\n",
       "      <td>0.365019</td>\n",
       "      <td>0.222920</td>\n",
       "      <td>0.904967</td>\n",
       "      <td>0.925881</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.906443</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998446</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.969069</td>\n",
       "      <td>0.988745</td>\n",
       "      <td>0.959906</td>\n",
       "      <td>9.800199e-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.951814</td>\n",
       "      <td>0.827605</td>\n",
       "      <td>0.342629</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.900542</td>\n",
       "      <td>0.732674</td>\n",
       "      <td>0.251352</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.229783</td>\n",
       "      <td>0.093575</td>\n",
       "      <td>0.484877</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.663482</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>100</td>\n",
       "      <td>1185</td>\n",
       "      <td>0.450585</td>\n",
       "      <td>0.197340</td>\n",
       "      <td>0.151455</td>\n",
       "      <td>0.301088</td>\n",
       "      <td>0.232980</td>\n",
       "      <td>0.155569</td>\n",
       "      <td>0.909111</td>\n",
       "      <td>0.919647</td>\n",
       "      <td>0.666356</td>\n",
       "      <td>0.911593</td>\n",
       "      <td>0.998078</td>\n",
       "      <td>0.999591</td>\n",
       "      <td>0.828320</td>\n",
       "      <td>0.981882</td>\n",
       "      <td>0.855693</td>\n",
       "      <td>0.859678</td>\n",
       "      <td>0.944414</td>\n",
       "      <td>8.544685e-07</td>\n",
       "      <td>0.977251</td>\n",
       "      <td>0.989587</td>\n",
       "      <td>0.894892</td>\n",
       "      <td>0.957043</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.878630</td>\n",
       "      <td>0.720393</td>\n",
       "      <td>0.329431</td>\n",
       "      <td>0.976848</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.839561</td>\n",
       "      <td>0.424285</td>\n",
       "      <td>0.281615</td>\n",
       "      <td>0.873610</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.218605</td>\n",
       "      <td>0.217137</td>\n",
       "      <td>0.897383</td>\n",
       "      <td>0.539171</td>\n",
       "      <td>0.429050</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   from    to  doc2vec:wikipedia,size=300  word2vec:wikipedia,size=300,mean  word2vec:wikipedia,size=300,max  doc2vec:tokenization,wikipedia,size=300  word2vec:tokenization,wikipedia,size=300,mean  word2vec:tokenization,wikipedia,size=300,max  noble coder:precise,tfidf  noble coder:partial,tfidf  noble coder:tokenization,precise,tfidf  noble coder:tokenization,partial,tfidf  topic modeling:nmf,full,topics=50  topic modeling:nmf,full,topics=100  topic modeling:tokenization,nmf,full,topics=50  topic modeling:tokenization,nmf,full,topics=100  topic modeling:lda,full,topics=50  topic modeling:lda,full,topics=100  topic modeling:tokenization,lda,full,topics=50  topic modeling:tokenization,lda,full,topics=100  n-grams:full,words,1-grams,tfidf  n-grams:full,words,1-grams,2-grams,tfidf  n-grams:tokenization,full,words,1-grams,tfidf  n-grams:tokenization,full,words,1-grams,2-grams,tfidf  n-grams:full,nouns,adjectives,1-grams  n-grams:linares_pontes,words,1-grams  \\\n",
       "0   100  1145                    0.484948                          0.503235                         0.263459                                 0.422335                                       0.478481                                      0.288674                   0.863608                   0.927264                                0.804840                                0.899720                           1.000000                            1.000000                                        0.985932                                         0.983500                           0.972852                            0.986386                                        0.956351                                     9.843608e-01                          1.000000                                  1.000000                                       1.000000                                           1.000000                                   1.000000                              1.000000   \n",
       "1   100  4114                    0.343207                          0.260014                         0.185656                                 0.260778                                       0.270105                                      0.180168                   0.936699                   0.963473                                0.915321                                0.957688                           0.999937                            1.000000                                        0.997800                                         0.984195                           0.848661                            0.988527                                        0.969091                                     9.845576e-01                          1.000000                                  1.000000                                       1.000000                                           1.000000                                   1.000000                              0.980422   \n",
       "2   100   231                    0.424650                          0.279231                         0.185035                                 0.296518                                       0.271672                                      0.188429                   0.888187                   0.921801                                1.000000                                1.000000                           0.824749                            0.978728                                        0.556710                                         0.931309                           0.668178                            0.980502                                        0.552669                                     9.768748e-01                          0.943099                                  0.972357                                       0.885369                                           0.931381                                   0.926808                              0.896132   \n",
       "3   100  5244                    0.515200                          0.602756                         0.363885                                 0.428738                                       0.607823                                      0.362408                   1.000000                   0.957448                                1.000000                                0.944979                           1.000000                            1.000000                                        0.999151                                         0.965712                           0.954950                            0.976779                                        0.950524                                     9.776629e-01                          1.000000                                  1.000000                                       1.000000                                           1.000000                                   1.000000                              1.000000   \n",
       "4   100   733                    0.527713                          0.270065                         0.181497                                 0.355785                                       0.293558                                      0.170425                   0.899698                   0.927390                                0.804250                                0.918117                           0.990412                            0.999971                                        0.999996                                         1.000000                           0.491172                            0.517408                                        0.958356                                     9.761760e-01                          1.000000                                  1.000000                                       1.000000                                           1.000000                                   1.000000                              0.877337   \n",
       "5   100  3896                    0.520128                          0.536171                         0.298879                                 0.399769                                       0.590710                                      0.391840                   0.973093                   0.970430                                0.971126                                0.966886                           0.981126                            0.913819                                        0.982271                                         1.000000                           0.967291                            0.983562                                        0.959602                                     9.657815e-01                          1.000000                                  1.000000                                       1.000000                                           1.000000                                   1.000000                              1.000000   \n",
       "6   100  4572                    0.490884                          0.326860                         0.179187                                 0.310596                                       0.341777                                      0.209361                   0.956777                   0.928798                                0.939667                                0.925504                           1.000000                            0.973819                                        0.910472                                         0.965566                           0.965742                            0.985249                                        0.941665                                     9.777083e-01                          1.000000                                  1.000000                                       1.000000                                           1.000000                                   1.000000                              0.916390   \n",
       "7   100  2823                    0.547941                          0.272979                         0.187657                                 0.279518                                       0.278486                                      0.199103                   0.893427                   0.902922                                1.000000                                0.889492                           0.981633                            0.978047                                        0.325492                                         0.707005                           0.970948                            0.940419                                        0.560160                                     7.171545e-01                          1.000000                                  1.000000                                       1.000000                                           1.000000                                   1.000000                              0.974706   \n",
       "8   100  1592                    0.448422                          0.438724                         0.198668                                 0.320943                                       0.365019                                      0.222920                   0.904967                   0.925881                                1.000000                                0.906443                           1.000000                            1.000000                                        0.998446                                         1.000000                           0.969069                            0.988745                                        0.959906                                     9.800199e-01                          1.000000                                  1.000000                                       1.000000                                           1.000000                                   1.000000                              0.951814   \n",
       "9   100  1185                    0.450585                          0.197340                         0.151455                                 0.301088                                       0.232980                                      0.155569                   0.909111                   0.919647                                0.666356                                0.911593                           0.998078                            0.999591                                        0.828320                                         0.981882                           0.855693                            0.859678                                        0.944414                                     8.544685e-07                          0.977251                                  0.989587                                       0.894892                                           0.957043                                   1.000000                              0.878630   \n",
       "\n",
       "   n-grams:full,precise_annotations,words,1-grams  n-grams:full,partial_annotations,words,1-grams  n-grams:full,plant overrepresented tokens,1-grams  n-grams:full,bio ontology tokens,1-grams  n-grams:tokenization,full,nouns,adjectives,1-grams  n-grams:tokenization,linares_pontes,words,1-grams  n-grams:tokenization,full,precise_annotations,words,1-grams  n-grams:tokenization,full,partial_annotations,words,1-grams  n-grams:tokenization,full,plant overrepresented tokens,1-grams  n-grams:tokenization,full,bio ontology tokens,1-grams  go:union  po:union  go:minimum  po:minimum      mean   same  pathways  kegg_only  pmn_only  subsets  known  predicted  orthologs  eqs_distance  curated  \n",
       "0                                        0.840402                                        0.568991                                           1.000000                                  1.000000                                           1.000000                                            1.000000                                           0.591617                                                     0.432781                                                     1.000000                                                          1.0000      1.000000  0.199791    1.000000    0.646186  0.696545  False        -1         -1        -1       -1   -1.0       -1.0       -1.0           1.0     True  \n",
       "1                                        0.812361                                        0.422756                                           1.000000                                  1.000000                                           1.000000                                            0.980264                                           0.748194                                                     0.437357                                                     1.000000                                                          1.0000      1.000000  1.000000    1.000000    1.000000  0.637134   True        -1         -1        -1       -1    0.0        0.0       -1.0          -1.0    False  \n",
       "2                                        0.560416                                        0.496319                                           0.943099                                  0.928882                                           0.813392                                            0.868671                                           0.387241                                                     0.423178                                                     0.885369                                                          0.8586      0.240786  0.097509    0.906796    0.000000  0.385529   True        -1         -1        -1        0    0.0        0.0       -1.0           1.0     True  \n",
       "3                                        1.000000                                        0.978017                                           1.000000                                  1.000000                                           1.000000                                            1.000000                                           1.000000                                                     0.897769                                                     1.000000                                                          1.0000      0.367580  0.108020    0.690276    0.474998  0.770669   True        -1         -1        -1       -1    0.0        0.0       -1.0          -1.0    False  \n",
       "4                                        0.810659                                        0.297326                                           1.000000                                  1.000000                                           1.000000                                            0.866671                                           0.604588                                                     0.252735                                                     1.000000                                                          1.0000      0.202688  0.089205    0.690276    0.000000  0.576333   True        -1         -1        -1        0    0.0        0.0       -1.0           1.0     True  \n",
       "5                                        0.921055                                        0.329352                                           1.000000                                  1.000000                                           1.000000                                            1.000000                                           0.847789                                                     0.309230                                                     1.000000                                                          1.0000      1.000000  1.000000    1.000000    1.000000  0.704863  False        -1         -1        -1       -1   -1.0       -1.0       -1.0          -1.0    False  \n",
       "6                                        0.740565                                        0.356273                                           1.000000                                  1.000000                                           1.000000                                            0.897864                                           0.598539                                                     0.266433                                                     1.000000                                                          1.0000      0.622213  0.110242    0.956128    0.474998  0.595887   True        -1         -1        -1       -1    0.0        0.0       -1.0          -1.0    False  \n",
       "7                                        0.741642                                        0.258536                                           1.000000                                  1.000000                                           1.000000                                            0.949664                                           0.555684                                                     0.233350                                                     1.000000                                                          1.0000      1.000000  1.000000    1.000000    1.000000  0.528961  False        -1         -1        -1       -1   -1.0       -1.0       -1.0          -1.0    False  \n",
       "8                                        0.827605                                        0.342629                                           1.000000                                  1.000000                                           1.000000                                            0.900542                                           0.732674                                                     0.251352                                                     1.000000                                                          1.0000      0.229783  0.093575    0.484877    0.000000  0.663482   True        -1         -1        -1        0    0.0        0.0       -1.0           1.0     True  \n",
       "9                                        0.720393                                        0.329431                                           0.976848                                  1.000000                                           1.000000                                            0.839561                                           0.424285                                                     0.281615                                                     0.873610                                                          1.0000      0.218605  0.217137    0.897383    0.539171  0.429050   True        -1         -1        -1        0    0.0        0.0       -1.0           1.0     True  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add a column that indicates whether or not both genes of the pair are mapped to all the curation types.\n",
    "relevant_ids = set(ids_with_all_annotations)\n",
    "df[\"from_is_valid\"] = df[\"from\"].map(lambda x: x in relevant_ids)\n",
    "df[\"to_is_valid\"] = df[\"to\"].map(lambda x: x in relevant_ids)\n",
    "df[\"curated\"] = df[\"from_is_valid\"]*df[\"to_is_valid\"]\n",
    "df.drop(labels=[\"from_is_valid\",\"to_is_valid\"], axis=\"columns\", inplace=True)\n",
    "df.head(10)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking to make sure that the number of genes and pairs matches what is expected at this point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a nested dictionary with shape dict[curated][question][species][approach][metric] --> value.\n",
    "curated = [True,False]\n",
    "species = [\"intra\",\"inter\",\"both\"]\n",
    "question = [\"subsets\", \"known\", \"predicted\", \"pathways\", \"orthologs\"]\n",
    "tables = defaultdict(dict)\n",
    "for c,q in itertools.product(curated,question): \n",
    "    tables[c][q] = defaultdict(dict)\n",
    "for c,q,s in itertools.product(curated,question,species): \n",
    "    tables[c][q][s] = defaultdict(dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"n_values\"></a>\n",
    "### What are the value of *n* for each type of iteration through a subset of the dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>curated</th>\n",
       "      <th>species</th>\n",
       "      <th>num_genes</th>\n",
       "      <th>positive</th>\n",
       "      <th>negative</th>\n",
       "      <th>num_pairs</th>\n",
       "      <th>positive_fraction</th>\n",
       "      <th>negative_fraction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>subsets</td>\n",
       "      <td>true</td>\n",
       "      <td>intra</td>\n",
       "      <td>247</td>\n",
       "      <td>2940</td>\n",
       "      <td>27477</td>\n",
       "      <td>30417</td>\n",
       "      <td>0.096656</td>\n",
       "      <td>0.903344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>subsets</td>\n",
       "      <td>true</td>\n",
       "      <td>inter</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>subsets</td>\n",
       "      <td>true</td>\n",
       "      <td>both</td>\n",
       "      <td>247</td>\n",
       "      <td>2940</td>\n",
       "      <td>27477</td>\n",
       "      <td>30417</td>\n",
       "      <td>0.096656</td>\n",
       "      <td>0.903344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>known</td>\n",
       "      <td>true</td>\n",
       "      <td>intra</td>\n",
       "      <td>262</td>\n",
       "      <td>566</td>\n",
       "      <td>29173</td>\n",
       "      <td>29739</td>\n",
       "      <td>0.019032</td>\n",
       "      <td>0.980968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>known</td>\n",
       "      <td>true</td>\n",
       "      <td>inter</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>known</td>\n",
       "      <td>true</td>\n",
       "      <td>both</td>\n",
       "      <td>262</td>\n",
       "      <td>566</td>\n",
       "      <td>29173</td>\n",
       "      <td>29739</td>\n",
       "      <td>0.019032</td>\n",
       "      <td>0.980968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>predicted</td>\n",
       "      <td>true</td>\n",
       "      <td>intra</td>\n",
       "      <td>262</td>\n",
       "      <td>426</td>\n",
       "      <td>29313</td>\n",
       "      <td>29739</td>\n",
       "      <td>0.014325</td>\n",
       "      <td>0.985675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>predicted</td>\n",
       "      <td>true</td>\n",
       "      <td>inter</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>predicted</td>\n",
       "      <td>true</td>\n",
       "      <td>both</td>\n",
       "      <td>262</td>\n",
       "      <td>426</td>\n",
       "      <td>29313</td>\n",
       "      <td>29739</td>\n",
       "      <td>0.014325</td>\n",
       "      <td>0.985675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>pathways</td>\n",
       "      <td>true</td>\n",
       "      <td>intra</td>\n",
       "      <td>115</td>\n",
       "      <td>155</td>\n",
       "      <td>5866</td>\n",
       "      <td>6021</td>\n",
       "      <td>0.025743</td>\n",
       "      <td>0.974257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>pathways</td>\n",
       "      <td>true</td>\n",
       "      <td>inter</td>\n",
       "      <td>117</td>\n",
       "      <td>19</td>\n",
       "      <td>769</td>\n",
       "      <td>788</td>\n",
       "      <td>0.024112</td>\n",
       "      <td>0.975888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>pathways</td>\n",
       "      <td>true</td>\n",
       "      <td>both</td>\n",
       "      <td>117</td>\n",
       "      <td>174</td>\n",
       "      <td>6635</td>\n",
       "      <td>6809</td>\n",
       "      <td>0.025554</td>\n",
       "      <td>0.974446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>orthologs</td>\n",
       "      <td>true</td>\n",
       "      <td>intra</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>orthologs</td>\n",
       "      <td>true</td>\n",
       "      <td>inter</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>583</td>\n",
       "      <td>584</td>\n",
       "      <td>0.001712</td>\n",
       "      <td>0.998288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>orthologs</td>\n",
       "      <td>true</td>\n",
       "      <td>both</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>583</td>\n",
       "      <td>584</td>\n",
       "      <td>0.001712</td>\n",
       "      <td>0.998288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>subsets</td>\n",
       "      <td>false</td>\n",
       "      <td>intra</td>\n",
       "      <td>250</td>\n",
       "      <td>2986</td>\n",
       "      <td>28175</td>\n",
       "      <td>31161</td>\n",
       "      <td>0.095825</td>\n",
       "      <td>0.904175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>subsets</td>\n",
       "      <td>false</td>\n",
       "      <td>inter</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>subsets</td>\n",
       "      <td>false</td>\n",
       "      <td>both</td>\n",
       "      <td>250</td>\n",
       "      <td>2986</td>\n",
       "      <td>28175</td>\n",
       "      <td>31161</td>\n",
       "      <td>0.095825</td>\n",
       "      <td>0.904175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>known</td>\n",
       "      <td>false</td>\n",
       "      <td>intra</td>\n",
       "      <td>452</td>\n",
       "      <td>1243</td>\n",
       "      <td>85845</td>\n",
       "      <td>87088</td>\n",
       "      <td>0.014273</td>\n",
       "      <td>0.985727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>known</td>\n",
       "      <td>false</td>\n",
       "      <td>inter</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>known</td>\n",
       "      <td>false</td>\n",
       "      <td>both</td>\n",
       "      <td>452</td>\n",
       "      <td>1243</td>\n",
       "      <td>85845</td>\n",
       "      <td>87088</td>\n",
       "      <td>0.014273</td>\n",
       "      <td>0.985727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>predicted</td>\n",
       "      <td>false</td>\n",
       "      <td>intra</td>\n",
       "      <td>452</td>\n",
       "      <td>853</td>\n",
       "      <td>86235</td>\n",
       "      <td>87088</td>\n",
       "      <td>0.009795</td>\n",
       "      <td>0.990205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>predicted</td>\n",
       "      <td>false</td>\n",
       "      <td>inter</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>predicted</td>\n",
       "      <td>false</td>\n",
       "      <td>both</td>\n",
       "      <td>452</td>\n",
       "      <td>853</td>\n",
       "      <td>86235</td>\n",
       "      <td>87088</td>\n",
       "      <td>0.009795</td>\n",
       "      <td>0.990205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>pathways</td>\n",
       "      <td>false</td>\n",
       "      <td>intra</td>\n",
       "      <td>182</td>\n",
       "      <td>336</td>\n",
       "      <td>12738</td>\n",
       "      <td>13074</td>\n",
       "      <td>0.025700</td>\n",
       "      <td>0.974300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>pathways</td>\n",
       "      <td>false</td>\n",
       "      <td>inter</td>\n",
       "      <td>184</td>\n",
       "      <td>98</td>\n",
       "      <td>3687</td>\n",
       "      <td>3785</td>\n",
       "      <td>0.025892</td>\n",
       "      <td>0.974108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>pathways</td>\n",
       "      <td>false</td>\n",
       "      <td>both</td>\n",
       "      <td>184</td>\n",
       "      <td>434</td>\n",
       "      <td>16425</td>\n",
       "      <td>16859</td>\n",
       "      <td>0.025743</td>\n",
       "      <td>0.974257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>orthologs</td>\n",
       "      <td>false</td>\n",
       "      <td>intra</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>orthologs</td>\n",
       "      <td>false</td>\n",
       "      <td>inter</td>\n",
       "      <td>99</td>\n",
       "      <td>3</td>\n",
       "      <td>2791</td>\n",
       "      <td>2794</td>\n",
       "      <td>0.001074</td>\n",
       "      <td>0.998926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>orthologs</td>\n",
       "      <td>false</td>\n",
       "      <td>both</td>\n",
       "      <td>99</td>\n",
       "      <td>3</td>\n",
       "      <td>2791</td>\n",
       "      <td>2794</td>\n",
       "      <td>0.001074</td>\n",
       "      <td>0.998926</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     question curated species  num_genes  positive  negative  num_pairs  positive_fraction  negative_fraction\n",
       "0     subsets    true   intra        247      2940     27477      30417           0.096656           0.903344\n",
       "1     subsets    true   inter          0         0         0          0                NaN                NaN\n",
       "2     subsets    true    both        247      2940     27477      30417           0.096656           0.903344\n",
       "3       known    true   intra        262       566     29173      29739           0.019032           0.980968\n",
       "4       known    true   inter          0         0         0          0                NaN                NaN\n",
       "5       known    true    both        262       566     29173      29739           0.019032           0.980968\n",
       "6   predicted    true   intra        262       426     29313      29739           0.014325           0.985675\n",
       "7   predicted    true   inter          0         0         0          0                NaN                NaN\n",
       "8   predicted    true    both        262       426     29313      29739           0.014325           0.985675\n",
       "9    pathways    true   intra        115       155      5866       6021           0.025743           0.974257\n",
       "10   pathways    true   inter        117        19       769        788           0.024112           0.975888\n",
       "11   pathways    true    both        117       174      6635       6809           0.025554           0.974446\n",
       "12  orthologs    true   intra          0         0         0          0                NaN                NaN\n",
       "13  orthologs    true   inter         41         1       583        584           0.001712           0.998288\n",
       "14  orthologs    true    both         41         1       583        584           0.001712           0.998288\n",
       "15    subsets   false   intra        250      2986     28175      31161           0.095825           0.904175\n",
       "16    subsets   false   inter          0         0         0          0                NaN                NaN\n",
       "17    subsets   false    both        250      2986     28175      31161           0.095825           0.904175\n",
       "18      known   false   intra        452      1243     85845      87088           0.014273           0.985727\n",
       "19      known   false   inter          0         0         0          0                NaN                NaN\n",
       "20      known   false    both        452      1243     85845      87088           0.014273           0.985727\n",
       "21  predicted   false   intra        452       853     86235      87088           0.009795           0.990205\n",
       "22  predicted   false   inter          0         0         0          0                NaN                NaN\n",
       "23  predicted   false    both        452       853     86235      87088           0.009795           0.990205\n",
       "24   pathways   false   intra        182       336     12738      13074           0.025700           0.974300\n",
       "25   pathways   false   inter        184        98      3687       3785           0.025892           0.974108\n",
       "26   pathways   false    both        184       434     16425      16859           0.025743           0.974257\n",
       "27  orthologs   false   intra          0         0         0          0                NaN                NaN\n",
       "28  orthologs   false   inter         99         3      2791       2794           0.001074           0.998926\n",
       "29  orthologs   false    both         99         3      2791       2794           0.001074           0.998926"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset_idx_lists = []\n",
    "subset_properties = []\n",
    "table_lists = defaultdict(list)\n",
    "for c,q,s in itertools.product(curated,question,species):\n",
    "    \n",
    "    # Remembering what the properties for this particular subset are.\n",
    "    subset_properties.append((c,q,s))\n",
    "    \n",
    "    # Subsetting the dataframe to the rows (gene pairs) that are relevant for this particular biological question.\n",
    "    subset = df[df[q] != -1]\n",
    "    if c:\n",
    "        subset = subset[subset[\"curated\"] == True]\n",
    "        \n",
    "        \n",
    "    # Subsetting the dataframe to the rows (gene pairs) where both genes are from the same or different species.\n",
    "    if s == \"intra\":\n",
    "        subset = subset[subset[\"same\"] == True]\n",
    "    elif s == \"inter\":\n",
    "        subset = subset[subset[\"same\"] == False]\n",
    "        \n",
    "    subset_idx_lists.append(subset.index.to_list())\n",
    "    \n",
    "    # Adding values to the table that are specific to this biological question.\n",
    "    counts = Counter(subset[q].values)\n",
    "    \n",
    "    table_lists[\"question\"].append(q.lower())\n",
    "    table_lists[\"curated\"].append(str(c).lower())\n",
    "    table_lists[\"species\"].append(s.lower())\n",
    "    table_lists[\"num_genes\"].append(len(set(subset[\"to\"].values).union(set(subset[\"from\"].values))))\n",
    "    table_lists[\"positive\"].append(counts[1])\n",
    "    table_lists[\"negative\"].append(counts[0])\n",
    "    #table_lists[\"class_ratio\"].append(\"{:0.4f}\".format(counts[1]/counts[0]))\n",
    "\n",
    "pairs_table = pd.DataFrame(table_lists)  \n",
    "pairs_table[\"num_pairs\"] = pairs_table[\"positive\"]+pairs_table[\"negative\"]\n",
    "pairs_table[\"positive_fraction\"] = pairs_table[\"positive\"] / pairs_table[\"num_pairs\"]\n",
    "pairs_table[\"negative_fraction\"] = pairs_table[\"negative\"] / pairs_table[\"num_pairs\"]\n",
    "pairs_table.to_csv(os.path.join(OUTPUT_DIR,\"part_5_biological_question_n_values.csv\"), index=False)\n",
    "pairs_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"objective_similarities\"></a>\n",
    "### How similar are the different biological objectives to each other?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_1</th>\n",
       "      <th>question_2</th>\n",
       "      <th>num_pairs_1</th>\n",
       "      <th>num_pairs_2</th>\n",
       "      <th>num_overlap</th>\n",
       "      <th>sim_overlap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>subsets</td>\n",
       "      <td>orthologs</td>\n",
       "      <td>31161</td>\n",
       "      <td>2794</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>known</td>\n",
       "      <td>orthologs</td>\n",
       "      <td>87088</td>\n",
       "      <td>2794</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>predicted</td>\n",
       "      <td>orthologs</td>\n",
       "      <td>87088</td>\n",
       "      <td>2794</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pathways</td>\n",
       "      <td>orthologs</td>\n",
       "      <td>16859</td>\n",
       "      <td>2794</td>\n",
       "      <td>197</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>known</td>\n",
       "      <td>pathways</td>\n",
       "      <td>87088</td>\n",
       "      <td>16859</td>\n",
       "      <td>12778</td>\n",
       "      <td>0.164049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>known</td>\n",
       "      <td>predicted</td>\n",
       "      <td>87088</td>\n",
       "      <td>87088</td>\n",
       "      <td>87088</td>\n",
       "      <td>0.084325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>predicted</td>\n",
       "      <td>pathways</td>\n",
       "      <td>87088</td>\n",
       "      <td>16859</td>\n",
       "      <td>12778</td>\n",
       "      <td>0.063625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>subsets</td>\n",
       "      <td>pathways</td>\n",
       "      <td>31161</td>\n",
       "      <td>16859</td>\n",
       "      <td>6127</td>\n",
       "      <td>0.057299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>subsets</td>\n",
       "      <td>known</td>\n",
       "      <td>31161</td>\n",
       "      <td>87088</td>\n",
       "      <td>30417</td>\n",
       "      <td>0.027908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>subsets</td>\n",
       "      <td>predicted</td>\n",
       "      <td>31161</td>\n",
       "      <td>87088</td>\n",
       "      <td>30417</td>\n",
       "      <td>0.019459</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  question_1 question_2  num_pairs_1  num_pairs_2  num_overlap  sim_overlap\n",
       "0    subsets  orthologs        31161         2794            0     1.000000\n",
       "1      known  orthologs        87088         2794            0     1.000000\n",
       "2  predicted  orthologs        87088         2794            0     1.000000\n",
       "3   pathways  orthologs        16859         2794          197     0.333333\n",
       "4      known   pathways        87088        16859        12778     0.164049\n",
       "5      known  predicted        87088        87088        87088     0.084325\n",
       "6  predicted   pathways        87088        16859        12778     0.063625\n",
       "7    subsets   pathways        31161        16859         6127     0.057299\n",
       "8    subsets      known        31161        87088        30417     0.027908\n",
       "9    subsets  predicted        31161        87088        30417     0.019459"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Looking more at the distributions of target values for each of the biological questions.\n",
    "from scipy.spatial.distance import jaccard\n",
    "row_tuples = []\n",
    "for q1,q2 in itertools.combinations(question, 2):\n",
    "    q1_subset = df[df[q1] != -1]\n",
    "    q2_subset = df[df[q2] != -1]\n",
    "    overlap_subset  = q1_subset[q1_subset[q2] != -1]\n",
    "    q1_num_pairs = q1_subset.shape[0]\n",
    "    q2_num_pairs = q2_subset.shape[0]\n",
    "    overlap_size = overlap_subset.shape[0]\n",
    "    overlap_sim = 1-jaccard(overlap_subset[q1].values, overlap_subset[q2].values)\n",
    "    row_tuples.append((q1, q2, q1_num_pairs, q2_num_pairs, overlap_size, overlap_sim))\n",
    "question_overlaps_table = pd.DataFrame(row_tuples)\n",
    "question_overlaps_table.columns = [\"question_1\", \"question_2\", \"num_pairs_1\", \"num_pairs_2\", \"num_overlap\", \"sim_overlap\"]\n",
    "question_overlaps_table.sort_values(by=\"sim_overlap\", ascending=False, inplace=True)\n",
    "question_overlaps_table.reset_index(inplace=True, drop=True)\n",
    "question_overlaps_table.to_csv(os.path.join(OUTPUT_DIR,\"part_5_biological_question_overlaps.csv\"), index=False)\n",
    "question_overlaps_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"part_6\"></a>\n",
    "# Part 6. Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"ks\"></a>\n",
    "### Do the edges joining genes that share a group, pathway, or interaction come from a different distribution?\n",
    "The purpose of this section is to visualize kernel estimates for the distributions of distance or similarity scores generated by each of the methods tested for measuring semantic similarity or generating vector representations of the phenotype descriptions. Ideally, better methods should show better separation betwene the distributions for distance values between two genes involved in a common specified group or two genes that are not. Additionally, a statistical test is used to check whether these two distributions are significantly different from each other or not, although this is a less informative measure than the other tests used in subsequent sections, because it does not address how useful these differences in the distributions actually are for making predictions about group membership."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for properties,idxs in zip(subset_properties, subset_idx_lists):\n",
    "    \n",
    "    # Remember the properties for this subset being looked at, and subset the dataframe accordingly.\n",
    "    c,q,s = properties\n",
    "    \n",
    "    # Don't look at the inter-species and intra-species edges except for pathways, otherwise irrelevant.\n",
    "    if (s != \"both\") and (q != \"pathways\"):\n",
    "        continue\n",
    "    \n",
    "    # Only look at gene pairs where both are relevant to the given biological question.\n",
    "    subset = df.loc[idxs]\n",
    "        \n",
    "    # Check that this subsetting leaves a valid dataset with both positive and negatives samples.\n",
    "    class_values = pd.unique(subset[q].values)\n",
    "    if not (len(class_values)==2 and 0 in class_values and 1 in class_values):\n",
    "        continue\n",
    "    \n",
    "    # Use Kolmogorov-Smirnov test to see if edges between genes that share a group come from a distinct distribution.\n",
    "    ppi_pos_dict = {name:(subset[subset[q] > 0.00][name].values) for name in names}\n",
    "    ppi_neg_dict = {name:(subset[subset[q] == 0.00][name].values) for name in names}\n",
    "    for name in names:\n",
    "        stat,p = ks_2samp(ppi_pos_dict[name],ppi_neg_dict[name])\n",
    "        pos_mean = np.average(ppi_pos_dict[name])\n",
    "        neg_mean = np.average(ppi_neg_dict[name])\n",
    "        pos_n = len(ppi_pos_dict[name])\n",
    "        neg_n = len(ppi_neg_dict[name])\n",
    "        \n",
    "        tables[c][q][s][name].update({\"mean_1\":pos_mean, \"mean_0\":neg_mean, \"n_1\":pos_n, \"n_0\":neg_n})\n",
    "        tables[c][q][s][name].update({\"ks\":stat, \"ks_pval\":p})\n",
    "\n",
    "    # Show the kernel estimates for each distribution of weights for each method.\n",
    "    #num_plots, plots_per_row, row_width, row_height = (len(names), 4, 14, 3)\n",
    "    #fig,axs = plt.subplots(math.ceil(num_plots/plots_per_row), plots_per_row, squeeze=False)\n",
    "    #for name,ax in zip(names,axs.flatten()):\n",
    "    #    ax.set_title(name)\n",
    "    #    ax.set_xlabel(\"value\")\n",
    "    #    ax.set_ylabel(\"density\")\n",
    "    #    sns.kdeplot(ppi_pos_dict[name], color=\"black\", shade=False, alpha=1.0, ax=ax)\n",
    "    #    sns.kdeplot(ppi_neg_dict[name], color=\"black\", shade=True, alpha=0.1, ax=ax) \n",
    "    #fig.set_size_inches(row_width, row_height*math.ceil(num_plots/plots_per_row))\n",
    "    #fig.tight_layout()\n",
    "    #fig.savefig(os.path.join(OUTPUT_DIR,\"part_6_kernel_density.png\"),dpi=400)\n",
    "    #plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"within\"></a>\n",
    "### Looking at within-group or within-pathway distances in each graph\n",
    "The purpose of this section is to determine which methods generated graphs which tightly group genes which share common pathways or group membership with one another. In order to compare across different methods where the distance value distributions are different, the mean distance values for each group for each method are convereted to percentile scores. Lower percentile scores indicate that the average distance value between any two genes that belong to that group is lower than most of the distance values in the entire distribution for that method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# What are the different groupings we are interested in for these mean within-group distance tables?\n",
    "grouping_objects = [kegg_groups, pmn_groups, phe_subsets_groups]\n",
    "grouping_names = [\"kegg_only\",\"pmn_only\",\"subsets\"]\n",
    "for (groups,q) in zip(grouping_objects,grouping_names):\n",
    "\n",
    "    # Only look at gene pairs where both are relevant to the given biological question.\n",
    "    subset = df[df[q] != -1]\n",
    "    \n",
    "    # The grouping dictionaries for this particular biological question.    \n",
    "    id_to_group_ids, group_id_to_ids = groups.get_groupings_for_dataset(dataset)\n",
    "\n",
    "    # Get all the average within-group distance values for each approach.\n",
    "    group_ids = list(group_id_to_ids.keys())\n",
    "    graph = IndexedGraph(subset)\n",
    "    within_percentiles_dict = defaultdict(lambda: defaultdict(list))\n",
    "    all_weights_dict = {}\n",
    "    for name in names:\n",
    "        for group in group_ids:\n",
    "            within_ids = group_id_to_ids[group]\n",
    "            within_pairs = [(i,j) for i,j in itertools.permutations(within_ids,2)]\n",
    "            mean_weight = np.mean((graph.get_values(within_pairs, kind=name)))\n",
    "            within_percentiles_dict[name][group] = stats.percentileofscore(subset[name].values, mean_weight, kind=\"rank\")\n",
    "\n",
    "    # Generating a dataframe of percentiles of the mean in-group distance scores.\n",
    "    within_dist_data = pd.DataFrame(within_percentiles_dict)\n",
    "    within_dist_data = within_dist_data.dropna(axis=0, inplace=False)\n",
    "    within_dist_data = within_dist_data.round(4)\n",
    "\n",
    "    # Adding relevant information to this dataframe and saving.\n",
    "    # Defining mean_group_rank: the average of the individual rank given to this pathway by each approach.\n",
    "    # Defining mean_avg_pair_percentile: the average across all approaches of the average distance percentile for each gene pair.\n",
    "    within_dist_data[\"mean_group_rank\"] = within_dist_data.rank().mean(axis=1)\n",
    "    within_dist_data[\"mean_avg_pair_percentile\"] = within_dist_data.mean(axis=1)\n",
    "    within_dist_data.sort_values(by=\"mean_avg_pair_percentile\", inplace=True)\n",
    "    within_dist_data.reset_index(inplace=True)\n",
    "    within_dist_data[\"group_id\"] = within_dist_data[\"index\"]\n",
    "    within_dist_data[\"full_name\"] = within_dist_data[\"group_id\"].apply(lambda x: groups.get_long_name(x))\n",
    "    within_dist_data[\"n\"] = within_dist_data[\"group_id\"].apply(lambda x: len(group_id_to_ids[x]))\n",
    "    within_dist_data = within_dist_data[flatten([\"group_id\",\"full_name\",\"n\",\"mean_avg_pair_percentile\",\"mean_group_rank\",names])]\n",
    "    within_dist_data.to_csv(os.path.join(OUTPUT_DIR,\"part_5_{}_within_distances.csv\".format(q)), index=False)\n",
    "    within_dist_data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"auc\"></a>\n",
    "### Predicting whether two genes belong to the same group, pathway, or share an interaction\n",
    "The purpose of this section is to see if whether or not two genes share atleast one common pathway can be predicted from the distance scores assigned using analysis of text similarity. The evaluation of predictability is done by reporting a precision and recall curve for each method, as well as remembering the area under the curve, and ratio between the area under the curve and the baseline (expected area when guessing randomly) for each method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap(fraction, num_iterations, y_true, y_prob):\n",
    "    # Run the desired number of bootstrap iterations over the full population of predictions and return st devs.\n",
    "    scores = pd.DataFrame([bootstrap_iteration(fraction, y_true, y_prob) for i in range(num_iterations)])\n",
    "    standard_deviations = {\n",
    "        \"f_1_max_std\": np.std(scores[\"f_1_max\"].values),\n",
    "        \"f_2_max_std\": np.std(scores[\"f_2_max\"].values),\n",
    "        \"f_point5_max_std\": np.std(scores[\"f_point5_max\"].values)}\n",
    "    return(standard_deviations)\n",
    "\n",
    "\n",
    "def bootstrap_iteration(fraction, y_true, y_prob):\n",
    "    assert len(y_true) == len(y_prob)\n",
    "    # Subset the total population of predictions using the provided fraction.\n",
    "    num_predictions = len(y_true)\n",
    "    bootstrapping_fraction = fraction\n",
    "    num_to_retain = int(np.ceil(num_predictions*bootstrapping_fraction))\n",
    "    idx = np.random.choice(np.arange(num_predictions), num_to_retain, replace=False)\n",
    "    y_true_sample = y_true[idx]\n",
    "    y_prob_sample = y_prob[idx]\n",
    "    \n",
    "    # Calculate any desired metrics using just that subset.\n",
    "    n_pos, n_neg = Counter(y_true_sample)[1], Counter(y_true_sample)[0]\n",
    "    precision, recall, thresholds = precision_recall_curve(y_true_sample, y_prob_sample)\n",
    "    baseline = Counter(y_true_sample)[1]/len(y_true_sample) \n",
    "    area = auc(recall, precision)\n",
    "    auc_to_baseline_auc_ratio = area/baseline\n",
    "    \n",
    "    # Find the maximum F score for different values of .  \n",
    "    f_beta = lambda pr,re,beta: [((1+beta**2)*p*r)/((((beta**2)*p)+r)) for p,r in zip(pr,re)]\n",
    "    f_1_scores = f_beta(precision,recall,beta=1)\n",
    "    f_2_scores = f_beta(precision,recall,beta=2)\n",
    "    f_point5_scores = f_beta(precision,recall,beta=0.5)\n",
    "    \n",
    "    # Create a dictionary of those metric values to return.\n",
    "    scores={\"f_1_max\":np.nanmax(f_1_scores),\"f_2_max\":np.nanmax(f_2_scores),\"f_point5_max\":np.nanmax(f_point5_scores)}\n",
    "    return(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>hyperparameters</th>\n",
       "      <th>task</th>\n",
       "      <th>curated</th>\n",
       "      <th>species</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>basline_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>doc2vec</td>\n",
       "      <td>wikipedia,size=300</td>\n",
       "      <td>subsets</td>\n",
       "      <td>true</td>\n",
       "      <td>both</td>\n",
       "      <td>0.096991</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.096656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>doc2vec</td>\n",
       "      <td>wikipedia,size=300</td>\n",
       "      <td>subsets</td>\n",
       "      <td>true</td>\n",
       "      <td>both</td>\n",
       "      <td>0.096968</td>\n",
       "      <td>0.999660</td>\n",
       "      <td>0.096656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>doc2vec</td>\n",
       "      <td>wikipedia,size=300</td>\n",
       "      <td>subsets</td>\n",
       "      <td>true</td>\n",
       "      <td>both</td>\n",
       "      <td>0.096981</td>\n",
       "      <td>0.999660</td>\n",
       "      <td>0.096656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>doc2vec</td>\n",
       "      <td>wikipedia,size=300</td>\n",
       "      <td>subsets</td>\n",
       "      <td>true</td>\n",
       "      <td>both</td>\n",
       "      <td>0.097000</td>\n",
       "      <td>0.999660</td>\n",
       "      <td>0.096656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>doc2vec</td>\n",
       "      <td>wikipedia,size=300</td>\n",
       "      <td>subsets</td>\n",
       "      <td>true</td>\n",
       "      <td>both</td>\n",
       "      <td>0.097013</td>\n",
       "      <td>0.999660</td>\n",
       "      <td>0.096656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>doc2vec</td>\n",
       "      <td>wikipedia,size=300</td>\n",
       "      <td>subsets</td>\n",
       "      <td>true</td>\n",
       "      <td>both</td>\n",
       "      <td>0.097019</td>\n",
       "      <td>0.999660</td>\n",
       "      <td>0.096656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>doc2vec</td>\n",
       "      <td>wikipedia,size=300</td>\n",
       "      <td>subsets</td>\n",
       "      <td>true</td>\n",
       "      <td>both</td>\n",
       "      <td>0.097045</td>\n",
       "      <td>0.999660</td>\n",
       "      <td>0.096656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>doc2vec</td>\n",
       "      <td>wikipedia,size=300</td>\n",
       "      <td>subsets</td>\n",
       "      <td>true</td>\n",
       "      <td>both</td>\n",
       "      <td>0.097028</td>\n",
       "      <td>0.999320</td>\n",
       "      <td>0.096656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>doc2vec</td>\n",
       "      <td>wikipedia,size=300</td>\n",
       "      <td>subsets</td>\n",
       "      <td>true</td>\n",
       "      <td>both</td>\n",
       "      <td>0.097060</td>\n",
       "      <td>0.999320</td>\n",
       "      <td>0.096656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>doc2vec</td>\n",
       "      <td>wikipedia,size=300</td>\n",
       "      <td>subsets</td>\n",
       "      <td>true</td>\n",
       "      <td>both</td>\n",
       "      <td>0.097073</td>\n",
       "      <td>0.999320</td>\n",
       "      <td>0.096656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>doc2vec</td>\n",
       "      <td>wikipedia,size=300</td>\n",
       "      <td>subsets</td>\n",
       "      <td>true</td>\n",
       "      <td>both</td>\n",
       "      <td>0.097095</td>\n",
       "      <td>0.999320</td>\n",
       "      <td>0.096656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>doc2vec</td>\n",
       "      <td>wikipedia,size=300</td>\n",
       "      <td>subsets</td>\n",
       "      <td>true</td>\n",
       "      <td>both</td>\n",
       "      <td>0.097081</td>\n",
       "      <td>0.998980</td>\n",
       "      <td>0.096656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>doc2vec</td>\n",
       "      <td>wikipedia,size=300</td>\n",
       "      <td>subsets</td>\n",
       "      <td>true</td>\n",
       "      <td>both</td>\n",
       "      <td>0.097104</td>\n",
       "      <td>0.998980</td>\n",
       "      <td>0.096656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>doc2vec</td>\n",
       "      <td>wikipedia,size=300</td>\n",
       "      <td>subsets</td>\n",
       "      <td>true</td>\n",
       "      <td>both</td>\n",
       "      <td>0.097057</td>\n",
       "      <td>0.998299</td>\n",
       "      <td>0.096656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>doc2vec</td>\n",
       "      <td>wikipedia,size=300</td>\n",
       "      <td>subsets</td>\n",
       "      <td>true</td>\n",
       "      <td>both</td>\n",
       "      <td>0.097070</td>\n",
       "      <td>0.998299</td>\n",
       "      <td>0.096656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>doc2vec</td>\n",
       "      <td>wikipedia,size=300</td>\n",
       "      <td>subsets</td>\n",
       "      <td>true</td>\n",
       "      <td>both</td>\n",
       "      <td>0.097079</td>\n",
       "      <td>0.998299</td>\n",
       "      <td>0.096656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>doc2vec</td>\n",
       "      <td>wikipedia,size=300</td>\n",
       "      <td>subsets</td>\n",
       "      <td>true</td>\n",
       "      <td>both</td>\n",
       "      <td>0.097086</td>\n",
       "      <td>0.998299</td>\n",
       "      <td>0.096656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>doc2vec</td>\n",
       "      <td>wikipedia,size=300</td>\n",
       "      <td>subsets</td>\n",
       "      <td>true</td>\n",
       "      <td>both</td>\n",
       "      <td>0.097115</td>\n",
       "      <td>0.998299</td>\n",
       "      <td>0.096656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>doc2vec</td>\n",
       "      <td>wikipedia,size=300</td>\n",
       "      <td>subsets</td>\n",
       "      <td>true</td>\n",
       "      <td>both</td>\n",
       "      <td>0.097134</td>\n",
       "      <td>0.998299</td>\n",
       "      <td>0.096656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>doc2vec</td>\n",
       "      <td>wikipedia,size=300</td>\n",
       "      <td>subsets</td>\n",
       "      <td>true</td>\n",
       "      <td>both</td>\n",
       "      <td>0.097156</td>\n",
       "      <td>0.998299</td>\n",
       "      <td>0.096656</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     method     hyperparameters     task curated species  precision    recall  basline_auc\n",
       "0   doc2vec  wikipedia,size=300  subsets    true    both   0.096991  1.000000     0.096656\n",
       "1   doc2vec  wikipedia,size=300  subsets    true    both   0.096968  0.999660     0.096656\n",
       "2   doc2vec  wikipedia,size=300  subsets    true    both   0.096981  0.999660     0.096656\n",
       "3   doc2vec  wikipedia,size=300  subsets    true    both   0.097000  0.999660     0.096656\n",
       "4   doc2vec  wikipedia,size=300  subsets    true    both   0.097013  0.999660     0.096656\n",
       "5   doc2vec  wikipedia,size=300  subsets    true    both   0.097019  0.999660     0.096656\n",
       "6   doc2vec  wikipedia,size=300  subsets    true    both   0.097045  0.999660     0.096656\n",
       "7   doc2vec  wikipedia,size=300  subsets    true    both   0.097028  0.999320     0.096656\n",
       "8   doc2vec  wikipedia,size=300  subsets    true    both   0.097060  0.999320     0.096656\n",
       "9   doc2vec  wikipedia,size=300  subsets    true    both   0.097073  0.999320     0.096656\n",
       "10  doc2vec  wikipedia,size=300  subsets    true    both   0.097095  0.999320     0.096656\n",
       "11  doc2vec  wikipedia,size=300  subsets    true    both   0.097081  0.998980     0.096656\n",
       "12  doc2vec  wikipedia,size=300  subsets    true    both   0.097104  0.998980     0.096656\n",
       "13  doc2vec  wikipedia,size=300  subsets    true    both   0.097057  0.998299     0.096656\n",
       "14  doc2vec  wikipedia,size=300  subsets    true    both   0.097070  0.998299     0.096656\n",
       "15  doc2vec  wikipedia,size=300  subsets    true    both   0.097079  0.998299     0.096656\n",
       "16  doc2vec  wikipedia,size=300  subsets    true    both   0.097086  0.998299     0.096656\n",
       "17  doc2vec  wikipedia,size=300  subsets    true    both   0.097115  0.998299     0.096656\n",
       "18  doc2vec  wikipedia,size=300  subsets    true    both   0.097134  0.998299     0.096656\n",
       "19  doc2vec  wikipedia,size=300  subsets    true    both   0.097156  0.998299     0.096656"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pr_df_rows = []\n",
    "for properties,idxs in zip(subset_properties, subset_idx_lists):\n",
    "    \n",
    "    # Remember the properties for this subset being looked at, and subset the dataframe accordingly.\n",
    "    c,q,s = properties\n",
    "    \n",
    "    # Don't look at the inter-species and intra-species edges except for pathways, otherwise irrelevant.\n",
    "    if (s != \"both\") and (q != \"pathways\"):\n",
    "        continue\n",
    "    \n",
    "    # Create a subset of the dataframe that contains only the gene pairs for this question.\n",
    "    subset = df.loc[idxs]\n",
    "\n",
    "    # Check that this subsetting leaves a valid dataset with both positive and negatives samples.\n",
    "    class_values = pd.unique(subset[q].values)\n",
    "    if not (len(class_values)==2 and 0 in class_values and 1 in class_values):\n",
    "        continue\n",
    "\n",
    "\n",
    "\n",
    "    y_true_dict = {name:subset[q].values for name in names}       #just added .values here...\n",
    "    y_prob_dict = {name:(1 - subset[name].values) for name in names}\n",
    "    num_plots, plots_per_row, row_width, row_height = (len(names), 4, 14, 3)\n",
    "    fig,axs = plt.subplots(math.ceil(num_plots/plots_per_row), plots_per_row, squeeze=False)\n",
    "    for name,ax in zip(names, axs.flatten()):\n",
    "\n",
    "        # Obtaining the values and metrics.\n",
    "        y_true, y_prob = y_true_dict[name], y_prob_dict[name]\n",
    "        n_pos, n_neg = Counter(y_true)[1], Counter(y_true)[0]\n",
    "        precision, recall, thresholds = precision_recall_curve(y_true, y_prob)\n",
    "        baseline_auc = Counter(y_true)[1]/len(y_true) \n",
    "        area = auc(recall, precision)\n",
    "        auc_to_baseline_auc_ratio = area/baseline_auc\n",
    "        \n",
    "        \n",
    "        # The baseline F1 max has a precision of the ratio of positives to all samples and a recall of 1.\n",
    "        # This is because a random classifier achieves that precision at all recall values, so recall is maximized to\n",
    "        # find the maximum F1 value that can be expected due to random chance.\n",
    "        baseline_f1_max = (2*baseline_auc*1)/(baseline_auc+1)\n",
    "        tables[c][q][s][name].update({\"auc\":area,\"auc_baseline\":baseline_auc, \"f1_max_baseline\":baseline_f1_max, })\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "        # Add a row to the dataframe that specifically keeps track of the precision and recall distributions.\n",
    "        # We don't want to remember all the precision and recall values that sklearn generates, file would\n",
    "        # get enormous. Instead, round the thresholds to 3 decimal places and then just remember the indices\n",
    "        # where we jumpt to the next thresholds (subsets to <= 1000 precision and recall value pairs). \n",
    "        # Note this only works when the threshold values are sorted in increasing order, which they currently are\n",
    "        # for this sklearn function. \n",
    "        pr_indices_to_use = []\n",
    "        last_threshold = -0.001 # A value smaller than any real threshold in this case.\n",
    "        for idx,threshold in enumerate(thresholds):\n",
    "            this_threshold = round(threshold,3)\n",
    "            if this_threshold != last_threshold:\n",
    "                pr_indices_to_use.append(idx)\n",
    "                last_threshold = this_threshold\n",
    "        pr_indices_to_use.append(len(thresholds)) # This is the index of the '1' and '0' that cap the P and R arrays.    \n",
    "        p_values_to_use = precision[pr_indices_to_use]\n",
    "        r_values_to_use = recall[pr_indices_to_use]\n",
    "\n",
    "        \n",
    "        # Use those 1000 or fewer precision and recall pairs to build a file from which curves can be plotted. \n",
    "        for p,r in zip(p_values_to_use,r_values_to_use):\n",
    "            method = name.split(\":\")[0]\n",
    "            if len(name.split(\":\"))>1:\n",
    "                hyperparameters = name.split(\":\")[1]\n",
    "            else:\n",
    "                hyperparameters = \"none\"\n",
    "            pr_df_rows.append((method, hyperparameters, q.lower(), str(c).lower(), s.lower(), p, r, baseline_auc))\n",
    "        \n",
    "        \n",
    "        # Find the maximum F score for different values of .  \n",
    "        f_beta = lambda pr,re,beta: [((1+beta**2)*p*r)/((((beta**2)*p)+r)) for p,r in zip(pr,re)]\n",
    "        f_1_scores = f_beta(precision,recall,beta=1)\n",
    "        f_2_scores = f_beta(precision,recall,beta=2)\n",
    "        f_point5_scores = f_beta(precision,recall,beta=0.5)\n",
    "        f_1_max, f_1_std = np.nanmax(f_1_scores), np.std(f_1_scores)\n",
    "        f_2_max, f_2_std = np.nanmax(f_2_scores), np.std(f_2_scores)\n",
    "        f_point5_max, f_point5_std = np.nanmax(f_point5_scores), np.std(f_point5_scores)\n",
    "        tables[c][q][s][name].update({\"f1_max\":f_1_max, \"f5_max\":f_point5_max, \"f2_max\":f_2_max})\n",
    "        \n",
    "        \n",
    "        # Find the standard deviation of each metric when subsampling the dataset of predictions for each method.\n",
    "        #bootstrap_fraction = 0.9\n",
    "        #bootstrap_iterations = 100\n",
    "        #bootstrapped_std_dict = bootstrap(bootstrap_fraction, bootstrap_iterations, y_true, y_prob)\n",
    "        #tables[c][q][s][name].update({\"f1_std\":bootstrapped_std_dict[\"f_1_max_std\"], \"f5_std\":bootstrapped_std_dict[\"f_point5_max_std\"], \"f2_std\":bootstrapped_std_dict[\"f_2_max_std\"]}) \n",
    "\n",
    "        # Producing the precision recall curve.\n",
    "        #step_kwargs = ({'step': 'post'} if 'step' in signature(plt.fill_between).parameters else {})\n",
    "        #ax.step(recall, precision, color='black', alpha=0.2, where='post')\n",
    "        #ax.fill_between(recall, precision, alpha=0.7, color='black', **step_kwargs)\n",
    "        #ax.axhline(baseline_auc, linestyle=\"--\", color=\"lightgray\")\n",
    "        #ax.set_xlabel('Recall')\n",
    "        #ax.set_ylabel('Precision')\n",
    "        #ax.set_ylim([0.0, 1.05])\n",
    "        #ax.set_xlim([0.0, 1.0])\n",
    "        #ax.set_title(\"PR {0} (Baseline={1:0.3f})\".format(name, baseline_auc))\n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "    #fig.set_size_inches(row_width, row_height*math.ceil(num_plots/plots_per_row))\n",
    "    #fig.tight_layout()\n",
    "    #fig.savefig(os.path.join(OUTPUT_DIR,\"part_5_prcurve_shared.png\"),dpi=400)\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "# Create a CSV file for the precision recall curves for each different approach. \n",
    "precision_recall_curves_df = pd.DataFrame(pr_df_rows, columns=[\"method\", \"hyperparameters\", \"task\", \"curated\", \"species\", \"precision\", \"recall\", \"basline_auc\"])\n",
    "precision_recall_curves_df.to_csv(os.path.join(OUTPUT_DIR,\"part_5_precision_recall_curves.csv\"), index=False) \n",
    "precision_recall_curves_df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"y\"></a>\n",
    "### Are genes in the same group or pathway ranked higher with respect to individual nodes?\n",
    "This is a way of statistically seeing if for some value k, the graph ranks more edges from some particular gene to any other gene that it has a true protein-protein interaction with higher or equal to rank k, than we would expect due to random chance. This way of looking at the problem helps to be less ambiguous than the previous methods, because it gets at the core of how this would actually be used. In other words, we don't really care how much true information we're missing as long as we're still able to pick up some new useful information by building these networks, so even though we could be missing a lot, what's going on at the very top of the results? These results should be comparable to very strictly thresholding the network and saying that the remaining edges are our guesses at interactions. This is comparable to just looking at the far left-hand side of the precision recall curves, but just quantifies it slightly differently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if NOTEBOOK:\n",
    "    \n",
    "    # When the edgelist is generated above, only the lower triangle of the pairwise matrix is retained for edges in the \n",
    "    # graph. This means that in terms of the indices of each node, only the (i,j) node is listed in the edge list where\n",
    "    # i is less than j. This makes sense because the graph that's specified is assumed to already be undirected. However\n",
    "    # in order to be able to easily subset the edgelist by a single column to obtain rows that correspond to all edges\n",
    "    # connected to a particular node, this method will double the number of rows to include both (i,j) and (j,i) edges.\n",
    "    df = make_undirected(df)\n",
    "\n",
    "    # What's the number of functional partners ranked k or higher in terms of phenotypic description similarity for \n",
    "    # each gene? Also figure out the maximum possible number of functional partners that could be theoretically\n",
    "    # recovered in this dataset if recovered means being ranked as k or higher here.\n",
    "    k = 10      # The threshold of interest for gene ranks.\n",
    "    n = 100     # Number of Monte Carlo simulation iterations to complete.\n",
    "    df[list(names)] = df.groupby(\"from\")[list(names)].rank()\n",
    "    ys = df[df[\"shared\"]==1][list(names)].apply(lambda s: len([x for x in s if x<=k]))\n",
    "    ymax = sum(df.groupby(\"from\")[\"shared\"].apply(lambda s: min(len([x for x in s if x==1]),k)))\n",
    "\n",
    "    # Monte Carlo simulation to see what the probability is of achieving each y-value by just randomly pulling k \n",
    "    # edges for each gene rather than taking the top k ones that the similarity methods specifies when ranking.\n",
    "    ysims = [sum(df.groupby(\"from\")[\"shared\"].apply(lambda s: len([x for x in s.sample(k) if x>0.00]))) for i in range(n)]\n",
    "    for name in names:\n",
    "        pvalue = len([ysim for ysim in ysims if ysim>=ys[name]])/float(n)\n",
    "        TABLE[name].update({\"y\":ys[name], \"y_max\":ymax, \"y_ratio\":ys[name]/ymax, \"y_pval\":pvalue})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"mean\"></a>\n",
    "### Predicting biochemical pathway or group membership based on mean vectors\n",
    "This section looks at how well the biochemical pathways that a particular gene is a member of can be predicted based on the similarity between the vector representation of the phenotype descriptions for that gene and the average vector for all the vector representations of phenotypes asociated with genes that belong to that particular pathway. In calculating the average vector for a given biochemical pathway, the vector corresponding to the gene that is currently being classified is not accounted for, to avoid overestimating the performance by including information about the ground truth during classification. This leads to missing information in the case of biochemical pathways that have only one member. This can be accounted for by only limiting the overall dataset to only include genes that belong to pathways that have atleast two genes mapped to them, and only including those pathways, or by removing the missing values before calculating the performance metrics below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get the list of methods to look at, and a mapping between each method and the correct similarity metric to apply.\n",
    "# vector_dicts = {k:v.vector_dictionary for k,v in graphs.items()}\n",
    "# names = list(vector_dicts.keys())\n",
    "# group_id_to_ids = groups.get_group_id_to_ids_dict(dataset.get_gene_dictionary())\n",
    "# valid_group_ids = [group for group,id_list in group_id_to_ids.items() if len(id_list)>1]\n",
    "# valid_ids = [i for i in dataset.get_ids() if len(set(valid_group_ids).intersection(set(id_to_group_ids[i])))>0]\n",
    "# pred_dict = defaultdict(lambda: defaultdict(dict))\n",
    "# true_dict = defaultdict(lambda: defaultdict(dict))\n",
    "# for name in names:\n",
    "#     for group in valid_group_ids:\n",
    "#         ids = group_id_to_ids[group]\n",
    "#         for identifier in valid_ids:\n",
    "#             # What's the mean vector of this group, without this particular one that we're trying to classify.\n",
    "#             vectors = np.array([vector_dicts[name][some_id] for some_id in ids if not some_id==identifier])\n",
    "#             mean_vector = vectors.mean(axis=0)\n",
    "#             this_vector = vector_dicts[name][identifier]\n",
    "#             pred_dict[name][identifier][group] = 1-metric_dict[name](mean_vector, this_vector)\n",
    "#             true_dict[name][identifier][group] = (identifier in group_id_to_ids[group])*1                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# num_plots, plots_per_row, row_width, row_height = (len(names), 4, 14, 3)\n",
    "# fig,axs = plt.subplots(math.ceil(num_plots/plots_per_row), plots_per_row, squeeze=False)\n",
    "# for name,ax in zip(names, axs.flatten()):\n",
    "#     \n",
    "#     # Obtaining the values and metrics.\n",
    "#     y_true = pd.DataFrame(true_dict[name]).as_matrix().flatten()\n",
    "#     y_prob = pd.DataFrame(pred_dict[name]).as_matrix().flatten()\n",
    "#     n_pos, n_neg = Counter(y_true)[1], Counter(y_true)[0]\n",
    "#     precision, recall, thresholds = precision_recall_curve(y_true, y_prob)\n",
    "#     baseline = Counter(y_true)[1]/len(y_true) \n",
    "#     area = auc(recall, precision)\n",
    "#     auc_to_baseline_auc_ratio = area/baseline\n",
    "#     TABLE[name].update({\"mean_auc\":area, \"mean_baseline\":baseline, \"mean_ratio\":auc_to_baseline_auc_ratio})\n",
    "# \n",
    "#     # Producing the precision recall curve.\n",
    "#     step_kwargs = ({'step': 'post'} if 'step' in signature(plt.fill_between).parameters else {})\n",
    "#     ax.step(recall, precision, color='black', alpha=0.2, where='post')\n",
    "#     ax.fill_between(recall, precision, alpha=0.7, color='black', **step_kwargs)\n",
    "#     ax.axhline(baseline, linestyle=\"--\", color=\"lightgray\")\n",
    "#     ax.set_xlabel('Recall')\n",
    "#     ax.set_ylabel('Precision')\n",
    "#     ax.set_ylim([0.0, 1.05])\n",
    "#     ax.set_xlim([0.0, 1.0])\n",
    "#     ax.set_title(\"PR {0} (Baseline={1:0.3f})\".format(name[:10], baseline))\n",
    "#     \n",
    "# fig.set_size_inches(row_width, row_height*math.ceil(num_plots/plots_per_row))\n",
    "# fig.tight_layout()\n",
    "# fig.savefig(os.path.join(OUTPUT_DIR,\"part_6_prcurve_mean_classifier.png\"),dpi=400)\n",
    "# plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting biochemical pathway membership based on mean similarity values\n",
    "This section looks at how well the biochemical pathways that a particular gene is a member of can be predicted based on the average similarity between the vector representationt of the phenotype descriptions for that gene and each of the vector representations for other phenotypes associated with genes that belong to that particular pathway. In calculating the average similarity to other genes from a given biochemical pathway, the gene that is currently being classified is not accounted for, to avoid overestimating the performance by including information about the ground truth during classification. This leads to missing information in the case of biochemical pathways that have only one member. This can be accounted for by only limiting the overall dataset to only include genes that belong to pathways that have atleast two genes mapped to them, and only including those pathways, or by removing the missing values before calculating the performance metrics below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting biochemical pathway or group membership with KNN classifier\n",
    "This section looks at how well the group(s) or biochemical pathway(s) that a particular gene belongs to can be predicted based on a KNN classifier generated using every other gene. For this section, only the groups or pathways which contain more than one gene, and the genes mapped to those groups or pathways, are of interest. This is because for other genes, if we consider them then it will be true that that gene belongs to that group in the target vector, but the KNN classifier could never predict this because when that gene is held out, nothing could provide a vote for that group, because there are zero genes available to be members of the K nearest neighbors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"output\"></a>\n",
    "### Summarizing the results for this notebook\n",
    "Write a large table of results to an output file. Columns are generally metrics and rows are generally methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "result_dfs = []\n",
    "for s,c,q in itertools.product(species,curated,question):\n",
    "    if (s != \"both\") and (q != \"pathways\"):\n",
    "        continue\n",
    "    TABLE = tables[c][q][s]\n",
    "    results = pd.DataFrame(TABLE).transpose()\n",
    "    columns = flatten([\"species\", \"objective\",\"curated\",\"hyperparameters\",\"group\",\"order\",results.columns])\n",
    "    results[\"hyperparameters\"] = \"\"\n",
    "    results[\"group\"] = \"nlp\"\n",
    "    results[\"order\"] = np.arange(results.shape[0])\n",
    "    results[\"species\"] = s.lower()\n",
    "    results[\"objective\"] = q.lower()\n",
    "    results[\"curated\"] = str(c).lower()\n",
    "    results = results[columns]\n",
    "    results.reset_index(inplace=True)\n",
    "    results = results.rename({\"index\":\"method\"}, axis=\"columns\")\n",
    "    hyperparam_sep = \":\"\n",
    "    results[\"hyperparameters\"] = results[\"method\"].map(lambda x: x.split(hyperparam_sep)[1] if hyperparam_sep in x else \"none\")\n",
    "    results[\"method\"] = results[\"method\"].map(lambda x: x.split(hyperparam_sep)[0])\n",
    "    result_dfs.append(results)\n",
    "\n",
    "results = pd.concat(result_dfs)\n",
    "results.reset_index(inplace=True, drop=True)\n",
    "results.to_csv(os.path.join(OUTPUT_DIR,\"part_5_full_table.csv\"), index=False)\n",
    "results.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make another version of the table that is more useful for looking at one particular metric or value.\n",
    "metric_of_interest = \"f1_max\"\n",
    "reshaped_results = results[[\"method\",\"hyperparameters\",\"order\"]].drop_duplicates()\n",
    "for c,q,s in itertools.product(curated,question,species):\n",
    "    if (s != \"both\") and (q != \"pathways\"):\n",
    "        continue\n",
    "    c_label = {True:\"curated\",False:\"all\"}[c]\n",
    "    col_name = \"{}_{}_{}\".format(s,c_label,q)\n",
    "    reshaped_results[col_name] = reshaped_results[\"order\"].map(lambda x: results.loc[(results[\"order\"]==x) & (results[\"curated\"]==str(c).lower()) & (results[\"objective\"]==q.lower()) & (results[\"species\"]==s.lower()), metric_of_interest])\n",
    "    reshaped_results[col_name] = reshaped_results[col_name].map(lambda x: None if len(x)==0 else x.values[0])\n",
    "reshaped_results.to_csv(os.path.join(OUTPUT_DIR,\"part_5_f_scores_table.csv\"), index=False)\n",
    "reshaped_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"part_7\"></a>\n",
    "# Part 7. Clustering Analysis\n",
    "The purpose of this section is to look at different ways that the embeddings obtained for the dataset of phenotype descriptions can be used to cluster or organize the genes to which those phenotypes are mapped into subgroups or representations. These approaches include generating topic models from the data, and doing agglomerative clustering to find clusters to which each gene belongs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rereading in the datasets used by this section so that it can be run independently of other notebook sections.\n",
    "dataset = load_from_pickle(dataset_filename)\n",
    "dataset.filter_has_description()\n",
    "groups = phe_subsets_groups\n",
    "id_to_group_ids, group_id_to_ids = groups.get_groupings_for_dataset(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"topic_modeling\"></a>\n",
    "### Approach 1: Topic modeling based on n-grams with a reduced vocabulary\n",
    "Topic modelling learns a set of word probability distributions from the dataset of text descriptions, which represent distinct topics which are present in the dataset. Each text description can then be represented as a discrete probability distribution over the learned topics based on the probability that a given piece of text belongs to each particular topics. This is a form of data reduction because a high dimensionsal bag-of-words can be represented as a vector of *k* probabilities where *k* is the number of topics. The main advantages of topic modelling over clustering is that topic modelling provides soft classifications that can be additionally interpreted, rather than hard classifications into a single cluster. Topic models are also explainable, because the word probability distributions for that topic can be used to determine which words are most representative of any given topic. One problem with topic modelling is that is uses the n-grams embeddings to semantic similarity between different words is not accounted for. To help alleviate this, this section uses implementations of some existing algorithms to compress the vocabulary as a preprocessing step based on word distance matrices generated using word embeddings.\n",
    "\n",
    "Topic models define topics present in a dataset of texts as word or n-gram probability distributions. These models represent each instance of text then as being composed of or generated as as mixture of these topics. The vector for each text that indicates which fraction of that text is generated by a each topic is of length *n* where *n* is the number of topics, and can be used as a reduced dimensionality of the text, with a much smaller vector length than the n-grams embedding itself. Therefore we can build a topic model of the data with 100 topics for example in order to then represent each description in the dataset as a a vector of length 100. This section constructs topic models from the n-gram representations of the dataset and selects different values for the number of topics in order to find a value that works well during the grid search over the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Gene IDs are used in this section, so we want to map gene IDs to fully preprocessed descriptions.\n",
    "descriptions = dataset.get_description_dictionary()\n",
    "preprocessed_descriptions = {i:\" \".join(preprocess_string(d)) for i,d in descriptions.items()}\n",
    "texts = list(preprocessed_descriptions.values())\n",
    "\n",
    "# Basic parameters for this problem that are currently used.\n",
    "number_of_topics = 42\n",
    "seed = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating and fitting the topic model, either NFM or LDA or something like that.\n",
    "vectorizer = TfidfVectorizer(max_features=10000, stop_words=\"english\", max_df=0.95, min_df=2, lowercase=True)\n",
    "features = vectorizer.fit_transform(texts)\n",
    "cls = NMF(n_components=number_of_topics, random_state=seed)\n",
    "cls.fit(features)\n",
    "\n",
    "# Function for retrieving the topic vectors for a list of text descriptions.\n",
    "def get_topic_embeddings(texts, model, vectorizer):\n",
    "    ngrams_vectors = vectorizer.transform(texts).toarray()\n",
    "    topic_vectors = model.transform(ngrams_vectors)\n",
    "    return(topic_vectors)\n",
    "\n",
    "# Create the dataframe containing the average score assigned to each topic for the genes from each subset.\n",
    "group_to_topic_vector = {}\n",
    "for group_id,ids in group_id_to_ids.items():\n",
    "    texts = [preprocessed_descriptions[i] for i in ids]\n",
    "    topic_vectors = get_topic_embeddings(texts, cls, vectorizer)\n",
    "    mean_topic_vector = np.mean(topic_vectors, axis=0)\n",
    "    group_to_topic_vector[group_id] = mean_topic_vector\n",
    "    \n",
    "# Turning that matrix of weights into a dataframe so it can be worked with.\n",
    "tm_df = pd.DataFrame(group_to_topic_vector)\n",
    "\n",
    "# Changing the order of the Lloyd, Meinke phenotype subsets to match other figures and tables for consistency.\n",
    "lmtm_df = pd.read_csv(lloyd_function_hierarchy_path)    \n",
    "columns_in_order = [col for col in lmtm_df[\"Subset Symbol\"].values if col in tm_df.columns]\n",
    "columns_in_order.reverse()\n",
    "assert len(columns_in_order) == number_of_topics\n",
    "tm_df = tm_df[columns_in_order]\n",
    "    \n",
    "# Reordering so consistency with the curated subsets can be checked by looking at the diagonal.\n",
    "tm_df[\"idxmax\"] = tm_df.idxmax(axis = 1)\n",
    "tm_df[\"idxmax\"] = tm_df[\"idxmax\"].apply(lambda x: tm_df.columns.get_loc(x))\n",
    "tm_df = tm_df.sort_values(by=\"idxmax\")\n",
    "tm_df.drop(columns=[\"idxmax\"], inplace=True)\n",
    "\n",
    "# Saving a version of this dataframe this is indexed by topic integers and subset strings, before makings topics a column instead.\n",
    "topic_subset_similarity_df = tm_df\n",
    "tm_df = tm_df.reset_index(drop=False).rename({\"index\":\"topic\"},axis=1).reset_index(drop=False).rename({\"index\":\"order\"},axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_subset_similarity_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tm_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describing what the most representative tokens for each topic in the model are.\n",
    "num_top_words = 5\n",
    "map_top_words = {}\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "for i,topic_vec in enumerate(cls.components_):\n",
    "    top_words = []\n",
    "    print(i,end=\": \")\n",
    "    for fid in topic_vec.argsort()[-1:-num_top_words-1:-1]:\n",
    "        word = feature_names[fid]\n",
    "        # The next line is applicable if words in the topic model are actually a function of the words in the texts.\n",
    "        #word = \" \".join(unreduce[word])\n",
    "        top_words.append(word)\n",
    "        print(word, end=\" \")  \n",
    "    map_top_words[i] = top_words\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a column that specifies what the top tokens for each topic are.\n",
    "tm_df[\"tokens\"] = tm_df[\"topic\"].map(lambda x: \"|\".join(map_top_words[x]))\n",
    "\n",
    "# Move that column to the left for readability before writing to the file.\n",
    "tokens_col = tm_df.pop(\"tokens\")\n",
    "tm_df.insert(2, \"tokens\", tokens_col)\n",
    "\n",
    "# Renaming the topics to be in order, to be more helpful when preparing figures that are more intuitive.\n",
    "tm_df[\"topic_renumbered\"] = tm_df[\"order\"].values[::-1]+1\n",
    "topic_renumbered_col = tm_df.pop(\"topic_renumbered\")\n",
    "tm_df.insert(2, \"topic_renumbered\", topic_renumbered_col)\n",
    "\n",
    "# Remembering a mapping between the topics, their order, and what the renumbered names are.\n",
    "topic_order_map = {t:i for t,i in zip(tm_df[\"topic\"].values, tm_df[\"order\"].values)}\n",
    "topic_renumbered_map = {t:i for t,i in zip(tm_df[\"topic\"].values, tm_df[\"topic_renumbered\"].values)}\n",
    "\n",
    "# Saving this version of the subset and topic similarity data to a file.\n",
    "tm_df.to_csv(os.path.join(OUTPUT_DIR,\"part_6_topic_modeling_matrix.csv\"), index=False)\n",
    "tm_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Producing a version of the previous table that is useful for producing line drawings representing these results.\n",
    "tm_lines_dict = defaultdict(list)\n",
    "\n",
    "\n",
    "# Remembering the order of the Lloyd, Meinke phenotype subsets to match other figures for consistency.\n",
    "lmtm_df = pd.read_csv(lloyd_function_hierarchy_path)   \n",
    "subset_to_class_map = {s:c for s,c in zip(lmtm_df[\"Subset Symbol\"].values, lmtm_df[\"Class Name\"].values)}\n",
    "subset_to_desc_map = {s:c for s,c in zip(lmtm_df[\"Subset Symbol\"].values, lmtm_df[\"Subset Name and Description \"].values)}\n",
    "subset_abbrevs_in_order = [col for col in lmtm_df[\"Subset Symbol\"].values if col in tm_df.columns]\n",
    "subset_abbrevs_in_order.reverse()\n",
    "subset_order_map = {subset_abbrev:i for i,subset_abbrev in enumerate(subset_abbrevs_in_order)}\n",
    "\n",
    "\n",
    "\n",
    "# Producing the line entries that represent connections between the subsets and topics.\n",
    "line_number = 0\n",
    "topic_int_list = list(topic_subset_similarity_df.columns)\n",
    "subset_str_list = list(topic_subset_similarity_df.index)\n",
    "for subset_abbrev, topic_int in itertools.product(topic_int_list,subset_str_list):\n",
    "    \n",
    "    # The weight of the line, extracted from the similarity matrix between subsets and topics built previously.\n",
    "    weight = topic_subset_similarity_df.loc[topic_int,subset_abbrev]\n",
    "    \n",
    "    # The strings that should be used to represent classes, subsets, and topics in a figure or plot.\n",
    "    subset_str = \"{} ({})\".format(subset_abbrev, subset_to_desc_map[subset_abbrev].lower())\n",
    "    tm_lines_dict[\"subset_str\"].extend([subset_str,subset_str])\n",
    "    tm_lines_dict[\"class_str\"].extend([subset_to_class_map[subset_abbrev],subset_to_class_map[subset_abbrev]])\n",
    "    topic_str = \"Topic {}: ({})\".format(topic_renumbered_map[topic_int], \"|\".join(map_top_words[topic_int]))\n",
    "    tm_lines_dict[\"topic_str\"].extend([topic_str,topic_str])\n",
    "    \n",
    "    # Which line is this, they all have individual numbers so that each line can be its own group in a ggplot object.\n",
    "    tm_lines_dict[\"line_number\"].extend([line_number,line_number])\n",
    "    tm_lines_dict[\"weight\"].extend([weight,weight])\n",
    "    \n",
    "    # Where should the line start and stop? The horizontal values are arbitrary and just have to match.\n",
    "    # The vertical values are determined by which subset and topic are being connected to each other.\n",
    "    tm_lines_dict[\"x\"].extend([0,10])\n",
    "    tm_lines_dict[\"y\"].extend([subset_order_map[subset_abbrev],topic_order_map[topic_int]])\n",
    "    \n",
    "    line_number = line_number+1\n",
    "    \n",
    "tm_lines_df = pd.DataFrame(tm_lines_dict)\n",
    "tm_lines_df.to_csv(os.path.join(OUTPUT_DIR,\"part_6_topic_modeling_lines.csv\"), index=False)\n",
    "tm_lines_df.head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"clustering\"></a>\n",
    "### Approach 2: Agglomerative clustering and comparison to predefined groups\n",
    "This clustering approach uses agglomerative clustering to cluster the genes into a fixed number of clusters based off the distances between their embedding representations using all of the above methods. Clustering into a fixed number of clusters allows for clustering into a similar number of groups as a present in some existing grouping of the data, such as phenotype categories or biochemical pathways, and then determining if the clusters obtained are at all similar to the groupings that already exist. Agglomerative clustering is used here in order to use an arbitrary predefined distance matrix, in this case the matrix being used is the mean distance percentiles from each of the different approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Generate the numpy array where values are mean distance percentiles between all the methods.\n",
    "mean_pct_array = name_to_array[\"mean\"]\n",
    "to_id = array_index_to_id\n",
    "\n",
    "# Do agglomerative clustering based on that distance matrix.\n",
    "number_of_clusters = 42\n",
    "ac = AgglomerativeClustering(n_clusters=number_of_clusters, linkage=\"complete\", affinity=\"precomputed\")\n",
    "clustering = ac.fit(mean_pct_array)\n",
    "id_to_cluster = {}\n",
    "cluster_to_ids = defaultdict(list)\n",
    "for idx,c in enumerate(clustering.labels_):\n",
    "    id_to_cluster[to_id[idx]] = c\n",
    "    cluster_to_ids[c].append(to_id[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Create the dataframe containing the average score assigned to each topic for the genes from each subset.\n",
    "group_to_cluster_vector = {}\n",
    "for group_id,ids in group_id_to_ids.items():\n",
    "    \n",
    "    mean_cluster_vector = np.zeros(number_of_clusters)\n",
    "    for i in ids:\n",
    "        print(ids)\n",
    "        cluster = id_to_cluster[i]\n",
    "        mean_cluster_vector[cluster] = mean_cluster_vector[cluster]+1\n",
    "    mean_cluster_vector = mean_cluster_vector/mean_cluster_vector.sum(axis=0,keepdims=1)\n",
    "    group_to_cluster_vector[group_id] = mean_cluster_vector\n",
    "    \n",
    "ac_df = pd.DataFrame(group_to_cluster_vector)\n",
    "\n",
    "# Changing the order of the Lloyd, Meinke phenotype subsets to match other figures for consistency.\n",
    "filename = \"../data/group_related_files/lloyd/lloyd_function_hierarchy_irb_cleaned.csv\"\n",
    "lmtm_df = pd.read_csv(filename)    \n",
    "columns_in_order = [col for col in lmtm_df[\"Subset Symbol\"].values if col in ac_df.columns]\n",
    "ac_df = ac_df[columns_in_order]\n",
    "\n",
    "# Reordering so consistency with the curated subsets can be checked by looking at the diagonal.\n",
    "ac_df[\"idxmax\"] = ac_df.idxmax(axis = 1)\n",
    "ac_df[\"idxmax\"] = ac_df[\"idxmax\"].apply(lambda x: ac_df.columns.get_loc(x))\n",
    "ac_df = ac_df.sort_values(by=\"idxmax\")\n",
    "ac_df.drop(columns=[\"idxmax\"], inplace=True)\n",
    "ac_df = ac_df.reset_index(drop=False).rename({\"index\":\"cluster\"},axis=1).reset_index(drop=False).rename({\"index\":\"order\"},axis=1)\n",
    "ac_df.to_csv(os.path.join(OUTPUT_DIR,\"part_6_agglomerative_clustering.csv\"), index=False)\n",
    "ac_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_to_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approach 3: Agglomerative clustering and sillhouette scores for each NLP method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if NOTEBOOK:\n",
    "    from sklearn.metrics.cluster import silhouette_score\n",
    "    # Note that homogeneity scores don't fit for evaluating how close the clustering is to pathway membership, etc.\n",
    "    # This is because genes can be assigned to more than one pathway, metric would have to be changed to account for this.\n",
    "    # So all this section does is determines which values of n_clusters provide good clustering results for each matrix.\n",
    "    n_clusters_silhouette_scores = defaultdict(dict)\n",
    "    min_n_clusters = 20\n",
    "    max_n_clusters = 80\n",
    "    step_size = 4\n",
    "    number_of_clusters = np.arange(min_n_clusters, max_n_clusters, step_size)\n",
    "    for n in number_of_clusters:\n",
    "        for name in names:\n",
    "            distance_matrix = name_to_array[name]\n",
    "            ac = AgglomerativeClustering(n_clusters=n, linkage=\"complete\", affinity=\"precomputed\")\n",
    "            clustering = ac.fit(distance_matrix)\n",
    "            sil_score = silhouette_score(distance_matrix, clustering.labels_, metric=\"precomputed\")\n",
    "            n_clusters_silhouette_scores[name][n] = sil_score\n",
    "    sil_df = pd.DataFrame(n_clusters_silhouette_scores).reset_index(drop=False).rename({\"index\":\"n\"},axis=\"columns\")\n",
    "    sil_df.to_csv(os.path.join(OUTPUT_DIR,\"part_6_silhouette_scores_by_n.csv\"), index=False)\n",
    "    sil_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"phenologs\"></a>\n",
    "### Approach 4: Looking for phenolog relationships between clusters and OMIM disease phenotypes\n",
    "This section produces a table of values that provides a score for the a particular pair of a cluster found for this dataset of plant genes and a disease phenotype. Currently the value indicates the fraction of the plant genes in that cluster that have orthologs associated with that disease phenotype. This should be replaced or supplemented with a p-value for evaluating the significance of this value given the distribution of genes and their mappings to all of the disease phenotypes. All the rows from the input dataframe containing the PantherDB and OMIM information where the ID from this dataset is not known or the mapping to a phenotype was unsuccessful are removed at this step, fix this if the metric for evaluating cluster to phenotype phenolog mappings need this information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Read in the dataframe mapping plant genes --> human orthologs --> disease phenotypes.\n",
    "omim_df = pd.read_csv(panther_to_omim_filename)\n",
    "# Add a column that indicates which ID in the dataset those plant genes refer to, for mapping to phenotypes.\n",
    "name_to_id = dataset.get_name_to_id_dictionary()\n",
    "omim_df[\"id\"] = omim_df[\"gene_identifier\"].map(lambda x: name_to_id.get(x,None))\n",
    "omim_df = omim_df.dropna(subset=[\"id\",\"phenotype_mim_name\"], inplace=False)\n",
    "omim_df[\"phenotype_mim_name\"] = omim_df[\"phenotype_mim_name\"].astype(str)\n",
    "omim_df[\"compressed_phenotype_mim_name\"] = omim_df[\"phenotype_mim_name\"].map(lambda x: x.split(\",\")[0])\n",
    "omim_df[\"id\"] = omim_df[\"id\"].astype(\"int64\")\n",
    "omim_df[\"phenotype_mim_number\"] = omim_df[\"phenotype_mim_number\"].astype(\"int64\")\n",
    "# Generate mappings between the IDs in this dataset and disease phenotypes or orthologous genes.\n",
    "id_to_mim_phenotype_names = defaultdict(list)\n",
    "for i,p in zip(omim_df[\"id\"].values,omim_df[\"compressed_phenotype_mim_name\"].values):\n",
    "    id_to_mim_phenotype_names[i].append(p)\n",
    "id_to_human_gene_symbols = defaultdict(list)\n",
    "for i,s in zip(omim_df[\"id\"].values,omim_df[\"human_ortholog_gene_symbol\"].values):\n",
    "    id_to_human_gene_symbols[i].append(s)\n",
    "omim_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many genes in our dataset map to orthologs that map to the same OMIM phenotype?\n",
    "omim_df.groupby(\"compressed_phenotype_mim_name\").size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "phenolog_x_dict = defaultdict(dict)\n",
    "phenolog_p_dict = defaultdict(dict)\n",
    "candidate_genes_dict = defaultdict(dict)\n",
    "phenotypes = pd.unique(omim_df[\"compressed_phenotype_mim_name\"].values)\n",
    "clusters = list(cluster_to_ids.keys())\n",
    "for cluster,phenotype in itertools.product(clusters,phenotypes):\n",
    "    \n",
    "    # What are the candidate genes predicted if this phenolog pairing is real?\n",
    "    ids = cluster_to_ids[cluster]\n",
    "    candidate_genes_dict[cluster][phenotype] = list(set(flatten([id_to_human_gene_symbols[i] for i in ids if phenotype not in id_to_mim_phenotype_names.get(i,[])])))\n",
    "\n",
    "    # What is the p-value for this phenolog pairing?\n",
    "    # The size of the population (genes in the dataset).\n",
    "    M = len(id_to_cluster.keys())\n",
    "    # The number of elements we draw without replacement (genes in the cluster).\n",
    "    N = len(cluster_to_ids[cluster])     \n",
    "    # The number of available successes in the population (genes that map to orthologs that map to this phenotype).\n",
    "    n = len([i for i in id_to_cluster.keys() if phenotype in id_to_mim_phenotype_names.get(i,[])])\n",
    "    # The number of successes drawn (genes in this cluster that map to orthologs that map to this phenotype).\n",
    "    x = list(set(flatten([id_to_mim_phenotype_names.get(i,[]) for i in ids]))).count(phenotype)\n",
    "    prob = 1-hypergeom.cdf(x-1, M, n, N) # Equivalent to prob = 1-sum([hypergeom.pmf(x_i, M, n, N) for x_i in range(0,x)])\n",
    "    phenolog_x_dict[cluster][phenotype] = x\n",
    "    phenolog_p_dict[cluster][phenotype] = prob\n",
    "    \n",
    "\n",
    "# Convert the dictionary to a table of values with cluster and phenotype as the rows and columns.\n",
    "phenolog_matrix = pd.DataFrame(phenolog_x_dict)        \n",
    "phenolog_matrix.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Produce a melted version of the phenolog matrix sorted by value and including predicted candidate genes.\n",
    "phenolog_matrix_reset = phenolog_matrix.reset_index(drop=False).rename({\"index\":\"omim_phenotype_name\"}, axis=\"columns\")\n",
    "phenolog_df = pd.melt(phenolog_matrix_reset, id_vars=[\"omim_phenotype_name\"], value_vars=phenolog_matrix.columns[1:], var_name=\"cluster\", value_name=\"x\")\n",
    "# What other information should be present in this melted phenologs matrix?\n",
    "phenolog_df[\"size\"] = phenolog_df[\"cluster\"].map(lambda x: len(cluster_to_ids[x]))\n",
    "phenolog_df[\"candidate_gene_symbols\"] = np.vectorize(lambda x,y: concatenate_with_bar_delim(*candidate_genes_dict[x][y]))(phenolog_df[\"cluster\"], phenolog_df[\"omim_phenotype_name\"])\n",
    "phenolog_df[\"p_value\"] = np.vectorize(lambda x,y: phenolog_p_dict[x][y])(phenolog_df[\"cluster\"], phenolog_df[\"omim_phenotype_name\"])\n",
    "phenolog_df[\"p_adjusted\"] = multipletests(phenolog_df[\"p_value\"].values, method='bonferroni')[1]\n",
    "phenolog_df.sort_values(by=[\"p_value\"], inplace=True, ascending=True)\n",
    "phenolog_df = phenolog_df[[\"omim_phenotype_name\", \"cluster\", \"size\", \"x\", \"p_value\", \"p_adjusted\", \"candidate_gene_symbols\"]]\n",
    "phenolog_df.to_csv(os.path.join(OUTPUT_DIR,\"part_6_phenologs.csv\"), index=False)\n",
    "phenolog_df.head(30)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
