{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import math\n",
    "import sys\n",
    "import gensim\n",
    "import os\n",
    "import warnings\n",
    "import torch\n",
    "import itertools\n",
    "import multiprocessing as mp\n",
    "from collections import Counter, defaultdict\n",
    "from inspect import signature\n",
    "from scipy.stats import ks_2samp, hypergeom\n",
    "from sklearn.metrics import precision_recall_curve, f1_score, auc\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from scipy import spatial, stats\n",
    "from statsmodels.sandbox.stats.multicomp import multipletests\n",
    "from nltk.corpus import brown\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from pytorch_pretrained_bert import BertTokenizer, BertModel, BertForMaskedLM\n",
    "from gensim.parsing.preprocessing import strip_non_alphanum, stem_text, preprocess_string, remove_stopwords\n",
    "from gensim.utils import simple_preprocess\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.decomposition import LatentDirichletAllocation as LDA\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "sys.path.append(\"../../oats\")\n",
    "from oats.utils.utils import save_to_pickle, load_from_pickle, merge_list_dicts, flatten, to_hms\n",
    "from oats.utils.utils import function_wrapper_with_duration\n",
    "from oats.biology.dataset import Dataset\n",
    "from oats.biology.groupings import Groupings\n",
    "from oats.biology.relationships import ProteinInteractions, AnyInteractions\n",
    "from oats.annotation.ontology import Ontology\n",
    "from oats.annotation.annotation import annotate_using_noble_coder\n",
    "from oats.distances import pairwise as pw\n",
    "from oats.distances.edgelists import merge_edgelists, make_undirected, remove_self_loops, subset_with_ids\n",
    "\n",
    "mpl.rcParams[\"figure.dpi\"] = 400\n",
    "warnings.simplefilter('ignore')\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('brown', quiet=True)\n",
    "nltk.download('averaged_perceptron_tagger', quiet=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999995</th>\n",
       "      <td>9999995</td>\n",
       "      <td>9999996</td>\n",
       "      <td>9999997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999996</th>\n",
       "      <td>9999996</td>\n",
       "      <td>9999997</td>\n",
       "      <td>9999998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999997</th>\n",
       "      <td>9999997</td>\n",
       "      <td>9999998</td>\n",
       "      <td>9999999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999998</th>\n",
       "      <td>9999998</td>\n",
       "      <td>9999999</td>\n",
       "      <td>10000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999999</th>\n",
       "      <td>9999999</td>\n",
       "      <td>10000000</td>\n",
       "      <td>10000001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               a         b         c\n",
       "0              0         1         2\n",
       "1              1         2         3\n",
       "2              2         3         4\n",
       "3              3         4         5\n",
       "4              4         5         6\n",
       "...          ...       ...       ...\n",
       "9999995  9999995   9999996   9999997\n",
       "9999996  9999996   9999997   9999998\n",
       "9999997  9999997   9999998   9999999\n",
       "9999998  9999998   9999999  10000000\n",
       "9999999  9999999  10000000  10000001\n",
       "\n",
       "[10000000 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = []\n",
    "for i in range(10000000):\n",
    "    t.append((i,i+1,i+2))\n",
    "a = pd.DataFrame(t)\n",
    "a.columns = [\"a\",\"b\",\"c\"]\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "      <th>m</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999995</th>\n",
       "      <td>9999995</td>\n",
       "      <td>9999996</td>\n",
       "      <td>9999997</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999996</th>\n",
       "      <td>9999996</td>\n",
       "      <td>9999997</td>\n",
       "      <td>9999998</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999997</th>\n",
       "      <td>9999997</td>\n",
       "      <td>9999998</td>\n",
       "      <td>9999999</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999998</th>\n",
       "      <td>9999998</td>\n",
       "      <td>9999999</td>\n",
       "      <td>10000000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999999</th>\n",
       "      <td>9999999</td>\n",
       "      <td>10000000</td>\n",
       "      <td>10000001</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               a         b         c      m\n",
       "0              0         1         2   True\n",
       "1              1         2         3   True\n",
       "2              2         3         4   True\n",
       "3              3         4         5   True\n",
       "4              4         5         6   True\n",
       "...          ...       ...       ...    ...\n",
       "9999995  9999995   9999996   9999997  False\n",
       "9999996  9999996   9999997   9999998  False\n",
       "9999997  9999997   9999998   9999999  False\n",
       "9999998  9999998   9999999  10000000  False\n",
       "9999999  9999999  10000000  10000001  False\n",
       "\n",
       "[10000000 rows x 4 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = range(5000)\n",
    "d = {i:True for i in l}\n",
    "a[\"m\"] = a[\"c\"].map(lambda x: x in l)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "      <th>m</th>\n",
       "      <th>n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999995</th>\n",
       "      <td>9999995</td>\n",
       "      <td>9999996</td>\n",
       "      <td>9999997</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999996</th>\n",
       "      <td>9999996</td>\n",
       "      <td>9999997</td>\n",
       "      <td>9999998</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999997</th>\n",
       "      <td>9999997</td>\n",
       "      <td>9999998</td>\n",
       "      <td>9999999</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999998</th>\n",
       "      <td>9999998</td>\n",
       "      <td>9999999</td>\n",
       "      <td>10000000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999999</th>\n",
       "      <td>9999999</td>\n",
       "      <td>10000000</td>\n",
       "      <td>10000001</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               a         b         c      m      n\n",
       "0              0         1         2   True   True\n",
       "1              1         2         3   True   True\n",
       "2              2         3         4   True   True\n",
       "3              3         4         5   True   True\n",
       "4              4         5         6   True   True\n",
       "...          ...       ...       ...    ...    ...\n",
       "9999995  9999995   9999996   9999997  False  False\n",
       "9999996  9999996   9999997   9999998  False  False\n",
       "9999997  9999997   9999998   9999999  False  False\n",
       "9999998  9999998   9999999  10000000  False  False\n",
       "9999999  9999999  10000000  10000001  False  False\n",
       "\n",
       "[10000000 rows x 5 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[\"n\"] = a[\"c\"].map(lambda x: d.get(x,False))\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_filename = \"../data/pickles/gene_phenotype_dataset_all_text_and_annotations.pickle\"\n",
    "dataset = load_from_pickle(dataset_filename)\n",
    "pppn_edgelist_path = \"../data/supplemental_files_oellrich_walls/13007_2015_53_MOESM9_ESM.txt\"\n",
    "pppn_edgelist = AnyInteractions(dataset.get_name_to_id_dictionary(), pppn_edgelist_path, default=0.00)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-2dc7347f3058>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mgenes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_gene_dictionary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mstring_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mProteinInteractions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnaming_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minteraction_files\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;31m#dataset.filter_with_ids(string_data.ids)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mstring_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/oats/oats/biology/relationships.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, gene_to_id_dict, name_mapping_file, *string_data_files)\u001b[0m\n\u001b[1;32m     37\u001b[0m \t\t\"\"\"\n\u001b[1;32m     38\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_mapping_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_interaction_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgene_to_id_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring_data_files\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/oats/oats/biology/relationships.py\u001b[0m in \u001b[0;36m_process_interaction_files\u001b[0;34m(self, gene_to_id_dict, string_data_files)\u001b[0m\n\u001b[1;32m    122\u001b[0m                 \u001b[0;31m# These are the IDs that would be removed when removing all rows with NaN, so remember them first.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m                 \u001b[0ml1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"from\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'K'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m                 \u001b[0ml2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"to\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'K'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m                 \u001b[0mids_mentioned_in_string\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml1\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0ml2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/envs/oats/lib/python3.6/site-packages/pandas/core/algorithms.py\u001b[0m in \u001b[0;36munique\u001b[0;34m(values)\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[0mtable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhtable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m     \u001b[0muniques\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m     \u001b[0muniques\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_reconstruct_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0muniques\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Filter the dataset based on whether or not the genes were successfully mapped to an interaction.\n",
    "# Reduce size of the dataset by removing genes not mentioned in the STRING.\n",
    "naming_file = \"../data/group_related_files/string/all_organisms.name_2_string.tsv\"\n",
    "interaction_files = [\n",
    "    \"../data/group_related_files/string/3702.protein.links.detailed.v11.0.txt\", # Arabidopsis thaliana\n",
    "    \"../data/group_related_files/string/4577.protein.links.detailed.v11.0.txt\", # maize\n",
    "    \"../data/group_related_files/string/4530.protein.links.detailed.v11.0.txt\", # tomato \n",
    "    \"../data/group_related_files/string/4081.protein.links.detailed.v11.0.txt\", # medicago\n",
    "    \"../data/group_related_files/string/3880.protein.links.detailed.v11.0.txt\", # rice \n",
    "    \"../data/group_related_files/string/3847.protein.links.detailed.v11.0.txt\", # soybean\n",
    "]\n",
    "\n",
    "genes = dataset.get_gene_dictionary()\n",
    "string_data = ProteinInteractions(genes, naming_file, *interaction_files)\n",
    "#dataset.filter_with_ids(string_data.ids)\n",
    "string_data.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "string_data.df.head(300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pppn_edgelist.df.shape[0])\n",
    "print(len(pppn_edgelist.ids))\n",
    "print(len(pppn_edgelist.ids)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pppn_edgelist.df.tail(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tasdfa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../outputs/04_25_2020_h18m07s00-phe-c/part_5_topic_modeling.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o = Ontology(\"../ontologies/go.obo\")\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(o)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pronto\n",
    "o = pronto.Ontology(\"../ontologies/go-basic.obo\")\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how fast is it to get root terms?\n",
    "a = []\n",
    "for t in o.terms():\n",
    "    parents = [t for t in t.superclasses(with_self=False)]\n",
    "    if t.name is not None:\n",
    "        if len(parents) == 0:\n",
    "            if \"obsolete\" not in t.name:\n",
    "                a.append(t.id)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_terms = len([t for t in o.terms()])\n",
    "depths = {i:0 for i in a}\n",
    "#checked = set(depths.keys())\n",
    "\n",
    "depth = 1\n",
    "cont = True\n",
    "while cont:\n",
    "    before = len(depths)\n",
    "    print(len(depths))\n",
    "    print(num_terms)\n",
    "    \n",
    "    new_terms = []\n",
    "    for t in depths.keys():\n",
    "        new_terms.extend([y.id for y in o[t].subclasses(with_self=False, distance=1)])\n",
    "    \n",
    "    for i in new_terms:\n",
    "        if i not in depths:\n",
    "            depths[i] = depth\n",
    "    \n",
    "    depth = depth + 1\n",
    "    after = len(depths)\n",
    "    if before == after:\n",
    "        cont = False\n",
    "    \n",
    "print(\"done\")\n",
    "\n",
    "# this gets all the ones we can find using this method,\n",
    "# and then we'll need to make sure to default to 1 on all the other terms (things that were excluded from the \n",
    "# previous hunt for whatever reason... no .name? obsolete? etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pronto\n",
    "pronto_ontology_obj = pronto.Ontology(\"../ontologies/go-basic.obo\")\n",
    "\n",
    "\n",
    "def get_term_depth_dictionary(pronto_ontology_obj):\n",
    "\n",
    "    # Find the root term(s) of the ontology.\n",
    "    root_term_ids = []\n",
    "    for term in pronto_ontology_obj.terms():\n",
    "        # Check if this term has no inherited terms (is a root), discounting terms that are obsolete.\n",
    "        inherited_terms = [t for t in term.superclasses(with_self=False)]\n",
    "        if (len(inherited_terms)==0) and (term.name is not None) and (\"obsolete\" not in term.name):\n",
    "            root_term_ids.append(term.id)\n",
    "            \n",
    "    # Find the depths of all terms in the ontology below those terms.\n",
    "    depths = {i:0 for i in root_term_ids}\n",
    "    depth = 1\n",
    "    done = False\n",
    "    while not done:\n",
    "        \n",
    "        # Add all the terms immediately below \n",
    "        before = len(depths)\n",
    "        new_terms = []\n",
    "        for old_term_id in [i for i in depths.keys() if depths[i] == depth-1]:\n",
    "            for new_term_id in [t.id for t in pronto_ontology_obj[old_term_id].subclasses(with_self=False,distance=1)]:\n",
    "                if new_term_id not in depths:\n",
    "                    depths[new_term_id] = depth\n",
    "        \n",
    "        # Increment the depth and see if any new terms were added to the distance dictionary during this pass.\n",
    "        depth = depth + 1\n",
    "        after = len(depths)\n",
    "        if before == after:\n",
    "            done = True\n",
    "            \n",
    "    # Add any other remaining terms to the dictionary with a depth of 0 indicating minimal specificity.\n",
    "    for term in pronto_ontology_obj.terms():\n",
    "        if term.id not in depths:\n",
    "            depths[term.id] = 0\n",
    "    \n",
    "    # Return the dictionary mapping term IDs to their depth in the hierarchy.\n",
    "    return(depths)\n",
    "    \n",
    "d = get_term_depth_dictionary(pronto_ontology_obj)\n",
    "\n",
    "print(d)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "terms = [term for term in o.terms()]\n",
    "\n",
    "\n",
    "t = terms[100]\n",
    "print(t.name)\n",
    "print(t.id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [x.name for x in t.superclasses(with_self=False)]\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o = Ontology(\"../../oats/tests/data/test_ontology.obo\")\n",
    "for k,v in o.subclass_dict.items():\n",
    "    print(k,v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pronto\n",
    "pronto_o = pronto.Ontology(\"../ontologies/go-basic.obo\")\n",
    "print(\"done\")\n",
    "for t in pronto_o.terms():\n",
    "    print(t.name)\n",
    "    if (t.name is not None) and (\"obsolete\" not in t.name):    \n",
    "        print(t.name)\n",
    "        #pass\n",
    "    else:\n",
    "        print(\"HERE\")\n",
    "\n",
    "#import pronto\n",
    "#pronto_o = pronto.Ontology(\"../ontologies/po.obo\")\n",
    "\n",
    "#term = pronto_o[\"PO:0000003\"]\n",
    "\n",
    "#for term in pronto_o.terms():\n",
    "#sup = [t for t in term.subclasses(distance=1)]\n",
    "#print(sup)\n",
    "#break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in pronto_o.terms():\n",
    "    for s in t.synonyms:\n",
    "        print(s.description)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
