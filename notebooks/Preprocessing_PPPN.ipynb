{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading in data available from the Oellrich, Walls et al. (2015) paper\n",
    "The purpose of this notebook is to read in and do a preliminary analysis of the data that is present in the supplementary file of this paper. The dataset also needs to be converted to a standard set of columns containing information in a standard format. This notebook takes the following input files that were obtained from that study and produces a set of files that have standard columns, including the species name, gene names, gene synonyms, text descriptions, and ontology term annotations. The gene names column includes unique gene accessions, names, symbols, or identifiers. The gene synonyms column is included for strings that are not necessary unique identifiers for a particular gene but still refer to that gene or describe its function.\n",
    "\n",
    "\n",
    "\n",
    "### Files read\n",
    "```\n",
    "phenologs-with-oats/data/gene_related_files/pppn/oellrich_walls_dataset_irb_cleaned.txt\n",
    "```\n",
    "\n",
    "### Files created\n",
    "```\n",
    "phenologs-with-oats/data/reshaped_files/ppn_phenotypes.csv\n",
    "phenologs-with-oats/data/reshaped_files/ppn_phenes.csv\n",
    "phenologs-with-oats/data/reshaped_files/ppn_annotations.csv\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "import sys\n",
    "import os\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "sys.path.append(\"../../oats\")\n",
    "from oats.utils.utils import to_abbreviation\n",
    "from oats.nlp.preprocess import concatenate_with_bar_delim\n",
    "from oats.nlp.preprocess import other_delim_to_bar_delim\n",
    "from oats.nlp.preprocess import remove_punctuation\n",
    "from oats.nlp.preprocess import remove_enclosing_brackets\n",
    "\n",
    "OUTPUT_DIR = \"../data/reshaped_files\"\n",
    "mpl.rcParams[\"figure.dpi\"] = 200\n",
    "warnings.simplefilter('ignore')\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phenotypic Text Data (oellrich_walls_dataset_irb_cleaned.txt)\n",
    "This data contains the phenotype descriptions for dominant mutants of genes across six different plant species. The data is read in from a cleaned version that removed some small delimiter errors from the original dataset that is available as a supplemental file from that publication. The data itself is unchanged.\n",
    "\n",
    "There are several columns that contain information about gene names and accessions. We need to know what type of information is in each in order to know which should be retained in the dataset we are preparing. We are interested in both gene names that should map to a specific accession (like cyp716A12 or Medtr3g021350) as well as gene names that are enzyme descriptions (like Ubiquitin-Specific Protease) that could map to more than one gene in a particular species. Each type of information is valuable, but needs to be differentiated so that when comparing whether two rows are specifying the same gene, this is not confused with specifying two different genes that have the same function. In the case of this dataset, the gene symbol and gene identifier columns contain strings that we want to consider to be unique to a particular gene for a particular species, meaning that we can use those strings to look for these gene objects in other resources such as databases of pathway membership. The strings in the gene name column could be unique (narrow sheath1), but they can also be generic descriptions of enzymes (Ubiquitin-Specific Protease). For this reason, this column is not used in downstream analysis.\n",
    "\n",
    "This dataset includes both full phenotype descriptions in one field, and atomized statements (which are phene descriptions) in another field. Either or both of these can be used as a source of text annotations on which to calculate similarity between phenotypes, phenes, or assess a hypothesized connected between genes in a network. We will look at quantity and properties of each of these categerogies of descriptions available and save the restructured datasets separately for each type.\n",
    "\n",
    "This section creates a set of columns that have standardized names and include data in a standardized format that other functions within the package expect. The species column contains strings which are KEGG abbreviations for particular species. The gene names column contains any strings we want to consider to be uniquely mapped to some particular gene.\n",
    "\n",
    "When saving the dataset using the phenotype descriptions as the text description column, there will be duplicates with respect to the combination of that column and the gene names column. This is because for each phenotype description there can be one or more atomized statement that it is comprised of. However, merging these rows requires also merging the ontology term annotations that each was annotated with, and this requires logic that is applied later. At this step we're only concerned with getting the right information in the right columns, and any datset with that correct can be merged later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6366, 29)\n",
      "   gene symbol Gene Identifier allele (optional)                     gene name\n",
      "0          ns1   GRMZM2G069028                                  narrow sheath1\n",
      "1          ns2  NM_001111772.1                                  narrow sheath2\n",
      "2          ns1   GRMZM2G069028                                  narrow sheath1\n",
      "3          ns1   GRMZM2G069028                                  narrow sheath1\n",
      "4          ns2  NM_001111772.1                                  narrow sheath2\n",
      "5          ns2  NM_001111772.1                                  narrow sheath2\n",
      "6        UBP26       At3g49600                     Ubiquitin-Specific Protease\n",
      "7        UBP26       At3g49600                     Ubiquitin-Specific Protease\n",
      "8        UBP26       At3g49600                     Ubiquitin-Specific Protease\n",
      "9        UBP26       At3g49600                     Ubiquitin-Specific Protease\n",
      "10   cyp716A12   Medtr3g021350               lha  cytochrome P450 monoxygenase\n",
      "11   cyp716A12   Medtr3g021350               lha  cytochrome P450 monoxygenase\n",
      "12   cyp716A12   Medtr3g021180               lha  cytochrome P450 monoxygenase\n",
      "13   cyp716A12   Medtr3g021180               lha  cytochrome P450 monoxygenase\n",
      "14         SL1    Os01g0129200            stl1.1                  STAMENLESS 1\n"
     ]
    }
   ],
   "source": [
    "filename = \"../data/gene_related_files/pppn/oellrich_walls_dataset_irb_cleaned.csv\"\n",
    "usecols = [\"Species\", \"gene symbol\", \"Gene Identifier\", \"allele (optional)\", \n",
    "           \"gene name\", \"phenotype name\", \"phenotype description\", 'atomized statement', \n",
    "           'primary entity1 ID', 'primary entity1 text', 'relation_to (optional)', \n",
    "           'primary entity2 ID (optional)', 'primary entity2 text (optional)', \n",
    "           'quality ID', 'quality text', 'PATO Qualifier ID (optional)', \n",
    "           'PATO Qualifier text (optional)', 'secondary_entity1 ID (optional)', \n",
    "           'secondary_entity1 text (optional)', 'relation_to (optional)', \n",
    "           'secondary entity2 ID (optional)','secondary_entity2 text (opyional)',\n",
    "           'developmental stage ID (optional)', 'developmental stage text (optional)', \n",
    "           'condition ID (optional)', 'condition text (optional)', 'Pubmed ID (optional)', \n",
    "           'Dominant, recessive, codominant, semi-dominant (optional)', \n",
    "           'Loss or gain of function (optional)', 'Comment on mode of inheritance (optional)']\n",
    "df = pd.read_csv(filename, usecols=usecols)\n",
    "df.fillna(\"\", inplace=True)\n",
    "print(df.shape)\n",
    "print(df[[\"gene symbol\",\"Gene Identifier\",\"allele (optional)\",\"gene name\"]].head(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting distributions of number of words in each class of description.\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "ax1.set_title(\"Phenotype Descriptions\")\n",
    "ax2.set_title(\"Phene Descriptions\")\n",
    "ax1.set_xlabel(\"Number of words\")\n",
    "ax2.set_xlabel(\"Number of words\")\n",
    "x1 = [len(word_tokenize(x)) for x in df[\"phenotype description\"].values]\n",
    "x2 = [len(word_tokenize(x)) for x in df[\"atomized statement\"].values]\n",
    "ax1.hist(x1, bins=30, range=(0,150), density=False, alpha=0.8, histtype='stepfilled', color=\"black\", edgecolor='none')\n",
    "ax2.hist(x2, bins=30, range=(0,150), density=False, alpha=0.8, histtype='stepfilled', color=\"black\", edgecolor='none')\n",
    "fig.set_size_inches(15,4)\n",
    "fig.tight_layout()\n",
    "fig.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1952\n",
      "2682\n"
     ]
    }
   ],
   "source": [
    "# Finding the number of unique descriptions in each class of text description.\n",
    "print(len(pd.unique(df[\"phenotype description\"])))\n",
    "print(len(pd.unique(df[\"atomized statement\"])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ontology Term Annotations (oellrich_walls_dataset_irb_cleaned.txt)\n",
    "There are several columns in the original dataset which refer to ontology terms, and specify a particular aspect of the EQ statement structure that that particular term refers to. For this dataset we are constructing, we will treat ontology term annotations as a 'bag of terms', and ignore the context of multi-term structured annotations such as EQ statements. Therefore these columns can be combined and any mentioned terms can be combined into a new column (as a bar delimited list). Contex of these terms in their respective ontologies are ignored (more than just leaf terms are retained), because this is handled later when comparing term sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                term_ids\n",
      "0                GO:0009739|PATO:0002302\n",
      "1                GO:0009739|PATO:0002302\n",
      "2                PO:0000003|PATO:0000569\n",
      "3                PO:0020142|PATO:0000574\n",
      "4                PO:0000003|PATO:0000569\n",
      "5                PO:0020142|PATO:0000574\n",
      "6   PO:0009010|PATO:0001241|PATO:0000460\n",
      "7   GO:2000014|PATO:0001236|PATO:0000460\n",
      "8                PO:0000003|PATO:0001834\n",
      "9                PO:0009010|PATO:0002460\n",
      "10  GO:0016135|PATO:0001236|PATO:0000460\n",
      "11               PO:0000003|PATO:0000587\n",
      "12  GO:0016135|PATO:0001236|PATO:0000460\n",
      "13               PO:0000003|PATO:0000587\n",
      "14    PO:0009037|PATO:0000646|PO:0007130\n"
     ]
    }
   ],
   "source": [
    "# Combining the different components of the EQ statement into a single column.\n",
    "df[\"term_ids\"] = np.vectorize(concatenate_with_bar_delim)(\n",
    "    df[\"primary entity1 ID\"], df[\"primary entity2 ID (optional)\"], \n",
    "    df[\"quality ID\"], df[\"PATO Qualifier ID (optional)\"], \n",
    "    df[\"secondary_entity1 ID (optional)\"], df[\"secondary entity2 ID (optional)\"], \n",
    "    df[\"developmental stage ID (optional)\"], df[\"condition ID (optional)\"])\n",
    "print(df[[\"term_ids\"]].head(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   species               gene_names pmid\n",
      "0      zma        GRMZM2G069028|ns1     \n",
      "1      zma       NM_001111772.1|ns2     \n",
      "2      zma        GRMZM2G069028|ns1     \n",
      "3      zma        GRMZM2G069028|ns1     \n",
      "4      zma       NM_001111772.1|ns2     \n",
      "5      zma       NM_001111772.1|ns2     \n",
      "6      ath          At3g49600|UBP26     \n",
      "7      ath          At3g49600|UBP26     \n",
      "8      ath          At3g49600|UBP26     \n",
      "9      ath          At3g49600|UBP26     \n",
      "10     mtr  Medtr3g021350|cyp716A12     \n",
      "11     mtr  Medtr3g021350|cyp716A12     \n",
      "12     mtr  Medtr3g021180|cyp716A12     \n",
      "13     mtr  Medtr3g021180|cyp716A12     \n",
      "14     osa         Os01g0129200|SL1     \n",
      "15     osa         Os01g0129200|SL1     \n",
      "16     osa         Os01g0129200|SL1     \n",
      "17     osa         Os01g0129200|SL1     \n",
      "18     osa         Os01g0129200|SL1     \n",
      "19     osa         Os01g0129200|SL1     \n"
     ]
    }
   ],
   "source": [
    "# Organizing the desired information into a standard set of column headers.\n",
    "df[\"species\"] = df[\"Species\"].apply(to_abbreviation)\n",
    "df[\"gene_names\"] = np.vectorize(concatenate_with_bar_delim)(df[\"Gene Identifier\"], df[\"gene symbol\"])\n",
    "df[\"gene_synonyms\"] = df[\"allele (optional)\"]\n",
    "df[\"pmid\"] = df[\"Pubmed ID (optional)\"]\n",
    "print(df[[\"species\",\"gene_names\",\"pmid\"]].head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving a version that uses the full phenotype descriptions.\n",
    "df[\"description\"] = df[\"phenotype description\"]\n",
    "df_subset = df[[\"species\", \"gene_names\", \"gene_synonyms\", \"description\", \"term_ids\"]]\n",
    "df_subset[\"term_ids\"] = \"\"\n",
    "path = os.path.join(OUTPUT_DIR,\"ppn_phenotypes.csv\")\n",
    "df_subset.to_csv(path, index=False)\n",
    "\n",
    "# Saving a version that uses the individual phene descriptions.\n",
    "df[\"description\"] = df[\"atomized statement\"]\n",
    "df_subset = df[[\"species\", \"gene_names\", \"gene_synonyms\", \"description\", \"term_ids\"]]\n",
    "df_subset[\"term_ids\"] = \"\"\n",
    "path = os.path.join(OUTPUT_DIR,\"ppn_phenes.csv\")\n",
    "df_subset.to_csv(path, index=False)\n",
    "\n",
    "# Saving a version that includes only the ontology term annotations.\n",
    "df[\"description\"] = \"\"\n",
    "df_subset = df[[\"species\", \"gene_names\", \"gene_synonyms\", \"description\", \"term_ids\"]]\n",
    "path = os.path.join(OUTPUT_DIR,\"ppn_annotations.csv\")\n",
    "df_subset.to_csv(path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
