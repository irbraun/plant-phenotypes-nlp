{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Looking at the Dataset\n",
    "The purpose of this notebook is to look closer at the dataset of genes, natural language descriptions, and ontology term annotations that are used in this work. As included in the preprocessing notebooks, these data are drawn from files from either publications supplements like Oellrich, Walls et al. (2015) or model species databases such as TAIR, MaizeGDB, and SGN. The datasets are already loaded and merged using classe available through the oats package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import math\n",
    "import sys\n",
    "import gensim\n",
    "import os\n",
    "import warnings\n",
    "from collections import defaultdict\n",
    "from nltk.corpus import brown\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from gensim.parsing.preprocessing import strip_non_alphanum, stem_text, preprocess_string, remove_stopwords\n",
    "from gensim.utils import simple_preprocess\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "sys.path.append(\"../../oats\")\n",
    "from oats.utils.utils import save_to_pickle, load_from_pickle, merge_list_dicts, flatten, to_hms\n",
    "from oats.biology.dataset import Dataset\n",
    "from oats.biology.groupings import Groupings\n",
    "from oats.biology.relationships import ProteinInteractions, AnyInteractions\n",
    "from oats.annotation.ontology import Ontology\n",
    "\n",
    "warnings.simplefilter('ignore')\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('brown', quiet=True)\n",
    "nltk.download('averaged_perceptron_tagger', quiet=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>species</th>\n",
       "      <th>num_genes</th>\n",
       "      <th>unique_descriptions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ath</td>\n",
       "      <td>628658</td>\n",
       "      <td>9110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gmx</td>\n",
       "      <td>156</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mtr</td>\n",
       "      <td>342</td>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>osa</td>\n",
       "      <td>772</td>\n",
       "      <td>389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sly</td>\n",
       "      <td>786</td>\n",
       "      <td>314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>zma</td>\n",
       "      <td>6526</td>\n",
       "      <td>998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>total</td>\n",
       "      <td>637240</td>\n",
       "      <td>11015</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  species  num_genes  unique_descriptions\n",
       "0     ath     628658                 9110\n",
       "1     gmx        156                   49\n",
       "2     mtr        342                  155\n",
       "3     osa        772                  389\n",
       "4     sly        786                  314\n",
       "5     zma       6526                  998\n",
       "6   total     637240                11015"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = load_from_pickle(\"../data/pickles/gene_phenotype_dataset_all_text_and_annotations_unmerged.pickle\")\n",
    "data.to_pandas().head()\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>species</th>\n",
       "      <th>num_genes</th>\n",
       "      <th>unique_descriptions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ath</td>\n",
       "      <td>6364</td>\n",
       "      <td>3813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gmx</td>\n",
       "      <td>30</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mtr</td>\n",
       "      <td>37</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>osa</td>\n",
       "      <td>92</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sly</td>\n",
       "      <td>70</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>zma</td>\n",
       "      <td>1406</td>\n",
       "      <td>811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>total</td>\n",
       "      <td>7999</td>\n",
       "      <td>4839</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  species  num_genes  unique_descriptions\n",
       "0     ath       6364                 3813\n",
       "1     gmx         30                   24\n",
       "2     mtr         37                   36\n",
       "3     osa         92                   85\n",
       "4     sly         70                   70\n",
       "5     zma       1406                  811\n",
       "6   total       7999                 4839"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = load_from_pickle(\"../data/pickles/gene_phenotype_dataset_all_text_and_annotations.pickle\")\n",
    "data.filter_has_description()\n",
    "data.to_pandas().head()\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What's there for each species?\n",
    "The previously loaded dataset contains all of the genes that across six plant species that have natural language description data for phenotype(s) related to that gene. Each gene can have multiple descriptions annotated to it, which were combined or concatenated when the datasets from multiple sources were merged in creating the pickled datasets. Arabidopsis has the highest number of genes that satisfy this criteria, followed by maize, and then followed by the other four species which have a relatively low number of genes that satisfy this criteria, atleast given the sources used for this work. Note that the number of unique descriptions is lower than the number of genes in call cases, because multiple genes can have the same phenotype description associated with them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>species</th>\n",
       "      <th>num_genes</th>\n",
       "      <th>unique_descriptions</th>\n",
       "      <th>total_words</th>\n",
       "      <th>unique_words</th>\n",
       "      <th>unique_stems</th>\n",
       "      <th>total_lemmas</th>\n",
       "      <th>unique_lemmas</th>\n",
       "      <th>unique_lemmas_to_species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ath</td>\n",
       "      <td>6364</td>\n",
       "      <td>3813</td>\n",
       "      <td>264189</td>\n",
       "      <td>7085</td>\n",
       "      <td>5116</td>\n",
       "      <td>264189</td>\n",
       "      <td>6561</td>\n",
       "      <td>4864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>zma</td>\n",
       "      <td>1406</td>\n",
       "      <td>811</td>\n",
       "      <td>50029</td>\n",
       "      <td>1846</td>\n",
       "      <td>1317</td>\n",
       "      <td>50029</td>\n",
       "      <td>1722</td>\n",
       "      <td>503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>osa</td>\n",
       "      <td>92</td>\n",
       "      <td>85</td>\n",
       "      <td>3887</td>\n",
       "      <td>826</td>\n",
       "      <td>586</td>\n",
       "      <td>3887</td>\n",
       "      <td>760</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sly</td>\n",
       "      <td>70</td>\n",
       "      <td>70</td>\n",
       "      <td>1810</td>\n",
       "      <td>577</td>\n",
       "      <td>438</td>\n",
       "      <td>1810</td>\n",
       "      <td>552</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mtr</td>\n",
       "      <td>37</td>\n",
       "      <td>36</td>\n",
       "      <td>2672</td>\n",
       "      <td>718</td>\n",
       "      <td>516</td>\n",
       "      <td>2672</td>\n",
       "      <td>671</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gmx</td>\n",
       "      <td>30</td>\n",
       "      <td>24</td>\n",
       "      <td>233</td>\n",
       "      <td>81</td>\n",
       "      <td>68</td>\n",
       "      <td>233</td>\n",
       "      <td>78</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>total</td>\n",
       "      <td>7999</td>\n",
       "      <td>4839</td>\n",
       "      <td>322820</td>\n",
       "      <td>8043</td>\n",
       "      <td>5802</td>\n",
       "      <td>322820</td>\n",
       "      <td>7443</td>\n",
       "      <td>5703</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  species  num_genes  unique_descriptions  total_words  unique_words  unique_stems  total_lemmas  unique_lemmas  unique_lemmas_to_species\n",
       "0     ath       6364                 3813       264189          7085          5116        264189           6561                      4864\n",
       "5     zma       1406                  811        50029          1846          1317         50029           1722                       503\n",
       "3     osa         92                   85         3887           826           586          3887            760                        99\n",
       "4     sly         70                   70         1810           577           438          1810            552                        99\n",
       "2     mtr         37                   36         2672           718           516          2672            671                       126\n",
       "1     gmx         30                   24          233            81            68           233             78                        12\n",
       "6   total       7999                 4839       322820          8043          5802        322820           7443                      5703"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wnl = WordNetLemmatizer()\n",
    "lemmatize_doc = lambda d: [wnl.lemmatize(x) for x in simple_preprocess(d)]\n",
    "\n",
    "dists = defaultdict(list)\n",
    "\n",
    "\n",
    "token_lists = {}\n",
    "stems_lists = {}\n",
    "lemma_lists = {}\n",
    "\n",
    "# For each individual species.\n",
    "for species in data.get_species():\n",
    "    df = data.to_pandas()\n",
    "    subset = df[df[\"species\"]==species]\n",
    "    descriptions_not_stemmed = [simple_preprocess(d) for d in subset[\"description\"].values]\n",
    "    descriptions_stemmed = [preprocess_string(d) for d in subset[\"description\"].values]\n",
    "    descriptions_lemmatized = [lemmatize_doc(d) for d in subset[\"description\"].values]\n",
    "    token_lists[species] = flatten(descriptions_not_stemmed)\n",
    "    stems_lists[species] = flatten(descriptions_stemmed)    \n",
    "    lemma_lists[species] = flatten(descriptions_lemmatized)\n",
    "    \n",
    "    # What about the distributions of words per gene and sentences per gene?\n",
    "    dists[\"species\"].extend([species]*subset.shape[0])\n",
    "    dists[\"num_words\"].extend([len(word_tokenize(x)) for x in subset[\"description\"].values])\n",
    "    dists[\"num_sents\"].extend([len(sent_tokenize(x)) for x in subset[\"description\"].values])\n",
    "    \n",
    "    # What about the number of ontology annotations?\n",
    "    #po = len([t for t in subset[\"term_ids\"].values if \"PO\" in t])\n",
    "    #go = len([t for t in subset[\"term_ids\"].values if \"GO\" in t])\n",
    "    \n",
    "# For the entire dataset including all of the species.\n",
    "df = data.to_pandas()\n",
    "subset = df\n",
    "descriptions_not_stemmed = [simple_preprocess(d) for d in subset[\"description\"].values]\n",
    "descriptions_stemmed = [preprocess_string(d) for d in subset[\"description\"].values]\n",
    "descriptions_lemmatized = [lemmatize_doc(d) for d in subset[\"description\"].values]\n",
    "token_lists[\"total\"] = flatten(descriptions_not_stemmed)\n",
    "stems_lists[\"total\"] = flatten(descriptions_stemmed)    \n",
    "lemma_lists[\"total\"] = flatten(descriptions_lemmatized)\n",
    "\n",
    "# What about lemmas that are uniquely used for a particular species?\n",
    "lemma_sets_unique_to_species = {}\n",
    "for species in data.get_species():\n",
    "    other_species = [s for s in data.get_species() if s != species]\n",
    "    lemmas_used_in_other_species = set(flatten([lemma_lists[s] for s in other_species]))\n",
    "    unique_lemmas = set(lemma_lists[species]).difference(lemmas_used_in_other_species)\n",
    "    lemma_sets_unique_to_species[species] = unique_lemmas\n",
    "lemma_sets_unique_to_species[\"total\"] = flatten([list(s) for s in lemma_sets_unique_to_species.values()])\n",
    "\n",
    "    \n",
    "# Create a dataframe to contain the summarizing information about this dataset, and sort it by number of genes.\n",
    "df = data.describe() \n",
    "condition = (df.species==\"total\")\n",
    "excluded = df[condition]\n",
    "included = df[~condition]\n",
    "df_sorted = included.sort_values(by=\"num_genes\", ascending=False)\n",
    "df = pd.concat([df_sorted,excluded])\n",
    "\n",
    "# Add columns summarizing information about the text descriptions in the dataset.\n",
    "df[\"total_words\"] = df[\"species\"].map(lambda x: len(token_lists[x]))\n",
    "df[\"unique_words\"] = df[\"species\"].map(lambda x: len(set(token_lists[x])))\n",
    "df[\"unique_stems\"] = df[\"species\"].map(lambda x: len(set(stems_lists[x])))\n",
    "df[\"total_lemmas\"] = df[\"species\"].map(lambda x: len(lemma_lists[x]))\n",
    "df[\"unique_lemmas\"] = df[\"species\"].map(lambda x: len(set(lemma_lists[x])))\n",
    "df[\"unique_lemmas_to_species\"] = df[\"species\"].map(lambda x: len(lemma_sets_unique_to_species[x]))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>species</th>\n",
       "      <th>num_words</th>\n",
       "      <th>num_sents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ath</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ath</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ath</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ath</td>\n",
       "      <td>67</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ath</td>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ath</td>\n",
       "      <td>78</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ath</td>\n",
       "      <td>117</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ath</td>\n",
       "      <td>71</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ath</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ath</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ath</td>\n",
       "      <td>773</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ath</td>\n",
       "      <td>202</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ath</td>\n",
       "      <td>296</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ath</td>\n",
       "      <td>36</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ath</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ath</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ath</td>\n",
       "      <td>119</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ath</td>\n",
       "      <td>70</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ath</td>\n",
       "      <td>57</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ath</td>\n",
       "      <td>42</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   species  num_words  num_sents\n",
       "0      ath          8          1\n",
       "1      ath          3          1\n",
       "2      ath         15          2\n",
       "3      ath         67          5\n",
       "4      ath         18          3\n",
       "5      ath         78         10\n",
       "6      ath        117          9\n",
       "7      ath         71          6\n",
       "8      ath         24          2\n",
       "9      ath          7          1\n",
       "10     ath        773         49\n",
       "11     ath        202         12\n",
       "12     ath        296         13\n",
       "13     ath         36          5\n",
       "14     ath          4          1\n",
       "15     ath         22          3\n",
       "16     ath        119         12\n",
       "17     ath         70          8\n",
       "18     ath         57          8\n",
       "19     ath         42          5"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_distributions = pd.DataFrame(dists)\n",
    "text_distributions.to_csv(\"../data/scratch/word_sent_distributions.csv\", index=False)\n",
    "text_distributions.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What about the ontology term annotations for each species?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>species</th>\n",
       "      <th>num_genes</th>\n",
       "      <th>unique_descriptions</th>\n",
       "      <th>total_words</th>\n",
       "      <th>unique_words</th>\n",
       "      <th>unique_stems</th>\n",
       "      <th>total_lemmas</th>\n",
       "      <th>unique_lemmas</th>\n",
       "      <th>unique_lemmas_to_species</th>\n",
       "      <th>go</th>\n",
       "      <th>po</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ath</td>\n",
       "      <td>6364</td>\n",
       "      <td>3813</td>\n",
       "      <td>264189</td>\n",
       "      <td>7085</td>\n",
       "      <td>5116</td>\n",
       "      <td>264189</td>\n",
       "      <td>6561</td>\n",
       "      <td>4864</td>\n",
       "      <td>5434</td>\n",
       "      <td>4420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>zma</td>\n",
       "      <td>1406</td>\n",
       "      <td>811</td>\n",
       "      <td>50029</td>\n",
       "      <td>1846</td>\n",
       "      <td>1317</td>\n",
       "      <td>50029</td>\n",
       "      <td>1722</td>\n",
       "      <td>503</td>\n",
       "      <td>184</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>osa</td>\n",
       "      <td>92</td>\n",
       "      <td>85</td>\n",
       "      <td>3887</td>\n",
       "      <td>826</td>\n",
       "      <td>586</td>\n",
       "      <td>3887</td>\n",
       "      <td>760</td>\n",
       "      <td>99</td>\n",
       "      <td>46</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sly</td>\n",
       "      <td>70</td>\n",
       "      <td>70</td>\n",
       "      <td>1810</td>\n",
       "      <td>577</td>\n",
       "      <td>438</td>\n",
       "      <td>1810</td>\n",
       "      <td>552</td>\n",
       "      <td>99</td>\n",
       "      <td>23</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mtr</td>\n",
       "      <td>37</td>\n",
       "      <td>36</td>\n",
       "      <td>2672</td>\n",
       "      <td>718</td>\n",
       "      <td>516</td>\n",
       "      <td>2672</td>\n",
       "      <td>671</td>\n",
       "      <td>126</td>\n",
       "      <td>30</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gmx</td>\n",
       "      <td>30</td>\n",
       "      <td>24</td>\n",
       "      <td>233</td>\n",
       "      <td>81</td>\n",
       "      <td>68</td>\n",
       "      <td>233</td>\n",
       "      <td>78</td>\n",
       "      <td>12</td>\n",
       "      <td>28</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>total</td>\n",
       "      <td>7999</td>\n",
       "      <td>4839</td>\n",
       "      <td>322820</td>\n",
       "      <td>8043</td>\n",
       "      <td>5802</td>\n",
       "      <td>322820</td>\n",
       "      <td>7443</td>\n",
       "      <td>5703</td>\n",
       "      <td>5745</td>\n",
       "      <td>4747</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  species  num_genes  unique_descriptions  total_words  unique_words  unique_stems  total_lemmas  unique_lemmas  unique_lemmas_to_species    go    po\n",
       "0     ath       6364                 3813       264189          7085          5116        264189           6561                      4864  5434  4420\n",
       "5     zma       1406                  811        50029          1846          1317         50029           1722                       503   184   111\n",
       "3     osa         92                   85         3887           826           586          3887            760                        99    46    92\n",
       "4     sly         70                   70         1810           577           438          1810            552                        99    23    65\n",
       "2     mtr         37                   36         2672           718           516          2672            671                       126    30    32\n",
       "1     gmx         30                   24          233            81            68           233             78                        12    28    27\n",
       "6   total       7999                 4839       322820          8043          5802        322820           7443                      5703  5745  4747"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many of the genes in this dataset for each species are mapped to atleast one term from a given ontology?\n",
    "num_mapped_go = {}\n",
    "num_mapped_po = {}\n",
    "for species in data.get_species():\n",
    "    d = data.to_pandas()\n",
    "    subset = d[d[\"species\"]==species]    \n",
    "    num_mapped_po[species] = len([t for t in subset[\"term_ids\"].values if \"PO\" in t])\n",
    "    num_mapped_go[species] = len([t for t in subset[\"term_ids\"].values if \"GO\" in t])\n",
    "num_mapped_go[\"total\"] = sum(list(num_mapped_go.values()))   \n",
    "num_mapped_po[\"total\"] = sum(list(num_mapped_po.values()))\n",
    "df[\"go\"] = df[\"species\"].map(lambda x: num_mapped_go[x])\n",
    "df[\"po\"] = df[\"species\"].map(lambda x: num_mapped_po[x])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What about the biologically relevant groups like biochemical pathways and phenotypes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>species</th>\n",
       "      <th>num_genes</th>\n",
       "      <th>unique_descriptions</th>\n",
       "      <th>total_words</th>\n",
       "      <th>unique_words</th>\n",
       "      <th>unique_stems</th>\n",
       "      <th>total_lemmas</th>\n",
       "      <th>unique_lemmas</th>\n",
       "      <th>unique_lemmas_to_species</th>\n",
       "      <th>go</th>\n",
       "      <th>po</th>\n",
       "      <th>kegg</th>\n",
       "      <th>plantcyc</th>\n",
       "      <th>lloyd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ath</td>\n",
       "      <td>6364</td>\n",
       "      <td>3813</td>\n",
       "      <td>264189</td>\n",
       "      <td>7085</td>\n",
       "      <td>5116</td>\n",
       "      <td>264189</td>\n",
       "      <td>6561</td>\n",
       "      <td>4864</td>\n",
       "      <td>5434</td>\n",
       "      <td>4420</td>\n",
       "      <td>1572</td>\n",
       "      <td>926</td>\n",
       "      <td>2868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>zma</td>\n",
       "      <td>1406</td>\n",
       "      <td>811</td>\n",
       "      <td>50029</td>\n",
       "      <td>1846</td>\n",
       "      <td>1317</td>\n",
       "      <td>50029</td>\n",
       "      <td>1722</td>\n",
       "      <td>503</td>\n",
       "      <td>184</td>\n",
       "      <td>111</td>\n",
       "      <td>156</td>\n",
       "      <td>133</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>osa</td>\n",
       "      <td>92</td>\n",
       "      <td>85</td>\n",
       "      <td>3887</td>\n",
       "      <td>826</td>\n",
       "      <td>586</td>\n",
       "      <td>3887</td>\n",
       "      <td>760</td>\n",
       "      <td>99</td>\n",
       "      <td>46</td>\n",
       "      <td>92</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sly</td>\n",
       "      <td>70</td>\n",
       "      <td>70</td>\n",
       "      <td>1810</td>\n",
       "      <td>577</td>\n",
       "      <td>438</td>\n",
       "      <td>1810</td>\n",
       "      <td>552</td>\n",
       "      <td>99</td>\n",
       "      <td>23</td>\n",
       "      <td>65</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mtr</td>\n",
       "      <td>37</td>\n",
       "      <td>36</td>\n",
       "      <td>2672</td>\n",
       "      <td>718</td>\n",
       "      <td>516</td>\n",
       "      <td>2672</td>\n",
       "      <td>671</td>\n",
       "      <td>126</td>\n",
       "      <td>30</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gmx</td>\n",
       "      <td>30</td>\n",
       "      <td>24</td>\n",
       "      <td>233</td>\n",
       "      <td>81</td>\n",
       "      <td>68</td>\n",
       "      <td>233</td>\n",
       "      <td>78</td>\n",
       "      <td>12</td>\n",
       "      <td>28</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>total</td>\n",
       "      <td>7999</td>\n",
       "      <td>4839</td>\n",
       "      <td>322820</td>\n",
       "      <td>8043</td>\n",
       "      <td>5802</td>\n",
       "      <td>322820</td>\n",
       "      <td>7443</td>\n",
       "      <td>5703</td>\n",
       "      <td>5745</td>\n",
       "      <td>4747</td>\n",
       "      <td>1746</td>\n",
       "      <td>1066</td>\n",
       "      <td>2868</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  species  num_genes  unique_descriptions  total_words  unique_words  unique_stems  total_lemmas  unique_lemmas  unique_lemmas_to_species    go    po  kegg  plantcyc  lloyd\n",
       "0     ath       6364                 3813       264189          7085          5116        264189           6561                      4864  5434  4420  1572       926   2868\n",
       "5     zma       1406                  811        50029          1846          1317         50029           1722                       503   184   111   156       133      0\n",
       "3     osa         92                   85         3887           826           586          3887            760                        99    46    92     0         3      0\n",
       "4     sly         70                   70         1810           577           438          1810            552                        99    23    65    17         2      0\n",
       "2     mtr         37                   36         2672           718           516          2672            671                       126    30    32     0         2      0\n",
       "1     gmx         30                   24          233            81            68           233             78                        12    28    27     1         0      0\n",
       "6   total       7999                 4839       322820          8043          5802        322820           7443                      5703  5745  4747  1746      1066   2868"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What are the groupings that we're interested in mapping to?\n",
    "kegg_pathways_filename = \"../data/pickles/groupings_from_kegg_pathways.pickle\" \n",
    "pmn_pathways_filename = \"../data/pickles/groupings_from_pmn_pathways.pickle\"                        \n",
    "lloyd_subsets_filename = \"../data/pickles/groupings_from_lloyd_subsets.pickle\"                     \n",
    "groupings_dict = {\"kegg\":kegg_pathways_filename,\"plantcyc\":pmn_pathways_filename,\"lloyd\":lloyd_subsets_filename}\n",
    "\n",
    "for name,filename in groupings_dict.items():\n",
    "    groups = load_from_pickle(filename)\n",
    "    id_to_group_ids, group_id_to_ids = groups.get_groupings_for_dataset(data)\n",
    "    group_mapped_ids = [k for (k,v) in id_to_group_ids.items() if len(v)>0]\n",
    "    species_dict = data.get_species_dictionary()\n",
    "    num_mapped = {}\n",
    "    for species in data.get_species():\n",
    "        num_mapped[species] = len([x for x in group_mapped_ids if species_dict[x]==species])\n",
    "    num_mapped[\"total\"] = sum(list(num_mapped.values()))    \n",
    "    df[name] = df[\"species\"].map(lambda x: num_mapped[x])  \n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What about the other biologically relevant information like orthologous genes and protein interactions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PantherDB for plant orthologs.\n",
    "ortholog_file_path = \"../data/orthology_related_files/pantherdb/PlantGenomeOrthologs_IRB_Modified.txt\"\n",
    "ortholog_edgelist = AnyInteractions(data.get_name_to_id_dictionary(), ortholog_file_path)\n",
    "species_dict = data.get_species_dictionary()\n",
    "num_mapped = {}\n",
    "for species in data.get_species():\n",
    "    num_mapped[species] = len([x for x in ortholog_edgelist.ids if species_dict[x]==species])\n",
    "num_mapped[\"total\"] = sum(list(num_mapped.values()))\n",
    "df[\"panther\"] = df[\"species\"].map(lambda x: num_mapped[x])    \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STRING DB for protein-protein interactions.\n",
    "naming_file = \"../data/group_related_files/string/all_organisms.name_2_string.tsv\"\n",
    "interaction_files = [\n",
    "    \"../data/group_related_files/string/3702.protein.links.detailed.v11.0.txt\", # Arabidopsis thaliana\n",
    "    \"../data/group_related_files/string/4577.protein.links.detailed.v11.0.txt\", # maize\n",
    "    \"../data/group_related_files/string/4530.protein.links.detailed.v11.0.txt\", # tomato \n",
    "    \"../data/group_related_files/string/4081.protein.links.detailed.v11.0.txt\", # medicago\n",
    "    \"../data/group_related_files/string/3880.protein.links.detailed.v11.0.txt\", # rice \n",
    "    \"../data/group_related_files/string/3847.protein.links.detailed.v11.0.txt\", # soybean\n",
    "]\n",
    "genes = data.get_gene_dictionary()\n",
    "string_data = ProteinInteractions(genes, naming_file, *interaction_files)\n",
    "species_dict = data.get_species_dictionary()\n",
    "num_mapped = {}\n",
    "for species in data.get_species():\n",
    "    num_mapped[species] = len([x for x in string_data.ids if species_dict[x]==species])\n",
    "num_mapped[\"total\"] = sum(list(num_mapped.values()))\n",
    "df[\"stringdb\"] = df[\"species\"].map(lambda x: num_mapped[x])    \n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How do the vocabularies used for different species compare?\n",
    "One of the things we are interested in is discovering or recovering phenotype similarity between different species in order to identify phenologs (phenotypes between species that share some underlying genetic cause). For this reason, we are interested in how the vocabularies used to describe phenotypes between different species vary, because this will impact how feasible it is to use a dataset like this to identify phenologs. Because the Arabidopsis and maize datasets are the largest in this case, we will compare the vocabularies used in describing the phenotypes associated with the genes from these species in this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>part_of_speech</th>\n",
       "      <th>ath_freq</th>\n",
       "      <th>ath_rate</th>\n",
       "      <th>zma_freq</th>\n",
       "      <th>zma_rate</th>\n",
       "      <th>diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>adding</td>\n",
       "      <td>VB</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000757</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>profound</td>\n",
       "      <td>NN</td>\n",
       "      <td>5</td>\n",
       "      <td>0.001893</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cancer</td>\n",
       "      <td>NN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000379</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>central</td>\n",
       "      <td>JJ</td>\n",
       "      <td>29</td>\n",
       "      <td>0.010977</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001999</td>\n",
       "      <td>0.008978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>erf</td>\n",
       "      <td>NN</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000757</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ptohrcc</td>\n",
       "      <td>NN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000379</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>phytoglycogens</td>\n",
       "      <td>NN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000379</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>attribute</td>\n",
       "      <td>NN</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000757</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>respond</td>\n",
       "      <td>NN</td>\n",
       "      <td>25</td>\n",
       "      <td>0.009463</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>change</td>\n",
       "      <td>NN</td>\n",
       "      <td>162</td>\n",
       "      <td>0.061320</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001999</td>\n",
       "      <td>0.059321</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            token part_of_speech  ath_freq  ath_rate  zma_freq  zma_rate      diff\n",
       "0          adding             VB         2  0.000757         0  0.000000  0.000757\n",
       "1        profound             NN         5  0.001893         0  0.000000  0.001893\n",
       "2          cancer             NN         1  0.000379         0  0.000000  0.000379\n",
       "3         central             JJ        29  0.010977         1  0.001999  0.008978\n",
       "4             erf             NN         2  0.000757         0  0.000000  0.000757\n",
       "5         ptohrcc             NN         1  0.000379         0  0.000000  0.000379\n",
       "6  phytoglycogens             NN         1  0.000379         0  0.000000  0.000379\n",
       "7       attribute             NN         2  0.000757         0  0.000000  0.000757\n",
       "8         respond             NN        25  0.009463         0  0.000000  0.009463\n",
       "9          change             NN       162  0.061320         1  0.001999  0.059321"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.probability import FreqDist\n",
    "\n",
    "vocabs = {s:set(lemma_list) for s,lemma_list in lemma_lists.items()}\n",
    "fdist_zma = FreqDist(lemma_lists[\"zma\"])\n",
    "fdist_ath = FreqDist(lemma_lists[\"ath\"])\n",
    "\n",
    "#vocabs = {s:set(stems_list) for s,stems_list in stems_lists.items()}\n",
    "#fdist_zma = FreqDist(stems_lists[\"zma\"])\n",
    "#fdist_ath = FreqDist(stems_lists[\"ath\"])\n",
    "\n",
    "#vocabs = {s:set(token_list) for s,token_list in token_lists.items()}\n",
    "#fdist_zma = FreqDist(token_lists[\"zma\"])\n",
    "#fdist_ath = FreqDist(token_lists[\"ath\"])\n",
    "\n",
    "\n",
    "union_vocab = vocabs[\"zma\"].union(vocabs[\"ath\"])\n",
    "table = pd.DataFrame({\"token\":list(union_vocab)})\n",
    "stops = set(stopwords.words('english'))\n",
    "table = table[~table.token.isin(stops)]\n",
    "table[\"part_of_speech\"] = table[\"token\"].map(lambda x: nltk.pos_tag([x])[0][1][:2])\n",
    "table[\"ath_freq\"] = table[\"token\"].map(lambda x: fdist_ath[x])\n",
    "table[\"ath_rate\"] = table[\"ath_freq\"]*100/len(token_lists[\"ath\"])\n",
    "table[\"zma_freq\"] = table[\"token\"].map(lambda x: fdist_zma[x])\n",
    "table[\"zma_rate\"] = table[\"zma_freq\"]*100/len(token_lists[\"zma\"])\n",
    "table[\"diff\"] = table[\"ath_rate\"]-table[\"zma_rate\"]\n",
    "table.to_csv(\"../data/scratch/token_frequencies.csv\")\n",
    "table.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>part_of_speech</th>\n",
       "      <th>ath_freq</th>\n",
       "      <th>ath_rate</th>\n",
       "      <th>zma_freq</th>\n",
       "      <th>zma_rate</th>\n",
       "      <th>diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6839</th>\n",
       "      <td>embryo</td>\n",
       "      <td>NN</td>\n",
       "      <td>4995</td>\n",
       "      <td>1.890692</td>\n",
       "      <td>151</td>\n",
       "      <td>0.301825</td>\n",
       "      <td>1.588867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2766</th>\n",
       "      <td>mutant</td>\n",
       "      <td>NN</td>\n",
       "      <td>4778</td>\n",
       "      <td>1.808554</td>\n",
       "      <td>256</td>\n",
       "      <td>0.511703</td>\n",
       "      <td>1.296851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2757</th>\n",
       "      <td>phenotype</td>\n",
       "      <td>NN</td>\n",
       "      <td>3583</td>\n",
       "      <td>1.356226</td>\n",
       "      <td>78</td>\n",
       "      <td>0.155910</td>\n",
       "      <td>1.200316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1170</th>\n",
       "      <td>root</td>\n",
       "      <td>NN</td>\n",
       "      <td>2943</td>\n",
       "      <td>1.113975</td>\n",
       "      <td>72</td>\n",
       "      <td>0.143917</td>\n",
       "      <td>0.970059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3249</th>\n",
       "      <td>type</td>\n",
       "      <td>NN</td>\n",
       "      <td>2540</td>\n",
       "      <td>0.961433</td>\n",
       "      <td>15</td>\n",
       "      <td>0.029983</td>\n",
       "      <td>0.931450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6757</th>\n",
       "      <td>wild</td>\n",
       "      <td>NN</td>\n",
       "      <td>2456</td>\n",
       "      <td>0.929637</td>\n",
       "      <td>7</td>\n",
       "      <td>0.013992</td>\n",
       "      <td>0.915646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3704</th>\n",
       "      <td>defective</td>\n",
       "      <td>JJ</td>\n",
       "      <td>3341</td>\n",
       "      <td>1.264625</td>\n",
       "      <td>285</td>\n",
       "      <td>0.569670</td>\n",
       "      <td>0.694955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>814</th>\n",
       "      <td>reduced</td>\n",
       "      <td>VB</td>\n",
       "      <td>2860</td>\n",
       "      <td>1.082558</td>\n",
       "      <td>216</td>\n",
       "      <td>0.431750</td>\n",
       "      <td>0.650809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5341</th>\n",
       "      <td>stage</td>\n",
       "      <td>NN</td>\n",
       "      <td>1814</td>\n",
       "      <td>0.686630</td>\n",
       "      <td>63</td>\n",
       "      <td>0.125927</td>\n",
       "      <td>0.560703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2718</th>\n",
       "      <td>cotyledon</td>\n",
       "      <td>NN</td>\n",
       "      <td>1443</td>\n",
       "      <td>0.546200</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.546200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3813</th>\n",
       "      <td>growth</td>\n",
       "      <td>NN</td>\n",
       "      <td>1830</td>\n",
       "      <td>0.692686</td>\n",
       "      <td>79</td>\n",
       "      <td>0.157908</td>\n",
       "      <td>0.534778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5586</th>\n",
       "      <td>seed</td>\n",
       "      <td>NN</td>\n",
       "      <td>1890</td>\n",
       "      <td>0.715397</td>\n",
       "      <td>113</td>\n",
       "      <td>0.225869</td>\n",
       "      <td>0.489528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3965</th>\n",
       "      <td>increased</td>\n",
       "      <td>VB</td>\n",
       "      <td>1316</td>\n",
       "      <td>0.498128</td>\n",
       "      <td>11</td>\n",
       "      <td>0.021987</td>\n",
       "      <td>0.476141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4620</th>\n",
       "      <td>terminal</td>\n",
       "      <td>NN</td>\n",
       "      <td>1268</td>\n",
       "      <td>0.479959</td>\n",
       "      <td>4</td>\n",
       "      <td>0.007995</td>\n",
       "      <td>0.471964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5714</th>\n",
       "      <td>level</td>\n",
       "      <td>NN</td>\n",
       "      <td>1336</td>\n",
       "      <td>0.505699</td>\n",
       "      <td>22</td>\n",
       "      <td>0.043974</td>\n",
       "      <td>0.461724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1720</th>\n",
       "      <td>cell</td>\n",
       "      <td>NN</td>\n",
       "      <td>1646</td>\n",
       "      <td>0.623039</td>\n",
       "      <td>112</td>\n",
       "      <td>0.223870</td>\n",
       "      <td>0.399169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4263</th>\n",
       "      <td>rosette</td>\n",
       "      <td>NN</td>\n",
       "      <td>967</td>\n",
       "      <td>0.366026</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001999</td>\n",
       "      <td>0.364027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4814</th>\n",
       "      <td>double</td>\n",
       "      <td>RB</td>\n",
       "      <td>956</td>\n",
       "      <td>0.361862</td>\n",
       "      <td>3</td>\n",
       "      <td>0.005997</td>\n",
       "      <td>0.355866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4681</th>\n",
       "      <td>globular</td>\n",
       "      <td>NN</td>\n",
       "      <td>905</td>\n",
       "      <td>0.342558</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.342558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003</th>\n",
       "      <td>abnormal</td>\n",
       "      <td>JJ</td>\n",
       "      <td>1049</td>\n",
       "      <td>0.397064</td>\n",
       "      <td>28</td>\n",
       "      <td>0.055968</td>\n",
       "      <td>0.341097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1865</th>\n",
       "      <td>wa</td>\n",
       "      <td>NN</td>\n",
       "      <td>886</td>\n",
       "      <td>0.335366</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001999</td>\n",
       "      <td>0.333367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599</th>\n",
       "      <td>flower</td>\n",
       "      <td>NN</td>\n",
       "      <td>940</td>\n",
       "      <td>0.355806</td>\n",
       "      <td>14</td>\n",
       "      <td>0.027984</td>\n",
       "      <td>0.327822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6866</th>\n",
       "      <td>flowering</td>\n",
       "      <td>VB</td>\n",
       "      <td>1031</td>\n",
       "      <td>0.390251</td>\n",
       "      <td>32</td>\n",
       "      <td>0.063963</td>\n",
       "      <td>0.326288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4512</th>\n",
       "      <td>short</td>\n",
       "      <td>JJ</td>\n",
       "      <td>1504</td>\n",
       "      <td>0.569289</td>\n",
       "      <td>123</td>\n",
       "      <td>0.245857</td>\n",
       "      <td>0.323432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>921</th>\n",
       "      <td>compared</td>\n",
       "      <td>VB</td>\n",
       "      <td>882</td>\n",
       "      <td>0.333852</td>\n",
       "      <td>9</td>\n",
       "      <td>0.017990</td>\n",
       "      <td>0.315862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3204</th>\n",
       "      <td>silique</td>\n",
       "      <td>NN</td>\n",
       "      <td>798</td>\n",
       "      <td>0.302056</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.302056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6871</th>\n",
       "      <td>sensitive</td>\n",
       "      <td>JJ</td>\n",
       "      <td>827</td>\n",
       "      <td>0.313033</td>\n",
       "      <td>6</td>\n",
       "      <td>0.011993</td>\n",
       "      <td>0.301040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2620</th>\n",
       "      <td>visible</td>\n",
       "      <td>JJ</td>\n",
       "      <td>838</td>\n",
       "      <td>0.317197</td>\n",
       "      <td>13</td>\n",
       "      <td>0.025985</td>\n",
       "      <td>0.291212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1655</th>\n",
       "      <td>development</td>\n",
       "      <td>NN</td>\n",
       "      <td>862</td>\n",
       "      <td>0.326282</td>\n",
       "      <td>19</td>\n",
       "      <td>0.037978</td>\n",
       "      <td>0.288304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4402</th>\n",
       "      <td>hypocotyl</td>\n",
       "      <td>NN</td>\n",
       "      <td>752</td>\n",
       "      <td>0.284645</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.284645</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            token part_of_speech  ath_freq  ath_rate  zma_freq  zma_rate      diff\n",
       "6839       embryo             NN      4995  1.890692       151  0.301825  1.588867\n",
       "2766       mutant             NN      4778  1.808554       256  0.511703  1.296851\n",
       "2757    phenotype             NN      3583  1.356226        78  0.155910  1.200316\n",
       "1170         root             NN      2943  1.113975        72  0.143917  0.970059\n",
       "3249         type             NN      2540  0.961433        15  0.029983  0.931450\n",
       "6757         wild             NN      2456  0.929637         7  0.013992  0.915646\n",
       "3704    defective             JJ      3341  1.264625       285  0.569670  0.694955\n",
       "814       reduced             VB      2860  1.082558       216  0.431750  0.650809\n",
       "5341        stage             NN      1814  0.686630        63  0.125927  0.560703\n",
       "2718    cotyledon             NN      1443  0.546200         0  0.000000  0.546200\n",
       "3813       growth             NN      1830  0.692686        79  0.157908  0.534778\n",
       "5586         seed             NN      1890  0.715397       113  0.225869  0.489528\n",
       "3965    increased             VB      1316  0.498128        11  0.021987  0.476141\n",
       "4620     terminal             NN      1268  0.479959         4  0.007995  0.471964\n",
       "5714        level             NN      1336  0.505699        22  0.043974  0.461724\n",
       "1720         cell             NN      1646  0.623039       112  0.223870  0.399169\n",
       "4263      rosette             NN       967  0.366026         1  0.001999  0.364027\n",
       "4814       double             RB       956  0.361862         3  0.005997  0.355866\n",
       "4681     globular             NN       905  0.342558         0  0.000000  0.342558\n",
       "2003     abnormal             JJ      1049  0.397064        28  0.055968  0.341097\n",
       "1865           wa             NN       886  0.335366         1  0.001999  0.333367\n",
       "1599       flower             NN       940  0.355806        14  0.027984  0.327822\n",
       "6866    flowering             VB      1031  0.390251        32  0.063963  0.326288\n",
       "4512        short             JJ      1504  0.569289       123  0.245857  0.323432\n",
       "921      compared             VB       882  0.333852         9  0.017990  0.315862\n",
       "3204      silique             NN       798  0.302056         0  0.000000  0.302056\n",
       "6871    sensitive             JJ       827  0.313033         6  0.011993  0.301040\n",
       "2620      visible             JJ       838  0.317197        13  0.025985  0.291212\n",
       "1655  development             NN       862  0.326282        19  0.037978  0.288304\n",
       "4402    hypocotyl             NN       752  0.284645         0  0.000000  0.284645"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What are the tokens more frequently used for Arabidopsis than maize descriptions in this dataset?\n",
    "table.sort_values(by=\"diff\", ascending=False, inplace=True)\n",
    "table.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>part_of_speech</th>\n",
       "      <th>ath_freq</th>\n",
       "      <th>ath_rate</th>\n",
       "      <th>zma_freq</th>\n",
       "      <th>zma_rate</th>\n",
       "      <th>diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3620</th>\n",
       "      <td>endosperm</td>\n",
       "      <td>NN</td>\n",
       "      <td>124</td>\n",
       "      <td>0.046936</td>\n",
       "      <td>1078</td>\n",
       "      <td>2.154750</td>\n",
       "      <td>-2.107814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6073</th>\n",
       "      <td>seedling</td>\n",
       "      <td>VB</td>\n",
       "      <td>1560</td>\n",
       "      <td>0.590486</td>\n",
       "      <td>1318</td>\n",
       "      <td>2.634472</td>\n",
       "      <td>-2.043986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3494</th>\n",
       "      <td>kernel</td>\n",
       "      <td>NN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>766</td>\n",
       "      <td>1.531112</td>\n",
       "      <td>-1.531112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>yellow</td>\n",
       "      <td>NN</td>\n",
       "      <td>304</td>\n",
       "      <td>0.115069</td>\n",
       "      <td>775</td>\n",
       "      <td>1.549102</td>\n",
       "      <td>-1.434032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1288</th>\n",
       "      <td>leaf</td>\n",
       "      <td>NN</td>\n",
       "      <td>3879</td>\n",
       "      <td>1.468267</td>\n",
       "      <td>1445</td>\n",
       "      <td>2.888325</td>\n",
       "      <td>-1.420058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004</th>\n",
       "      <td>green</td>\n",
       "      <td>JJ</td>\n",
       "      <td>884</td>\n",
       "      <td>0.334609</td>\n",
       "      <td>788</td>\n",
       "      <td>1.575086</td>\n",
       "      <td>-1.240478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4668</th>\n",
       "      <td>white</td>\n",
       "      <td>JJ</td>\n",
       "      <td>375</td>\n",
       "      <td>0.141944</td>\n",
       "      <td>642</td>\n",
       "      <td>1.283256</td>\n",
       "      <td>-1.141312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>866</th>\n",
       "      <td>albino</td>\n",
       "      <td>NN</td>\n",
       "      <td>222</td>\n",
       "      <td>0.084031</td>\n",
       "      <td>396</td>\n",
       "      <td>0.791541</td>\n",
       "      <td>-0.707510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6849</th>\n",
       "      <td>usually</td>\n",
       "      <td>RB</td>\n",
       "      <td>46</td>\n",
       "      <td>0.017412</td>\n",
       "      <td>353</td>\n",
       "      <td>0.705591</td>\n",
       "      <td>-0.688179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>782</th>\n",
       "      <td>color</td>\n",
       "      <td>NN</td>\n",
       "      <td>43</td>\n",
       "      <td>0.016276</td>\n",
       "      <td>330</td>\n",
       "      <td>0.659617</td>\n",
       "      <td>-0.643341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>674</th>\n",
       "      <td>tassel</td>\n",
       "      <td>NN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>310</td>\n",
       "      <td>0.619641</td>\n",
       "      <td>-0.619641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>922</th>\n",
       "      <td>ear</td>\n",
       "      <td>NN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>284</td>\n",
       "      <td>0.567671</td>\n",
       "      <td>-0.567671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1169</th>\n",
       "      <td>often</td>\n",
       "      <td>RB</td>\n",
       "      <td>149</td>\n",
       "      <td>0.056399</td>\n",
       "      <td>278</td>\n",
       "      <td>0.555678</td>\n",
       "      <td>-0.499279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3909</th>\n",
       "      <td>aleurone</td>\n",
       "      <td>NN</td>\n",
       "      <td>3</td>\n",
       "      <td>0.001136</td>\n",
       "      <td>248</td>\n",
       "      <td>0.495712</td>\n",
       "      <td>-0.494577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1993</th>\n",
       "      <td>opaque</td>\n",
       "      <td>NN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000379</td>\n",
       "      <td>244</td>\n",
       "      <td>0.487717</td>\n",
       "      <td>-0.487339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1658</th>\n",
       "      <td>class</td>\n",
       "      <td>NN</td>\n",
       "      <td>8</td>\n",
       "      <td>0.003028</td>\n",
       "      <td>240</td>\n",
       "      <td>0.479722</td>\n",
       "      <td>-0.476694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2244</th>\n",
       "      <td>tissue</td>\n",
       "      <td>NN</td>\n",
       "      <td>236</td>\n",
       "      <td>0.089330</td>\n",
       "      <td>259</td>\n",
       "      <td>0.517700</td>\n",
       "      <td>-0.428370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5121</th>\n",
       "      <td>small</td>\n",
       "      <td>JJ</td>\n",
       "      <td>670</td>\n",
       "      <td>0.253606</td>\n",
       "      <td>323</td>\n",
       "      <td>0.645626</td>\n",
       "      <td>-0.392019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2563</th>\n",
       "      <td>pale</td>\n",
       "      <td>NN</td>\n",
       "      <td>651</td>\n",
       "      <td>0.246414</td>\n",
       "      <td>318</td>\n",
       "      <td>0.635631</td>\n",
       "      <td>-0.389217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5821</th>\n",
       "      <td>vp</td>\n",
       "      <td>NN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>190</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.379780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3867</th>\n",
       "      <td>palegreen</td>\n",
       "      <td>NN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000379</td>\n",
       "      <td>171</td>\n",
       "      <td>0.341802</td>\n",
       "      <td>-0.341423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2481</th>\n",
       "      <td>general</td>\n",
       "      <td>JJ</td>\n",
       "      <td>13</td>\n",
       "      <td>0.004921</td>\n",
       "      <td>171</td>\n",
       "      <td>0.341802</td>\n",
       "      <td>-0.336881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>term</td>\n",
       "      <td>NN</td>\n",
       "      <td>22</td>\n",
       "      <td>0.008327</td>\n",
       "      <td>172</td>\n",
       "      <td>0.343801</td>\n",
       "      <td>-0.335473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1271</th>\n",
       "      <td>surface</td>\n",
       "      <td>NN</td>\n",
       "      <td>138</td>\n",
       "      <td>0.052235</td>\n",
       "      <td>190</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.327544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6341</th>\n",
       "      <td>appearance</td>\n",
       "      <td>NN</td>\n",
       "      <td>131</td>\n",
       "      <td>0.049586</td>\n",
       "      <td>188</td>\n",
       "      <td>0.375782</td>\n",
       "      <td>-0.326196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3136</th>\n",
       "      <td>texture</td>\n",
       "      <td>NN</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000757</td>\n",
       "      <td>163</td>\n",
       "      <td>0.325811</td>\n",
       "      <td>-0.325054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>otherwise</td>\n",
       "      <td>RB</td>\n",
       "      <td>10</td>\n",
       "      <td>0.003785</td>\n",
       "      <td>158</td>\n",
       "      <td>0.315817</td>\n",
       "      <td>-0.312032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>700</th>\n",
       "      <td>anther</td>\n",
       "      <td>NN</td>\n",
       "      <td>139</td>\n",
       "      <td>0.052614</td>\n",
       "      <td>167</td>\n",
       "      <td>0.333806</td>\n",
       "      <td>-0.281193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1963</th>\n",
       "      <td>pericarp</td>\n",
       "      <td>NN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>140</td>\n",
       "      <td>0.279838</td>\n",
       "      <td>-0.279838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>sometimes</td>\n",
       "      <td>RB</td>\n",
       "      <td>44</td>\n",
       "      <td>0.016655</td>\n",
       "      <td>148</td>\n",
       "      <td>0.295828</td>\n",
       "      <td>-0.279174</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           token part_of_speech  ath_freq  ath_rate  zma_freq  zma_rate      diff\n",
       "3620   endosperm             NN       124  0.046936      1078  2.154750 -2.107814\n",
       "6073    seedling             VB      1560  0.590486      1318  2.634472 -2.043986\n",
       "3494      kernel             NN         0  0.000000       766  1.531112 -1.531112\n",
       "133       yellow             NN       304  0.115069       775  1.549102 -1.434032\n",
       "1288        leaf             NN      3879  1.468267      1445  2.888325 -1.420058\n",
       "2004       green             JJ       884  0.334609       788  1.575086 -1.240478\n",
       "4668       white             JJ       375  0.141944       642  1.283256 -1.141312\n",
       "866       albino             NN       222  0.084031       396  0.791541 -0.707510\n",
       "6849     usually             RB        46  0.017412       353  0.705591 -0.688179\n",
       "782        color             NN        43  0.016276       330  0.659617 -0.643341\n",
       "674       tassel             NN         0  0.000000       310  0.619641 -0.619641\n",
       "922          ear             NN         0  0.000000       284  0.567671 -0.567671\n",
       "1169       often             RB       149  0.056399       278  0.555678 -0.499279\n",
       "3909    aleurone             NN         3  0.001136       248  0.495712 -0.494577\n",
       "1993      opaque             NN         1  0.000379       244  0.487717 -0.487339\n",
       "1658       class             NN         8  0.003028       240  0.479722 -0.476694\n",
       "2244      tissue             NN       236  0.089330       259  0.517700 -0.428370\n",
       "5121       small             JJ       670  0.253606       323  0.645626 -0.392019\n",
       "2563        pale             NN       651  0.246414       318  0.635631 -0.389217\n",
       "5821          vp             NN         0  0.000000       190  0.379780 -0.379780\n",
       "3867   palegreen             NN         1  0.000379       171  0.341802 -0.341423\n",
       "2481     general             JJ        13  0.004921       171  0.341802 -0.336881\n",
       "212         term             NN        22  0.008327       172  0.343801 -0.335473\n",
       "1271     surface             NN       138  0.052235       190  0.379780 -0.327544\n",
       "6341  appearance             NN       131  0.049586       188  0.375782 -0.326196\n",
       "3136     texture             NN         2  0.000757       163  0.325811 -0.325054\n",
       "15     otherwise             RB        10  0.003785       158  0.315817 -0.312032\n",
       "700       anther             NN       139  0.052614       167  0.333806 -0.281193\n",
       "1963    pericarp             NN         0  0.000000       140  0.279838 -0.279838\n",
       "349    sometimes             RB        44  0.016655       148  0.295828 -0.279174"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What are the tokens more frequently used for maize than Arabidopsis descriptions in this dataset?\n",
    "table.sort_values(by=\"diff\", ascending=True, inplace=True)\n",
    "table.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>part_of_speech</th>\n",
       "      <th>abs_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MD</td>\n",
       "      <td>0.059430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CD</td>\n",
       "      <td>0.027894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IN</td>\n",
       "      <td>0.026202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>JJ</td>\n",
       "      <td>0.023688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DT</td>\n",
       "      <td>0.019077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RB</td>\n",
       "      <td>0.016302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NN</td>\n",
       "      <td>0.014463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>VB</td>\n",
       "      <td>0.012131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>CC</td>\n",
       "      <td>0.007617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>WP</td>\n",
       "      <td>0.001620</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  part_of_speech  abs_diff\n",
       "0             MD  0.059430\n",
       "1             CD  0.027894\n",
       "2             IN  0.026202\n",
       "3             JJ  0.023688\n",
       "4             DT  0.019077\n",
       "5             RB  0.016302\n",
       "6             NN  0.014463\n",
       "7             VB  0.012131\n",
       "8             CC  0.007617\n",
       "9             WP  0.001620"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Is the mean absolute value of the rate differences different between the different parts of speech?\n",
    "table[\"abs_diff\"] = abs(table[\"diff\"])\n",
    "pos_table = table.groupby(\"part_of_speech\").mean()\n",
    "pos_table.sort_values(by=\"abs_diff\", inplace=True, ascending=False)\n",
    "pos_table = pos_table[[\"abs_diff\"]]\n",
    "pos_table.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7000, 8)\n",
      "(540, 8)\n",
      "(5352, 8)\n",
      "5892\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>part_of_speech</th>\n",
       "      <th>ath_freq</th>\n",
       "      <th>ath_rate</th>\n",
       "      <th>zma_freq</th>\n",
       "      <th>zma_rate</th>\n",
       "      <th>diff</th>\n",
       "      <th>abs_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>861</th>\n",
       "      <td>fmo</td>\n",
       "      <td>NN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000379</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000379</td>\n",
       "      <td>0.000379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6323</th>\n",
       "      <td>rastafari</td>\n",
       "      <td>NN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000379</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000379</td>\n",
       "      <td>0.000379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>853</th>\n",
       "      <td>reorientation</td>\n",
       "      <td>NN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000379</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000379</td>\n",
       "      <td>0.000379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>841</th>\n",
       "      <td>glycoprotein</td>\n",
       "      <td>NN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000379</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000379</td>\n",
       "      <td>0.000379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>443</th>\n",
       "      <td>undergone</td>\n",
       "      <td>NN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000379</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000379</td>\n",
       "      <td>0.000379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>839</th>\n",
       "      <td>thad</td>\n",
       "      <td>NN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000379</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000379</td>\n",
       "      <td>0.000379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>837</th>\n",
       "      <td>reside</td>\n",
       "      <td>NN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000379</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000379</td>\n",
       "      <td>0.000379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5449</th>\n",
       "      <td>coffee</td>\n",
       "      <td>NN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000379</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000379</td>\n",
       "      <td>0.000379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>850</th>\n",
       "      <td>wmv</td>\n",
       "      <td>NN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000379</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000379</td>\n",
       "      <td>0.000379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6321</th>\n",
       "      <td>vernalized</td>\n",
       "      <td>VB</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000379</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000379</td>\n",
       "      <td>0.000379</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              token part_of_speech  ath_freq  ath_rate  zma_freq  zma_rate      diff  abs_diff\n",
       "861             fmo             NN         1  0.000379         0       0.0  0.000379  0.000379\n",
       "6323      rastafari             NN         1  0.000379         0       0.0  0.000379  0.000379\n",
       "853   reorientation             NN         1  0.000379         0       0.0  0.000379  0.000379\n",
       "841    glycoprotein             NN         1  0.000379         0       0.0  0.000379  0.000379\n",
       "443       undergone             NN         1  0.000379         0       0.0  0.000379  0.000379\n",
       "839            thad             NN         1  0.000379         0       0.0  0.000379  0.000379\n",
       "837          reside             NN         1  0.000379         0       0.0  0.000379  0.000379\n",
       "5449         coffee             NN         1  0.000379         0       0.0  0.000379  0.000379\n",
       "850             wmv             NN         1  0.000379         0       0.0  0.000379  0.000379\n",
       "6321     vernalized             VB         1  0.000379         0       0.0  0.000379  0.000379"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(table.shape)\n",
    "zma_only = table[table[\"ath_rate\"]==0]\n",
    "ath_only = table[table[\"zma_rate\"]==0]\n",
    "print(zma_only.shape)\n",
    "print(ath_only.shape)\n",
    "print(ath_only.shape[0]+zma_only.shape[0])\n",
    "ath_only.head(10)\n",
    "# We need to create a mapping between stems and the words that were present for them.\n",
    "# This is because what we want is the stems that are exclusive to a species.\n",
    "# but then the words that are actually there for those stems, so that we can count their parts of speech."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
