{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading in data available from the Sol Genomics Network (SGN) database\n",
    "The purpose of this notebook is to read in and do a preliminary survey of the data related to text descriptions obtained from the Sol Genomics Network. The data was provided in the form of the input file by request, rather than obtained through an already available file from the database. The data needs to be organized and restructured into a standard format that will allow it to be easily combined with datasets from other resources.\n",
    "\n",
    "### Files read\n",
    "```\n",
    "phenologs-with-oats/data/gene_related_files/sgn/sgn_tomato_phenotyped_loci.txt\n",
    "```\n",
    "\n",
    "\n",
    "### Files created\n",
    "```\n",
    "phenologs-with-oats/data/reshaped_files/sly_phenotypes.csv\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "import sys\n",
    "import os\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "sys.path.append(\"../../oats\")\n",
    "from oats.utils.utils import to_abbreviation\n",
    "from oats.nlp.preprocess import concatenate_with_bar_delim\n",
    "from oats.nlp.preprocess import other_delim_to_bar_delim\n",
    "from oats.nlp.preprocess import remove_punctuation\n",
    "from oats.nlp.preprocess import remove_enclosing_brackets\n",
    "\n",
    "OUTPUT_DIR = \"../data/reshaped_files\"\n",
    "mpl.rcParams[\"figure.dpi\"] = 200\n",
    "warnings.simplefilter('ignore')\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File with genes and phenotype descriptions (sgn_tomato_phenotyped_loci.txt)\n",
    "Note that fillna is being used here to replace missing values with an empty string. This is done so that the missing string will be quantified when checking for the number of occurences of unique values from different columns, see the analysis below. However this is not necessary as a preprocessing step because when the data is read in and appended to a dataset object later, any missing values or empty strings will be handled at that step.\n",
    "\n",
    "There are several columns that contain information about gene names and accessions. We need to know what type of information is in each in order to know which should be retained in the dataset we are preparing. We are interested in both gene names that should map to a specific accession (like cyp716A12 or Medtr3g021350) as well as gene names that are enzyme descriptions (like Ubiquitin-Specific Protease) that could map to more than one gene in a particular species. Each type of information is valuable, but needs to be differentiated so that when comparing whether two rows are specifying the same gene, this is not confused with specifying two different genes that have the same function. In the case of this dataset, we only want to considered the locus names in a single column, the rest of the columns are more ambiguous and as long as all the mapping can be done with the locus names the other names can be ignored for downstream analysis.\n",
    "\n",
    "This section creates a set of columns that have standardized names and include data in a standardized format that other functions within the package expect. The species column contains strings which are KEGG abbreviations for particular species. The gene names column contains any strings we want to consider to be uniquely mapped to some particular gene."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"../data/gene_related_files/sgn/sgn_tomato_phenotyped_loci.txt\"\n",
    "df = pd.read_table(filename)\n",
    "df.fillna(\"\", inplace=True)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing rows that have missing inforrmation in the columns we want to keep.\n",
    "df = df[(df[\"locus\"] != \"\") & (df[\"allele_phenotype\"] != \"\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding out how many unique values there are for each column.\n",
    "unique_values = {col:len(pd.unique(df[col].values)) for col in df.columns}\n",
    "for k,v in unique_values.items():\n",
    "    print(\"{:24}{:8}\".format(k,v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting distributions of number of word and phrases in each description.\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "ax1.set_title(\"Phenotype Descriptions\")\n",
    "ax2.set_title(\"Phenotype Descriptions\")\n",
    "ax1.set_xlabel(\"Number of phrases\")\n",
    "ax2.set_xlabel(\"Number of words\")\n",
    "x1 = [len(sent_tokenize(x)) for x in df[\"allele_phenotype\"].values]\n",
    "x2 = [len(word_tokenize(x)) for x in df[\"allele_phenotype\"].values]\n",
    "ax1.hist(x1, bins=10, range=(0,10), density=False, alpha=0.8, histtype='stepfilled', color=\"black\", edgecolor='none')\n",
    "ax2.hist(x2, bins=25, range=(0,50), density=False, alpha=0.8, histtype='stepfilled', color=\"black\", edgecolor='none')\n",
    "fig.set_size_inches(15,4)\n",
    "fig.tight_layout()\n",
    "fig.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Organizing the desired information into a standard set of column headers.\n",
    "df[\"species\"] = \"sly\"\n",
    "df[\"description\"] = df[\"allele_phenotype\"]\n",
    "df[\"gene_names\"] = df[\"locus\"]\n",
    "df[\"term_ids\"] = \"\"\n",
    "df = df[[\"species\", \"gene_names\", \"description\", \"term_ids\"]]\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.join(OUTPUT_DIR,\"sly_phenotypes.csv\")\n",
    "df.to_csv(path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
