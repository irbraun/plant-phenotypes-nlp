{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making plots to illustrate the results of some queries with the web tool\n",
    "This notebook takes a file describing a list of genes with those genes species and identifying strings. It loads the dataset that is used by the search tool, finds out if those genes are in the dataset, and then subsets the set of genes to include just those. It then uses the descriptions of those genes to query the tool (using the script rather than the streamlit web app, but the results are identical), and keeps track of where other genes from the list fall in the resulting gene rankings. The output of the notebook is a summary of these results that specifies the mean and standard deviation of binned ranks for each search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warming up PyWSD (takes ~10 secs)... took 5.49912691116333 secs.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import math\n",
    "import sys\n",
    "import gensim\n",
    "import os\n",
    "import random\n",
    "import warnings\n",
    "from collections import defaultdict\n",
    "from nltk.corpus import brown\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.probability import FreqDist\n",
    "from gensim.parsing.preprocessing import strip_non_alphanum, stem_text, preprocess_string, remove_stopwords\n",
    "from gensim.utils import simple_preprocess\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from statsmodels.sandbox.stats.multicomp import multipletests\n",
    "from itertools import product\n",
    "\n",
    "sys.path.append(\"../../oats\")\n",
    "sys.path.append(\"../../oats\")\n",
    "from oats.utils.utils import save_to_pickle, load_from_pickle, flatten, to_hms\n",
    "from oats.utils.utils import function_wrapper_with_duration, remove_duplicates_retain_order\n",
    "from oats.biology.dataset import Dataset\n",
    "from oats.biology.groupings import Groupings\n",
    "from oats.biology.relationships import ProteinInteractions, AnyInteractions\n",
    "from oats.annotation.ontology import Ontology\n",
    "from oats.annotation.annotation import annotate_using_noble_coder, term_enrichment\n",
    "from oats.distances import pairwise as pw\n",
    "from oats.nlp.vocabulary import get_overrepresented_tokens, get_vocab_from_tokens\n",
    "from oats.nlp.vocabulary import reduce_vocab_connected_components, reduce_vocab_linares_pontes, token_enrichment\n",
    "\n",
    "warnings.simplefilter('ignore')\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('brown', quiet=True)\n",
    "nltk.download('averaged_perceptron_tagger', quiet=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>species</th>\n",
       "      <th>unique_gene_identifiers</th>\n",
       "      <th>unique_descriptions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ath</td>\n",
       "      <td>5850</td>\n",
       "      <td>3493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gmx</td>\n",
       "      <td>30</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mtr</td>\n",
       "      <td>37</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>osa</td>\n",
       "      <td>92</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sly</td>\n",
       "      <td>69</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>zma</td>\n",
       "      <td>1405</td>\n",
       "      <td>810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>total</td>\n",
       "      <td>7483</td>\n",
       "      <td>4516</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  species  unique_gene_identifiers  unique_descriptions\n",
       "0     ath                     5850                 3493\n",
       "1     gmx                       30                   23\n",
       "2     mtr                       37                   36\n",
       "3     osa                       92                   85\n",
       "4     sly                       69                   69\n",
       "5     zma                     1405                  810\n",
       "6   total                     7483                 4516"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Paths to the files that are used for this notebook.\n",
    "dataset_path = \"../../quoats/data/genes_texts_annots.csv\"\n",
    "dataset = Dataset(dataset_path, keep_ids=True)\n",
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Anthocyanin biosynthesis genes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Previously out of this list we had 10 of 16 maize genes in the dataset and 16 of 18 Aribidopsis genes. Now we have 13 of 16 maize genes and 18 of 18 Arabidopsis genes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = dataset.get_species_to_name_to_ids_dictionary(include_synonyms=False, lowercase=True)\n",
    "genes = pd.read_csv(\"anthocyanin_biosynthesis_genes.csv\")\n",
    "genes[\"id\"] = genes.apply(lambda x: mapping[x[\"species_code\"]].get(x[\"identifier\"].strip().lower(),-1), axis=1)\n",
    "genes[genes[\"id\"]!=-1][\"id\"] = genes[genes[\"id\"]!=-1][\"id\"].map(lambda x: x[0])\n",
    "genes[\"in_current_dataset\"] = genes[\"id\"].map(lambda x: x!=-1)\n",
    "genes\n",
    "\n",
    "# Looking just at the ones that are in the current dataset.\n",
    "genes = genes[genes[\"in_current_dataset\"]]\n",
    "genes[\"id\"] = genes[\"id\"].map(lambda x: x[0])\n",
    "genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grabbing the texts dictionary from the dataset that we can use to grab the descriptions to query.\n",
    "texts = dataset.get_description_dictionary()\n",
    "texts[2617]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare dictionaries to hold the resulting arrays.\n",
    "resulting_bin_arrays = defaultdict(dict)\n",
    "resulting_bin_arrays[\"zma\"][\"zma\"] = []\n",
    "resulting_bin_arrays[\"ath\"][\"ath\"] = []\n",
    "resulting_bin_arrays[\"zma\"][\"ath\"] = []\n",
    "resulting_bin_arrays[\"ath\"][\"zma\"] = []\n",
    "resulting_bin_arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Searching within the same species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The searches within the same species.\n",
    "rank_for_not_found = 100\n",
    "bins =[0,11,21,31,41,51,rank_for_not_found]\n",
    "bin_names = [10,20,30,40,50,rank_for_not_found]\n",
    "assert len(bin_names) == len(bins)-1\n",
    "\n",
    "ctr = 0\n",
    "for gene in genes.itertuples():\n",
    "    \n",
    "    ctr = ctr+1\n",
    "    limit = 50\n",
    "    species = gene[1]\n",
    "    species_code = gene[2]\n",
    "    identifier = gene[3]\n",
    "    gene_id = gene[5]\n",
    "    text = texts[gene_id]\n",
    "    \n",
    "    # Because these are being passed as strings to the command line, quotes need to be removed now,\n",
    "    # instead of waiting for them to be removed as a preprocessing step of the search strings in the streamlit script.\n",
    "    text = text.replace(\"'\",\"\")\n",
    "    text = text.replace('\"','')\n",
    "    \n",
    "    path = \"/Users/irbraun/phenologs-with-oats/quoats/outputs_within_anthocyanin/output_{}.tsv\".format(ctr)\n",
    "    os.chdir('/Users/irbraun/quoats')\n",
    "    os.system(\"python main.py -s {} -t identifiers -q '{}:{}' -l {} -o {} -r 0.000 -a TFIDF\".format(species,species,identifier,limit,path))\n",
    "    time.sleep(4)\n",
    "    df = pd.read_csv(path, sep='\\t')\n",
    "    df = df[[\"Rank\",\"Internal ID\"]]\n",
    "    df = df.drop_duplicates()\n",
    "    id_to_rank = dict(zip(df[\"Internal ID\"].values,df[\"Rank\"].values))\n",
    "    assert rank_for_not_found > limit\n",
    "    \n",
    "    # For within the same species, get rid of the identical gene (always rank 1).\n",
    "    ids_of_interest = [i for i in genes[genes[\"species\"]==species][\"id\"].values if i != gene_id]\n",
    "    ranks = [id_to_rank.get(i, rank_for_not_found) for i in ids_of_interest]\n",
    "    resulting_bin_arrays[species_code][species_code].append(np.histogram(ranks, bins=bins)[0])\n",
    "    \n",
    "    #print(np.array( resulting_bin_arrays[species_code][species_code]))\n",
    "    print(ranks)\n",
    "    print(\"done with {} queries\".format(ctr))\n",
    "print('done with all queries')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Searching across different species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The searches across different species.\n",
    "rank_for_not_found = 100\n",
    "bins =[0,11,21,31,41,51,rank_for_not_found]\n",
    "bin_names = [10,20,30,40,50,rank_for_not_found]\n",
    "assert len(bin_names) == len(bins)-1\n",
    "\n",
    "ctr = 0\n",
    "for gene in genes.itertuples():\n",
    "    \n",
    "    ctr = ctr+1\n",
    "    limit = 50\n",
    "    from_species = gene[1]\n",
    "    from_species_code = gene[2]\n",
    "    identifier = gene[3]\n",
    "    gene_id = gene[5]\n",
    "    text = texts[gene_id]\n",
    "    \n",
    "    \n",
    "    # Do the switch to make the species for the query and IDs of interest the opposite one.\n",
    "    to_species = {\"Arabidopsis\":\"Maize\",\"Maize\":\"Arabidopsis\"}[from_species]\n",
    "    to_species_code = {\"ath\":\"zma\",\"zma\":\"ath\"}[from_species_code]\n",
    "    \n",
    "    # Because these are being passed as strings to the command line, quotes need to be removed now,\n",
    "    # instead of waiting for them to be removed as a preprocessing step of the search strings in the streamlit script.\n",
    "    text = text.replace(\"'\",\"\")\n",
    "    text = text.replace('\"','')\n",
    "    \n",
    "    \n",
    "    path = \"/Users/irbraun/phenologs-with-oats/quoats/outputs_across_anthocyanin/output_{}.tsv\".format(ctr)\n",
    "    os.chdir('/Users/irbraun/quoats')\n",
    "    os.system(\"python main.py -s {} -t identifiers -q '{}:{}' -l {} -o {} -r 0.000 -a TFIDF\".format(to_species,from_species,identifier,limit,path))\n",
    "    time.sleep(4)\n",
    "    df = pd.read_csv(path, sep='\\t')\n",
    "    df = df[[\"Rank\",\"Internal ID\"]]\n",
    "    df = df.drop_duplicates()\n",
    "    id_to_rank = dict(zip(df[\"Internal ID\"].values,df[\"Rank\"].values))\n",
    "    assert rank_for_not_found > limit\n",
    "    \n",
    "    # For within the same species, get rid of the identical gene (always rank 1).\n",
    "    ids_of_interest = [i for i in genes[genes[\"species\"]==to_species][\"id\"].values if i != gene_id]\n",
    "    ranks = [id_to_rank.get(i, rank_for_not_found) for i in ids_of_interest]\n",
    "    resulting_bin_arrays[from_species_code][to_species_code].append(np.histogram(ranks, bins=bins)[0])\n",
    "    \n",
    "    #print(np.array( resulting_bin_arrays[species_code][species_code]))\n",
    "    print(ranks)\n",
    "    print(\"done with {} queries\".format(ctr))\n",
    "print('done with all queries')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the output dataframe with the means and standard deviation for each bin and direction.\n",
    "output_rows = []\n",
    "for (s1,s2) in product([\"ath\",\"zma\"],[\"ath\",\"zma\"]):\n",
    "    means = np.mean(np.array(resulting_bin_arrays[s1][s2]),axis=0)\n",
    "    std_devs = np.std(np.array(resulting_bin_arrays[s1][s2]),axis=0)\n",
    "    for i in range(len(bin_names)):\n",
    "        output_rows.append([s1, s2, bin_names[i], means[i], std_devs[i]])    \n",
    "names = [\"from\",\"to\",\"bin\",\"mean\",\"sd\"]    \n",
    "output_df = pd.DataFrame(output_rows,columns=names)\n",
    "output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/Users/irbraun/phenologs-with-oats/quoats')\n",
    "output_path = \"plots/anthocyanin_plot_data.csv\"\n",
    "output_df.to_csv(output_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autophagy genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>species</th>\n",
       "      <th>species_code</th>\n",
       "      <th>name</th>\n",
       "      <th>identifier</th>\n",
       "      <th>id</th>\n",
       "      <th>in_current_dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Arabidopsis</td>\n",
       "      <td>ath</td>\n",
       "      <td>ATG2</td>\n",
       "      <td>AT3G19190</td>\n",
       "      <td>23</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arabidopsis</td>\n",
       "      <td>ath</td>\n",
       "      <td>ATG4</td>\n",
       "      <td>AT2G44140</td>\n",
       "      <td>4688</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Arabidopsis</td>\n",
       "      <td>ath</td>\n",
       "      <td>ATG5</td>\n",
       "      <td>AT5G17290</td>\n",
       "      <td>462</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Arabidopsis</td>\n",
       "      <td>ath</td>\n",
       "      <td>ATG6</td>\n",
       "      <td>AT3G61710</td>\n",
       "      <td>297</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Arabidopsis</td>\n",
       "      <td>ath</td>\n",
       "      <td>ATG7</td>\n",
       "      <td>AT5G45900</td>\n",
       "      <td>5585</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Arabidopsis</td>\n",
       "      <td>ath</td>\n",
       "      <td>ATG9</td>\n",
       "      <td>AT2G31260</td>\n",
       "      <td>533</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Arabidopsis</td>\n",
       "      <td>ath</td>\n",
       "      <td>ATG10</td>\n",
       "      <td>AT3G07525</td>\n",
       "      <td>2377</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Arabidopsis</td>\n",
       "      <td>ath</td>\n",
       "      <td>ATG11</td>\n",
       "      <td>AT4G30790</td>\n",
       "      <td>5272</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Arabidopsis</td>\n",
       "      <td>ath</td>\n",
       "      <td>ATG12</td>\n",
       "      <td>AT1G54210</td>\n",
       "      <td>4274</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Arabidopsis</td>\n",
       "      <td>ath</td>\n",
       "      <td>ATG13</td>\n",
       "      <td>AT3G49590</td>\n",
       "      <td>4968</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        species species_code   name identifier    id  in_current_dataset\n",
       "1   Arabidopsis          ath   ATG2  AT3G19190    23                True\n",
       "3   Arabidopsis          ath   ATG4  AT2G44140  4688                True\n",
       "4   Arabidopsis          ath   ATG5  AT5G17290   462                True\n",
       "5   Arabidopsis          ath   ATG6  AT3G61710   297                True\n",
       "6   Arabidopsis          ath   ATG7  AT5G45900  5585                True\n",
       "8   Arabidopsis          ath   ATG9  AT2G31260   533                True\n",
       "9   Arabidopsis          ath  ATG10  AT3G07525  2377                True\n",
       "10  Arabidopsis          ath  ATG11  AT4G30790  5272                True\n",
       "11  Arabidopsis          ath  ATG12  AT1G54210  4274                True\n",
       "12  Arabidopsis          ath  ATG13  AT3G49590  4968                True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir('/Users/irbraun/phenologs-with-oats/quoats')\n",
    "mapping = dataset.get_species_to_name_to_ids_dictionary(include_synonyms=False, lowercase=True)\n",
    "genes = pd.read_csv(\"autophagy_core_genes.csv\")\n",
    "genes[\"id\"] = genes.apply(lambda x: mapping[x[\"species_code\"]].get(x[\"identifier\"].strip().lower(),-1), axis=1)\n",
    "genes[genes[\"id\"]!=-1][\"id\"] = genes[genes[\"id\"]!=-1][\"id\"].map(lambda x: x[0])\n",
    "genes[\"in_current_dataset\"] = genes[\"id\"].map(lambda x: x!=-1)\n",
    "genes\n",
    "\n",
    "# Looking just at the ones that are in the current dataset.\n",
    "genes = genes[genes[\"in_current_dataset\"]]\n",
    "genes[\"id\"] = genes[\"id\"].map(lambda x: x[0])\n",
    "genes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12 out of the 16 core autophagy genes from the list are present in the dataset, see the core genes file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Small plants and premature senescence under normal soil-grown conditions. Hypersensitivity to N and fixed-C deprivation.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grabbing the texts dictionary from the dataset that we can use to grab the descriptions to query.\n",
    "texts = dataset.get_description_dictionary()\n",
    "texts[4688]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(dict, {'ath': {'ath': []}})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prepare dictionaries to hold the resulting arrays.\n",
    "resulting_bin_arrays = defaultdict(dict)\n",
    "resulting_bin_arrays[\"ath\"][\"ath\"] = []\n",
    "resulting_bin_arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100, 100, 100, 100, 100, 100, 100, 100, 100]\n",
      "done with 1 queries\n",
      "[100, 100, 100, 100, 100, 100, 100, 100, 100]\n",
      "done with 2 queries\n",
      "[100, 100, 100, 100, 100, 13, 100, 100, 100]\n",
      "done with 3 queries\n",
      "[100, 4, 10, 100, 100, 9, 6, 5, 7]\n",
      "done with 5 queries\n",
      "[100, 100, 100, 100, 100, 9, 100, 100, 100]\n",
      "done with 6 queries\n",
      "[100, 100, 18, 100, 100, 100, 100, 100, 100]\n",
      "done with 7 queries\n",
      "[29, 4, 23, 100, 8, 100, 19, 5, 6]\n",
      "done with 8 queries\n",
      "[100, 5, 12, 100, 8, 100, 13, 7, 6]\n",
      "done with 10 queries\n",
      "done with all queries\n"
     ]
    }
   ],
   "source": [
    "# The searches within the same species.\n",
    "rank_for_not_found = 100\n",
    "bins =[0,11,21,31,41,51,rank_for_not_found]\n",
    "bin_names = [10,20,30,40,50,rank_for_not_found]\n",
    "assert len(bin_names) == len(bins)-1\n",
    "\n",
    "ctr = 0\n",
    "for gene in genes.itertuples():\n",
    "    \n",
    "    ctr = ctr+1\n",
    "    limit = 50\n",
    "    species = gene[1]\n",
    "    species_code = gene[2]\n",
    "    identifier = gene[3]\n",
    "    gene_id = gene[5]\n",
    "    text = texts[gene_id]\n",
    "    \n",
    "    # Because these are being passed as strings to the command line, quotes need to be removed now,\n",
    "    # instead of waiting for them to be removed as a preprocessing step of the search strings in the streamlit script.\n",
    "    text = text.replace(\"'\",\"\")\n",
    "    text = text.replace('\"','')\n",
    "    \n",
    "    \n",
    "    \n",
    "    path = \"/Users/irbraun/phenologs-with-oats/quoats/outputs_within_autophagy/output_{}.tsv\".format(ctr)\n",
    "    os.chdir('/Users/irbraun/quoats')\n",
    "    os.system(\"python main.py -s {} -t identifiers -q '{}:{}' -l {} -o {} -r 0.000 -a tfidf\".format(species,species,identifier,limit,path))\n",
    "    time.sleep(4)\n",
    "    if os.path.exists(path):\n",
    "        df = pd.read_csv(path, sep='\\t')\n",
    "        df = df[[\"Rank\",\"Internal ID\"]]\n",
    "        df = df.drop_duplicates()\n",
    "        id_to_rank = dict(zip(df[\"Internal ID\"].values,df[\"Rank\"].values))\n",
    "        assert rank_for_not_found > limit\n",
    "\n",
    "\n",
    "        # For within the same species, get rid of the identical gene (always rank 1).\n",
    "        ids_of_interest = [i for i in genes[genes[\"species\"]==species][\"id\"].values if i != gene_id]\n",
    "        ranks = [id_to_rank.get(i, rank_for_not_found) for i in ids_of_interest]\n",
    "        resulting_bin_arrays[species_code][species_code].append(np.histogram(ranks, bins=bins)[0])\n",
    "\n",
    "        print(ranks)\n",
    "        print(\"done with {} queries\".format(ctr))\n",
    "print('done with all queries')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>from</th>\n",
       "      <th>to</th>\n",
       "      <th>bin</th>\n",
       "      <th>mean</th>\n",
       "      <th>sd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ath</td>\n",
       "      <td>ath</td>\n",
       "      <td>10</td>\n",
       "      <td>1.363636</td>\n",
       "      <td>2.100767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ath</td>\n",
       "      <td>ath</td>\n",
       "      <td>20</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.655555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ath</td>\n",
       "      <td>ath</td>\n",
       "      <td>30</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.574960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ath</td>\n",
       "      <td>ath</td>\n",
       "      <td>40</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ath</td>\n",
       "      <td>ath</td>\n",
       "      <td>50</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ath</td>\n",
       "      <td>ath</td>\n",
       "      <td>100</td>\n",
       "      <td>6.909091</td>\n",
       "      <td>2.644189</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  from   to  bin      mean        sd\n",
       "0  ath  ath   10  1.363636  2.100767\n",
       "1  ath  ath   20  0.545455  0.655555\n",
       "2  ath  ath   30  0.181818  0.574960\n",
       "3  ath  ath   40  0.000000  0.000000\n",
       "4  ath  ath   50  0.000000  0.000000\n",
       "5  ath  ath  100  6.909091  2.644189"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the output dataframe with the means and standard deviation for each bin and direction.\n",
    "output_rows = []\n",
    "s1 = \"ath\"\n",
    "s2 = \"ath\"\n",
    "means = np.mean(np.array(resulting_bin_arrays[s1][s2]),axis=0)\n",
    "std_devs = np.std(np.array(resulting_bin_arrays[s1][s2]),axis=0)\n",
    "for i in range(len(bin_names)):\n",
    "    output_rows.append([s1, s2, bin_names[i], means[i], std_devs[i]])    \n",
    "names = [\"from\",\"to\",\"bin\",\"mean\",\"sd\"]    \n",
    "output_df = pd.DataFrame(output_rows,columns=names)\n",
    "output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/Users/irbraun/phenologs-with-oats/quoats')\n",
    "output_path = \"plots/autophagy_plot_data.csv\"\n",
    "output_df.to_csv(output_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
